[{"path":"index.html","id":"introduction-and-welcome","chapter":"Introduction and Welcome!","heading":"Introduction and Welcome!","text":"main course notes CSDE 502 Winter 2022. contain link lecture notes, code examples, exercises, assignments. review course notes lecture. Assignment answer keys provided Canvas site, accessible currently enrolled CSDE 502 students.","code":""},{"path":"index.html","id":"about-this-course","chapter":"Introduction and Welcome!","heading":"About this course","text":"Course listing syllabusLinks course listing page official course syllabus :Course description: CSDE 502 ProseminarEntry UW course catalog: Ctr Stdies Demography EcologyThe course syllabus available PDF: files/csde502_syllabus_2022.pdf DOCX: files/csde502_syllabus_2022.docxThis required course students wishing obtain Demographic Methods Graduate Certificate CSDE. However, open interested students.Scope: course meant fill perceived curriculum gap methods courses emphasize study design statistics courses teach statistical analysis. focuses applied methods data preparation introduce following topics: data management documentation, data cleaning variable creation, summarizing variables, working demographic data, reproducibility. short, course teaches introductory “data wrangling” focused primarily demographic analysis applications.CSDE 502 tightly paired SOC/CSSS/CSDE 533 (Research Methods Demography) (“CSDE 533”). Expect see cross-references notes notes CSDE 533 vice versa. Techniques introduced course applied CSDE 533. analytic topics introduced CSDE 533 covered depth, explanation data processing notes.Objectives: Upon completion, familiar range data processing approaches quantitative demographic analysis. skills support understanding use concepts tools demography introduced CSDE 533.Instructor: Phil Hurvitz, phurvitz@uw.edu\nOffice hours: appointment; see calendar suggest times meet.","code":""},{"path":"index.html","id":"course-logistics","chapter":"Introduction and Welcome!","heading":"Course logistics","text":"Class meetings happen initially Zoom. Zoom link course https://washington.zoom.us/j/97609440755.Hybrid -person/Zoom meetings start Feb 4, 2022 Communications B027.Friday 10:30-12:20\nPlease come class promptly scheduled time. 10-minute break halfway class session.course Canvas site https://canvas.uw.edu/courses/1515226, used collection assignments distribution graded assignments. site may also used distribution data sets used course.Correspondence among instructor students use class e-mail list, CSDE 502 Winter 2022. List archives available CSDE 502 Winter 2022 Archives.general, please send messages want entire class see list. message instructor don’t want others see, just send message directly instructor. answer valuable rest class, answer posted class e-mail list identification removed message question appear anonymous.","code":""},{"path":"index.html","id":"class-location","chapter":"Introduction and Welcome!","heading":"Class location","text":"Class meetings happen initially Zoom. Zoom link course https://washington.zoom.us/j/97609440755.Hybrid -person/Zoom meetings start Feb 4, 2022 Communications B027.","code":""},{"path":"index.html","id":"course-days-and-times","chapter":"Introduction and Welcome!","heading":"Course days and times","text":"Friday 10:30-12:20\nPlease come class promptly scheduled time. 10-minute break halfway class session.","code":""},{"path":"index.html","id":"canvas-site","chapter":"Introduction and Welcome!","heading":"Canvas site","text":"course Canvas site https://canvas.uw.edu/courses/1515226, used collection assignments distribution graded assignments. site may also used distribution data sets used course.","code":""},{"path":"index.html","id":"class-e-mail-list","chapter":"Introduction and Welcome!","heading":"Class e-mail list","text":"Correspondence among instructor students use class e-mail list, CSDE 502 Winter 2022. List archives available CSDE 502 Winter 2022 Archives.general, please send messages want entire class see list. message instructor don’t want others see, just send message directly instructor. answer valuable rest class, answer posted class e-mail list identification removed message question appear anonymous.","code":""},{"path":"index.html","id":"class-format","chapter":"Introduction and Welcome!","heading":"Class format","text":"Default class-time agenda:Address outstanding issues previous sessions assignments (~10 minutes)brief lecture introduce topics day (~5 minutes)hands-instructional session (~75 minutes)Overview/clarification assignment (~10 minutes)","code":""},{"path":"index.html","id":"computing","chapter":"Introduction and Welcome!","heading":"Computing","text":"assignments R. Use Internet-connected computer provisioned latest versions R,1 RStudio Desktop, latest versions number R packages.computing course optimally done CSDE Terminal Servers (TS). students already TS access (e.g., CSDE trainees) able use existing TS1, TS2, TS3 accounts, encouraged use TS4 course using environment. recent student CSDE computing accounts general UW student population use TS4 (csde-ts4.csde.washington.edu).students computers capable running R handling relatively large data sets. However, using common computing environment help us avoid problems associated running code different machines different operating systems, processors, RAM, graphics cards, R versions, etc. aid troubleshooting problems arise. may use computer lessons, limited time available problems arise due computer’s unique environment addressed quickly.order get access CSDE Terminal Servers, see CSDE Computing Accounts. students UW pay Student Technology Fee legible obtain CSDE computing accounts.information CSDE Terminal Servers, see Choosing Terminal Server. instructions connecting Terminal Server, see Computing tutorials.order make remote connections TS4, need remote desktop protocol (RDP) client. Windows built-“Remote Desktop” application. available Macs Apple Store. Windows users may also want use mRemoteNG, find bit full-featured built-Windows application. example, mRemoteNG can window size, whereas Windows RDP application fixed size must specified time connection. Linux users can use Remmina.addition RDP client, order access CSDE’s computing resources -campus locations, necessary install enable Husky OnNet, UW virtual private network (VPN) client. Instructions available Download use Husky OnNetComputing resource linksCSDE Computing ResourcesRStudio Education Beginners course","code":""},{"path":"index.html","id":"assignments-and-grading","chapter":"Introduction and Welcome!","heading":"Assignments and grading","text":"week assignment made available 12:00 day class meetings. assignments designed allow students practice skills introduced class sessions. Assignments due 09:00 Friday week following assignment distributed; answer keys posted time. answer keys posted due date/time, late work reviewed without prior arrangement instructor. Assignments submitted using Canvas site; send assignments instructor via e-mail.Assignments reviewed thoroughly returned relevant mark-, corrections, suggestions, etc. returned via course Canvas site.course graded credit/credit. Students complete much assignments can within reasonable amount time. general, courses require two hours homework every hour class, expect spend least 4 hours assignments outside class time.","code":""},{"path":"index.html","id":"course-policies","chapter":"Introduction and Welcome!","heading":"Course policies","text":"Student conduct: “Students University Washington expected maintain certain standard conduct responsible members community. Student Conduct Code defines prohibited conduct describes University holds students accountable pursue academic goals.” Prohibited academic conduct includes cheating, falsification, plagiarism. Evidence academic misconduct referred relevant UW conduct office.encouraged work assignments students, work turn must best effort.UW Libraries Plagiarism Awareness guideA link guide :UW Libraries Plagiarism Awareness guideAccommodation: experience class important . already established accommodations Disability Resources Students (DRS), please communicate approved accommodations earliest convenience can discuss needs course. website DRS provides resources students faculty making accommodations.Washington state law requires UW develop policy accommodation student absences significant hardship due reasons faith conscience, organized religious activities. UW’s policy, including information request accommodation, available Religious Accommodations Policy. Accommodations must requested within first two weeks course using Religious Accommodations Request form.Accommodation resource linksDisability Resources StudentsReligious Accommodations PolicyReligious Accommodations Request formDiversity inclusion: “University Washington, diversity integral excellence. value honor diverse experiences perspectives, strive create welcoming respectful learning environments, promote access, opportunity justice .”SafeCampus: Preventing violence shared responsibility everyone UW plays part. experience harassment studies, please report SafeCampus website (anonymous reports possible). SafeCampus provides information counseling safety resources, University policies, violence reporting requirements help us maintain safe personal, work learning environment.SafeCampus websiteA link SafeCampus program :SafeCampus website","code":""},{"path":"index.html","id":"course-calendar","chapter":"Introduction and Welcome!","heading":"Course calendar","text":"Week 1TopicsCourse introductionGetting started CSDE terminal server 4Introduction R/RStudio/RMarkdownR data typesR data structuresR pipes (magrittr. tidyverse, native pipes)Data manipulation tidyverseEmployee turnover data\nBabushkin data\nKaggle documentation Babuskin data\nBen’s attrition rate code\nBabushkin dataKaggle documentation Babuskin dataBen’s attrition rate codeWeek 2TopicsRmarkdown\nCode blocks R Markdown\nGraphs R Markdown\nTables R Markdown\nPretty printouts life tables flextable DT\n\nEquations R Markdown\nHTML output R Markdown\nCode blocks R MarkdownGraphs R MarkdownTables R Markdown\nPretty printouts life tables flextable DT\nPretty printouts life tables flextable DTEquations R MarkdownHTML output R MarkdownKeyring: securely store secretsData:\nHuman Mortality Database\nHuman Fertility Database\nHuman Mortality DatabaseHuman Fertility DatabaseWeek 3Topics:tidycensus: Load US Census Boundary Attribute Data ‘tidyverse’ ‘sf’-Ready Data Framesidbr: R Interface US Census Bureau International Data Base APIsf: Simple Features R: Simple Features (GIS) Rleaflet: Create Interactive Web Maps JavaScript ‘Leaflet’ Librarymapview: Interactive Viewing Spatial Data RData:\nAccessing Human Mortality Database life tables using HMDHFDplus\nAccessing Human Mortality Database life tables using HMDHFDplusWeek 4Topics:R environmentsR functionsSampling RRevisiting Ben’s code reading HMD HFD datademogR: Analysis Age-Structured Demographic Modelsdemography: Forecasting Mortality, Fertility, Migration Population Data; R intro demography package)Week 5Topics:Git: file versioning code repositoryWeek 6Topics:Reading labelled dataMetadata data setsCcmpp: Cohort Component Method Population ProjectionData:\nAdd Health public-use data\nAdd Health public-use dataWeek 7Topics:Creating value labelsTabulation (summarizing data)Week 8Topics:Scale scoring variablesReordering variable valuesWeek 9Topics:Miscellaneous data processingWeek 10Topics:Miscellaneous data processing, continued","code":""},{"path":"index.html","id":"about-this-web-site","chapter":"Introduction and Welcome!","heading":"About this web site","text":"web site built R using Rmarkdown bookdown bs4_book template, uses Bootstrap framework. One unfortunate side effects format captions placed table figure!pages book section bottom including link source file printed source code page.Rendered 2022-03-04 00:41:57","code":""},{"path":"index.html","id":"source-code","chapter":"Introduction and Welcome!","heading":"0.1 Source code","text":"File H:/csde502-winter-2022-main/index.Rmd.","code":""},{"path":"index.html","id":"r-code-used-in-this-document","chapter":"Introduction and Welcome!","heading":"0.1.1 R code used in this document","text":"","code":"\nlibrary(dplyr)\nlibrary(emo)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(scales)\nlibrary(tibble)\n\nknitr::opts_chunk$set(echo = FALSE, cache = TRUE)\n\nyear <- Sys.Date() %>% format(\"%Y\")\nsyllabus <- paste0(\"files/csde502_syllabus_\", year, \".pdf\")\nsyllabusdocx <- paste0(\"files/csde502_syllabus_\", year, \".docx\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"index.html","id":"complete-rmd-code","chapter":"Introduction and Welcome!","heading":"0.1.2 Complete Rmd code","text":"","code":"--- \ntitle: \"UW CSDE 502 A Course Notes\"\nauthor: \"Phil Hurvitz\"\ndate: '`r format(Sys.time(), \"%Y-%m-%d %H:%M\")`'\nsite: bookdown::bookdown_site\ndescription: \"These are the course notes for Proseminar Winter 2022 (CSDE 502 A) at the University of Washington.\"\n\nbibliography: [book.bib, packages.bib]\nbiblio-style: apalike\ncsl: chicago-fullnote-bibliography.csl\nsuppress-bibliography: true\n---\n\n```{r setup, warning=FALSE, message=FALSE, echo=FALSE}\nlibrary(dplyr)\nlibrary(emo)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(scales)\nlibrary(tibble)\n\nknitr::opts_chunk$set(echo = FALSE, cache = TRUE)\n\nyear <- Sys.Date() %>% format(\"%Y\")\nsyllabus <- paste0(\"files/csde502_syllabus_\", year, \".pdf\")\nsyllabusdocx <- paste0(\"files/csde502_syllabus_\", year, \".docx\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\n\n# Introduction and Welcome! {.unnumbered}\n\nThis is the main course notes for CSDE 502 for Winter 2022. It will contain or link to all lecture notes, code examples, exercises, and assignments. We will review these course notes during lecture. Assignment answer keys will be provided on the Canvas site, accessible only to currently enrolled CSDE 502 students.\n\n## About this course {.unnumbered}\n\n:::{.rmdnote}\n**Course listing and syllabus**\n\nLinks to the course listing page and official course syllabus are below:\n\n* Course description: [CSDE 502 Proseminar](https://csde.washington.edu/training/demographic-certificate/courses/csde-502/a)\n* Entry in the UW course catalog: [Ctr for Stdies in Demography and Ecology](https://www.washington.edu/students/crscat/csde.html)\n* The course syllabus is available as a PDF: [`r syllabus`](`r syllabus`) or DOCX: [`r syllabusdocx`](`r syllabusdocx`)\n:::\n\nThis is a required course for students wishing to obtain a [Demographic Methods Graduate Certificate from CSDE](https://csde.washington.edu/training/demographic-certificate/). However, it is open to all interested students.\n\n**Scope:** This course is meant to fill a perceived curriculum gap between methods courses that emphasize study design and statistics courses that teach statistical analysis. It focuses on applied methods for data preparation and will introduce the following topics: data management and documentation, data cleaning and variable creation, summarizing variables, working with demographic data, and reproducibility. In short, this course teaches introductory â€œdata wranglingâ€ focused primarily on demographic analysis applications. \n\n\nCSDE 502 is tightly paired with [SOC/CSSS/CSDE 533 A (Research Methods in Demography)](https://hanowell.github.io/uwsoc533a/index.html) (\"CSDE 533\"). Expect to see cross-references in these notes to the notes for CSDE 533 and vice versa. Techniques introduced in this course will be applied in CSDE 533. Some analytic topics introduced in CSDE 533 will be covered in more depth, with explanation of the data and processing in these notes.\n\n**Objectives:** Upon completion, you will be familiar with a range of data processing approaches for quantitative demographic analysis. These skills will support your understanding and use of concepts and tools of demography introduced in CSDE 533.\n\n**Instructor:** [Phil Hurvitz](gis.washington.edu/phurvitz), phurvitz@uw.edu<br>\nOffice hours: by appointment; see [my calendar](http://staff.washington.edu/phurvitz/calendar) and suggest times to meet.\n\n\n## Course logistics {.unnumbered}\n\n:::{.rmdnote}\n### Class location {.unnumbered}\n\nClass meetings will happen initially over Zoom. The Zoom link for this course is [https://washington.zoom.us/j/97609440755](https://washington.zoom.us/j/976094407559). \n\nHybrid in-person/Zoom meetings will start on Feb 4, 2022 in [Communications](https://www.washington.edu/classroom/CMU) B027.\n\n### Course days and times {.unnumbered}\nFriday 10:30-12:20<br>\nPlease come to class promptly at the scheduled time. There will be a 10-minute break about halfway through each class session.\n\n### Canvas site {.unnumbered}\n\nThe course has a Canvas site [https://canvas.uw.edu/courses/1515226](https://canvas.uw.edu/courses/1515226), which will be used for collection of assignments and distribution of graded assignments. The site may also be used for distribution of data sets used in the course.\n\n### Class e-mail list {.unnumbered}\nCorrespondence among instructor and students should use the class e-mail list, [CSDE 502 Winter 2022](mailto:csde502a_wi22@uw.edu). List archives are available [CSDE 502 Winter 2022 Archives](https://mailman11.u.washington.edu/mailman/private/csde502a_wi22/).\n\nIn general, please send any messages you want the entire class to see to the list. If you have a message to the instructor that you don't want others to see, just send the message directly to the instructor. If the answer would be valuable to the rest of the class, the answer will be posted to the class e-mail list and any identification will be removed from the message so the question will appear anonymous.\n:::\n\n### Class format {.unnumbered}\n\nDefault class-time agenda:\n\n1. Address outstanding issues from previous sessions or assignments (~10 minutes)\n1. A brief lecture to introduce the topics of the day (~5 minutes)\n1. A hands-on instructional session (~75 minutes)\n1. Overview/clarification of assignment (~10 minutes)\n\n## Computing {.unnumbered}\nWe will do our assignments in R. Use an Internet-connected computer provisioned with the latest versions of [R](https://www.r-project.org/) [-@R-base], [RStudio Desktop](https://www.rstudio.com/products/rstudio/), and the latest versions of a number of R packages.\n\nAll computing for this course should optimally be done on CSDE Terminal Servers (TS). Those students that already have TS access (e.g., CSDE trainees) should be able to use their existing TS1, TS2, or TS3 accounts, but are encouraged to use TS4 for this course so that we will all be using the same environment. More recent student CSDE computing accounts for the general UW student population will use TS4 (csde-ts4.csde.washington.edu).\n\nMost students have computers capable of running R and handling relatively large data sets. However, using a common computing environment will help us avoid some of the problems associated with running the same code on different machines that have different operating systems, processors, RAM, graphics cards, R versions, etc. This will aid in troubleshooting any problems that arise. You may use your own computer during lessons, but only limited time will be available if problems arise due to your computer's unique environment that cannot be addressed quickly.\n\nIn order to get access to the CSDE Terminal Servers, see [CSDE Computing Accounts](https://csde.washington.edu/computing/accounts/). All students at UW who pay the [Student Technology Fee](https://uwstf.org/) are legible to obtain CSDE computing accounts.\n\nFor information about the CSDE Terminal Servers, see [Choosing a Terminal  Server](https://csde.washington.edu/computing/resources/#TerminalServerChoosing). For instructions on connecting to a Terminal Server, see [Computing tutorials](https://csde.washington.edu/computing/tutorials/).\n\nIn order to make remote connections to TS4, you will need a remote desktop protocol (RDP) client. Windows has a built-in \"Remote Desktop\" application. The same is available for Macs at the Apple Store. Windows users may also want to use [mRemoteNG](https://mremoteng.org/), which I find to be a bit more full-featured than the built-in Windows application. For example, mRemoteNG can have any window size, whereas the Windows RDP application has fixed size that must be specified at the time of connection. Linux users can use [Remmina](https://sourceforge.net/projects/remmina/).\n\nIn addition to the RDP client, in order to access any of CSDE's computing resources from off-campus locations, it is necessary to install and enable Husky OnNet, the UW virtual private network (VPN) client. Instructions are available at [Download and use Husky OnNet](https://itconnect.uw.edu/connect/uw-networks/about-husky-onnet/use-husky-onnet/)\n\n:::{.rmdnote}\n**Computing resource links**\n\n* [CSDE Computing Resources](https://csde.washington.edu/computing/resources/)\n* [RStudio Education Beginners course](https://education.rstudio.com/learn/beginner/)\n:::\n\n## Assignments and grading {.unnumbered}\nEach week there will be an assignment made available at 12:00 on the day of class meetings. The assignments are designed to allow students to practice the skills introduced in class sessions. Assignments are due at 09:00 AM on Friday of the week following when the assignment was distributed; answer keys will be posted at this time. Because the answer keys are posted at the due date/time, <u>late work will not be reviewed without prior arrangement with the instructor<\/u>. Assignments are to be submitted using the Canvas site; <u>do not send any assignments to the instructor via e-mail<\/u>.\n\nAssignments will be reviewed thoroughly and returned with relevant mark-up, corrections, suggestions, etc. and returned via the course Canvas site.\n\nThis course is graded credit/no credit. Students should complete as much of each of the assignments as they can within a reasonable amount of time.  In general, courses require two hours of homework for every hour of class, so you should expect to spend at least 4 hours on assignments outside of class time.\n\n## Course policies {.unnumbered}\n\n**Student conduct:** [\"Students at the University of Washington are expected to maintain a certain standard of conduct and be responsible members of the community. The Student Conduct Code defines prohibited conduct and describes how the University holds students accountable as they pursue their academic goals.\"](https://www.washington.edu/studentconduct/) Prohibited academic conduct includes cheating, falsification, and plagiarism. Evidence of academic misconduct will be referred to the relevant UW conduct office.\n\n_You are encouraged to work on assignments with other students_, but the work you turn in must be your own best effort.\n\n:::{.rmdnote}\n**UW Libraries Plagiarism Awareness guide**\n\nA link to the guide is below:\n\n* [UW Libraries Plagiarism Awareness guide](https://www.lib.washington.edu/teaching/plagiarism)\n:::\n\n**Accommodation:** Your experience in this class is important to me. If you have already established accommodations with Disability Resources for Students (DRS), please communicate your approved accommodations to me at your earliest convenience so we can discuss your needs in this course. The website for the DRS provides other resources for students and faculty for making accommodations.\n\nWashington state law requires that UW develop a policy for accommodation of student absences or significant hardship due to reasons of faith or conscience, or for organized religious activities. The UW's policy, including more information about how to request an accommodation, is available at Religious Accommodations Policy. Accommodations must be requested within the first two weeks of this course using the Religious Accommodations Request form.\n\n:::{.rmdnote}\n**Accommodation resource links**\n\n* [Disability Resources for Students](https://depts.washington.edu/uwdrs/)\n* [Religious Accommodations Policy](https://registrar.washington.edu/staffandfaculty/religious-accommodations-policy/)\n* [Religious Accommodations Request form](https://registrar.washington.edu/students/religious-accommodations-request/)\n:::\n\n**Diversity and inclusion:** [\"At the University of Washington, diversity is integral to excellence. We value and honor diverse experiences and perspectives, strive to create welcoming and respectful learning environments, and promote access, opportunity and justice for all.\"](https://www.washington.edu/diversity/)\n\n**SafeCampus:** Preventing violence is a shared responsibility in which everyone at the UW plays a part. If you experience harassment during your studies, please report it to the SafeCampus website (anonymous reports are possible). SafeCampus provides information on counseling and safety resources, University policies, and violence reporting requirements help us maintain a safe personal, work and learning environment.\n\n:::{.rmdnote}\n**SafeCampus website**\n\nA link to the SafeCampus program is below:\n\n* [SafeCampus website](https://www.washington.edu/safecampus/)\n:::\n\n## Course calendar {.unnumbered}\n***Week 1***\n\n**Topics**\n\n* Course introduction\n* Getting started with CSDE terminal server 4\n* [Introduction to R/RStudio/RMarkdown](#intrormd)\n* R data types\n* R data structures\n* R pipes (`magrittr`. `tidyverse`, and native pipes)\n* Data manipulation in the `tidyverse`\n* Employee turnover data\n    * [Babushkin data](https://github.com/teuschb/hr_data/blob/master/datasets/turnover_babushkin.csv)\n    * [Kaggle documentation of Babuskin data](https://www.kaggle.com/davinwijaya/employee-turnover)\n    * [Ben's attrition rate code](https://github.com/hanowell/uwsoc533a/blob/main/gists/employee-turnover-gist.R)\n\n***Week 2***\n\n**Topics**\n\n* Rmarkdown\n    * Code blocks in R Markdown\n    * Graphs in R Markdown\n    * Tables in R Markdown\n        * Pretty printouts of life tables with `flextable` and `DT`\n    * Equations in R Markdown\n    * HTML output from R Markdown\n* [Keyring: securely store secrets](https://cran.r-project.org/web/packages/keyring/)\n* Data:\n    * [Human Mortality Database](https://www.mortality.org/)\n    * [Human Fertility Database](https://www.humanfertility.org/cgi-bin/main.php)\n\n***Week 3***\n\n**Topics**: \n\n* [`tidycensus`](https://walker-data.com/tidycensus/): Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready Data Frames\n* [`idbr`](https://cran.r-project.org/web/packages/idbr/index.html): R Interface to the US Census Bureau International Data Base API\n* [`sf: Simple Features for R`](https://cran.r-project.org/web/packages/sf/): Simple Features (GIS) for R\n* [`leaflet`](https://cran.r-project.org/web/packages/leaflet/): Create Interactive Web Maps with the JavaScript 'Leaflet' Library\n* [`mapview`](https://cran.r-project.org/web/packages/mapview/): Interactive Viewing of Spatial Data in R\n* Data:\n    * Accessing Human Mortality Database life tables using [HMDHFDplus](https://cran.r-project.org/web/packages/HMDHFDplus/index.html)\n\n***Week 4***\n\n**Topics**: \n\n* R environments\n* R functions\n* Sampling in R\n* Revisiting [Ben's code for reading HMD and HFD data](https://github.com/hanowell/uwsoc533a/blob/main/gists/HMDHFDplus-gist.R)\n* [`demogR`](https://cran.r-project.org/web/packages/demogR/index.html): Analysis of Age-Structured Demographic Models\n* [`demography`](https://cran.r-project.org/web/packages/demography/): Forecasting Mortality, Fertility, Migration and Population Data; [An R intro to the demography package](https://rpubs.com/Timexpo/487053))\n\n***Week 5***\n\n**Topics**: \n\n* Git: file versioning and code repository\n\n***Week 6***\n\n**Topics**: \n\n* Reading labelled data\n* Metadata on data sets\n* Ccmpp: Cohort Component Method of Population Projection\n* Data: \n    * Add Health public-use data\n\n***Week 7***\n\n**Topics**: \n\n* Creating value labels\n* Tabulation (summarizing data)\n\n***Week 8***\n\n**Topics**: \n\n* Scale scoring variables\n* Reordering variable values\n\n***Week 9***\n\n**Topics**: \n\n* Miscellaneous data processing\n\n***Week 10***\n\n**Topics**: \n\n* Miscellaneous data processing, continued\n\n\n## About this web site {.unnumbered}\nThis web site was built in R using Rmarkdown and [bookdown](https://cran.r-project.org/web/packages/bookdown/) with the [bs4_book](https://pkgs.rstudio.com/bookdown/reference/bs4_book.html) template, which uses the [Bootstrap](https://getbootstrap.com/) framework. One of the unfortunate side effects of this format is that all captions are placed _below_ the table or figure! \n\n<h4>Source code for this document<\/h4>\nEach of the pages in this book will have a section at the bottom including a link to the source file and the printed source code for the page.\n\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week1.html","id":"week1","chapter":"1 Week 1","heading":"1 Week 1","text":"Getting started terminal server 4Introduction R/RStudio/R MarkdownR data typesR data structuresFile systemsData manipulation tidyverseData sets:\nEmployee turnover data\nEmployee turnover dataToday’s lessons cover getting started computing CSDE, quickly introduce R, RStudio, R Markdown.assumed students course basic working knowledge using R, including create variables assignment operator (“<-”), run simple functions(e.g., mean(dat$age)). Often courses include using R statistical analysis, following foundations explained fully. section intended comprehensive treatment R data types structures, provide background students either relatively new using R systematic introduction.main topic today tidyverse, refers related set R packages data management, analysis, display. See Hadley Wickham’s tidy tools manifesto logic behind suite tools. brief description specific R packages, see Tidyverse packages. intended complete introduction tidyverse, provide sufficient background data handling support technical aspects rest course CSDE 533.","code":""},{"path":"week1.html","id":"gettingstarted","chapter":"1 Week 1","heading":"1.1 Getting started on Terminal Server 4","text":"First, campus, make sure Husky OnNet VPN application running connected UW network. see f5 icon task area:Connect TS4: csde-ts4.csde.washington.eduIf using Windows Remote Desktop Protocol (RDP) connection, connection parameters look like :using mRemoteNG, connection parameters match :connected see number icons desktop application shortcuts Start area.Open Windows Explorer (running RDP full screen mode able use key combination Win-E).anything, let’s change annoying default settings Windows Explorer. Tap File > Options. View tab, make sure Always show menus checked Hide extensions known file types unchecked. latter setting important want see complete file name files times.Click Apply Folders settings become default. Click Yes next dialog.Now let’s make folder files course.Navigate PC:see H: drive. mapped drive links U Drive, place data course stored. store data C: drive! C: drive can wiped without prior notification.careful files U Drive! delete files, “undo” functionality. deleting files, get warning take seriously:Navigate H: create new folder named csde502_winter_2022. Note use lowercase letters underscores rather spaces. discussed section file systems later lesson.","code":""},{"path":"week1.html","id":"intrormd","chapter":"1 Week 1","heading":"1.2 Introduction to R Markdown in RStudio","text":"","code":""},{"path":"week1.html","id":"create-a-project","chapter":"1 Week 1","heading":"1.2.1 Create a project","text":"Now use RStudio create first R Markdown source file render HTML.Start RStudio either dbl-clicking desktop shortcut navigating alphabetical R section Start menu:brief aside: install R packages.get started, usually takes time install, open second RStudio session console, install tidyverse, packages CSDE 502 533, lesson, download file packages.R.Open file second RStudio session upper right source code pane, click Source > Source.Now continue lesson original RStudio session…..Create new project (File > New Project...).Since just created directory house project, select Existing Directory.Navigate directory select Open.Click Create Project.now blank project project file.","code":""},{"path":"week1.html","id":"create-an-r-markdown-file-from-built-in-rstudio-functionality","chapter":"1 Week 1","heading":"1.2.2 Create an R Markdown file from built-in RStudio functionality","text":"Let’s make R Markdown file (File > New File > R Markdown...).change metadata … just quick example.Click OK name file week_01.Rmd.","code":""},{"path":"week1.html","id":"render-the-rmd-file-as-html","chapter":"1 Week 1","heading":"1.2.2.1 Render the Rmd file as HTML","text":"console prompt, enter R Markdown::render(\"W tap TAB key. bring list files character “w” file name. Click week_01.Rmd.syntax means “run render() function R Markdown package file week_01.Rmd”moments, process complete message output created.HTML page open automatically, look week_01.html list files. Click select View Web Browser.now see bare-bones HTML file.Compare output file source code week_01.Rmd. Note section headers begin hash marks, R code indicated starting characters\n```{r}\nending characters\n```\nNext, explore enhancements basic R Markdown syntax.","code":""},{"path":"week1.html","id":"create-an-r-markdown-file-with-some-enhancements","chapter":"1 Week 1","heading":"1.2.3 Create an R Markdown file with some enhancements","text":"Download version week_01.Rmd overwrite version just created.RStudio prints message packages required installed, click Install.Change line 3 include name e-mail address shown.","code":""},{"path":"week1.html","id":"render-and-view-the-enhanced-output","chapter":"1 Week 1","heading":"1.2.3.1 Render and view the enhanced output","text":"Repeat rendering process (R Markdown::render(\"Week_01.Rmd\"))new HTML file number enhancements, including mailto: hyperlink name, table contents upper left, table easier read, Leaflet map, captions cross-references figures table, image derived PNG file referenced URL, code used generate various parts document produced R code, complete source code document. downloadable version rendered file: week_01.html.Including source code document especially useful readers documents lets see exactly . entire research chain can documented way, reading raw data, performing data cleaning analysis, generating results.","code":""},{"path":"week1.html","id":"rdatatypes","chapter":"1 Week 1","heading":"1.3 R data types","text":"may want download file week01.Rmd, contains many examples .six fundamental data types R:logicalnumericintegercomplexcharacterrawThe atomic object R exist one data types, described . atomic object data type can value, NA represents observation data (e.g., missing measurement), NULL isn’t really value , can still data type class.encounter data types, Date POSIXct working dates time stamps. data types extensions fundamental data types.determine data type object , use (obj), str(obj), class(obj).","code":"\nprint(is(\"a\"))## [1] \"character\"           \"vector\"              \"data.frameRowLabels\"\n## [4] \"SuperClassMethod\"\nprint(str(TRUE))##  logi TRUE\n## NULL\nprint(class(123.45))## [1] \"numeric\"\nprint(class(as.integer(1000)))## [1] \"integer\"\nn <- as.numeric(999999999999999999999)\n\nprint(class(n))## [1] \"numeric\""},{"path":"week1.html","id":"logical","chapter":"1 Week 1","heading":"1.3.1 Logical","text":"Use logical values characteristics either TRUE FALSE. Note logical elements can also NA value observation missing. following examples,Logical values often expressed binary format 0 = FALSE =TRUE`. R values interconvertible. software (e.g., Excel, MS Access) may convert logical values numbers expect.","code":"\n# evaluate as logical, test whether 1 is greater than two\na <- 1 > 2\n# create two numerical values, one being NA, representing ages\nage_john <- 39\nage_jane <- NA\n\n# logical NA from Jane's undefined age\n(jo <- age_john > 50)## [1] FALSE\n(ja <- age_jane > 50)## [1] NA\n(t <- as.logical(1))## [1] TRUE\n(f <- as.logical(0))## [1] FALSE"},{"path":"week1.html","id":"numeric","chapter":"1 Week 1","heading":"1.3.2 Numeric","text":"Numeric values numbers range 2e-308 2e+308, depending computer using. can see possible range entering .Machine R console. can also include decimals. information, see Double-precision floating-point format","code":""},{"path":"week1.html","id":"integer","chapter":"1 Week 1","heading":"1.3.3 Integer","text":"Integer values numerical, can take whole, rather fractional values, truncated range compared numeric. example, see , try create integer range. object created integer, range, value set NA.","code":"\ni <- as.integer(999999999999999999999)## Warning: NAs introduced by coercion to integer range\nprint(class(i))## [1] \"integer\""},{"path":"week1.html","id":"complex","chapter":"1 Week 1","heading":"1.3.4 Complex","text":"complex type used mathematics unlikely use applied social science research unless get heavy statistics. See Complex number full treatment.","code":""},{"path":"week1.html","id":"character","chapter":"1 Week 1","heading":"1.3.5 Character","text":"Character data include full set keys keyboard print character, typically [-Z], [-z], [0-9], punctuation, etc. full set ASCII characters supported, e.g. accent aigu Café:Also numbers can function characters. careful converting numerical character versions. example, see ZIP codes:","code":"\nprint(class(\"Café\"))## [1] \"character\"\n# this is a character\nmy_zip <- \"98115\"\n\n# it is not numeric.\nmy_zip + 2## Error in my_zip + 2: non-numeric argument to binary operator\n# we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values\nas.numeric(my_zip) + 2## [1] 98117\n# Boston has ZIP codes starting with zeros\nboston_zip <- \"02134\"\nas.numeric(boston_zip)## [1] 2134"},{"path":"week1.html","id":"raw","chapter":"1 Week 1","heading":"1.3.6 Raw","text":"Raw values used store raw bytes hexadecimal format. unlikely use applied social science research. example, hexadecimal value character z 7a:","code":"\nprint(charToRaw(\"z\"))## [1] 7a\nclass(charToRaw(\"z\"))## [1] \"raw\""},{"path":"week1.html","id":"rdatastructures","chapter":"1 Week 1","heading":"1.4 R data structures","text":"5 basic data structures R, shown graphic:vectormatrixarraylistdata frameIn addition, factor data type important","code":""},{"path":"week1.html","id":"vector","chapter":"1 Week 1","heading":"1.4.1 Vector","text":"vector ordered set elements one elements data type created using c() constructor function. example, single value vector:try creating vector mixed data types, may get unexpected results; mixing character elements type elements result character representations, e.g.,Results depend data type mixing, example logical values can expressed numerically, TRUE FALSE values converted 1 0, respectively.character added, elements converted characters.Order important, .e.,1, 2, 3 1, 3, 2R maintain order elements vectors unless process initiated changes order elements:can get information vectors, length data type:Elements vectors specified index number (1 .. n):","code":"\n# create a vector of length 1\na <- 1\nis(a)## [1] \"numeric\" \"vector\"\nc(1, \"a\", TRUE, charToRaw(\"z\"))## [1] \"1\"    \"a\"    \"TRUE\" \"7a\"\n(c(1:3, TRUE, FALSE))## [1] 1 2 3 1 0\nc(1:3, TRUE, FALSE, \"awesome!\")## [1] \"1\"        \"2\"        \"3\"        \"TRUE\"     \"FALSE\"    \"awesome!\"\n# a vector \n(v <- c(1, 3, 2))## [1] 1 3 2\n(sort(v))## [1] 1 2 3\n# create a random normal \nset.seed(5)\nnormvec1000 <- rnorm(n = 1000)\n\nlength(normvec1000)## [1] 1000\nclass(normvec1000)## [1] \"numeric\"\nclass(normvec1000 > 1)## [1] \"logical\"\nv <- seq(from = 0, to = 10, by = 2)\nv[4]## [1] 6"},{"path":"week1.html","id":"matrix","chapter":"1 Week 1","heading":"1.4.2 Matrix","text":"matrix like vector, contain one data type, two-dimensional, rows columns. simple example:try force vector matrix whose row \\(\\times\\) col length match length vector, elements recycled, may want. least R give warning.","code":"\n# make a vector 1 to 100\n(v <- 1:100)##   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n##  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n##  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n##  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n##  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n##  [91]  91  92  93  94  95  96  97  98  99 100\n# load to a matrix\n(m1 <- matrix(v, ncol = 10, byrow = TRUE))##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n##  [1,]    1    2    3    4    5    6    7    8    9    10\n##  [2,]   11   12   13   14   15   16   17   18   19    20\n##  [3,]   21   22   23   24   25   26   27   28   29    30\n##  [4,]   31   32   33   34   35   36   37   38   39    40\n##  [5,]   41   42   43   44   45   46   47   48   49    50\n##  [6,]   51   52   53   54   55   56   57   58   59    60\n##  [7,]   61   62   63   64   65   66   67   68   69    70\n##  [8,]   71   72   73   74   75   76   77   78   79    80\n##  [9,]   81   82   83   84   85   86   87   88   89    90\n## [10,]   91   92   93   94   95   96   97   98   99   100\n# different r, c ordering\n(m2 <- matrix(v, ncol = 10, byrow = FALSE))##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n##  [1,]    1   11   21   31   41   51   61   71   81    91\n##  [2,]    2   12   22   32   42   52   62   72   82    92\n##  [3,]    3   13   23   33   43   53   63   73   83    93\n##  [4,]    4   14   24   34   44   54   64   74   84    94\n##  [5,]    5   15   25   35   45   55   65   75   85    95\n##  [6,]    6   16   26   36   46   56   66   76   86    96\n##  [7,]    7   17   27   37   47   57   67   77   87    97\n##  [8,]    8   18   28   38   48   58   68   78   88    98\n##  [9,]    9   19   29   39   49   59   69   79   89    99\n## [10,]   10   20   30   40   50   60   70   80   90   100\n(m3 <- matrix(letters, ncol = 10, nrow = 10))## Warning in matrix(letters, ncol = 10, nrow = 10): data length [26] is not a sub-\n## multiple or multiple of the number of rows [10]##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n##  [1,] \"a\"  \"k\"  \"u\"  \"e\"  \"o\"  \"y\"  \"i\"  \"s\"  \"c\"  \"m\"  \n##  [2,] \"b\"  \"l\"  \"v\"  \"f\"  \"p\"  \"z\"  \"j\"  \"t\"  \"d\"  \"n\"  \n##  [3,] \"c\"  \"m\"  \"w\"  \"g\"  \"q\"  \"a\"  \"k\"  \"u\"  \"e\"  \"o\"  \n##  [4,] \"d\"  \"n\"  \"x\"  \"h\"  \"r\"  \"b\"  \"l\"  \"v\"  \"f\"  \"p\"  \n##  [5,] \"e\"  \"o\"  \"y\"  \"i\"  \"s\"  \"c\"  \"m\"  \"w\"  \"g\"  \"q\"  \n##  [6,] \"f\"  \"p\"  \"z\"  \"j\"  \"t\"  \"d\"  \"n\"  \"x\"  \"h\"  \"r\"  \n##  [7,] \"g\"  \"q\"  \"a\"  \"k\"  \"u\"  \"e\"  \"o\"  \"y\"  \"i\"  \"s\"  \n##  [8,] \"h\"  \"r\"  \"b\"  \"l\"  \"v\"  \"f\"  \"p\"  \"z\"  \"j\"  \"t\"  \n##  [9,] \"i\"  \"s\"  \"c\"  \"m\"  \"w\"  \"g\"  \"q\"  \"a\"  \"k\"  \"u\"  \n## [10,] \"j\"  \"t\"  \"d\"  \"n\"  \"x\"  \"h\"  \"r\"  \"b\"  \"l\"  \"v\""},{"path":"week1.html","id":"array","chapter":"1 Week 1","heading":"1.4.3 Array","text":"array similar matrix, can one dimension. can useful analyzing time series data multidimensional data. using array data course, simple example creating viewing contents array:","code":"\n# a vector 1 to 27\nv <- 1:27\n\n# create an array, 3 x 3 x 3\n(a <- array(v, dim = c(3, 3, 3)))## , , 1\n## \n##      [,1] [,2] [,3]\n## [1,]    1    4    7\n## [2,]    2    5    8\n## [3,]    3    6    9\n## \n## , , 2\n## \n##      [,1] [,2] [,3]\n## [1,]   10   13   16\n## [2,]   11   14   17\n## [3,]   12   15   18\n## \n## , , 3\n## \n##      [,1] [,2] [,3]\n## [1,]   19   22   25\n## [2,]   20   23   26\n## [3,]   21   24   27\n# array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3:\n(a[1,2,3])## [1] 22"},{"path":"week1.html","id":"list","chapter":"1 Week 1","heading":"1.4.4 List","text":"R lists ordered collections objects need data type. objects can single-value vectors, multiple-value vectors, matrices, data frames, lists, etc. , lists flexible data type. can little much structure want, can become difficult manage analyze.example list comprised single value vectors different data type. Compare attempt make vector comprised elements different data type:Let’s modify list bit:top-level indexing list denoted using two sets square brackets. example, first element list can accessed l[[1]]. example, mean element 2 obtained mean(l[[2]]): 10.5.perform operations elements list, use lapply():","code":"\n(l <- list(\"a\", 1, TRUE))## [[1]]\n## [1] \"a\"\n## \n## [[2]]\n## [1] 1\n## \n## [[3]]\n## [1] TRUE\n(l <- list(\"a\", \n           1:20, \n           as.logical(c(0,1,1,0))))## [[1]]\n## [1] \"a\"\n## \n## [[2]]\n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n## \n## [[3]]\n## [1] FALSE  TRUE  TRUE FALSE\n# show the data types\n(lapply(X = l, FUN = class))## [[1]]\n## [1] \"character\"\n## \n## [[2]]\n## [1] \"integer\"\n## \n## [[3]]\n## [1] \"logical\"\n# mean, maybe?\n(lapply(X = l, FUN = function(x) {mean(x)}))## Warning in mean.default(x): argument is not numeric or logical: returning NA## [[1]]\n## [1] NA\n## \n## [[2]]\n## [1] 10.5\n## \n## [[3]]\n## [1] 0.5"},{"path":"week1.html","id":"factor","chapter":"1 Week 1","heading":"1.4.5 Factor","text":"Factors similar vectors, one-dimensional ordered sets. However, factors also use informational labels. example, may variable household income text value:“<$10,000”“$10,000-$549,999”“$50,000-$99,999”“$100,000-$200,000”“>$200,000”vector:characters, sort proper numeric order:treated factor, levels can set proper ordering:factor, data can also used statistical models magnitude variable also correctly ordered.","code":"\n(income <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\"))## [1] \"<$10,000\"          \"$10,000-$49,999\"   \"$50,000-$99,999\"  \n## [4] \"$100,000-$200,000\" \">$200,000\"\nsort(income)## [1] \"$10,000-$49,999\"   \"$100,000-$200,000\" \"$50,000-$99,999\"  \n## [4] \"<$10,000\"          \">$200,000\"\n# create a factor from income and set the levels\n(income_factor <- factor(x = income, levels = income))## [1] <$10,000          $10,000-$49,999   $50,000-$99,999   $100,000-$200,000\n## [5] >$200,000        \n## 5 Levels: <$10,000 $10,000-$49,999 $50,000-$99,999 ... >$200,000\n# sort again\n(sort(income_factor))## [1] <$10,000          $10,000-$49,999   $50,000-$99,999   $100,000-$200,000\n## [5] >$200,000        \n## 5 Levels: <$10,000 $10,000-$49,999 $50,000-$99,999 ... >$200,000"},{"path":"week1.html","id":"data-frame","chapter":"1 Week 1","heading":"1.4.6 Data frame","text":"vectors, data frames probably used data type R. can think data frames matrices allow columns different data type. example, might data set represents subject IDs characters, sex gender text, height, weight, age numerical values, income factor, smoking status logical. matrix requires one data type, possible store matrix. example:","code":"\n# income levels \ninc <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\")\n\nBMI <-  data.frame(\n   sid = c(\"A1001\", \"A1002\", \"B1001\"),\n   gender = c(\"Male\", \"Male\",\"Female\"), \n   height_cm = c(152, 171.5, 165), \n   weight_kg = c(81, 93, 78),\n   age_y = c(42, 38, 26),\n   income = factor(c(\"$50,000-$99,999\", \"$100,000-$200,000\", \"<$10,000\"), levels = inc)\n)\nprint(BMI)##     sid gender height_cm weight_kg age_y            income\n## 1 A1001   Male     152.0        81    42   $50,000-$99,999\n## 2 A1002   Male     171.5        93    38 $100,000-$200,000\n## 3 B1001 Female     165.0        78    26          <$10,000"},{"path":"week1.html","id":"filesystems","chapter":"1 Week 1","heading":"1.5 File systems","text":"Although full treatment effective uses file systems beyond scope course, basic rules worth covering:Never use spaces folder file names.\nNinety-nine 44/100ths percent time, modern software problems handling file names spaces. 0.56% time software chokes, may wonder processes failing. directly file names spaces, can least rule !Never use spaces folder file names.\nNinety-nine 44/100ths percent time, modern software problems handling file names spaces. 0.56% time software chokes, may wonder processes failing. directly file names spaces, can least rule !Use lowercase letters directory file names.\nolden days (MS-DOS), case sensitivity file names. UNIX always used case sensitive file names. \nMyGloriousPhDDissertation.tex mygloriousphddissertation.tex actually different files. Macs, based UNIX kernel, also employ case sensitivity file names. Windows? . Consider following: foo.txt FOO.txt directory.\n\nWindows doesn’t care, ? Save keyboarding time confusion using lowercase characters file names.Use lowercase letters directory file names.\nolden days (MS-DOS), case sensitivity file names. UNIX always used case sensitive file names. \nMyGloriousPhDDissertation.tex mygloriousphddissertation.tex actually different files. Macs, based UNIX kernel, also employ case sensitivity file names. Windows? . Consider following: foo.txt FOO.txt directory.\nWindows doesn’t care, ? Save keyboarding time confusion using lowercase characters file names.Include dates file names.\nexpect multiple files sequential versions file progress, alternative using content management system git, particularly binary files Word documents SAS data files, multiple versions files including date part file name. expect multiple versions date, include lowercase alphabetical character; improbable 26 versions fine single calendar date. paranoid, use suffix number 0000, 0002 .. 9999. ten thousand versions file given date, probably something right.\nNow convinced including dates file names good idea, please use format yyyy-mm-dd yyyymmdd. , file names sort temporal order.Include dates file names.\nexpect multiple files sequential versions file progress, alternative using content management system git, particularly binary files Word documents SAS data files, multiple versions files including date part file name. expect multiple versions date, include lowercase alphabetical character; improbable 26 versions fine single calendar date. paranoid, use suffix number 0000, 0002 .. 9999. ten thousand versions file given date, probably something right.\nNow convinced including dates file names good idea, please use format yyyy-mm-dd yyyymmdd. , file names sort temporal order.Make use directories!\nAlthough folder containing 100,000 files can handled programatically (file naming conventions used), possible human visually scan 100,000 file names. lot files project, consider creating directories, e.g.,\n- raw_data\n- processed_data\n- analysis_results\n- scripts\n- manuscriptMake use directories!\nAlthough folder containing 100,000 files can handled programatically (file naming conventions used), possible human visually scan 100,000 file names. lot files project, consider creating directories, e.g.,\n- raw_data\n- processed_data\n- analysis_results\n- scripts\n- manuscriptAgonize file names.\nOptimally look file names, able know something content file. spend lot time analysis creating output. Spending extra minute thinking good file names time well spent.Agonize file names.\nOptimally look file names, able know something content file. spend lot time analysis creating output. Spending extra minute thinking good file names time well spent.","code":""},{"path":"week1.html","id":"tidyverse","chapter":"1 Week 1","heading":"1.6 Data manipulation in the tidyverse","text":"One R packages use frequently tidyverse, collection several packages, specific domain:ggplot2 (graphics)dplyr (data manipulation)tidyr (reformatting data efficient processing)readr (reading rectangular R x C data)purrr (functional programming, e.g., replace () loops)tibble (enhanced data frames)stringr (string, .e., text manipulation)forcats (handling factor, .e., categorical variables)touch course, full review treatment tidyverse.section introduce main workhorse functions tidy data handling.Installing tidyverse straightforward may take time download install packages. done yet, useFor today’s lesson using one Add Health public use data sets, AHwave1_v1.dta.data set includes variable labels, make handling data easier. print column names labels. Wrapping DT::data_table presents nice interface showing variables time allows sorting searching.","code":"install.packages(\"tidyverse\")\n# load pacman if necessary\npackage.check <- lapply(\"pacman\", FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n        install.packages(x, dependencies = TRUE)\n        library(x, character.only = TRUE)\n    }\n})\n\n# load readstata13 if necessary\npacman::p_load(readstata13)\n\n# read the dta file\ndat <- readstata13::read.dta13(file.path(myurl, \"data/AHwave1_v1.dta\"))\nx <- data.frame(colname = names(dat), label = attributes(dat)$var.labels)\nDT::datatable(data = x, caption = \"Column names and labels in AHwave1_v1.dta.\")"},{"path":"week1.html","id":"magrittr","chapter":"1 Week 1","heading":"1.6.1 magrittr","text":"R package magrittr allows use “pipes.” UNIX, pipes used take output one program feed input another program. example, UNIX command cat prints contents text file. print contents file 00README.txt:cat 00README.txtbut large files, entire contents scroll fast read. Using “pipe,” denoted vertical bar character | allowed using command print one screen time tapping Enter key screen full text:cat 00README.txt | moreAs shown two screen captures:two main pipe operators use magrittr %>% ‘%<>%.’%>% pipe operator, functions UNIX pipe, , take something left hand side operator feed right hand side.%<>% assignment pipe operator, takes something left hand side operator, feeds right hand side, replaces object left-hand side.simple example pipe, list first 6 lines data frame base R, use head(), e.g.,using tidy version :R base version, first read head, know printing first 6 elements something, don’t know “something” . read ahead know reading first 6 records iris. tidy version, start knowing something data set, know printing first 6 records.base R functions, process evaluated inside . example, get mean sepal length setosa species iris, :inside , read making subset iris Species = “setosa,” selecting column “Sepal.Length,” taking mean. However, requires reading inside . large set nested functions, y <- f(g(h(((x))))), require first creating innermost function (()) working outward.tidy approach like y <- x %>% () %>% h() %>% g() %>% f()first function applied data setxisi()`. Revisiting mean sepal length setosa irises, example, tidy approach :, read left right, translates “using iris data frame, make subset records species setosa, summarize records get mean value sepal length.” tidy version intended easier write, read, understand. command uses filter() function, described .","code":"\nhead(iris)##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\niris %>% head()##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\nmean(iris[iris$Species == 'setosa', \"Sepal.Length\"])## [1] 5.006\niris %>% filter(Species == 'setosa') %>% summarise(mean(Sepal.Length))##   mean(Sepal.Length)\n## 1              5.006"},{"path":"week1.html","id":"data-subsetting-dplyr","chapter":"1 Week 1","heading":"1.6.2 Data subsetting (dplyr)","text":"dplyr tidyverse R package used frequently data manipulation. Selection records (.e., subsetting) done using logical tests determine selected set. First look logical tests cover subsetting rows columns data frames.","code":""},{"path":"week1.html","id":"logical-tests","chapter":"1 Week 1","heading":"1.6.2.0.1 Logical tests","text":"elements meet logical test, end selected set. data frame records values variables meet logical criteria, records selected.logical tests shown .","code":""},{},{},{},{},{"path":"week1.html","id":"subset-rows-filter","chapter":"1 Week 1","heading":"1.6.2.1 Subset rows (filter())","text":"filter() function creates subset records based logical test. Logical tests can combined “” statements using & operator “” statements using | operator. perform filters subset data.June\n1995\nFemale\nOctober\n1977\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nFemale\nNovember\n1976\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nOctober\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nMale\nJanuary\n1977\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nFemale\nJune\n1976\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nDecember\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nMale\nOctober\n1983\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nMarch\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nSeptember\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nAugust\n1995\nMale\nJune\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nSeptember\n1995\nMale\nSeptember\n1980\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nMale\nJanuary\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nApril\n1980\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nMale\nSeptember\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nFemale\nOctober\n1982\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nFemale\nOctober\n1982\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nFemale\nApril\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nMale\nSeptember\n1982\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nAugust\n1995\nMale\nOctober\n1976\nYes\nMarked\nmarked\nJuly\n1995\nFemale\nAugust\n1976\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nRecords one month:Records one month females:Records one month females day month 15th, probably include males:Although examples silly trivial, show filter() used create selected set data","code":"\n# first 20 records, fist 10 columns\ndat_sub <- dat[1:20, 1:10]\nkable(dat_sub, format = \"html\") %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# from May\n(dat_sub %>% filter(imonth == \"(5) May\"))##        aid  imonth iday     iyear    bio_sex        h1gi1m    h1gi1y  h1gi4\n## 1 57101310 (5) May    5 (95) 1995 (2) Female (11) November (76) 1976 (0) No\n## 2 57104676 (5) May   31 (95) 1995   (1) Male  (10) October (83) 1983 (0) No\n## 3 57113943 (5) May   20 (95) 1995   (1) Male   (1) January (79) 1979 (0) No\n## 4 57117997 (5) May   20 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n## 5 57118381 (5) May    6 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n## 6 57120005 (5) May   25 (95) 1995   (1) Male (9) September (82) 1982 (0) No\n##                               h1gi5a                             h1gi5b\n## 1 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 4 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 5 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 6 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n(dat_sub %>% filter(imonth == \"(5) May\" & bio_sex == \"(2) Female\"))##        aid  imonth iday     iyear    bio_sex        h1gi1m    h1gi1y  h1gi4\n## 1 57101310 (5) May    5 (95) 1995 (2) Female (11) November (76) 1976 (0) No\n## 2 57117997 (5) May   20 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n## 3 57118381 (5) May    6 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n##                               h1gi5a                             h1gi5b\n## 1 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n(dat_sub %>% filter(imonth == \"(5) May\" & (bio_sex == \"(2) Female\") | iday < 15))##         aid        imonth iday     iyear    bio_sex        h1gi1m    h1gi1y\n## 1  57101310       (5) May    5 (95) 1995 (2) Female (11) November (76) 1976\n## 2  57103869      (7) July   14 (95) 1995   (1) Male   (1) January (77) 1977\n## 3  57104553      (7) July   14 (95) 1995 (2) Female      (6) June (76) 1976\n## 4  57104649      (6) June   12 (95) 1995   (1) Male (12) December (81) 1981\n## 5  57109625      (6) June    7 (95) 1995   (1) Male     (3) March (81) 1981\n## 6  57111071    (8) August    3 (95) 1995   (1) Male      (6) June (81) 1981\n## 7  57111786 (9) September    7 (95) 1995   (1) Male (9) September (80) 1980\n## 8  57117542      (7) July   11 (95) 1995   (1) Male (9) September (79) 1979\n## 9  57117997       (5) May   20 (95) 1995 (2) Female  (10) October (82) 1982\n## 10 57118381       (5) May    6 (95) 1995 (2) Female  (10) October (82) 1982\n##     h1gi4                             h1gi5a                             h1gi5b\n## 1  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 4  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 5  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 6  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 7  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 8  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 9  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 10 (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)"},{"path":"week1.html","id":"subset-columns-select","chapter":"1 Week 1","heading":"1.6.2.2 Subset columns (select())","text":"subset columns can extracted data frames using select() function, simply using named list columns keep.select() can also used rename columns:column renaming can done rename(), maintains input data changes named columns:","code":"\n# select 3 columns\n(dat_sub_sel <- dat_sub %>%   \n    select(\"aid\", \"imonth\", \"iday\"))##         aid        imonth iday\n## 1  57100270      (6) June   23\n## 2  57101310       (5) May    5\n## 3  57103171      (6) June   27\n## 4  57103869      (7) July   14\n## 5  57104553      (7) July   14\n## 6  57104649      (6) June   12\n## 7  57104676       (5) May   31\n## 8  57109625      (6) June    7\n## 9  57110897      (6) June   27\n## 10 57111071    (8) August    3\n## 11 57111786 (9) September    7\n## 12 57113943       (5) May   20\n## 13 57116359      (6) June   24\n## 14 57117542      (7) July   11\n## 15 57117997       (5) May   20\n## 16 57118381       (5) May    6\n## 17 57118943      (7) July   19\n## 18 57120005       (5) May   25\n## 19 57120046    (8) August   20\n## 20 57120371      (7) July   20\n# select all but two named columns\n(dat_sub_sel <- dat_sub %>%   \n    select(-\"imonth\", -\"iday\"))##         aid     iyear    bio_sex        h1gi1m    h1gi1y   h1gi4\n## 1  57100270 (95) 1995 (2) Female  (10) October (77) 1977  (0) No\n## 2  57101310 (95) 1995 (2) Female (11) November (76) 1976  (0) No\n## 3  57103171 (95) 1995   (1) Male  (10) October (79) 1979  (0) No\n## 4  57103869 (95) 1995   (1) Male   (1) January (77) 1977  (0) No\n## 5  57104553 (95) 1995 (2) Female      (6) June (76) 1976  (0) No\n## 6  57104649 (95) 1995   (1) Male (12) December (81) 1981  (0) No\n## 7  57104676 (95) 1995   (1) Male  (10) October (83) 1983  (0) No\n## 8  57109625 (95) 1995   (1) Male     (3) March (81) 1981  (0) No\n## 9  57110897 (95) 1995   (1) Male (9) September (81) 1981  (0) No\n## 10 57111071 (95) 1995   (1) Male      (6) June (81) 1981  (0) No\n## 11 57111786 (95) 1995   (1) Male (9) September (80) 1980  (0) No\n## 12 57113943 (95) 1995   (1) Male   (1) January (79) 1979  (0) No\n## 13 57116359 (95) 1995   (1) Male     (4) April (80) 1980  (0) No\n## 14 57117542 (95) 1995   (1) Male (9) September (79) 1979  (0) No\n## 15 57117997 (95) 1995 (2) Female  (10) October (82) 1982  (0) No\n## 16 57118381 (95) 1995 (2) Female  (10) October (82) 1982  (0) No\n## 17 57118943 (95) 1995 (2) Female     (4) April (79) 1979  (0) No\n## 18 57120005 (95) 1995   (1) Male (9) September (82) 1982  (0) No\n## 19 57120046 (95) 1995   (1) Male  (10) October (76) 1976 (1) Yes\n## 20 57120371 (95) 1995 (2) Female    (8) August (76) 1976  (0) No\n##                                h1gi5a                             h1gi5b\n## 1  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 4  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 5  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 6  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 7  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 8  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 9  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 10 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 11 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 12 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 13 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 14 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 15 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 16 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 17 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 18 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 19                         (1) Marked                     (0) Not marked\n## 20 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n# select columns by position and whose name matches a pattern, in this case the regular expression \"^i\" meaning \"starts with lowercase i\"\n(dat_sub_sel <- dat_sub %>%   \n    select(1, matches(\"^i\")))##         aid        imonth iday     iyear\n## 1  57100270      (6) June   23 (95) 1995\n## 2  57101310       (5) May    5 (95) 1995\n## 3  57103171      (6) June   27 (95) 1995\n## 4  57103869      (7) July   14 (95) 1995\n## 5  57104553      (7) July   14 (95) 1995\n## 6  57104649      (6) June   12 (95) 1995\n## 7  57104676       (5) May   31 (95) 1995\n## 8  57109625      (6) June    7 (95) 1995\n## 9  57110897      (6) June   27 (95) 1995\n## 10 57111071    (8) August    3 (95) 1995\n## 11 57111786 (9) September    7 (95) 1995\n## 12 57113943       (5) May   20 (95) 1995\n## 13 57116359      (6) June   24 (95) 1995\n## 14 57117542      (7) July   11 (95) 1995\n## 15 57117997       (5) May   20 (95) 1995\n## 16 57118381       (5) May    6 (95) 1995\n## 17 57118943      (7) July   19 (95) 1995\n## 18 57120005       (5) May   25 (95) 1995\n## 19 57120046    (8) August   20 (95) 1995\n## 20 57120371      (7) July   20 (95) 1995\n#select one column, rename two columns\n(dat_sub_sel %>% \n   select(aid, Month = imonth, Day = iday))##         aid         Month Day\n## 1  57100270      (6) June  23\n## 2  57101310       (5) May   5\n## 3  57103171      (6) June  27\n## 4  57103869      (7) July  14\n## 5  57104553      (7) July  14\n## 6  57104649      (6) June  12\n## 7  57104676       (5) May  31\n## 8  57109625      (6) June   7\n## 9  57110897      (6) June  27\n## 10 57111071    (8) August   3\n## 11 57111786 (9) September   7\n## 12 57113943       (5) May  20\n## 13 57116359      (6) June  24\n## 14 57117542      (7) July  11\n## 15 57117997       (5) May  20\n## 16 57118381       (5) May   6\n## 17 57118943      (7) July  19\n## 18 57120005       (5) May  25\n## 19 57120046    (8) August  20\n## 20 57120371      (7) July  20\n(dat_sub_sel %>% \n   rename(Month = imonth, Day = iday))##         aid         Month Day     iyear\n## 1  57100270      (6) June  23 (95) 1995\n## 2  57101310       (5) May   5 (95) 1995\n## 3  57103171      (6) June  27 (95) 1995\n## 4  57103869      (7) July  14 (95) 1995\n## 5  57104553      (7) July  14 (95) 1995\n## 6  57104649      (6) June  12 (95) 1995\n## 7  57104676       (5) May  31 (95) 1995\n## 8  57109625      (6) June   7 (95) 1995\n## 9  57110897      (6) June  27 (95) 1995\n## 10 57111071    (8) August   3 (95) 1995\n## 11 57111786 (9) September   7 (95) 1995\n## 12 57113943       (5) May  20 (95) 1995\n## 13 57116359      (6) June  24 (95) 1995\n## 14 57117542      (7) July  11 (95) 1995\n## 15 57117997       (5) May  20 (95) 1995\n## 16 57118381       (5) May   6 (95) 1995\n## 17 57118943      (7) July  19 (95) 1995\n## 18 57120005       (5) May  25 (95) 1995\n## 19 57120046    (8) August  20 (95) 1995\n## 20 57120371      (7) July  20 (95) 1995"},{"path":"week1.html","id":"subset-rows-and-columns-filter-and-select","chapter":"1 Week 1","heading":"1.6.2.3 Subset rows and columns: filter() and select()","text":"can combine filter() select() pipe create new data frame subset rows columns:","code":"\n# records with day of month > 15 and the first 3 named columns\n(x <- dat_sub %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday)\n   )##         aid     imonth iday\n## 1  57100270   (6) June   23\n## 2  57103171   (6) June   27\n## 3  57104676    (5) May   31\n## 4  57110897   (6) June   27\n## 5  57113943    (5) May   20\n## 6  57116359   (6) June   24\n## 7  57117997    (5) May   20\n## 8  57118943   (7) July   19\n## 9  57120005    (5) May   25\n## 10 57120046 (8) August   20\n## 11 57120371   (7) July   20"},{"path":"week1.html","id":"create-or-calculate-columns-mutate","chapter":"1 Week 1","heading":"1.6.2.4 Create or calculate columns: mutate()","text":"mutate() create new named columns re-calculate existing columns. make column stratifies birth month, cut June.Although birth month column (h1gi1m) factor, unordered, need make ordered using factor label numeric comparison. Fortunately, factor labels handled correct order:Assign order, create new column, print nicely:June\nOctober\nJune\nOctober\nMay\nOctober\nJune\nSeptember\nMay\nJanuary\nJune\nApril\nMay\nOctober\nJuly\nApril\nMay\nSeptember\nAugust\nOctober\nJuly\nAugust\nMay\nOctober\nJuly\nFebruary\nJuly\nFebruary\nAugust\nOctober\nApril\nJuly\nJuly\nFebruary\nJuly\nApril\nMay\nMay\nJune\nOctober\nsilly example showing mutate() can change values existing columns:… careful!functions can used mutate include (means limited !)if_else(): create column assigning values based logical criteriacase_when(): similar if_else() multiple input valuesrecode(): change particular valuesWhen recoded birth month, output logical data type. wanted create \ncharacter factor, use if_else(). creating new data frame based several operations dat.June\nOctober\nJune\nOctober\nMay\nOctober\nJune\nSeptember\nMay\nJanuary\nJune\nApril\nMay\nOctober\nJuly\nApril\nMay\nSeptember\nAugust\nOctober\nJuly\nAugust\nMay\nOctober\nJuly\nFebruary\nJuly\nFebruary\nAugust\nOctober\nApril\nJuly\nJuly\nFebruary\nJuly\nApril\nMay\nMay\nJune\nOctober\none variables contains multiple values want create classes, use case_when(). verbose example stratifying months quarters. Also using magrittr assignment pipe update input based statement, .e., dat_1 change based commands use. careful using assignment pipe change data frame.case_when() recode order way command written, months quarters, necessary specify ends quarter. Also cases explicitly handled can addressed TRUE ~ ... argument; case, records birth months September get assigned quarter 4.June\nOctober\nJune\nOctober\nMay\nOctober\nJune\nSeptember\nMay\nJanuary\nJune\nApril\nMay\nOctober\nJuly\nApril\nMay\nSeptember\nAugust\nOctober\nJuly\nAugust\nMay\nOctober\nJuly\nFebruary\nJuly\nFebruary\nAugust\nOctober\nApril\nJuly\nJuly\nFebruary\nJuly\nApril\nMay\nMay\nJune\nOctober\nrecode() used change birth_year_half column:","code":"\n# is this ordered?\nis.ordered(dat$h1gi1m)## [1] FALSE\n# what are the levels?\n(levels(dat$h1gi1m))##  [1] \"(1) January\"   \"(2) February\"  \"(3) March\"     \"(4) April\"    \n##  [5] \"(5) May\"       \"(6) June\"      \"(7) July\"      \"(8) August\"   \n##  [9] \"(9) September\" \"(10) October\"  \"(11) November\" \"(12) December\"\n## [13] \"(96) Refused\"\n# make birth month ordered\ndat$h1gi1m <- factor(dat$h1gi1m, ordered = TRUE)\n\n# now is it ordered?\nis.ordered(dat$h1gi1m)## [1] TRUE\n# perform the mutate() using the string representation of the factor for comparison\ndat %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_1st_half = (birth_month < \"(7) July\")) %>% \n    head(20) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n(X <- dat_sub %>% \n     mutate(iday = -1000 + iday))##         aid        imonth iday     iyear    bio_sex        h1gi1m    h1gi1y\n## 1  57100270      (6) June -977 (95) 1995 (2) Female  (10) October (77) 1977\n## 2  57101310       (5) May -995 (95) 1995 (2) Female (11) November (76) 1976\n## 3  57103171      (6) June -973 (95) 1995   (1) Male  (10) October (79) 1979\n## 4  57103869      (7) July -986 (95) 1995   (1) Male   (1) January (77) 1977\n## 5  57104553      (7) July -986 (95) 1995 (2) Female      (6) June (76) 1976\n## 6  57104649      (6) June -988 (95) 1995   (1) Male (12) December (81) 1981\n## 7  57104676       (5) May -969 (95) 1995   (1) Male  (10) October (83) 1983\n## 8  57109625      (6) June -993 (95) 1995   (1) Male     (3) March (81) 1981\n## 9  57110897      (6) June -973 (95) 1995   (1) Male (9) September (81) 1981\n## 10 57111071    (8) August -997 (95) 1995   (1) Male      (6) June (81) 1981\n## 11 57111786 (9) September -993 (95) 1995   (1) Male (9) September (80) 1980\n## 12 57113943       (5) May -980 (95) 1995   (1) Male   (1) January (79) 1979\n## 13 57116359      (6) June -976 (95) 1995   (1) Male     (4) April (80) 1980\n## 14 57117542      (7) July -989 (95) 1995   (1) Male (9) September (79) 1979\n## 15 57117997       (5) May -980 (95) 1995 (2) Female  (10) October (82) 1982\n## 16 57118381       (5) May -994 (95) 1995 (2) Female  (10) October (82) 1982\n## 17 57118943      (7) July -981 (95) 1995 (2) Female     (4) April (79) 1979\n## 18 57120005       (5) May -975 (95) 1995   (1) Male (9) September (82) 1982\n## 19 57120046    (8) August -980 (95) 1995   (1) Male  (10) October (76) 1976\n## 20 57120371      (7) July -980 (95) 1995 (2) Female    (8) August (76) 1976\n##      h1gi4                             h1gi5a\n## 1   (0) No (7) Legitimate skip (not Hispanic)\n## 2   (0) No (7) Legitimate skip (not Hispanic)\n## 3   (0) No (7) Legitimate skip (not Hispanic)\n## 4   (0) No (7) Legitimate skip (not Hispanic)\n## 5   (0) No (7) Legitimate skip (not Hispanic)\n## 6   (0) No (7) Legitimate skip (not Hispanic)\n## 7   (0) No (7) Legitimate skip (not Hispanic)\n## 8   (0) No (7) Legitimate skip (not Hispanic)\n## 9   (0) No (7) Legitimate skip (not Hispanic)\n## 10  (0) No (7) Legitimate skip (not Hispanic)\n## 11  (0) No (7) Legitimate skip (not Hispanic)\n## 12  (0) No (7) Legitimate skip (not Hispanic)\n## 13  (0) No (7) Legitimate skip (not Hispanic)\n## 14  (0) No (7) Legitimate skip (not Hispanic)\n## 15  (0) No (7) Legitimate skip (not Hispanic)\n## 16  (0) No (7) Legitimate skip (not Hispanic)\n## 17  (0) No (7) Legitimate skip (not Hispanic)\n## 18  (0) No (7) Legitimate skip (not Hispanic)\n## 19 (1) Yes                         (1) Marked\n## 20  (0) No (7) Legitimate skip (not Hispanic)\n##                                h1gi5b\n## 1  (7) Legitimate skip (not Hispanic)\n## 2  (7) Legitimate skip (not Hispanic)\n## 3  (7) Legitimate skip (not Hispanic)\n## 4  (7) Legitimate skip (not Hispanic)\n## 5  (7) Legitimate skip (not Hispanic)\n## 6  (7) Legitimate skip (not Hispanic)\n## 7  (7) Legitimate skip (not Hispanic)\n## 8  (7) Legitimate skip (not Hispanic)\n## 9  (7) Legitimate skip (not Hispanic)\n## 10 (7) Legitimate skip (not Hispanic)\n## 11 (7) Legitimate skip (not Hispanic)\n## 12 (7) Legitimate skip (not Hispanic)\n## 13 (7) Legitimate skip (not Hispanic)\n## 14 (7) Legitimate skip (not Hispanic)\n## 15 (7) Legitimate skip (not Hispanic)\n## 16 (7) Legitimate skip (not Hispanic)\n## 17 (7) Legitimate skip (not Hispanic)\n## 18 (7) Legitimate skip (not Hispanic)\n## 19                     (0) Not marked\n## 20 (7) Legitimate skip (not Hispanic)\ndat_1 <- dat %>% \n    filter(iday > 15) %>%\n    head(20) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_year_half = ifelse(test = birth_month < \"(7) July\", yes = \"first\", no = \"last\"))\n\n# make that a factor\ndat_1$birth_year_half <- factor(dat_1$birth_year_half, levels = c(\"first\", \"last\"))\n    \n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\ndat_1 %<>% \n    mutate(quarter = case_when(\n        birth_month < \"(3) March\" ~ 1,\n        birth_month < \"(6) June\" ~ 2,\n        birth_month < \"(9) September\" ~ 3,\n        TRUE ~ 4))\n\n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n(dat_1 %<>% \n     mutate(birth_year_half_split = recode(birth_year_half,\n                   \"first\" = \"early\",\n                   \"last\" = \"late\")))##         aid     imonth iday   birth_month birth_year_half quarter\n## 1  57100270   (6) June   23  (10) October            last       4\n## 2  57103171   (6) June   27  (10) October            last       4\n## 3  57104676    (5) May   31  (10) October            last       4\n## 4  57110897   (6) June   27 (9) September            last       4\n## 5  57113943    (5) May   20   (1) January           first       1\n## 6  57116359   (6) June   24     (4) April           first       2\n## 7  57117997    (5) May   20  (10) October            last       4\n## 8  57118943   (7) July   19     (4) April           first       2\n## 9  57120005    (5) May   25 (9) September            last       4\n## 10 57120046 (8) August   20  (10) October            last       4\n## 11 57120371   (7) July   20    (8) August            last       3\n## 12 57121476    (5) May   20  (10) October            last       4\n## 13 57123494   (7) July   21  (2) February           first       1\n## 14 57129567   (7) July   26  (2) February           first       1\n## 15 57130633 (8) August   26  (10) October            last       4\n## 16 57131909  (4) April   27      (7) July            last       3\n## 17 57133772   (7) July   19  (2) February           first       1\n## 18 57134457   (7) July   18     (4) April           first       2\n## 19 57136630    (5) May   16       (5) May           first       2\n## 20 57139880   (6) June   19  (10) October            last       4\n##    birth_year_half_split\n## 1                   late\n## 2                   late\n## 3                   late\n## 4                   late\n## 5                  early\n## 6                  early\n## 7                   late\n## 8                  early\n## 9                   late\n## 10                  late\n## 11                  late\n## 12                  late\n## 13                 early\n## 14                 early\n## 15                  late\n## 16                  late\n## 17                 early\n## 18                 early\n## 19                 early\n## 20                  late"},{"path":"week1.html","id":"summarizingaggregating-data","chapter":"1 Week 1","heading":"1.6.2.5 Summarizing/aggregating data","text":"spend time later course data summaries, introduction dplyr worthwhile introducing stage. two main functions summarise() group_by().simple summary tabulate count respondents mean age. filter ! str_detect(h1gi1y, \"Refused\") drops records respondents refused give birth year.summarize age sex using group_by() function, also piping prop_table() get percentage:","code":"\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    summarise(n = n(),\n              mean_age = mean(yeari - yearb))##      n mean_age\n## 1 6501 16.03676\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    group_by(bio_sex) %>% \n    summarise(mean_age = mean(yeari - yearb),\n              sd_age = sd(yeari - yearb),\n              n = n(),\n              .groups = \"drop_last\") %>% \n    mutate(pct = prop.table(n) * 100)## # A tibble: 2 x 5\n##   bio_sex    mean_age sd_age     n   pct\n##   <fct>         <dbl>  <dbl> <int> <dbl>\n## 1 (1) Male       16.1   1.77  3147  48.4\n## 2 (2) Female     16.0   1.77  3354  51.6"},{"path":"week1.html","id":"purrr-efficient-iterating-over-elements-in-vectors-and-lists","chapter":"1 Week 1","heading":"1.6.2.6 purrr: efficient iterating over elements in vectors and lists","text":"attention paid purrr lesson functions.workhorse function purrr map(), applies function list atomic vector.brief example uses vector c(9, 16, 25) map() function used get square root element. output listOther resources purrr: Learn purrr, purrr tutorial","code":"\n# apply the sqrt() function to each element of a vector of integers\nmap(c(9, 16, 25), sqrt)## [[1]]\n## [1] 3\n## \n## [[2]]\n## [1] 4\n## \n## [[3]]\n## [1] 5"},{"path":"week1.html","id":"datasets001","chapter":"1 Week 1","heading":"1.7 Data sets","text":"","code":""},{"path":"week1.html","id":"babushkin1","chapter":"1 Week 1","heading":"1.7.1 Edward Babushkin’s Employee turnover data","text":"data used CSDE 533: Edward Babushkin’s employee turnover data, explained bit kaggle.com downloadable file.load data set URL:Just get bit tidyverse last minute, let’s get mean standard deviation job tenure gender 10-year age class:Rendered 2022-03-04 00:42:04","code":"\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n# create 10-year age classes \netdata %<>% \n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling)) \n\n# summarize\netdata %>% \n    # group by gender and age class\n    group_by(gender, age_decade) %>% \n    # mean and sd\n    summarize(mean_tenure_months = mean(tenure) %>% round(1),\n              sd_tenure_months = sd(tenure) %>% round(1), \n              .groups = \"keep\") %>% \n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>% \n    # print it nicely\n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))"},{"path":"week1.html","id":"source-code-1","chapter":"1 Week 1","heading":"1.8 Source code","text":"File H:/csde502-winter-2022-main/01-week01.Rmd.","code":""},{"path":"week1.html","id":"r-code-used-in-this-document-1","chapter":"1 Week 1","heading":"1.8.1 R code used in this document","text":"","code":"\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# this course's URL\nmyurl <- \"https://csde-uw.github.io/csde502-winter-2022\"\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\nprint(is(\"a\"))\n\nprint(str(TRUE))\n\nprint(class(123.45))\n\nprint(class(as.integer(1000)))\n\nn <- as.numeric(999999999999999999999)\n\nprint(class(n))\n# evaluate as logical, test whether 1 is greater than two\na <- 1 > 2\n# create two numerical values, one being NA, representing ages\nage_john <- 39\nage_jane <- NA\n\n# logical NA from Jane's undefined age\n(jo <- age_john > 50)\n(ja <- age_jane > 50)\n(t <- as.logical(1))\n(f <- as.logical(0))\ni <- as.integer(999999999999999999999)\n\nprint(class(i))\nprint(class(\"Café\"))\n# this is a character\nmy_zip <- \"98115\"\n\n# it is not numeric.\nmy_zip + 2\n# we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values\nas.numeric(my_zip) + 2\n\n# Boston has ZIP codes starting with zeros\nboston_zip <- \"02134\"\nas.numeric(boston_zip)\nprint(charToRaw(\"z\"))\n\nclass(charToRaw(\"z\"))\n# create a vector of length 1\na <- 1\nis(a)\nc(1, \"a\", TRUE, charToRaw(\"z\"))\n(c(1:3, TRUE, FALSE))\nc(1:3, TRUE, FALSE, \"awesome!\")\n# a vector \n(v <- c(1, 3, 2))\n\n(sort(v))\n# create a random normal \nset.seed(5)\nnormvec1000 <- rnorm(n = 1000)\n\nlength(normvec1000)\nclass(normvec1000)\nclass(normvec1000 > 1)\nv <- seq(from = 0, to = 10, by = 2)\nv[4]\n# make a vector 1 to 100\n(v <- 1:100)\n\n# load to a matrix\n(m1 <- matrix(v, ncol = 10, byrow = TRUE))\n\n# different r, c ordering\n(m2 <- matrix(v, ncol = 10, byrow = FALSE))\n(m3 <- matrix(letters, ncol = 10, nrow = 10))\n# a vector 1 to 27\nv <- 1:27\n\n# create an array, 3 x 3 x 3\n(a <- array(v, dim = c(3, 3, 3)))\n\n# array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3:\n(a[1,2,3])\n(l <- list(\"a\", 1, TRUE))\n(l <- list(\"a\", \n           1:20, \n           as.logical(c(0,1,1,0))))\n# show the data types\n(lapply(X = l, FUN = class))\n\n# mean, maybe?\n(lapply(X = l, FUN = function(x) {mean(x)}))\n(income <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\"))\nsort(income)\n# create a factor from income and set the levels\n(income_factor <- factor(x = income, levels = income))\n\n# sort again\n(sort(income_factor))\n# income levels \ninc <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\")\n\nBMI <-  data.frame(\n   sid = c(\"A1001\", \"A1002\", \"B1001\"),\n   gender = c(\"Male\", \"Male\",\"Female\"), \n   height_cm = c(152, 171.5, 165), \n   weight_kg = c(81, 93, 78),\n   age_y = c(42, 38, 26),\n   income = factor(c(\"$50,000-$99,999\", \"$100,000-$200,000\", \"<$10,000\"), levels = inc)\n)\nprint(BMI)\n# load pacman if necessary\npackage.check <- lapply(\"pacman\", FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n        install.packages(x, dependencies = TRUE)\n        library(x, character.only = TRUE)\n    }\n})\n\n# load readstata13 if necessary\npacman::p_load(readstata13)\n\n# read the dta file\ndat <- readstata13::read.dta13(file.path(myurl, \"data/AHwave1_v1.dta\"))\nx <- data.frame(colname = names(dat), label = attributes(dat)$var.labels)\nDT::datatable(data = x, caption = \"Column names and labels in AHwave1_v1.dta.\")\nhead(iris)\niris %>% head()\nmean(iris[iris$Species == 'setosa', \"Sepal.Length\"])\niris %>% filter(Species == 'setosa') %>% summarise(mean(Sepal.Length))\n# numeric tests\n(1 == 2)\n(1 == 3 - 2)\n# character test (actually a factor)\n(dat$imonth %>% head() %>% str_c(collapse = \", \"))\n((dat$imonth == \"(6) June\") %>% head())\n# character test for multiple patterns\n(dat$imonth %in% c(\"(6) June\", \"(7) July\") %>% head())\n1 < 2\n1 > 2\n1 <= -10:10\n1 >= -10:10\n1 != 2\n# those of the first 6 days that are not 14\n(dat$iday %>% head())\n((dat$iday != 14) %>% head())\ndat$imonth %>% head(20)\n((!dat$imonth %in% c(\"(6) June\", \"(7) July\")) %>% head(20))\n# first 20 records, fist 10 columns\ndat_sub <- dat[1:20, 1:10]\nkable(dat_sub, format = \"html\") %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# from May\n(dat_sub %>% filter(imonth == \"(5) May\"))\n(dat_sub %>% filter(imonth == \"(5) May\" & bio_sex == \"(2) Female\"))\n(dat_sub %>% filter(imonth == \"(5) May\" & (bio_sex == \"(2) Female\") | iday < 15))\n\n# select 3 columns\n(dat_sub_sel <- dat_sub %>%   \n    select(\"aid\", \"imonth\", \"iday\"))\n# select all but two named columns\n(dat_sub_sel <- dat_sub %>%   \n    select(-\"imonth\", -\"iday\"))\n# select columns by position and whose name matches a pattern, in this case the regular expression \"^i\" meaning \"starts with lowercase i\"\n(dat_sub_sel <- dat_sub %>%   \n    select(1, matches(\"^i\")))\n#select one column, rename two columns\n(dat_sub_sel %>% \n   select(aid, Month = imonth, Day = iday))\n(dat_sub_sel %>% \n   rename(Month = imonth, Day = iday))\n# records with day of month > 15 and the first 3 named columns\n(x <- dat_sub %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday)\n   )\n# is this ordered?\nis.ordered(dat$h1gi1m)\n# what are the levels?\n(levels(dat$h1gi1m))\n# make birth month ordered\ndat$h1gi1m <- factor(dat$h1gi1m, ordered = TRUE)\n\n# now is it ordered?\nis.ordered(dat$h1gi1m)\n# perform the mutate() using the string representation of the factor for comparison\ndat %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_1st_half = (birth_month < \"(7) July\")) %>% \n    head(20) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n(X <- dat_sub %>% \n     mutate(iday = -1000 + iday))\ndat_1 <- dat %>% \n    filter(iday > 15) %>%\n    head(20) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_year_half = ifelse(test = birth_month < \"(7) July\", yes = \"first\", no = \"last\"))\n\n# make that a factor\ndat_1$birth_year_half <- factor(dat_1$birth_year_half, levels = c(\"first\", \"last\"))\n    \n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\ndat_1 %<>% \n    mutate(quarter = case_when(\n        birth_month < \"(3) March\" ~ 1,\n        birth_month < \"(6) June\" ~ 2,\n        birth_month < \"(9) September\" ~ 3,\n        TRUE ~ 4))\n\n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n(dat_1 %<>% \n     mutate(birth_year_half_split = recode(birth_year_half,\n                   \"first\" = \"early\",\n                   \"last\" = \"late\")))\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    summarise(n = n(),\n              mean_age = mean(yeari - yearb))\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    group_by(bio_sex) %>% \n    summarise(mean_age = mean(yeari - yearb),\n              sd_age = sd(yeari - yearb),\n              n = n(),\n              .groups = \"drop_last\") %>% \n    mutate(pct = prop.table(n) * 100)\n# apply the sqrt() function to each element of a vector of integers\nmap(c(9, 16, 25), sqrt)\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n# create 10-year age classes \netdata %<>% \n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling)) \n\n# summarize\netdata %>% \n    # group by gender and age class\n    group_by(gender, age_decade) %>% \n    # mean and sd\n    summarize(mean_tenure_months = mean(tenure) %>% round(1),\n              sd_tenure_months = sd(tenure) %>% round(1), \n              .groups = \"keep\") %>% \n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>% \n    # print it nicely\n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week1.html","id":"complete-rmd-code-1","chapter":"1 Week 1","heading":"1.8.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 1 {#week1}\n\n```{r, echo=FALSE, message=FALSE, error=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# this course's URL\nmyurl <- \"https://csde-uw.github.io/csde502-winter-2022\"\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\n<h2>Topics:<\/h2>\n* [Getting started on terminal server 4](#gettingstarted)\n* [Introduction to R/RStudio/R Markdown](#intrormd)\n* [R data types](#rdatatypes)\n* [R data structures](#rdatastructures)\n* [File systems](#filesystems)\n* [Data manipulation in the `tidyverse`](#tidyverse)\n* [Data sets:](#datasets001)\n    * Employee turnover data\n    \n<hr>\nToday's lessons will cover getting started with computing at CSDE, and quickly introduce R, RStudio, and R Markdown.\n\nIt is assumed that students in this course have a basic working knowledge of using R, including how to create variables with the assignment operator (\"`<-`\"), and how to run simple functions(e.g., `mean(dat$age)`). Often in courses that include using R for statistical analysis, some of the following foundations are not explained fully. This section is not intended to be a comprehensive treatment of R data types and structures, but should provide some background for students who are either relatively new at using R or who have not had a systematic introduction.    \n\nThe other main topic for today is [`tidyverse`](https://www.tidyverse.org/), which refers to a related set of R packages for data management, analysis, and display. See Hadley Wickham's [tidy tools manifesto](https://tidyverse.tidyverse.org/articles/manifesto.html) for the logic behind the suite of tools. For a brief description of the specific R packages, see [Tidyverse packages](https://www.tidyverse.org/packages/). This is not intended to be a complete introduction to the `tidyverse`, but should provide sufficient background for data handling to support most of the technical aspects of the rest of the course and CSDE 533.\n\n## Getting started on Terminal Server 4 {#gettingstarted}\nFirst, if you are not on campus, make sure you have the Husky OnNet VPN application running and have connected to the UW network. You should see the f5 icon in your task area:\n\n![](images/week01/2021-01-07_21_40_25-.png)\n\nConnect to TS4: `csde-ts4.csde.washington.edu`\n\nIf you are using the Windows Remote Desktop Protocol (RDP) connection, your connection parameters should look like this:\n\n![](images/week01/2021-01-07_21_48_03-Remote Desktop Connection.png)\n\nIf you are using mRemoteNG, the connection parameters will match this:\n\n![](images/week01/2021-01-07_21_37_36-Window.png)\n\nOnce you are connected you should see a number of icons on the desktop and application shortcuts in the Start area.\n\n![](images/week01/2021-01-07_21_59_38-.png)\n\n![](images/week01/2021-01-07_22_00_14-Window.png)\n\nOpen a Windows Explorer (if you are running RDP in full screen mode you should be able to use the key combination Win-E).\n\nBefore doing anything, let's change some of the annoying default settings of the Windows Explorer. Tap `File > Options`. In the `View` tab, make sure that `Always show menus` is checked and `Hide extensions for known file types` is unchecked. The latter setting is very important because we want to see the complete file name for all files at all times.\n\n![](images/week01/2021-01-07_22_30_46-Folder_Options.png)\n\nClick `Apply to Folders` so that these settings become default. Click `Yes` to the next dialog.\n\n![](images/week01/2021-01-07_22_31_37-FolderViews.png)\n\nNow let's make a folder for the files in this course.\n\nNavigate to This PC:\n\n![](images/week01/2021-01-07_22_05_59-Window.png)\n\nYou should see the `H:` drive. This is is the mapped drive that links to your [U Drive](https://itconnect.uw.edu/wares/online-storage/u-drive-central-file-storage-for-users/), and is the place where all of the data for this course is to be stored. __Do not store any data on the `C:` drive!__ The `C:` drive can be wiped without any prior notification.\n\n__Be very careful with your files on the U Drive!__ If you delete files, there is no \"undo\" functionality. When you are deleting files, you will get a warning that you should take seriously:\n\n![](images/week01/2021-01-07_23_01_10-Delete_Folder.png)\n\nNavigate into `H:` and create a new folder named `csde502_winter_2022`. Note the use of lowercase letters and underscores rather than spaces. This will be discussed in the section on file systems later in this lesson.\n\n![](images/week01/2021-01-07_22_32_29-new_folder.png)\n\n## Introduction to R Markdown in RStudio {#intrormd}\n\n### Create a project\nNow we will use RStudio to create the first R Markdown source file and render it to HTML.\n\nStart RStudio by either dbl-clicking the desktop shortcut or navigating to the alphabetical R section of the Start menu:\n\n![](images/week01/2021-01-07_23_05_49-Window.png)\n\n:::{.rmdnote}\nA brief aside: install R packages.\n\nTo get started, because it usually takes some time to install, open a second RStudio session and at the console, to install `tidyverse`, the other packages for CSDE 502 and 533, and for this lesson, download the file [`packages.R`](tools/packages.R).\n\nOpen the file in your second RStudio session and in the upper right of the source code pane, click `Source > Source`.\n\n![](images/week01/2022-01-06 21_47_15-source.png)\n\nNow continue on with the lesson in your original RStudio session.....\n:::\n\nCreate a new project (`File > New Project...`).\n\n![](images/week01/2021-01-07_23_08_34-rstudiorappbroker.csde.washington.edu.png)\n\nSince we just created the directory to house the project, select `Existing Directory`.\n\n![](images/week01/2021-01-07_23_09_11-csde502_winter_2021_course-RStudiorappbroker.csde.washington.edu.png)\n\nNavigate to that directory and select `Open`.\n\n![](images/week01/2021-01-07_23_09_48-ChooseDirectoryrappbroker.csde.washington.edu.png)\n\nClick `Create Project`.\n\n![](images/week01/2021-01-07_23_10_02-csde502_winter_2021_course-RStudiorappbroker.csde.washington.edu.png)\n\nYou will now have a blank project with only the project file.\n\n![](images/week01/2021-01-07_23_11_16-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\n### Create an R Markdown file from built-in RStudio functionality\nLet's make an R Markdown file (`File > New File > R Markdown...`).\n\n![](images/week01/2021-01-07_23_12_31-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nDo not change any of the metadata ... this is just for a quick example.\n\n![](images/week01/2021-01-07_23_13_41-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nClick `OK` and then name the file `week_01.Rmd`.\n\n![](images/week01/2021-01-07_23_14_59-SaveFile-Untitled1rappbroker.csde.washington.edu.png)\n\n#### Render the Rmd file as HTML\n\nAt the console prompt, enter `R Markdown::render(\"W` and tap the `TAB` key. This should bring up a list of files that have the character \"w\" in the file name. Click `week_01.Rmd`.\n\nThe syntax here means \"run the `render()` function from the `R Markdown` package on the file `week_01.Rmd`\"\n\n![](images/week01/2021-01-07_23_15_32-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nAfter a few moments, the process should complete with a message that the output has been created.\n\n![](images/week01/2021-01-07_23_16_13-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nIf the HTML page does not open automatically, look for `week_01.html` in the list of files. Click it and select `View in Web Browser`.\n\n![](images/week01/2021-01-07_23_16_39-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nYou will now see the bare-bones HTML file.\n\n![](images/week01/2021-01-07_23_17_10-Untitled.png)\n\nCompare the output of this file with the source code in `week_01.Rmd`. Note there are section headers that begin with hash marks, and R code is indicated with the starting characters \n\n<code>\n\\`\\`\\`\\{r\\}\n<\/code>\n\nand the ending characters\n\n<code>\n\\`\\`\\`\n<\/code>\n\nNext, we will explore some enhancements to the basic R Markdown syntax.\n\n### Create an R Markdown file with some enhancements\n\nDownload this version of [`week_01.Rmd`](files/week_01.Rmd) and overwrite the version you just created.\n\nIf RStudio prints a message that some packages are required but are not installed, click `Install`.\n\n![](images/week01/2021-01-07_23_26_55-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nChange line 3 to include your name and e-mail address as shown. \n\n![](images/week01/2021-01-08_00_35_18-Window.png)\n\n#### Render and view the enhanced output\nRepeat the rendering process (`R Markdown::render(\"Week_01.Rmd\")`) \n\nThe new HTML file has a number of enhancements, including a mailto: hyperlink for your name, a table of contents at the upper left, a table that is easier to read, a Leaflet map, captions and cross-references for the figures and table, an image derived from a PNG file referenced by a URL, the code used to generate various parts of the document that are produced by R code, and the complete source code for the document. A downloadable version of the rendered file: [week_01.html](files/week_01.html).\n\n![](images/week01/2021-01-08_00_19_27-Week01.png)\n\nIncluding the source code for the document is especially useful for readers of your documents because it lets them see exactly what you did. An entire research chain can be documented in this way, from reading in raw data, performing data cleaning and analysis, and generating results.\n\n## R data types {#rdatatypes}\nYou may want to download the file [week01.Rmd](files/week01/week01.R), which contains many of the examples below.\n\nThere are six fundamental data types in R:\n\n1. logical\n1. numeric\n1. integer\n1. complex\n1. character\n1. raw\n\nThe most atomic object in R will exist having one of those data types, described below. An atomic object of the data type can have a value, `NA` which represents an observation with no data (e.g., a missing measurement), or `NULL` which isn't really a value at all, but can still have the data type class.\n\nYou will encounter other data types, such as `Date` or `POSIXct` if you are working with dates or time stamps. These other data types are extensions of the fundamental data types.\n\nTo determine what data type an object is, use `is(obj)`, `str(obj)`, or `class(obj)`. \n\n```{r}\nprint(is(\"a\"))\n\nprint(str(TRUE))\n\nprint(class(123.45))\n\nprint(class(as.integer(1000)))\n\nn <- as.numeric(999999999999999999999)\n\nprint(class(n))\n```\n\n### Logical\nUse `logical` values for characteristics that are either `TRUE` or `FALSE`. Note that if `logical` elements can also have an `NA` value if the observation is missing. In the following examples, \n\n```{r}\n# evaluate as logical, test whether 1 is greater than two\na <- 1 > 2\n```\n\n```{r}\n# create two numerical values, one being NA, representing ages\nage_john <- 39\nage_jane <- NA\n\n# logical NA from Jane's undefined age\n(jo <- age_john > 50)\n(ja <- age_jane > 50)\n```\n\nLogical values are often expressed in binary format as 0 = `FALSE` and ` = `TRUE`. in R these values are interconvertible. Other software (e.g., Excel, MS Access) may convert logical values to numbers that you do not expect.\n\n```{r}\n(t <- as.logical(1))\n(f <- as.logical(0))\n```\n\n### Numeric\n`Numeric` values are numbers with range about 2e-308 to 2e+308, depending on the computer you are using. You can see the possible range by entering `.Machine` at the R console. These can also include decimals. For more information, see [Double-precision floating-point format](https://en.wikipedia.org/wiki/Double-precision_floating-point_format)\n\n\n### Integer\n`Integer` values are numerical, but can only take on whole, rather than fractional values, and have a truncated range compared to `numeric`. For example, see below, if we try to create an integer that is out of range. The object we created is an integer, but because it is out of range, is value is set to `NA`.\n\n```{r}\ni <- as.integer(999999999999999999999)\n\nprint(class(i))\n```\n\n### Complex\nThe `complex` type is used in mathematics and you are unlikely to use it in applied social science research unless you get into some heavy statistics. See [Complex number](https://en.wikipedia.org/wiki/Complex_number) for a full treatment.\n\n### Character\n`Character` data include the full set of keys on your keyboard that print out a character, typically [A-Z], [a-z], [0-9], punctuation, etc. The full set of ASCII characters is supported, e.g. the `accent aigu` in CafÃ©:\n\n```{r}\nprint(class(\"CafÃ©\"))\n```\n\nAlso numbers can function as characters. Be careful in converting between numerical and character versions. For example, see these ZIP codes:\n\n```{r error=TRUE}\n# this is a character\nmy_zip <- \"98115\"\n\n# it is not numeric.\nmy_zip + 2\n```\n\n```{r}\n# we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values\nas.numeric(my_zip) + 2\n\n# Boston has ZIP codes starting with zeros\nboston_zip <- \"02134\"\nas.numeric(boston_zip)\n```\n\n### Raw\n`Raw` values are used to store raw bytes in hexadecimal format. You are unlikely to use it in applied social science research. For example, the hexadecimal value for the character `z` is `7a`:\n\n```{r}\nprint(charToRaw(\"z\"))\n\nclass(charToRaw(\"z\"))\n```\n\n\n## R data structures {#rdatastructures}\n\n![](images/week02/data_structures.png)\n\nThere are 5 basic data structures in R, as shown in the graphic: \n\n1. vector\n1. matrix\n1. array\n1. list\n1. data frame\n\nIn addition, the `factor` data type is very important\n\n### Vector\nA vector is an ordered set of elements of one or more elements of the same data type and are created using the `c()` constructor function. For example, a single value is a vector:\n\n```{r}\n# create a vector of length 1\na <- 1\nis(a)\n```\n\n\nIf you try creating a vector with mixed data types, you may get unexpected results; mixing character elements with other type elements will result in character representations, e.g., \n\n```{r}\nc(1, \"a\", TRUE, charToRaw(\"z\"))\n```\n\nResults will depend on the data type you are mixing, for example because logical values can be expressed numerically, the `TRUE` and `FALSE` values are converted to `1` and `0`, respectively.\n\n```{r}\n(c(1:3, TRUE, FALSE))\n```\n\nBut if a character is added, all elements are converted to characters.\n\n```{r}\nc(1:3, TRUE, FALSE, \"awesome!\")\n```\n\nOrder is important, i.e., \n\n`1, 2, 3` is not the same as `1, 3, 2`\n\nR will maintain the order of elements in vectors unless a process is initiated that changes the order of those elements:\n\n```{r}\n# a vector \n(v <- c(1, 3, 2))\n\n(sort(v))\n```\n\nYou can get some information about vectors, such as length and data type:\n\n```{r}\n# create a random normal \nset.seed(5)\nnormvec1000 <- rnorm(n = 1000)\n\nlength(normvec1000)\nclass(normvec1000)\nclass(normvec1000 > 1)\n```\n\nElements of vectors are specified with their index number (1 .. n):\n\n```{r}\nv <- seq(from = 0, to = 10, by = 2)\nv[4]\n```\n\n### Matrix\nA matrix is like a vector, in that it an contain only one data type, but it is two-dimensional, having rows and columns. A simple example:\n\n```{r}\n# make a vector 1 to 100\n(v <- 1:100)\n\n# load to a matrix\n(m1 <- matrix(v, ncol = 10, byrow = TRUE))\n\n# different r, c ordering\n(m2 <- matrix(v, ncol = 10, byrow = FALSE))\n```\n\nIf you try to force a vector into a matrix whose row $\\times$ col length does not match the length of the vector, the elements will be recycled, which may not be what you want. At least R will give you a warning.\n\n```{r}\n(m3 <- matrix(letters, ncol = 10, nrow = 10))\n```\n\n### Array\nAn array is similar to matrix, but it can have more than one dimension. These can be useful for analyzing time series data or other multidimensional data. We will not be using array data in this course, but a simple example of creating and viewing the contents of an array:\n\n```{r}\n# a vector 1 to 27\nv <- 1:27\n\n# create an array, 3 x 3 x 3\n(a <- array(v, dim = c(3, 3, 3)))\n\n# array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3:\n(a[1,2,3])\n```\n\n### List\nR lists are ordered collections of objects that do not need to be of the same data type. Those objects can be single-value vectors, multiple-value vectors, matrices, data frames, other lists, etc. Because of this, lists are a very flexible data type. But because they can have as little or as much structure as you want, can become difficult to manage and analyze.\n\nHere is an example of a list comprised of single value vectors of different data type. Compare this with the attempt to make a vector comprised of elements of different data type:\n\n```{r}\n(l <- list(\"a\", 1, TRUE))\n```\n\nLet's modify that list a bit:\n\n```{r}\n(l <- list(\"a\", \n           1:20, \n           as.logical(c(0,1,1,0))))\n```\n\nThe top-level indexing for a list is denoted using two sets of square brackets. For example, the first element of our list can be accessed by `l[[1]]`. For example, the mean of element 2 is obtained by `mean(l[[2]])`: ``r mean(l[[2]])``.\n\nTo perform operations on all elements of a list, use `lapply()`:\n\n```{r}\n# show the data types\n(lapply(X = l, FUN = class))\n\n# mean, maybe?\n(lapply(X = l, FUN = function(x) {mean(x)}))\n```\n### Factor\nFactors are similar to vectors, in that they are one-dimensional ordered sets. However, factors also use informational labels. For example, you may have a variable with household income as a text value:\n\n* \"<$10,000\"\n* \"$10,000-$549,999\"\n* \"$50,000-$99,999\"\n* \"$100,000-$200,000\"\n* \">$200,000\"\n\nAs a vector:\n\n```{r}\n(income <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\"))\n```\n\nBecause these are characters, they do not sort in proper numeric order:\n\n```{r}\nsort(income)\n```\n\nIf these are treated as a factor, the levels can be set for proper ordering:\n\n```{r}\n# create a factor from income and set the levels\n(income_factor <- factor(x = income, levels = income))\n\n# sort again\n(sort(income_factor))\n```\n\nAs a factor, the data can also be used in statistical models and the magnitude of the variable will also be correctly ordered.\n\n### Data frame\nOther than vectors, data frames are probably the most used data type in R. You can think of data frames as matrices that allow columns with different data type. For example, you might have a data set that represents subject IDs as characters, sex or gender as text, height, weight, and age as numerical values, income as a factor, and smoking status as logical. Because a matrix requires only one data type, it would not be possible to store all of these as a matrix. An example:\n\n```{r}\n# income levels \ninc <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\")\n\nBMI <-  data.frame(\n   sid = c(\"A1001\", \"A1002\", \"B1001\"),\n   gender = c(\"Male\", \"Male\",\"Female\"), \n   height_cm = c(152, 171.5, 165), \n   weight_kg = c(81, 93, 78),\n   age_y = c(42, 38, 26),\n   income = factor(c(\"$50,000-$99,999\", \"$100,000-$200,000\", \"<$10,000\"), levels = inc)\n)\nprint(BMI)\n```\n\n## File systems {#filesystems}\nAlthough a full treatment of effective uses of file systems is beyond the scope of this course, a few basic rules are worth covering:\n\n1. Never use spaces in folder or file names. \n    Ninety-nine and 44/100ths percent of the time, most modern software will have no problems handling file names with spaces. But that 0.56% of the time when software chokes, you may wonder why your processes are failing. If your directly and file names do not have spaces, then you can at least rule that out!\n1. Use lowercase letters in directory and file names.\n    In the olden days (MS-DOS), there was not case sensitivity in file names. UNIX has has always used case sensitive file names. So \n    `MyGloriousPhDDissertation.tex` and `mygloriousphddissertation.tex` could actually be different files. Macs, being based on a UNIX kernel, also employ case sensitivity in file names. But Windows? No. Consider the following: there cannot be both `foo.txt` and `FOO.txt` in the same directory. \n    ![](images/week01/2021-01-08_01_13_50-CommandPrompt.png)\n    \n    So if Windows doesn't care, why should we? Save yourself some keyboarding time and confusion by using only lowercase characters in your file names.\n1. Include dates in your file names.\n    If you expect to have multiple files that are sequential versions of a file in progress, an alternative to using a content management system such as [git](https://git-scm.com/), particularly for binary files such as Word documents or SAS data files, is to have multiple versions of the files but including the date as part of the file name. If you expect to have multiple versions on the same date, include a lowercase alphabetical character; it is improbable that you would have more than 26 versions of a fine on a single calendar date. If you are paranoid, use a suffix number `0000`, `0002` .. `9999`. If you have ten thousand versions of the same file on a given date, you are probably doing something that is not right.\n    Now that you are convinced that including dates in file names is a good idea, _please_ use the format `yyyy-mm-dd` or `yyyymmdd`. If you do so, your file names will sort in temporal order.\n1. Make use of directories! \n   Although a folder containing 100,000 files can be handled programatically (if file naming conventions are used), it is not possible for a human being to visually scan 100,000 file names. If you have a lot of files for your project, consider creating directories, e.g., \n       - raw_data\n       - processed_data\n       - analysis_results\n       - scripts\n       - manuscript\n1. Agonize over file names. \n    Optimally when you look at your file names, you will be able to know something about the content of the file. We spend a lot of time doing analysis and creating output. Spending an extra minute thinking about good file names is time well spent.\n\n\n## Data manipulation in the `tidyverse` {#tidyverse}\nOne of the R packages we will use frequently is [`tidyverse`](https://www.tidyverse.org/packages/), which is itself a collection of several other packages, each with a specific domain: \n\n* `ggplot2` (graphics)\n* `dplyr` (data manipulation)\n* `tidyr` (reformatting data for efficient processing)\n* `readr` (reading rectangular R x C data)\n* `purrr` (functional programming, e.g., to replace `for()` loops)\n* `tibble` (enhanced data frames)\n* `stringr` (string, i.e., text manipulation)\n* `forcats` (handling factor, i.e., categorical variables)\n\nWe will touch on some of these during this course, but there will not be a full review or treatment of the `tidyverse`.\n\nThis section will introduce some of the main workhorse functions in tidy data handling. \n\nInstalling tidyverse is straightforward but it may take some time to download and install all of the packages. If you have not done so yet, use\n\n```\ninstall.packages(\"tidyverse\")\n```\n\nFor today's lesson we will be using one of the Add Health public use data sets, [AHwave1_v1.dta](data/AHwave1_v1.dta). \n\n```{r warning=FALSE, message=FALSE}\n# load pacman if necessary\npackage.check <- lapply(\"pacman\", FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n        install.packages(x, dependencies = TRUE)\n        library(x, character.only = TRUE)\n    }\n})\n\n# load readstata13 if necessary\npacman::p_load(readstata13)\n\n# read the dta file\ndat <- readstata13::read.dta13(file.path(myurl, \"data/AHwave1_v1.dta\"))\n```\n\nThe data set includes variable labels, which make handling the data easier. Here we print the column names and their labels. Wrapping this in a `DT::data_table` presents a nice interface for showing only a few variables at a time and that allows sorting and searching.\n\n```{r}\nx <- data.frame(colname = names(dat), label = attributes(dat)$var.labels)\nDT::datatable(data = x, caption = \"Column names and labels in AHwave1_v1.dta.\")\n```\n\n\n### magrittr{#magrittr}\n![](images/week02/unepipe.jpeg)\n\nThe R package [`magrittr`](https://cran.r-project.org/web/packages/magrittr/index.html) allows the use of \"pipes\". In UNIX, pipes were used to take the output of one program and to feed as input to another program. For example, the UNIX command `cat` prints the contents of a text file. This would print the contents of the file `00README.txt`:\n\n```cat 00README.txt```\n\nbut with large files, the entire contents would scroll by too fast to read. Using a \"pipe\", denoted with the vertical bar character `|` allowed using the `more` command to print one screen at a time by tapping the `Enter` key for each screen full of text:\n\n```cat 00README.txt | more```\n\nAs shown in these two screen captures:\n\n![](images/week02/cat_more.png)\n\n![](images/week02/cat_more2.png)\n\nThe two main pipe operators we will use in `magrittr` are `%>%` and '%<>%'.\n\n`%>%` is the pipe operator, which functions as a UNIX pipe, that is, to take something on the left hand side of the operator and feed it to the right hand side. \n\n`%<>%` is the assignment pipe operator, which takes something on the left hand side of the operator, feeds it to the right hand side, and replaces the object on the left-hand side.\n\nFor a simple example of the pipe, to list only the first 6 lines of a data frame in base R, we use `head()`, e.g.,\n\n```{r}\nhead(iris)\n```\n\nusing a tidy version of this:\n\n```{r}\niris %>% head()\n```\n\nIn the R base version, we first read `head`, so we know we will be printing the first 6 elements of something, but we don't know what that \"something\" is. We have to read ahead to know we are reading the first 6 records of `iris`. In the tidy version, we start by knowing we are doing something to the data set, after which we know we are printing the first 6 records.\n\nIn base R functions, the process is evaluated from the inside out. For example, to get the mean sepal length of the _setosa_ species in iris, we would do this:\n\n```{r}\nmean(iris[iris$Species == 'setosa', \"Sepal.Length\"])\n```\n\nFrom the inside out, we read that we are making a subset of `iris` where Species = \"setosa\", we are selecting the column \"Sepal.Length\", and taking the mean. However, it requires reading from the inside out. For a large set of nested functions, we would have ` y <- f(g(h((i(x)))))`, which would require first creating the innermost function (`i()`) and then working outward.\n\nIn a tidy approach this would be more like y <- x %>% i() %>% h() %>% g() %>% f()` because the first function applied to the data set `x` is `i()`. Revisiting the mean sepal length of _setosa_ irises, example, under a tidy approach we would do this:\n\n```{r}\niris %>% filter(Species == 'setosa') %>% summarise(mean(Sepal.Length))\n```\n\nWhich, read from left to right, translates to \"using the iris data frame, make a subset of records where species is _setosa_, and summarize those records to get the mean value of sepal length.\" The tidy version is intended to be easier to write, read, and understand. The command uses the `filter()` function, which will be described below.\n\n### Data subsetting (dplyr)\n`dplyr` is the tidyverse R package used most frequently for data manipulation. Selection of records (i.e., subsetting) is done using logical tests to determine what is in the selected set. First we will look at logical tests and then we will cover subsetting rows and columns from data frames.\n\n##### Logical tests\nIf elements meet a logical test, they will end up in the selected set. If data frame records have values in variables that meet logical criteria, the records will be selected. \n\nSome logical tests are shown below.\n\n###### `==`: equals\n\n```{r}\n# numeric tests\n(1 == 2)\n```\n\n```{r}\n(1 == 3 - 2)\n```\n\n```{r}\n# character test (actually a factor)\n(dat$imonth %>% head() %>% str_c(collapse = \", \"))\n((dat$imonth == \"(6) June\") %>% head())\n```\n\n```{r}\n# character test for multiple patterns\n(dat$imonth %in% c(\"(6) June\", \"(7) July\") %>% head())\n```\n\n\n###### `>`, `>=`, `<`, `<=`: numeric comparisons\n\n```{r}\n1 < 2\n```\n\n```{r}\n1 > 2\n```\n\n```{r}\n1 <= -10:10\n```\n\n```{r}\n1 >= -10:10\n```\n\n###### `!=`: not equals\n\n```{r}\n1 != 2\n```\n\n```{r}\n# those of the first 6 days that are not 14\n(dat$iday %>% head())\n((dat$iday != 14) %>% head())\n```\n\n###### `!`: invert, or \"not\"\nSometimes it is more convenient to negate a single condition rather than enumerating all possible matching conditions.\n\n```{r}\ndat$imonth %>% head(20)\n((!dat$imonth %in% c(\"(6) June\", \"(7) July\")) %>% head(20))\n```\n\n#### Subset rows (`filter()`)\nThe `filter()` function creates a subset of records based on a logical test. Logical tests can be combined as \"and\" statements using the `&` operator and \"or\" statements using the `|` operator. Here we will perform a few filters on a subset of the data.\n\n```{r}\n# first 20 records, fist 10 columns\ndat_sub <- dat[1:20, 1:10]\nkable(dat_sub, format = \"html\") %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nRecords from one month:\n\n```{r}\n# from May\n(dat_sub %>% filter(imonth == \"(5) May\"))\n```\n\nRecords from one month from females:\n\n```{r}\n(dat_sub %>% filter(imonth == \"(5) May\" & bio_sex == \"(2) Female\"))\n```\n\nRecords from one month and from females or where the day of month was before the 15th, which will probably include some males:\n\n```{r}\n(dat_sub %>% filter(imonth == \"(5) May\" & (bio_sex == \"(2) Female\") | iday < 15))\n\n```\n\nAlthough these examples are silly and trivial, they show how `filter()` is used to create a selected set of data\n\n#### Subset columns (`select()`)\nA subset of columns can be extracted from data frames using the `select()` function, most simply using  named list of columns to keep.\n\n```{r}\n# select 3 columns\n(dat_sub_sel <- dat_sub %>%   \n    select(\"aid\", \"imonth\", \"iday\"))\n```\n\n```{r}\n# select all but two named columns\n(dat_sub_sel <- dat_sub %>%   \n    select(-\"imonth\", -\"iday\"))\n```\n\n```{r}\n# select columns by position and whose name matches a pattern, in this case the regular expression \"^i\" meaning \"starts with lowercase i\"\n(dat_sub_sel <- dat_sub %>%   \n    select(1, matches(\"^i\")))\n```\n\n`select()` can also be used to rename columns:\n\n```{r}\n#select one column, rename two columns\n(dat_sub_sel %>% \n   select(aid, Month = imonth, Day = iday))\n```\n\nOr column renaming can be done with `rename()`, which maintains all input data and only changes the named columns:\n\n```{r}\n(dat_sub_sel %>% \n   rename(Month = imonth, Day = iday))\n```\n\n#### Subset rows and columns: `filter()` and `select()`\nWe can combine `filter()` and `select()` with a pipe to create a new data frame with a subset of rows and columns:\n\n```{r}\n# records with day of month > 15 and the first 3 named columns\n(x <- dat_sub %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday)\n   )\n```\n\n#### Create or calculate columns: `mutate()`\n`mutate()` will create new named columns or re-calculate existing columns. Here we will make a column that stratifies birth month, with the cut at June. \n\nAlthough the birth month column (`h1gi1m`) is a factor, it is unordered, so we need to make it ordered before using the factor label in a numeric comparison. Fortunately, the factor labels were handled in correct order:\n\n```{r}\n# is this ordered?\nis.ordered(dat$h1gi1m)\n```\n\n```{r}\n# what are the levels?\n(levels(dat$h1gi1m))\n```\n\nAssign order, create a new column, and print nicely:\n\n```{r}\n# make birth month ordered\ndat$h1gi1m <- factor(dat$h1gi1m, ordered = TRUE)\n\n# now is it ordered?\nis.ordered(dat$h1gi1m)\n```\n\n```{r}\n# perform the mutate() using the string representation of the factor for comparison\ndat %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_1st_half = (birth_month < \"(7) July\")) %>% \n    head(20) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nA silly example but showing that `mutate()` can change values of existing columns:\n\n```{r}\n(X <- dat_sub %>% \n     mutate(iday = -1000 + iday))\n```\n\n... so do be careful!\n\nOther functions can be used with mutate include (but are by no means limited to!) \n\n* `if_else()`: create a column by assigning values based on logical criteria\n* `case_when()`: similar to `if_else()` but for multiple input values\n* `recode()`: change particular values\n\nWhen we recoded the birth month, the output was a `logical` data type. If we wanted to create a \n`character` or `factor`, we could use `if_else()`. Here we are creating a new data frame based on several operations on `dat`.\n\n```{r}\ndat_1 <- dat %>% \n    filter(iday > 15) %>%\n    head(20) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_year_half = ifelse(test = birth_month < \"(7) July\", yes = \"first\", no = \"last\"))\n\n# make that a factor\ndat_1$birth_year_half <- factor(dat_1$birth_year_half, levels = c(\"first\", \"last\"))\n    \n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nIf one of your variables contains multiple values and you want to create classes, use `case_when()`. Here is a verbose example stratifying months into quarters. Also we are using the `magrittr` assignment pipe to update the input based on the statement, i.e., `dat_1` will change based on the commands we use. __Be careful using the assignment pipe because it will change your data frame.__\n\n`case_when()` will recode in order or the way the command is written, so for months and quarters, it is not necessary to specify both ends of the quarter. Also any cases that are not explicitly handled can be addressed with the `TRUE ~ ...` argument; in this case, any records that had birth months that were not before September get assigned to quarter 4.\n\n```{r}\ndat_1 %<>% \n    mutate(quarter = case_when(\n        birth_month < \"(3) March\" ~ 1,\n        birth_month < \"(6) June\" ~ 2,\n        birth_month < \"(9) September\" ~ 3,\n        TRUE ~ 4))\n\n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\n`recode()` is used to change the `birth_year_half` column:\n\n```{r}\n(dat_1 %<>% \n     mutate(birth_year_half_split = recode(birth_year_half,\n                   \"first\" = \"early\",\n                   \"last\" = \"late\")))\n```\n\n#### Summarizing/aggregating data\nWe will spend more time later in the course on data summaries, but an introduction with `dplyr` is worthwhile introducing at this stage. The two main functions are `summarise()` and `group_by()`.\n\nA simple summary will tabulate the count of respondents and the mean age. The filter `! str_detect(h1gi1y, \"Refused\")` drops records from respondents who refused to give their birth year.\n\n```{r}\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    summarise(n = n(),\n              mean_age = mean(yeari - yearb))\n```\n\nHere we will summarize age by sex using the `group_by()` function, and also piping to `prop_table()` to get the percentage:\n\n```{r}\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    group_by(bio_sex) %>% \n    summarise(mean_age = mean(yeari - yearb),\n              sd_age = sd(yeari - yearb),\n              n = n(),\n              .groups = \"drop_last\") %>% \n    mutate(pct = prop.table(n) * 100)\n```\n\n#### purrr: efficient iterating over elements in vectors and lists\nMore attention will be paid to `purrr` in the lesson on [functions](#week2).\n\nThe workhorse function in `purrr` is `map()`, which applies a function over a list or atomic vector.\n\nA brief example uses a vector `c(9, 16, 25)` and the `map()` function is used to get the square root of each element. The output is a list\n\n```{r}\n# apply the sqrt() function to each element of a vector of integers\nmap(c(9, 16, 25), sqrt)\n```\n\nOther resources for `purrr`: [Learn to purrr](https://www.rebeccabarter.com/blog/2019-08-19_purrr/), [purrr tutorial](https://jennybc.github.io/purrr-tutorial/)\n\n## Data sets {#datasets001}\n\n### Edward Babushkin's Employee turnover data {#babushkin1}\nSome data that will be used in CSDE 533: Edward Babushkin's employee turnover data, explained a bit at [kaggle.com](https://www.kaggle.com/davinwijaya/employee-turnover) and as a [downloadable file](https://github.com/teuschb/hr_data/blob/master/datasets/turnover_babushkin.csv).\n\nHere we will load the data set from a URL:\n\n```{r}\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n```\n\nJust to get a bit of `tidyverse` in at the last minute, let's get mean and standard deviation of job tenure by gender and 10-year age class:\n\n```{r}\n# create 10-year age classes \netdata %<>% \n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling)) \n\n# summarize\netdata %>% \n    # group by gender and age class\n    group_by(gender, age_decade) %>% \n    # mean and sd\n    summarize(mean_tenure_months = mean(tenure) %>% round(1),\n              sd_tenure_months = sd(tenure) %>% round(1), \n              .groups = \"keep\") %>% \n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>% \n    # print it nicely\n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week2.html","id":"week2","chapter":"2 Week 2","heading":"2 Week 2","text":"session covers basics creating R Markdown documents. also cover Keyring package securely storing passwords secrets one want hard-code R documents. Finally, introduce Human Mortality Human Fertility databases used CSDE 533.class session, building R Markdown document using various code chunks copied pasted page.Download file week02.Rmd use base. Change second line YAML header uses name web site. See UW Students Web Server web site.Code chunks RGraphs R MarkdownTables R MarkdowEquations R MarkdownCaptions cross-references R MarkdownKeyring storing passwords secretsData sets:\nData:\nHuman Mortality Database\nHuman Fertility Database\n\nData:\nHuman Mortality Database\nHuman Fertility Database\nHuman Mortality DatabaseHuman Fertility Database","code":""},{"path":"week2.html","id":"code-to-run-for-the-in-class-exercise","chapter":"2 Week 2","heading":"2.1 Code to run for the in-class exercise","text":"exercise class, download week02.R, use run code listed R Markdown result.","code":""},{"path":"week2.html","id":"r-markdown","chapter":"2 Week 2","heading":"2.2 R Markdown","text":"","code":""},{"path":"week2.html","id":"rmdcodeblocks","chapter":"2 Week 2","heading":"2.2.1 Code chunks","text":"Code chunks blocks text include R code. R Markdown file rendered, code run. code can run R routines perform number tasks, including analytics, printing tables, generating graphics. Anything regular R file can placed code chunks. Code chunks can print outputs (tables, figures), necessarily always ; example, code generate summary raw data set, export CSV file, zip CSV file. “manually” print hyperlink output.RStudio, code chunk can added R Markdown source file keystroke combination CTRL-ALT-","code":""},{"path":"week2.html","id":"code-chunk-structure","chapter":"2 Week 2","heading":"2.2.1.1 Code chunk structure","text":"Code chunks designated delimiting code characters ```{r} open block ``` close block.number additional options can included {r} opening delimiter, see Chunk options package options. Many options set default require set explicitly select option default.example, code chunk can run eval=FALSE option. code chunk generates graphic, fig.cap option can used print caption.example, following code chunk creates single element vector value 2.","code":"```{r, eval=TRUE}\na <- 1 + 1\n```"},{"path":"week2.html","id":"inline-code","chapter":"2 Week 2","heading":"2.2.2 Inline code","text":"Inline code designated using type syntax `r R_CODE`, R_CODE represents statement evaluated printed inline.example, get mean age Babushkin data, R_CODE readThat , document one write:renders ","code":"mean(etdata$age) %>% round(1)The mean age of the subjects in the Babushkin data was `r mean(etdata$age) %>% round(1)` years.The mean age of the subjects in the Babushkin data was 31.1 years."},{"path":"week2.html","id":"rmdgraphics","chapter":"2 Week 2","heading":"2.2.3 Graphics in R Markdown","text":"Data-driven graphics Rmd files typically created base R graphics ggplot2 package. tutorial intended provide anywhere near comprehensive treatment creating graphics data, provide instruction options creating including data-driven graphics well inserting graphics image files.See Tips tricks working images figures R Markdown documents good explanation.","code":""},{"path":"week2.html","id":"base-r-graphics","chapter":"2 Week 2","heading":"2.2.3.1 Base R graphics","text":"include base R graphics, simply place code generate graphic R code block, e.g., using Add Health data last week (AHWave1_v1.dta):… render graph:","code":"```{r}\n# since loading the data takes awhile, only load the data if necessary -- won't load if it was done already\nif(!exists(\"dat\")){\n    dat <- read.dta13(\"data/AHwave1_v1.dta\")\n}\n# birth year = h1gi1y\n# drop \"Refused\" birth year\n# for birth year and interview year, replace anything before white space, convert to numeric\n# subtract interview year - birth year\nages <- dat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    select(iyear, h1gi1y) %>% \n    mutate(yi = str_replace(iyear, \".*\\\\s\", \"\") %>% as.numeric(),\n           yb = str_replace(h1gi1y, \".*\\\\s\", \"\") %>% as.numeric(),\n           age = yi - yb)\n           \n# create a histogram using base graphics\nhist(ages$age, xlab = \"age (years)\", las = 1)\n```"},{"path":"week2.html","id":"ggplot2-graphics","chapter":"2 Week 2","heading":"2.2.3.2 ggplot2 graphics","text":"ggplot2 package creates compelling graphics use common syntax. main difference base R graphics ggplot2 graphics simply issuing plot() related command (e.g., hist(), barplot()) adds graphic output, whereas ggplot() necessary issue command prints graphic.Following previous example:following code generates box plot Babushkin employee turnover data. code chunk includes fig.cap = \"Box plot Babushkin data, self control profession\", caption automatically placed figure.\nFigure 2.1: Box plot Babushkin data, self control profession\n","code":"```{r}\n# how many unique bins? \nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\n``````{r, fig.cap = \"Box plot of Babushkin data, self control by profession\"}\nggplot(data = etdata, aes(x = reorder(profession, selfcontrol), y = selfcontrol)) +\n    geom_boxplot() +\n    coord_flip()\n```"},{"path":"week2.html","id":"embedding-graphics-files","chapter":"2 Week 2","heading":"2.2.3.3 Embedding graphics files","text":"Journals frequently require graphics files submitted separately manuscript. case, graphic can created saved file inserted Rmd using code, also accessed stand-alone file. Let’s take previous example, add correlation coefficients embellishments, create graphics file add graphics Rmd.base graphics file created using pdf() function, although png() also works desired output format. PDF vector format, generally renders better different zoom levels.create PNG format file:ggplot2 graphics can saved using ggsave(), e.g., PDF PNG outputs. dpi argument important bitmap images sets dots per inch, controls size graphics file.Graphics can added using several methods.","code":"\npdf(file = \"ah_age_hist.pdf\", width = 5, height = 5)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\npng(file = \"ah_age_hist.png\", width = 5, height = 5, units = \"in\", res = 300)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\nggsave(\n    filename = \"ah_age_hist_ggplot.pdf\",\n    plot = g, device = \"pdf\",\n    width = 5, height = 5\n)\nggsave(\n    filename = \"ah_age_hist_ggplot.png\",\n    plot = g, device = \"png\",\n    width = 5, height = 5,\n    units = \"in\", dpi = 300\n)"},{"path":"week2.html","id":"knitr","chapter":"2 Week 2","heading":"2.2.3.3.1 knitr","text":"knitr::include_graphics() function can used insert image files, caution inserted PDF files may produce unwanted results. syntax :code chunk can include .width, .height options r first line chunk,\n \ninsert PDF code chunk options, presents image scroll bar, rather full image:specify code chunk options .height = \"360px\", .width='360px', fig.align='left', … code chunk options .height = \"400px\", .width='100%', fig.align='left' seems embedding PDF files optimal.insert PNG: code chunk options:code chunk option .width = \"50%\"embedding bitmapped images appears work better embedding PDF files.","code":"```{r}\ninclude_graphics(\"graphics_filename\")\n```\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist_ggplot.png\")\ninclude_graphics(\"ah_age_hist_ggplot.png\")"},{"path":"week2.html","id":"markdown-captionfilename","chapter":"2 Week 2","heading":"2.2.3.3.2 Markdown: ![caption](filename)","text":"native Markdown syntax:includes graphics file optional caption, e.g., , PDF caption,![](ah_age_hist.pdf) structure ![]() indicates inserted graphic; caption can specified including text within square brackets, e.g., displays caption inserted image (caption number!).![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)Add Health respondent age histogram… although seems inserting PDF odd things image scrolling, PNG inserts complete image without scroll bars.![Add Health respondent age histogram](ah_age_hist_ggplot.png):Add Health respondent age histogram","code":"![](filename)"},{"path":"week2.html","id":"html-img-tag","chapter":"2 Week 2","heading":"2.2.3.3.3 HTML <img> tag","text":"file rendered HTML, image bitmap, rather vector PDF graphics, <img> tag can used. Different utilities can used convert PDF bitmapped formats, e.g., ImageMagick GraphicsMagick.<img src=\"ah_age_hist_ggplot.png\">Including percentage page width:<img src=\"ah_age_hist_ggplot.png\" width=\"30%\">","code":""},{"path":"week2.html","id":"rmdtables","chapter":"2 Week 2","heading":"2.2.4 Tables in R Markdown","text":"look three methods including tables R Markdown documents, using packages knitr (kableExtra), pander, stargazer.example table, use frequency table health \\(\\times\\) White African American Add Health data:","code":"\ndat <- readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")## Warning in readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\"): \n##    Factor codes of type double or float detected in variables\n## \n##    h1hr7a, h1hr7b\n## \n##    No labels have been assigned.\n##    Set option 'nonint.factors = TRUE' to assign labels anyway.## Warning in readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\"): \n##    Missing factor labels for variables\n## \n##    h1hr8e\n## \n##    No labels have beend assigned.\n##    Set option 'generate.factors=TRUE' to generate labels.\n# ordered factor; use fct_rev to establish the correct ordering where better health ranks higher\ndat %<>%\n    mutate(h1gh1 = fct_rev(as.ordered(h1gh1)))\n\n# stratify health; first we need to catch the \"don't know\" and \"refused\" as NAs\ndat %<>%\n    mutate(\n        health =\n            case_when(\n                h1gh1 <= \"(6) Refused\" ~ as.character(NA),\n                h1gh1 > \"(3) Good\" ~ \"high\",\n                h1gh1 <= \"(3) Good\" ~ \"low\"\n            )\n    )\n\n# tabulate by White\ntabhealth_white <- dat %>%\n    group_by(health, white = h1gi6a) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# tabulate by African American\ntabhealth_afram <- dat %>%\n    group_by(health, afram = h1gi6b) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# column-bind and remove the second \"health\" column\nsum_health_white_afram <- cbind(tabhealth_white, tabhealth_afram) %>%\n    select(-5)## New names:\n## * health -> health...1\n## * n -> n...3\n## * `%` -> `%...4`\n## * health -> health...5\n## * n -> n...7\n## * ..."},{"path":"week2.html","id":"kntir-kable-and-kableextra","chapter":"2 Week 2","heading":"2.2.4.1 kntir (kable()) and kableExtra","text":"simple table using kable() nice read.marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nadd kableExtra options, :marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nHowever, column names duplicated, necessary add column grouping:marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nalso add row groupings:marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nAnother simple example using Babushkin data; following code:… generates following table\n\n:","code":"\nkable(sum_health_white_afram)\nkable(sum_health_white_afram,\n    col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")\n) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\nkable(sum_health_white_afram,\n    col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")\n) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>%\n    add_header_above(c(\" \" = 1, \"White\" = 3, \"African American\" = 3))\nsum_health_white_afram %>%\n    select(-1) %>%\n    kable(col.names = c(\"race\", \"n\", \"%\", \"race\", \"n\", \"%\"), align = c(rep(\"r\", times = 6))) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>%\n    add_header_above(c(\"White\" = 3, \"African American\" = 3)) %>%\n    pack_rows(\"health high\", 1, 4) %>%\n    pack_rows(\"health low\", 5, 8) %>%\n    pack_rows(\"health N/A\", 9, 12)```{r, eval=TRUE}`r ''`\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n\n# create 10-year age classes \netdata %<>% \n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling)) \n\n# summarize\netdata %>% \n    # group by gender and age class\n    group_by(gender, age_decade) %>% \n    # mean and sd\n    summarize(mean_tenure_months = mean(tenure) %>% round(1),\n              sd_tenure_months = sd(tenure) %>% round(1), \n              .groups = \"keep\") %>% \n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>% \n    # print it nicely\n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```"},{"path":"week2.html","id":"stargazer","chapter":"2 Week 2","heading":"2.2.4.2 stargazer","text":"stargazer package especially good PDF outputs, fairly limited HTML output.","code":"\nstargazer(sum_health_white_afram,\n    type = \"html\",\n    summary = FALSE,\n    rownames = FALSE\n)"},{"path":"week2.html","id":"pander","chapter":"2 Week 2","heading":"2.2.4.3 pander","text":"pander can used create output HTML tables well, although also fewer options knitr kableExtra.","code":"\npander(sum_health_white_afram)"},{"path":"week2.html","id":"dtdatatable","chapter":"2 Week 2","heading":"2.2.4.4 DT::datatable","text":"DT::datatable presents tables interactive format, allowing filtering free text, sorting columns, displaying fewer records. , table loaded sorted descending order mean anxiety per industry. DT::datatable can sorted interactively based columns.","code":"\netdata %>% \n    group_by(industry) %>% \n    dplyr::summarize(n = n(),\n                     mean_anxiety = mean(anxiety) %>% round(1)) %>% \n    arrange(desc(mean_anxiety)) %>% \nDT::datatable()"},{"path":"week2.html","id":"flextable","chapter":"2 Week 2","heading":"2.2.4.5 flextable","text":"flextable full-featured package fine control table display. can merge cells, add header rows, add footer rows, change format specify data displayed cells. Tables content can also contain mixed type content, text images.example shows fairly simple output:\nTable 2.1: New York Air Quality Measurements\nTable 2.1: New York Air Quality MeasurementsAir qualityTimeOzoneSolar.RWindTempMonthDay1948.66951014.35655361188.072522814.9665681920.161591214912.67453232998.665571831311.56254199913.85958411907.46751Daily air quality measurements New York, May September 1973.advanced application (see Looping columns compose):cutEIJHFGDIdealPremiumGoodVery GoodFair","code":"\nft <- flextable(airquality[sample.int(10), ])\nft <- add_header_row(ft,\n    colwidths = c(4, 2),\n    values = c(\"Air quality\", \"Time\")\n)\nft <- theme_vanilla(ft)\nft <- add_footer_lines(ft, \"Daily air quality measurements in New York, May to September 1973.\")\nft <- color(ft, part = \"footer\", color = \"#666666\")\nft <- set_caption(ft, caption = \"New York Air Quality Measurements\")\nft\ndiamond_dat <- nest(diamonds, data = -all_of(c(\"cut\", \"color\"))) %>% \n  mutate(\n    gg = \n      lapply(\n        X = data, \n        FUN = function(subdat) {\n          ggplot(subdat, aes(x = x)) + \n            geom_density(color = \"white\") + theme_minimal() +\n            scale_x_continuous(limits = c(0, 11)) +\n            scale_y_continuous(limits = c(0, 1)) +\n            labs(x = \"\", y = \"\") + theme_void()\n        }\n      )\n  ) %>% \n  select(-data) %>% \n  pivot_wider(\n    id_cols = cut, \n    names_from = color, \n    values_from = gg)\n\ndiamond_dat %>% \n  flextable() %>% \n  mk_par(\n    value = as_paragraph(\n      gg_chunk(., width = 1, height = 1, unit = \"cm\")), \n    j = ~ . - cut,\n    use_dot = TRUE) %>% \n  theme_tron() %>% \n  align(align = \"center\", part = \"all\") %>% \n  autofit()"},{"path":"week2.html","id":"rmdcaptions","chapter":"2 Week 2","heading":"2.2.5 Captions to support tables, figures, and equations","text":"several ways support captions R Markdown. two main requirements good captions: (1) automatic sequential numbering, (2) ability cross-reference.options adding captions:","code":""},{"path":"week2.html","id":"figures","chapter":"2 Week 2","heading":"2.2.5.1 Figures","text":"","code":""},{"path":"week2.html","id":"r-markdown-code-chunk-fig.cap","chapter":"2 Week 2","heading":"2.2.5.1.1 R Markdown code chunk fig.cap","text":"Code chunks can include fig_cap option, shown . However, standard Rmd \\(\\rightarrow\\) HTML appear method cross-referencing. code chunk look like\nFigure 2.2: Cars: speed distance\n","code":"```{r plotcars, fig.cap=\"Cars: speed and distance\"}\nplot(cars)\n```"},{"path":"week2.html","id":"bookdown-with-html_document2-output-type","chapter":"2 Week 2","heading":"2.2.5.1.2 bookdown with html_document2 output type","text":"Using bookdown package html_document2 output type, possible cross-reference using chunk name. example, download run code fig_cap_bookdown.RmdWhich renders file:seems difference HTML output usingversusso former suggested one way include captions support cross-referencing.","code":"output: \n    bookdown::html_document2:output: \n    html_document:"},{"path":"week2.html","id":"tables-kable-caption","chapter":"2 Week 2","heading":"2.2.5.2 Tables: kable() “caption”","text":"Tables created kable() can include caption option. example:\nTable 2.2: Self-reported health race\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nappears direct way cross-referencing within standard Rmd \\(\\rightarrow\\) HTML.","code":"\nkable(x = sum_health_white_afram, caption = \"Self-reported health by race\")"},{"path":"week2.html","id":"bookdown-with-html_document2-output-type-1","chapter":"2 Week 2","heading":"2.2.5.2.1 bookdown with html_document2 output type","text":"Similarly figures, bookdown package html_document2 output type, possible cross-reference using chunk name. example, download run code table_cap_bookdown.RmdWhich renders file:","code":""},{"path":"week2.html","id":"rmdequations","chapter":"2 Week 2","heading":"2.2.5.3 Equations","text":"Equations numbered manuscripts. Using bookdown makes quite easy. equations require \\(\\LaTeX\\) syntax. numerous web sites examples tutorials creating mathematical expressions \\(\\LaTeX\\) example, include Einstein’s famous equation:sum squares:label equation set (\\#eq:emc) can referenced using \\@ref(eq:emc). Operationalized, see:Einstein’s equation, energy equals mass times square speed light shown (2.1).\\[\\begin{equation}\n  E=mc^2\n  \\tag{2.1}\n\\end{equation}\\]make sum squares n first integers, see (2.2).\\[\\begin{equation}\n  \\sum_{=1}^n ^2 = \\frac{n(n+1)(2n+1)}{6}\n  \\tag{2.2}\n\\end{equation}\\]","code":"\n\\begin{equation}\n  E=mc^2\n  (\\#eq:emc)\n\\end{equation}\n\n\\begin{equation}\n  \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\n  (\\#eq:sumn)\n\\end{equation}\n"},{"path":"week2.html","id":"captioner-for-any-captioning-and-cross-referencing-figures-and-tables","chapter":"2 Week 2","heading":"2.2.6 captioner for any captioning and cross-referencing figures and tables","text":"captioner package provides flexible, albeit cumbersome, framework captioning tables figures.R code :table_nums() figure_nums() functions used create captions cross-references, tied specific figure table, case kable table captions R code chunk fig.cap.caption created, e.g., figure:`r figure_nums(name = \"figname\", caption = \"Caption\")`referenced, e.g.,`r figure_nums(name = \"figname\", display = \"cite\")`matter whether reference precedes comes caption .Another benefit using captioner output can formatted using markdown syntax. example, format caption italics, use underscores:_`r figure_nums(name = \"figname\", caption = \"Caption\")`_Although method requires bit coding, allows great flexibility. complete example:shown Figure 1, distribution age slight negative skew.Figure 1: Add Health age histogramSimilarly, can present data frequency table, shown Table 2.Table 2: Add Health age frequency table","code":"library(captioner)\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n# how many unique bins?\nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\nages %>%\n    group_by(age) %>%\n    summarise(n = n()) %>%\n    mutate(\n        cumsum = cumsum(n),\n        \"%\" = round(n / sum(n) * 100, 1),\n        \"cum %\" = round(cumsum(n / sum(n) * 100), 1)\n    ) %>%\n    kable() %>%\n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        full_width = F,\n        position = \"left\"\n    )"},{"path":"week2.html","id":"keyring","chapter":"2 Week 2","heading":"2.3 Keyring","text":"preparation later work, go following web sites create user profile. require establish username password sites done already. Make note username password sites! need later. using password manager, ! Highly recommended: KeePass Password Safe. can store password database DropBox OneDrive always access passwords. Make sure record password correctly errors later !Human Mortality Database (HMD)Human Fertility Database (HFD)Keyring package used accessing credentials want store R code. use passwords Human Mortality Human Fertility databases (covered ) example use package.keyring stored part user profile computer. Therefore using multiple computers (e.g., computer well CSDE terminal server), need repeat steps setting keys. keys stored operating system level, set, need reset, R session access keys. Also log computer, keyring unlocked automatically.main functions likely use key_set() interactively store keys, key_list() list service username different keys created, key_get() retrieve key. want delete key, done key_delete().","code":""},{"path":"week2.html","id":"setting-storing-keys","chapter":"2 Week 2","heading":"2.3.1 Setting (storing) keys","text":"following code set keys user. want copy code R Markdown document change username. run code, already entered keys two sites, prompted, shown r figure_nums(name = “keyring1,” display = “cite”)`.Figure 2: keyring password storage dialogueOnce keys stored, service username can shown key_list():","code":"\n# get the keys\nmyKeys <- key_list()\n\n# Set your password for Human Mortality Database (HMD)\n# does a key exist? if not, create one\nif (key_list(service = \"human-mortality-database\") %>% nrow() == 0) {\n    keyring::key_set(\n        service = \"human-mortality-database\",\n        username = \"phurvitz@uw.edu\"\n    )\n    # Enter your HMD password in the prompt\n}\n\n# Set your password for Human Fertility Database (HFD)\nif (key_list(service = \"human-fertility-database\") %>% nrow() == 0) {\n    keyring::key_set(\n        service = \"human-fertility-database\",\n        username = \"phurvitz@uw.edu\"\n    )\n    # Enter your HFD password in the prompt\n}\nkey_list()##                    service        username\n## 1 human-fertility-database phurvitz@uw.edu\n## 2 human-mortality-database phurvitz@uw.edu"},{"path":"week2.html","id":"retreivingusing-usernames-and-passwords","chapter":"2 Week 2","heading":"2.3.2 Retreiving/using usernames and passwords","text":"following example, set bogus key demonstrate retrieving secret. Thde dialog appears enter fake password.Now retrieve key:","code":"\n# I only create the key if it does not exist\nif(nrow(key_list(service = \"bogus\")) == 0){\n    key_set_with_value(service = \"bogus\", \n                           username = \"fake@user.tv\",\n                           password = \"the user and password are fake.\")\n}\nkey_get(service = \"bogus\", \"fake@user.tv\")## [1] \"the user and password are fake.\""},{"path":"week2.html","id":"deleting-a-key","chapter":"2 Week 2","heading":"2.3.3 Deleting a key","text":"delete bogus key:","code":"\nkey_delete(service = \"bogus\", username = \"fake@user.tv\")"},{"path":"week2.html","id":"datasets002","chapter":"2 Week 2","heading":"2.4 Data sets:","text":"use keyring access data Human Mortality Human Fertility databases.","code":""},{"path":"week2.html","id":"using-keyring-in-an-application","chapter":"2 Week 2","heading":"2.4.1 Using keyring in an application","text":"Within code, rather storing passwords, can access password, example, get 1 year x 1 year death rates Israel Human Mortality Database:get total number live births Japan Human Fertility Database:benefit method password read fly data download process stored code. Also save R session, password stored object.Download Ben’s example access Human Mortality data using HMDHFplus\nHMDHFDplus-gist.R. annotated version:","code":"\nISR_mx <- HMDHFDplus::readHMDweb(\n    # data for Israel\n    CNTRY = \"ISR\",\n    # mortality 1 year age by 1 year interval\n    item = \"Mx_1x1\",\n    # get my username\n    username = keyring::key_list(\"human-mortality-database\") %>% pull(username),\n    password = keyring::key_get(\n        service = \"human-mortality-database\",\n        username = keyring::key_list(\"human-mortality-database\")$username\n    )\n)\nJPN_livebirths <- HMDHFDplus::readHFDweb(\n    # data for Japan\n    CNTRY = \"JPN\",\n    # live births\n    item = \"totbirthsRR\",\n    # get my username\n    username = keyring::key_list(\"human-mortality-database\") %>% pull(username),\n    password = keyring::key_get(\n        service = \"human-mortality-database\",\n        username = keyring::key_list(\"human-mortality-database\")$username\n    )\n)# load required packages\nlibrary(HMDHFDplus)\nlibrary(keyring)\nlibrary(tidyverse)\n\n# note to see country codes, \n# https://www.mortality.org/cgi-bin/hmd/DataAvailability.php\n\n# Running for a single country with item left NULL lists available series\n# for that country and ask for user entry of desired item\n# HMDHFDplus::readHMDweb(\n#   CNTRY = \"USA\",\n#   username = keyring::key_list(\"human-mortality-database\")$username,\n#   password = keyring::key_get(\n#     service = \"human-mortality-database\",\n#     username = keyring::key_list(\"human-mortality-database\")$username\n#   )\n# )\n\n# Function to download a specified HMD data set item for a single county\n# the country code is referenced as \"CNTRY\"\n# the \"item\" is the base name of the link with \".txt\" removed. For example,\n# https://www.mortality.org/hmd/ISR/STATS/Mx_1x1.txt\n#                                         Mx_1x1       <<- this is the item for 1 year x 1 year death rates\nread_hmd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHMDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\ncountries <- HMDHFDplus::getHMDcountries()\n\n# Download a data set iteratively for all countries using purrr::map()\n# In this case, age-specific mortality in 1-year periods x 1-year age groups\n# for all 1-year periods available\n# output is a data frame named \"mx_1x1\"\nmx_1x1 <- countries %>%\n    # Returns a list of data.frames, adding a column for country code to each\n    # the map() function performs a run of Ben's read_hmd_country() function for each listed country\n    purrr::map_dfr(function(country) {\n        # the item to read is 1 x 1 death rates\n        read_hmd_country(country, \"Mx_1x1\") %>%\n            # this adds the column \"country\" storing the country ISO code\n            dplyr::mutate(country = country)\n    }) %>%\n    # Phil added this to make it a tibble\n    tibble()"},{"path":"week2.html","id":"human-mortality-database-naming-conventions","chapter":"2 Week 2","heading":"2.4.2 Human Mortality Database naming conventions","text":"","code":""},{"path":"week2.html","id":"mortality-table-naming-conventions","chapter":"2 Week 2","heading":"2.4.2.1 Mortality table naming conventions","text":"deaths tables named coding [Deaths]_[length age interval years]x[length period years].txt, example deaths one-year age class year table named Deaths_1x1.txt; deaths one-year age class 5 year intervals named Deaths_1x5.txt; deaths 5-year age classes aggregated 5 year intervals named Deaths_5x5.txt.####Life table naming conventions\nData HMD life tables coded [one-letter sex code]ltper_[length age interval years]x[length period years].txtThe one-letter sex codes:b: male female\nf: Female\nm: MaleFor example, females listed one-year agre classes year, file named fltper_1x1.txt, whereas males 5-year age classes aggregated 10-year intervals, table named mltper_5x10.txt.Rendered 2022-03-04 00:42:18","code":""},{"path":"week2.html","id":"source-code-2","chapter":"2 Week 2","heading":"2.5 Source code","text":"File H:/csde502-winter-2022-main/02-week02.Rmd.","code":""},{"path":"week2.html","id":"r-code-used-in-this-document-2","chapter":"2 Week 2","heading":"2.5.1 R code used in this document","text":"","code":"pacman::p_load(tidyverse, magrittr, knitr, kableExtra, readstata13, stargazer, pander, captioner, keyring, HMDHFDplus, flextable)\n\n# captions\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n# generate the R code to run in class\n# O <- knitr::purl(input = \"02-week02.Rmd\", output = \"r_code/week02.R\", quiet = TRUE, documentation = 1)\n# read this for later\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\nThe mean age of the subjects in the Babushkin data was `r mean(etdata$age) %>% round(1)` years.\ncat(readLines(\"files/week02/rmd_insert_text_01.txt\"), sep = \"\\n\")\n# since loading the data takes awhile, only load the data if necessary -- won't load if it was done already\nif (!exists(\"dat\")) {\n    dat <- read.dta13(\"https://csde-uw.github.io/csde502-winter-2022/data/AHwave1_v1.dta\")\n}\n# birth year = h1gi1y\n# drop \"Refused\" birth year\n# for birth year and interview year, replace anything before white space, convert to numeric\n# subtract interview year - birth year\nages <- dat %>%\n    filter(!str_detect(h1gi1y, \"Refused\")) %>%\n    select(iyear, h1gi1y) %>%\n    mutate(\n        yi = str_replace(iyear, \".*\\\\s\", \"\") %>% as.numeric(),\n        yb = str_replace(h1gi1y, \".*\\\\s\", \"\") %>% as.numeric(),\n        age = yi - yb\n    )\nhist(ages$age, xlab = \"age (years)\", las = 1)\ncat(readLines(\"files/week02/geom_histogram.txt\"), sep = \"\\n\")\n# how many unique bins?\nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\ncat(readLines(\"files/week02/babushkin_boxplot.txt\"), sep = \"\\n\")\nggplot(data = etdata, aes(x = reorder(profession, selfcontrol), y = selfcontrol)) +\n    geom_boxplot() +\n    coord_flip()\npdf(file = \"ah_age_hist.pdf\", width = 5, height = 5)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\npng(file = \"ah_age_hist.png\", width = 5, height = 5, units = \"in\", res = 300)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\nggsave(\n    filename = \"ah_age_hist_ggplot.pdf\",\n    plot = g, device = \"pdf\",\n    width = 5, height = 5\n)\nggsave(\n    filename = \"ah_age_hist_ggplot.png\",\n    plot = g, device = \"png\",\n    width = 5, height = 5,\n    units = \"in\", dpi = 300\n)\ncat(readLines(\"files/week02/rmd_insert_text_02.txt\"), sep = \"\\n\")\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist.pdf\")\n\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist_ggplot.png\")\ninclude_graphics(\"ah_age_hist_ggplot.png\")\ndat <- readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\n\n# ordered factor; use fct_rev to establish the correct ordering where better health ranks higher\ndat %<>%\n    mutate(h1gh1 = fct_rev(as.ordered(h1gh1)))\n\n# stratify health; first we need to catch the \"don't know\" and \"refused\" as NAs\ndat %<>%\n    mutate(\n        health =\n            case_when(\n                h1gh1 <= \"(6) Refused\" ~ as.character(NA),\n                h1gh1 > \"(3) Good\" ~ \"high\",\n                h1gh1 <= \"(3) Good\" ~ \"low\"\n            )\n    )\n\n# tabulate by White\ntabhealth_white <- dat %>%\n    group_by(health, white = h1gi6a) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# tabulate by African American\ntabhealth_afram <- dat %>%\n    group_by(health, afram = h1gi6b) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# column-bind and remove the second \"health\" column\nsum_health_white_afram <- cbind(tabhealth_white, tabhealth_afram) %>%\n    select(-5)\nkable(sum_health_white_afram)\nkable(sum_health_white_afram,\n    col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")\n) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\nkable(sum_health_white_afram,\n    col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")\n) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>%\n    add_header_above(c(\" \" = 1, \"White\" = 3, \"African American\" = 3))\nsum_health_white_afram %>%\n    select(-1) %>%\n    kable(col.names = c(\"race\", \"n\", \"%\", \"race\", \"n\", \"%\"), align = c(rep(\"r\", times = 6))) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>%\n    add_header_above(c(\"White\" = 3, \"African American\" = 3)) %>%\n    pack_rows(\"health high\", 1, 4) %>%\n    pack_rows(\"health low\", 5, 8) %>%\n    pack_rows(\"health N/A\", 9, 12)\ncat(readLines(\"files/week02/etdata_kable.txt\"), sep = \"\\n\")\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n\n# create 10-year age classes\netdata %<>%\n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling))\n\n# summarize\netdata %>%\n    # group by gender and age class\n    group_by(gender, age_decade) %>%\n    # mean and sd\n    dplyr::summarize(\n        mean_tenure_months = mean(tenure) %>% round(1),\n        sd_tenure_months = sd(tenure) %>% round(1),\n        .groups = \"keep\"\n    ) %>%\n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>%\n    # print it nicely\n    kable() %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\nstargazer(sum_health_white_afram,\n    type = \"html\",\n    summary = FALSE,\n    rownames = FALSE\n)\npander(sum_health_white_afram)\netdata %>% \n    group_by(industry) %>% \n    dplyr::summarize(n = n(),\n                     mean_anxiety = mean(anxiety) %>% round(1)) %>% \n    arrange(desc(mean_anxiety)) %>% \nDT::datatable()\nft <- flextable(airquality[sample.int(10), ])\nft <- add_header_row(ft,\n    colwidths = c(4, 2),\n    values = c(\"Air quality\", \"Time\")\n)\nft <- theme_vanilla(ft)\nft <- add_footer_lines(ft, \"Daily air quality measurements in New York, May to September 1973.\")\nft <- color(ft, part = \"footer\", color = \"#666666\")\nft <- set_caption(ft, caption = \"New York Air Quality Measurements\")\nft\ndiamond_dat <- nest(diamonds, data = -all_of(c(\"cut\", \"color\"))) %>% \n  mutate(\n    gg = \n      lapply(\n        X = data, \n        FUN = function(subdat) {\n          ggplot(subdat, aes(x = x)) + \n            geom_density(color = \"white\") + theme_minimal() +\n            scale_x_continuous(limits = c(0, 11)) +\n            scale_y_continuous(limits = c(0, 1)) +\n            labs(x = \"\", y = \"\") + theme_void()\n        }\n      )\n  ) %>% \n  select(-data) %>% \n  pivot_wider(\n    id_cols = cut, \n    names_from = color, \n    values_from = gg)\n\ndiamond_dat %>% \n  flextable() %>% \n  mk_par(\n    value = as_paragraph(\n      gg_chunk(., width = 1, height = 1, unit = \"cm\")), \n    j = ~ . - cut,\n    use_dot = TRUE) %>% \n  theme_tron() %>% \n  align(align = \"center\", part = \"all\") %>% \n  autofit()\ncat(readLines(\"files/week02/rmd_insert_text_03.txt\"), sep = \"\\n\")\nplot(cars)\nkable(x = sum_health_white_afram, caption = \"Self-reported health by race\")\n# how many unique bins?\nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\nages %>%\n    group_by(age) %>%\n    summarise(n = n()) %>%\n    mutate(\n        cumsum = cumsum(n),\n        \"%\" = round(n / sum(n) * 100, 1),\n        \"cum %\" = round(cumsum(n / sum(n) * 100), 1)\n    ) %>%\n    kable() %>%\n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        full_width = F,\n        position = \"left\"\n    )\n# get the keys\nmyKeys <- key_list()\n\n# Set your password for Human Mortality Database (HMD)\n# does a key exist? if not, create one\nif (key_list(service = \"human-mortality-database\") %>% nrow() == 0) {\n    keyring::key_set(\n        service = \"human-mortality-database\",\n        username = \"phurvitz@uw.edu\"\n    )\n    # Enter your HMD password in the prompt\n}\n\n# Set your password for Human Fertility Database (HFD)\nif (key_list(service = \"human-fertility-database\") %>% nrow() == 0) {\n    keyring::key_set(\n        service = \"human-fertility-database\",\n        username = \"phurvitz@uw.edu\"\n    )\n    # Enter your HFD password in the prompt\n}\nkey_list()\n# I only create the key if it does not exist\nif(nrow(key_list(service = \"bogus\")) == 0){\n    key_set_with_value(service = \"bogus\", \n                           username = \"fake@user.tv\",\n                           password = \"the user and password are fake.\")\n}\nkey_get(service = \"bogus\", \"fake@user.tv\")\nkey_delete(service = \"bogus\", username = \"fake@user.tv\")\nISR_mx <- HMDHFDplus::readHMDweb(\n    # data for Israel\n    CNTRY = \"ISR\",\n    # mortality 1 year age by 1 year interval\n    item = \"Mx_1x1\",\n    # get my username\n    username = keyring::key_list(\"human-mortality-database\") %>% pull(username),\n    password = keyring::key_get(\n        service = \"human-mortality-database\",\n        username = keyring::key_list(\"human-mortality-database\")$username\n    )\n)\nJPN_livebirths <- HMDHFDplus::readHFDweb(\n    # data for Japan\n    CNTRY = \"JPN\",\n    # live births\n    item = \"totbirthsRR\",\n    # get my username\n    username = keyring::key_list(\"human-mortality-database\") %>% pull(username),\n    password = keyring::key_get(\n        service = \"human-mortality-database\",\n        username = keyring::key_list(\"human-mortality-database\")$username\n    )\n)\n# load required packages\nlibrary(HMDHFDplus)\nlibrary(keyring)\nlibrary(tidyverse)\n\n# note to see country codes, \n# https://www.mortality.org/cgi-bin/hmd/DataAvailability.php\n\n# Running for a single country with item left NULL lists available series\n# for that country and ask for user entry of desired item\n# HMDHFDplus::readHMDweb(\n#   CNTRY = \"USA\",\n#   username = keyring::key_list(\"human-mortality-database\")$username,\n#   password = keyring::key_get(\n#     service = \"human-mortality-database\",\n#     username = keyring::key_list(\"human-mortality-database\")$username\n#   )\n# )\n\n# Function to download a specified HMD data set item for a single county\n# the country code is referenced as \"CNTRY\"\n# the \"item\" is the base name of the link with \".txt\" removed. For example,\n# https://www.mortality.org/hmd/ISR/STATS/Mx_1x1.txt\n#                                         Mx_1x1       <<- this is the item for 1 year x 1 year death rates\nread_hmd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHMDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\ncountries <- HMDHFDplus::getHMDcountries()\n\n# Download a data set iteratively for all countries using purrr::map()\n# In this case, age-specific mortality in 1-year periods x 1-year age groups\n# for all 1-year periods available\n# output is a data frame named \"mx_1x1\"\nmx_1x1 <- countries %>%\n    # Returns a list of data.frames, adding a column for country code to each\n    # the map() function performs a run of Ben's read_hmd_country() function for each listed country\n    purrr::map_dfr(function(country) {\n        # the item to read is 1 x 1 death rates\n        read_hmd_country(country, \"Mx_1x1\") %>%\n            # this adds the column \"country\" storing the country ISO code\n            dplyr::mutate(country = country)\n    }) %>%\n    # Phil added this to make it a tibble\n    tibble()\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week2.html","id":"complete-rmd-code-2","chapter":"2 Week 2","heading":"2.5.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 2 {#week2}\n\nThis session covers the basics of creating R Markdown documents. We will also cover the [Keyring](https://cran.r-project.org/web/packages/keyring/index.html) package for securely storing passwords and other secrets that one would not want to hard-code into R documents. Finally, we will introduce the Human Mortality and Human Fertility databases that will be used in CSDE 533.\n\nFor this class session, we will be building up an R Markdown document using various code chunks copied and pasted from this page.\n\nDownload the file [week02.Rmd](files/week02/week02.Rmd) and use that as the base. Change the second line in the YAML header so it uses your name and your web site. See [UW Students Web Server](https://students.washington.edu/) if you do not have a web site.\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\npacman::p_load(tidyverse, magrittr, knitr, kableExtra, readstata13, stargazer, pander, captioner, keyring, HMDHFDplus, flextable)\n\n# captions\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\n<h2>Topics:<\/h2>\n* [Code chunks in R](#rmdcodeblocks)\n* [Graphs in R Markdown](#rmdgraphics)\n* [Tables in R Markdow](#rmdtables)\n* [Equations in R Markdown](#rmdequations)\n* [Captions and cross-references in R Markdown](#rmdcaptions)\n* [Keyring for storing passwords and other secrets](#keyring)\n* [Data sets:](#datasets002)\n    * Data:\n        * Human Mortality Database\n        * Human Fertility Database\n\n\n## Code to run for the in-class exercise\n\n```{r, echo=FALSE}\n# generate the R code to run in class\n# O <- knitr::purl(input = \"02-week02.Rmd\", output = \"r_code/week02.R\", quiet = TRUE, documentation = 1)\n```\n\nFor the exercise in class, download [week02.R](r_code/week02.R), which we will use to run the code listed in this R Markdown result.\n\n## R Markdown \n\n### Code chunks {#rmdcodeblocks}\nCode chunks are blocks of text that include R code. As the R Markdown file is rendered, the code is run. The code can run R routines to perform any number of tasks, including analytics, printing tables, and generating graphics. Anything you would do in a regular R file can be placed in the code chunks. Code chunks can print outputs (tables, figures), but they do not necessarily always do; for example, your code could generate a summary of a raw data set, export to a CSV file, and zip the CSV file. You could then \"manually\" print a hyperlink in your output.\n\nIn RStudio, a code chunk can be added to an R Markdown source file with the keystroke combination CTRL-ALT-i\n\n\n#### Code chunk structure\n\nCode chunks are designated by delimiting the code with the characters ` ```{r}` to open the block and ` ``` ` to close the block.\n\nThere are a number of additional options that can be included in the `{r}` opening delimiter, see [Chunk options and package options](https://yihui.org/knitr/options/). Many options are set by default and require being set explicitly to select any option other than the default.\n\nFor example, the code chunk can be not run with the `eval=FALSE` option. Or if the code chunk generates a graphic, the `fig.cap` option can be used to print a caption.\n\nFor example, the following code chunk creates a single element vector `a` with the value of `2`.\n\n````\n```{r, eval=TRUE}`r ''`\na <- 1 + 1\n```\n````\n\n### Inline code\n```{r, echo=FALSE}\n# read this for later\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n```\n\nInline code is designated using this type of syntax `` ``r ''`r R_CODE` ``, where `R_CODE` represents a statement to be evaluated and printed inline. \n\nFor example, to get the mean age from the Babushkin data, the `R_CODE` would read\n\n```md\nmean(etdata$age) %>% round(1)\n```\n\nThat is, in the document one would write:\n\n```{md}\nThe mean age of the subjects in the Babushkin data was `r mean(etdata$age) %>% round(1)` years.\n```\n\nwhich renders to \n\n```\nThe mean age of the subjects in the Babushkin data was `r mean(etdata$age) %>% round(1)` years.\n```\n\n### Graphics in R Markdown {#rmdgraphics}\nData-driven graphics in Rmd files are typically created as base R graphics or with the `ggplot2` package. This tutorial is not intended to provide anywhere near a comprehensive treatment of creating graphics from data, but will provide instruction on some options for creating and including data-driven graphics as well as inserting graphics from image files.\n\nSee [Tips and tricks for working with images and figures in R Markdown documents](http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/) for a good explanation.\n\n#### Base R graphics\nTo include base R graphics, simply place the code to generate the graphic in an R code block, e.g., using the Add Health data from last week ([AHWave1_v1.dta](data/AHwave1_v1.dta)):\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/week02/rmd_insert_text_01.txt\"), sep = \"\\n\")\n```\n\n... which will render the graph:\n\n```{r, echo=FALSE, warning=FALSE}\n# since loading the data takes awhile, only load the data if necessary -- won't load if it was done already\nif (!exists(\"dat\")) {\n    dat <- read.dta13(\"https://csde-uw.github.io/csde502-winter-2022/data/AHwave1_v1.dta\")\n}\n# birth year = h1gi1y\n# drop \"Refused\" birth year\n# for birth year and interview year, replace anything before white space, convert to numeric\n# subtract interview year - birth year\nages <- dat %>%\n    filter(!str_detect(h1gi1y, \"Refused\")) %>%\n    select(iyear, h1gi1y) %>%\n    mutate(\n        yi = str_replace(iyear, \".*\\\\s\", \"\") %>% as.numeric(),\n        yb = str_replace(h1gi1y, \".*\\\\s\", \"\") %>% as.numeric(),\n        age = yi - yb\n    )\nhist(ages$age, xlab = \"age (years)\", las = 1)\n```\n\n#### `ggplot2` graphics\nThe `ggplot2` package creates compelling graphics that use a common syntax. The main difference between base R graphics and `ggplot2` graphics is that simply issuing the `plot()` or related command (e.g., `hist()`, `barplot()`) adds the graphic to the output, whereas with `ggplot()` it is necessary to issue a command that prints the graphic.\n\nFollowing the previous example:\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/week02/geom_histogram.txt\"), sep = \"\\n\")\n```\n\n```{r, echo=FALSE}\n# how many unique bins?\nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\n```\n\nThe following code generates a box plot from the Babushkin employee turnover data. Because the code chunk includes `fig.cap = \"Box plot of Babushkin data, self control by profession\"`, a caption is automatically placed below the figure.\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/week02/babushkin_boxplot.txt\"), sep = \"\\n\")\n```\n\n```{r, fig.cap = \"Box plot of Babushkin data, self control by profession\", echo=FALSE}\nggplot(data = etdata, aes(x = reorder(profession, selfcontrol), y = selfcontrol)) +\n    geom_boxplot() +\n    coord_flip()\n```\n\n#### Embedding graphics files\nJournals frequently require graphics files to be submitted separately from the manuscript. In this case, the graphic can be created and saved as a file and then inserted in the Rmd using code, but also accessed as a a stand-alone file. Let's take the previous example, but add correlation coefficients and other embellishments, create a graphics file and add the graphics into the Rmd.\n\nThe base graphics file is created using the `pdf()` function, although `png()` also works if that is the desired output format. PDF is a vector format, so it generally renders better over different zoom levels.\n\n```{r, message=FALSE}\npdf(file = \"ah_age_hist.pdf\", width = 5, height = 5)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\n```\n\nHere we create a PNG format file:\n\n```{r, message=FALSE}\npng(file = \"ah_age_hist.png\", width = 5, height = 5, units = \"in\", res = 300)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\n```\n\n`ggplot2` graphics can be saved using `ggsave()`, e.g., for both PDF and PNG outputs. The `dpi` argument is important for bitmap images because it sets the dots per inch, which controls the size of the graphics file.\n\n```{r}\nggsave(\n    filename = \"ah_age_hist_ggplot.pdf\",\n    plot = g, device = \"pdf\",\n    width = 5, height = 5\n)\nggsave(\n    filename = \"ah_age_hist_ggplot.png\",\n    plot = g, device = \"png\",\n    width = 5, height = 5,\n    units = \"in\", dpi = 300\n)\n```\n\nGraphics can be added using several methods.\n\n##### `knitr`\nThe `knitr::include_graphics()` function can be used to insert image files, with the caution that inserted PDF files may produce unwanted results. The syntax is:\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/week02/rmd_insert_text_02.txt\"), sep = \"\\n\")\n```\n\nand the code chunk can include `out.width`, `out.height` and other options after the `r` in the first line of the chunk,\n\\  \nHere we insert a PDF with no code chunk options, which presents the image with a scroll bar, rather than the full image:\n\n```{r}\ninclude_graphics(\"ah_age_hist.pdf\")\n```\n\nHere we specify in the code chunk options `out.height = \"360px\", out.width='360px', fig.align='left'`, \n\n```{r, out.height = \"360px\", out.width='360px', fig.align='left'}\ninclude_graphics(\"ah_age_hist.pdf\")\n\n```\n\n\\  \n\n... and with code chunk options `out.height = \"400px\", out.width='100%', fig.align='left'`\n\n```{r, out.height = \"400px\", out.width='100%', fig.align='left'}\ninclude_graphics(\"ah_age_hist.pdf\")\n```\n\n\\  \n\nIt seems that embedding PDF files is not optimal.\n\nHere we insert a PNG: with no code chunk options:\n\n```{r}\ninclude_graphics(\"ah_age_hist_ggplot.png\")\n```\n\nand with code chunk option `out.width = \"50%\"`\n\n```{r, out.width = \"50%\"}\ninclude_graphics(\"ah_age_hist_ggplot.png\")\n```\n\nSo embedding bitmapped images appears to work better than embedding PDF files. \n\n##### Markdown: `![caption](filename)`\n\nThe native Markdown syntax:\n\n```\n![](filename)\n```\n\nincludes a graphics file with an optional caption, e.g., here, a PDF with no caption, \n\n`![](ah_age_hist.pdf)`\n\n![](ah_age_hist.pdf)\n\n\\  \n\nThe structure `![]()` indicates this is an inserted graphic; a caption can be specified by including text within the square brackets, e.g., displays the caption below the inserted image (but with no caption number!). \n\n```![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)```\n\n![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)\n\n... although it seems that inserting a PDF does odd things with image scrolling, while a PNG inserts the complete image without scroll bars.\n\n```![Add Health respondent age histogram](ah_age_hist_ggplot.png)```:\n\n![Add Health respondent age histogram](ah_age_hist_ggplot.png)\n\n##### HTML `<img>` tag\nIf the file is to be rendered as HTML, _and_ the image is a bitmap, rather than vector PDF graphics, the `<img>` tag can be used. Different utilities can be used to convert PDF to bitmapped formats, e.g., [ImageMagick](https://imagemagick.org/index.php) and [GraphicsMagick](http://www.graphicsmagick.org/).\n\n```<img src=\"ah_age_hist_ggplot.png\">```\n\n<img src=\"ah_age_hist_ggplot.png\">\n\nIncluding a percentage of page width:\n\n```<img src=\"ah_age_hist_ggplot.png\" width=\"30%\">```\n\n<img src=\"ah_age_hist_ggplot.png\" width=\"30%\">\n\n\n### Tables in R Markdown {#rmdtables}\nWe will look at three methods of including tables in R Markdown documents, using the packages `knitr` (with `kableExtra`), `pander`, and `stargazer`.\n\nFor the example table, we will use the frequency table of health $\\times$ White and African American from the Add Health data:\n\n```{r}\ndat <- readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\n\n# ordered factor; use fct_rev to establish the correct ordering where better health ranks higher\ndat %<>%\n    mutate(h1gh1 = fct_rev(as.ordered(h1gh1)))\n\n# stratify health; first we need to catch the \"don't know\" and \"refused\" as NAs\ndat %<>%\n    mutate(\n        health =\n            case_when(\n                h1gh1 <= \"(6) Refused\" ~ as.character(NA),\n                h1gh1 > \"(3) Good\" ~ \"high\",\n                h1gh1 <= \"(3) Good\" ~ \"low\"\n            )\n    )\n\n# tabulate by White\ntabhealth_white <- dat %>%\n    group_by(health, white = h1gi6a) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# tabulate by African American\ntabhealth_afram <- dat %>%\n    group_by(health, afram = h1gi6b) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# column-bind and remove the second \"health\" column\nsum_health_white_afram <- cbind(tabhealth_white, tabhealth_afram) %>%\n    select(-5)\n```\n\n#### `kntir` (`kable()`) and `kableExtra`\nThe simple table using `kable()` is not too nice to read.\n\n```{r}\nkable(sum_health_white_afram)\n```\n\nSo we add some `kableExtra` options, :\n\n```{r}\nkable(sum_health_white_afram,\n    col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")\n) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nHowever, because some column names are duplicated, it is necessary to add some column grouping:\n\n```{r}\nkable(sum_health_white_afram,\n    col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")\n) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>%\n    add_header_above(c(\" \" = 1, \"White\" = 3, \"African American\" = 3))\n```\n\nWe could also add some row groupings:\n\n```{r}\nsum_health_white_afram %>%\n    select(-1) %>%\n    kable(col.names = c(\"race\", \"n\", \"%\", \"race\", \"n\", \"%\"), align = c(rep(\"r\", times = 6))) %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>%\n    add_header_above(c(\"White\" = 3, \"African American\" = 3)) %>%\n    pack_rows(\"health high\", 1, 4) %>%\n    pack_rows(\"health low\", 5, 8) %>%\n    pack_rows(\"health N/A\", 9, 12)\n```\n\nAnother simple example using the Babushkin data; the following code: \n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/week02/etdata_kable.txt\"), sep = \"\\n\")\n```\n\n... generates the following table \n<!-- (`r table_nums(name = \"babushkin\", display = \"cite\")`) -->\n:\n\n<!-- _`r table_nums(name = \"babushkin\", caption = \"Babushkin data, tenure by gender and age\")`_ -->\n\n```{r, echo=FALSE}\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n\n# create 10-year age classes\netdata %<>%\n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling))\n\n# summarize\netdata %>%\n    # group by gender and age class\n    group_by(gender, age_decade) %>%\n    # mean and sd\n    dplyr::summarize(\n        mean_tenure_months = mean(tenure) %>% round(1),\n        sd_tenure_months = sd(tenure) %>% round(1),\n        .groups = \"keep\"\n    ) %>%\n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>%\n    # print it nicely\n    kable() %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n#### `stargazer`\nThe [`stargazer`](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf) package is especially good for PDF outputs, but is fairly limited for HTML output.\n\n```{r results='asis'}\nstargazer(sum_health_white_afram,\n    type = \"html\",\n    summary = FALSE,\n    rownames = FALSE\n)\n```\n\n#### `pander`\n`pander` can be used to create output HTML tables as well, although also with fewer options than `knitr` with `kableExtra`.\n\n```{r}\npander(sum_health_white_afram)\n```\n\n#### `DT::datatable`\n`DT::datatable` presents tables in an interactive format, allowing filtering by free text, sorting by columns, and displaying fewer or more records. Here, the table is loaded sorted in descending order of mean anxiety per industry. The `DT::datatable` can be sorted interactively based on any of the columns.\n\n```{r}\netdata %>% \n    group_by(industry) %>% \n    dplyr::summarize(n = n(),\n                     mean_anxiety = mean(anxiety) %>% round(1)) %>% \n    arrange(desc(mean_anxiety)) %>% \nDT::datatable()\n```\n\n#### `flextable`\n[`flextable`](https://ardata-fr.github.io/flextable-book/index.html) is a full-featured package for fine control over table display. You can merge cells, add header rows, add footer rows, change any format and specify how data should be displayed in cells. Tables content can also contain mixed type of content, text and images.\n\nThe example shows a fairly simple output:\n\n```{r}\nft <- flextable(airquality[sample.int(10), ])\nft <- add_header_row(ft,\n    colwidths = c(4, 2),\n    values = c(\"Air quality\", \"Time\")\n)\nft <- theme_vanilla(ft)\nft <- add_footer_lines(ft, \"Daily air quality measurements in New York, May to September 1973.\")\nft <- color(ft, part = \"footer\", color = \"#666666\")\nft <- set_caption(ft, caption = \"New York Air Quality Measurements\")\nft\n```\n\nA more advanced application (see [Looping over columns with compose](https://ardata-fr.github.io/flextable-book/programming.html#looping-over-columns-with-compose)):\n\n```{r, warning=FALSE}\ndiamond_dat <- nest(diamonds, data = -all_of(c(\"cut\", \"color\"))) %>% \n  mutate(\n    gg = \n      lapply(\n        X = data, \n        FUN = function(subdat) {\n          ggplot(subdat, aes(x = x)) + \n            geom_density(color = \"white\") + theme_minimal() +\n            scale_x_continuous(limits = c(0, 11)) +\n            scale_y_continuous(limits = c(0, 1)) +\n            labs(x = \"\", y = \"\") + theme_void()\n        }\n      )\n  ) %>% \n  select(-data) %>% \n  pivot_wider(\n    id_cols = cut, \n    names_from = color, \n    values_from = gg)\n\ndiamond_dat %>% \n  flextable() %>% \n  mk_par(\n    value = as_paragraph(\n      gg_chunk(., width = 1, height = 1, unit = \"cm\")), \n    j = ~ . - cut,\n    use_dot = TRUE) %>% \n  theme_tron() %>% \n  align(align = \"center\", part = \"all\") %>% \n  autofit()\n```\n\n\n### Captions to support tables, figures, and equations {#rmdcaptions}\nThere are several ways to support captions in R Markdown. The two main requirements for good captions: (1) automatic sequential numbering, and (2) ability to cross-reference.\n\nHere are some options for adding captions:\n\n#### Figures\n\n##### R Markdown code chunk `fig.cap`\nCode chunks can include `fig_cap` as an option, as shown below. However, in standard Rmd $\\rightarrow$ HTML there does not appear to be a method for cross-referencing. The code chunk would look like\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/week02/rmd_insert_text_03.txt\"), sep = \"\\n\")\n```\n\n```{r plotcars, fig.cap=\"Cars: speed and distance\", echo=FALSE}\nplot(cars)\n```\n\n##### `bookdown` with `html_document2` output type\n\nUsing the `bookdown` package with `html_document2` output type, it is possible to cross-reference using the chunk name. For example, download and run this code [fig_cap_bookdown.Rmd](files/fig_cap_bookdown.Rmd)\n\nWhich renders a file:\n\n![](images/week03/fig_ref.png)\n\nThere seems to be no difference in the HTML output using\n\n```\noutput: \n    bookdown::html_document2:\n```\n\nversus \n\n```\noutput: \n    html_document:\n````\n\nso the former is suggested as one way to include captions that support cross-referencing.\n\n#### Tables: `kable()` \"caption\"\nTables created with `kable()` can include the `caption` option. For example:\n\n```{r}\nkable(x = sum_health_white_afram, caption = \"Self-reported health by race\")\n```\n\nBut there appears to be no direct way of cross-referencing within standard Rmd $\\rightarrow$ HTML.\n\n##### `bookdown` with `html_document2` output type\n\nSimilarly for figures, the `bookdown` package with `html_document2` output type, it is possible to cross-reference using the chunk name. For example, download and run this code [table_cap_bookdown.Rmd](files/table_cap_bookdown.Rmd)\n\nWhich renders a file:\n\n![](images/week03/tab_ref.png)\n\n#### Equations {#rmdequations}\nEquations should be numbered in manuscripts. Using `bookdown` makes this quite easy. The equations themselves require $\\LaTeX$ syntax. There are numerous web sites with examples and tutorials for creating mathematical expressions with $\\LaTeX$ In this example, we include Einstein's famous equation:\n\n<pre>\n\\begin{equation}\n  E=mc^2\n  (\\#eq:emc)\n\\end{equation}\n<\/pre>\n\nand the sum of squares:\n\n<pre>\n\\begin{equation}\n  \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\n  (\\#eq:sumn)\n\\end{equation}\n<\/pre>\n\nThe label for the equation is set with `(\\#eq:emc)` and can be referenced using `\\@ref(eq:emc)`. Operationalized, we see:\n\nEinstein's equation, energy equals mass times the square of the speed of light is shown in \\@ref(eq:emc).\n\n\\begin{equation}\n  E=mc^2\n  (\\#eq:emc)\n\\end{equation}\n\nTo make a sum of squares of _n_ first integers, see \\@ref(eq:sumn).\n\n\\begin{equation}\n  \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\n  (\\#eq:sumn)\n\\end{equation}\n\n\n### `captioner` for any captioning and cross-referencing figures and tables\nThe `captioner` package provides a flexible, albeit cumbersome, framework for captioning both tables and figures. \n\nThe R code to do this:\n\n```\nlibrary(captioner)\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n```\n\nThe `table_nums()` and `figure_nums()` functions are used to create captions and cross-references, and are not tied to any specific figure or table, as is the case with `kable` table captions and R code chunk `fig.cap`.\n\nA caption is created, e.g., for a figure:\n\n`` `r\nfigure_nums(name = \"figname\", caption = \"My Caption\")` ``\n\nand referenced, e.g., \n\n`` `r\nfigure_nums(name = \"figname\", display = \"cite\")` ``\n\nIt does not matter whether the reference precedes or comes after the caption itself.\n\nAnother benefit to using `captioner` is that the output can be formatted using markdown syntax. For example, to format the caption in italics, use underscores:\n\n`` _`r\nfigure_nums(name = \"figname\", caption = \"My Caption\")`_ ``\n\nAlthough this method requires a bit more coding, it allows great flexibility. A complete example:\n\nAs shown in `r figure_nums(name = \"ageplot\", display = \"cite\")`, the distribution of age has a slight negative skew.\n\n```{r, fig.width=3, fig.height=3}\n# how many unique bins?\nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\n```\n\n_`r figure_nums(name = \"ageplot\", caption = \"Add Health age histogram\")`_\n\nSimilarly, we can present the same data as a frequency table, as shown in `r table_nums(name = \"agetab\", display = \"cite\")`.\n\n_`r table_nums(name = \"agetab\", caption = \"Add Health age frequency table\")`_\n\n```{r}\nages %>%\n    group_by(age) %>%\n    summarise(n = n()) %>%\n    mutate(\n        cumsum = cumsum(n),\n        \"%\" = round(n / sum(n) * 100, 1),\n        \"cum %\" = round(cumsum(n / sum(n) * 100), 1)\n    ) %>%\n    kable() %>%\n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        full_width = F,\n        position = \"left\"\n    )\n```\n\n\n## Keyring {#keyring}\nIn preparation for some later work, go to the following web sites and create a user profile. This will require that you establish a username and password for both sites if you have not done so already. Make a note of your username and password for these sites! You will need them later. If you are not using a password manager, you should! Highly recommended: [KeePass Password Safe](https://keepass.info/). You can store the password database on DropBox or OneDrive and you will always have access to your passwords. **Make sure you record your password correctly or you will have errors later on!**\n\n* [Human Mortality Database (HMD)](https://www.mortality.org/)\n* [Human Fertility Database (HFD)](https://www.humanfertility.org/cgi-bin/main.php)\n\nThe [Keyring](https://cran.r-project.org/web/packages/keyring/index.html) package is used for accessing credentials that you would not want to store in your R code. We will use the passwords for the Human Mortality and Human Fertility databases (covered below) as the example for how to use this package.\n\nThe keyring is stored as part of your user profile on the computer. Therefore if you are using multiple computers (e.g., your own computer as well as the CSDE terminal server), you will need to repeat the steps of setting keys. The keys are stored at the operating system level, so once set, they do not need to be reset, and any R session will have access to the keys. Also once you log on to the computer, the keyring is unlocked automatically.\n\nThe main functions you are likely to use are `key_set()` to interactively store keys, `key_list()` to list the service and username for the different keys you have created, and `key_get()` to retrieve a key. If you want to delete a key, that is done with `key_delete()`.\n\n### Setting (storing) keys\n\nThe following code will set the keys for my user. You will want to copy this code to your R Markdown document and change the username. When you run the code, if you have not already entered keys for these two sites, you will be prompted, as shown in r figure_nums(name = \"keyring1\", display = \"cite\")`.\n\n```{r}\n# get the keys\nmyKeys <- key_list()\n\n# Set your password for Human Mortality Database (HMD)\n# does a key exist? if not, create one\nif (key_list(service = \"human-mortality-database\") %>% nrow() == 0) {\n    keyring::key_set(\n        service = \"human-mortality-database\",\n        username = \"phurvitz@uw.edu\"\n    )\n    # Enter your HMD password in the prompt\n}\n\n# Set your password for Human Fertility Database (HFD)\nif (key_list(service = \"human-fertility-database\") %>% nrow() == 0) {\n    keyring::key_set(\n        service = \"human-fertility-database\",\n        username = \"phurvitz@uw.edu\"\n    )\n    # Enter your HFD password in the prompt\n}\n```\n\n![](images/week02/keyring01.png)\n\n_`r figure_nums(name = \"keyring1\", caption = \"The keyring password storage dialogue\")`_\n\nOnce the keys are stored, the service and username can be shown with `key_list()`:\n\n```{r}\nkey_list()\n```\n\n### Retreiving/using usernames and passwords\nIn the following example, I set a bogus key to demonstrate retrieving the secret. Thde dialog appears and I enter the fake password.\n\n```{r}\n# I only create the key if it does not exist\nif(nrow(key_list(service = \"bogus\")) == 0){\n    key_set_with_value(service = \"bogus\", \n                           username = \"fake@user.tv\",\n                           password = \"the user and password are fake.\")\n}\n```\n\nNow I retrieve the key:\n\n```{r}\nkey_get(service = \"bogus\", \"fake@user.tv\")\n```\n\n### Deleting a key\nHere I delete the bogus key:\n\n```{r}\nkey_delete(service = \"bogus\", username = \"fake@user.tv\")\n```\n\n## Data sets: {#datasets002}\nHere we will use the keyring to access data in the Human Mortality and Human Fertility databases.\n\n### Using keyring in an application\n\nWithin your code, rather than storing any passwords, you can access the password, for example, to get 1 year x 1 year death rates for Israel from the Human Mortality Database:\n\n```{r}\nISR_mx <- HMDHFDplus::readHMDweb(\n    # data for Israel\n    CNTRY = \"ISR\",\n    # mortality 1 year age by 1 year interval\n    item = \"Mx_1x1\",\n    # get my username\n    username = keyring::key_list(\"human-mortality-database\") %>% pull(username),\n    password = keyring::key_get(\n        service = \"human-mortality-database\",\n        username = keyring::key_list(\"human-mortality-database\")$username\n    )\n)\n```\n\nOr to get the total number of live births from Japan from the Human Fertility Database:\n\n```{r}\nJPN_livebirths <- HMDHFDplus::readHFDweb(\n    # data for Japan\n    CNTRY = \"JPN\",\n    # live births\n    item = \"totbirthsRR\",\n    # get my username\n    username = keyring::key_list(\"human-mortality-database\") %>% pull(username),\n    password = keyring::key_get(\n        service = \"human-mortality-database\",\n        username = keyring::key_list(\"human-mortality-database\")$username\n    )\n)\n```\n\nThe benefit to this method is that the password is read on the fly during the data download process and is not stored in code. Also if you were to save your R session, the password would not be stored as an object.\n\nDownload Ben's example for how to access the Human Mortality data using [HMDHFplus]()\n[HMDHFDplus-gist.R](https://raw.githubusercontent.com/hanowell/uwsoc533a/main/gists/HMDHFDplus-gist.R). Here is an annotated version:\n\n```{md}\n# load required packages\nlibrary(HMDHFDplus)\nlibrary(keyring)\nlibrary(tidyverse)\n\n# note to see country codes, \n# https://www.mortality.org/cgi-bin/hmd/DataAvailability.php\n\n# Running for a single country with item left NULL lists available series\n# for that country and ask for user entry of desired item\n# HMDHFDplus::readHMDweb(\n#   CNTRY = \"USA\",\n#   username = keyring::key_list(\"human-mortality-database\")$username,\n#   password = keyring::key_get(\n#     service = \"human-mortality-database\",\n#     username = keyring::key_list(\"human-mortality-database\")$username\n#   )\n# )\n\n# Function to download a specified HMD data set item for a single county\n# the country code is referenced as \"CNTRY\"\n# the \"item\" is the base name of the link with \".txt\" removed. For example,\n# https://www.mortality.org/hmd/ISR/STATS/Mx_1x1.txt\n#                                         Mx_1x1       <<- this is the item for 1 year x 1 year death rates\nread_hmd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHMDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\ncountries <- HMDHFDplus::getHMDcountries()\n\n# Download a data set iteratively for all countries using purrr::map()\n# In this case, age-specific mortality in 1-year periods x 1-year age groups\n# for all 1-year periods available\n# output is a data frame named \"mx_1x1\"\nmx_1x1 <- countries %>%\n    # Returns a list of data.frames, adding a column for country code to each\n    # the map() function performs a run of Ben's read_hmd_country() function for each listed country\n    purrr::map_dfr(function(country) {\n        # the item to read is 1 x 1 death rates\n        read_hmd_country(country, \"Mx_1x1\") %>%\n            # this adds the column \"country\" storing the country ISO code\n            dplyr::mutate(country = country)\n    }) %>%\n    # Phil added this to make it a tibble\n    tibble()\n```\n\n### Human Mortality Database naming conventions\n#### Mortality table naming conventions\nThe deaths tables are named with coding `[Deaths]_[length of age interval in years]x[length of period in years].txt`, for example deaths for each one-year age class over each year would be in a table named `Deaths_1x1.txt`; deaths for each one-year age class over 5 year intervals would be named `Deaths_1x5.txt`; deaths for 5-year age classes aggregated over 5 year intervals would be named `Deaths_5x5.txt`.\n\n####Life table naming conventions\nData in the HMD life tables are coded `[one-letter sex code]ltper_[length of age interval in years]x[length of period in years].txt`\n\nThe one-letter sex codes:\n\nb: Both male and female\nf: Female\nm: Male\n\nFor example, for females listed in one-year agre classes over each year, the file would be named `fltper_1x1.txt`, whereas for males in 5-year age classes aggregated over 10-year intervals, the table would be named `mltper_5x10.txt`.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week3.html","id":"week3","chapter":"3 Week 3","heading":"3 Week 3","text":"session covers two basic areas: (1) downloading census international data using tidycensus, tigris, idbr, (2) mapping GIS analysis leaflet, mapview, sf.Download file week03.Rmd use base. Change second line YAML header uses name web site. See UW Students Web Server web site.tidycensus: Load US Census Boundary Attribute Data ‘tidyverse’ ‘sf’-Ready Data Framestigris: Load Census TIGER/Line Shapefilesidbr: R Interface US Census Bureau International Data Base APIleaflet: Create Interactive Web Maps JavaScript ‘Leaflet’ Librarymapview: Interactive Viewing Spatial Data Rsf: Simple Features R: Simple Features (GIS) R","code":""},{"path":"week3.html","id":"tidycensus","chapter":"3 Week 3","heading":"3.1 Getting US Census data with tigris, tidycensus","text":"Dealing US Census data can overwhelming, particularly using raw text-based data. Census Bureau API allows streamlined downloads variables (data frames) geographies (simple format shapes). necessary get API key, available free. See tidycensus tidycensus basic usage, complete treatment, Analyzing US Census Data.tidycensus uses tigris, downloads geographic data portion census files.simple example download variables representing count White, Black/African American, American Indian/Native American, Asian persons American Community Survey (ACS) data King County 2019.","code":""},{"path":"week3.html","id":"us-census-api-key-installation","chapter":"3 Week 3","heading":"3.1.1 US Census API key installation","text":"example run, need US Census API key installed. run code, substituting actual API key asterisks.API key stored .Renviron can accessed Sys.getenv(“CENSUS_API_KEY”).\nuse now, restart R run readRenviron(\"~/.Renviron\")enable API key:option install = TRUE writes line ~/.Renviron file (~/ shorthand “home directory”; Windows typically C:\\users\\username\\Documents folder; MacOS, typically /home/username). Similarly, tigris_cahce_dir() writes ~/.Renviron file. example .Renviron file (Figure 1) shows API key persistent tigris cache folder.\n Figure 1: Census API key stored ~/.RenvironWith API key installed, can simply load tidycensus package download data. R starts, reads file creates system environment variables R session; case ’m setting two variables (TIGRIS_CACHE_DIR CENSUS_API_KEY). set system environment variables active R adding file.","code":"\n# set the census API key and the persistent tigris cache location\ntidycensus::census_api_key(\"*****************\", install = TRUE)\ntigris::tigris_cache_dir(\"H:/tigris_cache\")\nreadRenviron(\"~/.Renviron\")"},{"path":"week3.html","id":"census-variables","chapter":"3 Week 3","heading":"3.1.2 Census variables","text":"First, noted data products variables available census geographic units. See Geography variables tidycensus list geographic units available different data products using tidycensus.tidycensus helper function obtaining lists variables descriptions. necessary list variables quite long variable names codes functionally unintelligible.Census variable lists obtained using load_variables() function, used specify year, data set, whether cache results. variable lists large, may make sense cache lists.list variables 2019 ACS 5-year average data:table, 27040 records, can browsed using function View(v2019). Using tabular view way makes convenient search variable names concepts using filters. example can search term “race” concept field, shown (Figure 2).\n Figure 2: ACS 5 year variablesHowever, interface uses free text searches match record containing search string, whether search string word alone whole word. One can use specific searches using R syntax, example list variables tagged concept “RACE,” filtering explicit string specific (3.1).\nTable 3.1: ACS 5 year variables concept “race”\nshows variable count persons B02001_001 variables White alone, Black alone, American Indian/Alaskan Native alone, Asian alone, race alone B02001_002, B02001_003, B02001_004, B02001_005, B02001_007, respectively. One also use regular expressions search desired patterns concept.","code":"\nv2019 <- load_variables(year = 2019, dataset = \"acs5\", cache = TRUE)\nv2019 %>%\n    filter(concept == \"RACE\") %>%\n    kable(caption = 'ACS 5 year variables for the concept \"race\"') %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")"},{"path":"week3.html","id":"downloading-data","chapter":"3 Week 3","heading":"3.1.3 Downloading data","text":"tidycensus two main functions, get_decennial() downloading decennial data get_acs() downloading American Community Survey (ACS) data. functions quite similar structure.define set variables using named vector variable names.“named vector” refers elements vector names, example, first element name p_denom_race value “B02001_001.” construction used data downloaded, resultant data frame readable names.Next, download actual data. downloading census tract level data King County, WA, 5 year ACS estimates year ending 2019. also specify options(tigris_use_cache=TRUE) shapefile data downloaded cached re-downloaded necessary. Note Figure 1 specified location wanted tigris cache located (H:/tigris_cache). Another important option output = \"wide\", generates output table one record per census unit columns representing variables. tidy output present “long” table repeated records per census unit, one record per variable estimate.values shown Table 3.2. ACS data include margin error (MOE), estimate represented variable name terminal character “E” MOE represented variable name terminal character “M.” variables shown names specified earlier. Without named vector, downloaded variables given raw variable names, generally helpful. Note also geometry = TRUE option, geometry column containing geographic data. “wide” format data amenable applications requiring one record per census unit, typically census-unit level data represented one record per census unit, allows table joins, fro example mapping applications.\nTable 3.2: Selected census tract variables 5-year ACS 2019 King County, WA\nexample data downloaded “long” format shown 3.3. , column variable indicates measure stored record, estimate moe present data values particular variable \\(\\times\\) census unit combination. Data format amenable generating data summaries, rather applications mapping.\nTable 3.3: Selected census tract variables 5-year ACS 2019 King County, WA (long format)\n","code":"\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)## \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |=========                                                             |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  36%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\nctdat %<>% st_transform(4326)Getting data from the 2015-2019 5-year ACS\nUsing FIPS code '53' for state 'WA'\nUsing FIPS code '033' for 'King County'\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# get the data\nctdatlong <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"tidy\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)## Getting data from the 2015-2019 5-year ACS## Downloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\nctdatlong %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA (long format)\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")"},{"path":"week3.html","id":"idbr","chapter":"3 Week 3","heading":"3.2 Getting US Census International data with idbr","text":"also API US Census international data can accessed using idbr package.need use US Census API key access data using idbr. set key using system environment variable API key stored plain text:Data downloaded using get_idb() function. Data can obtained one countries, years, variables, concepts (groups variables), ages, sex (male female), low high resolution (part geometry() option.","code":"\n# the same census API key is used\nidb_api_key(Sys.getenv(\"CENSUS_API_KEY\"))"},{"path":"week3.html","id":"idb-variables","chapter":"3 Week 3","heading":"3.2.1 IDB variables","text":"Variables concepts can listed using idb_variables() idb_concepts() functions, respectively. informative list (Table 1) can generated variables5() function.Table 1: idbr variablesThe basic use get_idb() without specification variables concepts downloads population counts specific one-year age classes specific countries years. download data representing China India 2000 2021.generate population pyramid two countries two years, using ggplot() geom_col() format grid plots facet_grid().\nFigure 3.1: Population structure \nChina Japan, 2000 2021\n3.1 shows China India 2000 2021 larger proportion population moved younger older age classes. China much larger proportion older age classes India, China also large variations proportion population age class, whereas India relatively little variability across year age.","code":"\n# print the variables as a table\nvariables5 %>% DT::datatable()\n# get data only if necessary\nif(!exists(\"china_india_data\")){\n    china_india_data <- get_idb(\n        # from China and India\n        country = c(\"China\", \"India\"),\n        # years 2000 and 2021\n        year = c(2000, 2021),\n        # age range 0 to 100 years\n        age = 0:100,\n        # data for both sexes\n        sex = c(\"male\", \"female\")\n    )\n}\nchina_india_data %>%\n    # multiply male population by -1 to graph to the left of 0\n    mutate(pop = ifelse(sex == \"Male\", pop * -1, pop)) %>%\n    # plot with Y as age, color by sex\n    ggplot(aes(x = pop, y = as.factor(age), fill = sex)) +\n    # column plot\n    geom_col(width = 1) +\n    # minimal theme with no background annotations\n    theme_minimal(base_size = 15) +\n    # scale X with labels in the millions\n    scale_x_continuous(labels = function(x) paste0(abs(x / 1000000), \"m\")) +\n    # scale Y with breaks & labels every 10 years\n    scale_y_discrete(breaks = scales::pretty_breaks(n = 10)) +\n    # define the colors\n    scale_fill_manual(values = c(\"red\", \"gold\")) +\n    # set the labels\n    labs(\n        x = \"Population\",\n        y = \"Age\",\n        fill = \"\"\n    ) +\n    # facet by country and year\n    facet_grid(name ~ year)"},{"path":"week3.html","id":"downloading-variables-or-concept-groups","chapter":"3 Week 3","heading":"3.2.2 Downloading variables or concept groups","text":"Data can downloaded specific variables variables5 data frame idbr package. example can download female male infant mortality rates per 1000 population (variables IMR_F IMR_M) India China 2000 2021:create simple column graph data (3.2).\nFigure 3.2: Infant mortality, China Japan, 2000 2021\n","code":"\ninf_mort <- get_idb(\n        # from China and India\n        country = c(\"China\", \"India\"),\n        # years 2000 and 2021\n        year = c(2000, 2021),\n        # infant mortality\n        variables = c(\"IMR_F\", \"IMR_M\")\n) %>% \n    mutate(female = imr_f,\n           male = imr_m)\ninf_mort %>% \n    pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"count\") %>% \n    ggplot(aes(x = factor(sex), y = count)) +\n    geom_col() +\n    facet_grid(name ~ year) +\n    labs(x = \"year\", y = \"deaths per 1000 population\")"},{"path":"week3.html","id":"leaflet","chapter":"3 Week 3","heading":"3.3 Mapping census data from tidycensus and tigris using leaflet","text":"Using data downloaded tidycensus section, present simple map shown 3.3, percent African American residents tract identifier.\nFigure 3.3: Percent African American census tracts King County, 2019 ACS 5-year estimate\nOne thing note tidyverse::get_...() functions may downloading detailed GIS data. compare data obtained using tigris::tracts(), also King County, WA 2019 (3.4). First, tidycensus map data clipped shore line. Second, differences shape size tracts downtown area.\nFigure 3.4: tidyverse generalized tracts versus tigris detailed tracts\n","code":"\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\n# a color palette in red with 10% classes \n# max % AfrAm rounded up to the nearest 10\nmyMax <- (ctdat$pct_black %>% max(na.rm = TRUE) + 10) %>% round(0)\n# bins for color\nbins <- seq(0, myMax, by = 10)\n# palette with bins and % AfrAm\nmyPal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ myPal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # add the legend using the palette and % AfrAm\n    addLegend(\n        position = \"bottomright\", pal = myPal, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()\n# get the tracts\ntgtracts_kc_2019 <- tigris::tracts(state = \"WA\", county = \"King\", year = 2019, progress_bar = FALSE)\n# project the coordinates to WGS84 for mapping\ntgtracts_kc_2019 %<>%  st_transform(4326)\n\n# the leaflet map\nm <- leaflet(height = \"500\") %>%\n    addPolygons(\n        data = ctdat,\n        stroke = TRUE,\n        color = \"red\",\n        weight = 7,\n        fill = FALSE\n    ) %>%\n    addPolygons(\n        data = tgtracts_kc_2019,\n        stroke = TRUE,\n        color = \"black\",\n        weight = 2,\n        fill = FALSE\n    ) %>%\n    addLegend(\n        colors = c(\"red\", \"black\"),\n        labels = c(\"tidyverse generalized\", \"tigris detailed\")\n    ) %>%\n    addTiles() %>%\n    setView(lng = -122.3603, lat = 47.62231, zoom = 13)\n\nm"},{"path":"week3.html","id":"mapview","chapter":"3 Week 3","heading":"3.4 Mapping census data from tidycensus and tigris using mapview","text":"mapview provides fast easy interface creating interactive maps built top leaflet framework. Whereas leaflet provides fundamental controls mapping, mapview load layers useful defaults. map automatically includes XY location mouse pointer top interface, choices base map tiles, used zcol argument, color coding based numerical categorical variables data frame. create mapview choropleth map census tracts King County displaying ratio African American White population counts (Figure 3). popup argument used control variables shown popup appears feature clicked.NOTE: problem mapview implemented within R Markdown Bookdown allow page render mapview code. Copy run code . Unfortunately map rendered pages. Figure 3: mapview map ratio African American White population counts King County, 2019 ACS dataFor things can mapview see mapview, particular, look “Articles” link top page.","code":"\nctdat_mv <- ctdat %>%\n    mutate(afram_white = (p_n_aframE / p_n_whiteE) %>% round(2))\n\nmapview(ctdat_mv,\n        zcol = \"afram_white\",\n        popup = popupTable(ctdat_mv,\n            zcol = c(\"p_n_aframE\", \"p_n_whiteE\")\n        )\n    )"},{"path":"week3.html","id":"sf","chapter":"3 Week 3","heading":"3.5 Simple features: GIS in R","text":"maps displayed sections leaflet mapview possible using spatially explicit data. looked contents census tract data frames, geometry column contained specially formatted values. format standard developed Open Geospatial Consortium (OGC) International Organization Standardization (ISO) . known “simple features,” includes specifications store process data representing geographic features.Within R, developed package sf: Simple Features R. full treatment possible course, reference sf good start, well book Geocomputation RGeographic objects stored standard format. example, first census tract composed set attributes well geometry:geometry record composed MULTIPOLYGON, polygon can consist one parts (example, state Washington represented single multipolygon main land mass well islands disjointed parts polygon feature).first polygon consists set vertices define shape polygon:extract coordinates vertices polygon plot points top polygonThe sf package contains plethora analytic functions. st_difference() function erase water areas detailed census tract data downloaded tigirs earlier. Another package, mapshaper fewer functions, upon experimentation, ms_erase() function performed faster better sf::st_difference(), use instead.start downloading water areas, perform spatial overlay, download census values (without geometry) finally join geometry census variables together export geopackage (GPKG) file. geopackage GIS data format can contain multiple data sources suffer built-limitations shapefiles.GPKG layers viewable QGIS (Figure 4, Figure 5.\n Figure 4: King County census tracts\n Figure 5: King County census tracts water erasedRendered 2022-03-04 00:43:04","code":"\nprint(ctdat[1,])## Simple feature collection with 1 feature and 13 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -122.3552 ymin: 47.51728 xmax: -122.3337 ymax: 47.54035\n## Geodetic CRS:  WGS 84\n##         GEOID                                      NAME p_denom_raceE\n## 1 53033011300 Census Tract 113, King County, Washington          6656\n##   p_denom_raceM p_n_whiteE p_n_whiteM p_n_aframE p_n_aframM p_n_aianE p_n_aianM\n## 1           447       3412        323        480        209       133       100\n##   p_n_asianE p_n_asianM                       geometry pct_black\n## 1        880        409 MULTIPOLYGON (((-122.3551 4...       7.2\nst_geometry(ctdat$geometry)[[1]] %>% st_as_text() %>% str_replace_all(pattern = \", \", replacement = \"\\n\") %>% cat()## MULTIPOLYGON (((-122.3551 47.52103\n## -122.3551 47.52287\n## -122.3551 47.5247\n## -122.355 47.53368\n## -122.3528 47.5341\n## -122.3517 47.53426\n## -122.3471 47.53408\n## -122.3471 47.53639\n## -122.3458 47.53948\n## -122.3422 47.54035\n## -122.337 47.53736\n## -122.3365 47.53429\n## -122.3347 47.53441\n## -122.3347 47.53015\n## -122.3337 47.52666\n## -122.3348 47.52542\n## -122.3348 47.52182\n## -122.3344 47.52082\n## -122.3363 47.52124\n## -122.3401 47.51728\n## -122.3414 47.51728\n## -122.3439 47.51729\n## -122.3552 47.51738\n## -122.3551 47.52103)))\nctdat1 <- ctdat %>% head(1)\n\npts <- st_coordinates(ctdat$geometry[1]) %>% \n    as_tibble()\n\nggplot() +\n    geom_sf(data = ctdat1) +\n    geom_point(data = pts, mapping = aes(x = X, y = Y)) +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n# get water and transform to WGS84\nwater_kc <- area_water(state = \"WA\", county = \"King\", year = 2019) %>% \n    st_transform(4326)\n\n# erase water from tracts\ntract_nowater <- ms_erase(tgtracts_kc_2019, water_kc) %>% \n    filter(GEOID != \"53033990100\")\n\n# download census variables\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat_nogeom <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = FALSE,\n    survey = \"acs5\",\n    progress_bar = FALSE\n)\n\n# join\nctdat_nowater <- tract_nowater %>% left_join(ctdat_nogeom, by = \"GEOID\")\n\n# write as a GPKG\n# an output dir\nmyDir <- \"//udrive.uw.edu/udrive/csde502_winter_2022/week03\"\nif(!dir.exists(myDir)){\n    dir.create(myDir)\n}\n# write tracts no water\nst_write(obj = ctdat_nowater, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"ctdat_nowater\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write water\nst_write(obj = water_kc, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"water_kc\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write tracts\nst_write(obj = tgtracts_kc_2019, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"tgtracts_kc_2019\", append = TRUE, delete_layer = TRUE, quiet = TRUE)## \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%## Getting data from the 2015-2019 5-year ACS"},{"path":"week3.html","id":"source-code-3","chapter":"3 Week 3","heading":"3.6 Source code","text":"File H:/csde502-winter-2022-main/03-week03.Rmd.","code":""},{"path":"week3.html","id":"r-code-used-in-this-document-3","chapter":"3 Week 3","heading":"3.6.1 R code used in this document","text":"","code":"\npacman::p_load(animation, captioner, idbr, htmltools, kableExtra, knitr, leaflet, leafem, leafpop, magrittr, mapview, pander, pander, psych, readstata13, rmapshaper, sf, stargazer, tidyverse, tidycensus, tigris)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n# set the census API key and the persistent tigris cache location\ntidycensus::census_api_key(\"*****************\", install = TRUE)\ntigris::tigris_cache_dir(\"H:/tigris_cache\")\nreadRenviron(\"~/.Renviron\")\nv2019 <- load_variables(year = 2019, dataset = \"acs5\", cache = TRUE)\nv2019 %>%\n    filter(concept == \"RACE\") %>%\n    kable(caption = 'ACS 5 year variables for the concept \"race\"') %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)\n\nctdat %<>% st_transform(4326)\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# get the data\nctdatlong <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"tidy\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)\n\nctdatlong %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA (long format)\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# the same census API key is used\nidb_api_key(Sys.getenv(\"CENSUS_API_KEY\"))\n# print the variables as a table\nvariables5 %>% DT::datatable()\n# get data only if necessary\nif(!exists(\"china_india_data\")){\n    china_india_data <- get_idb(\n        # from China and India\n        country = c(\"China\", \"India\"),\n        # years 2000 and 2021\n        year = c(2000, 2021),\n        # age range 0 to 100 years\n        age = 0:100,\n        # data for both sexes\n        sex = c(\"male\", \"female\")\n    )\n}\nchina_india_data %>%\n    # multiply male population by -1 to graph to the left of 0\n    mutate(pop = ifelse(sex == \"Male\", pop * -1, pop)) %>%\n    # plot with Y as age, color by sex\n    ggplot(aes(x = pop, y = as.factor(age), fill = sex)) +\n    # column plot\n    geom_col(width = 1) +\n    # minimal theme with no background annotations\n    theme_minimal(base_size = 15) +\n    # scale X with labels in the millions\n    scale_x_continuous(labels = function(x) paste0(abs(x / 1000000), \"m\")) +\n    # scale Y with breaks & labels every 10 years\n    scale_y_discrete(breaks = scales::pretty_breaks(n = 10)) +\n    # define the colors\n    scale_fill_manual(values = c(\"red\", \"gold\")) +\n    # set the labels\n    labs(\n        x = \"Population\",\n        y = \"Age\",\n        fill = \"\"\n    ) +\n    # facet by country and year\n    facet_grid(name ~ year)\ninf_mort <- get_idb(\n        # from China and India\n        country = c(\"China\", \"India\"),\n        # years 2000 and 2021\n        year = c(2000, 2021),\n        # infant mortality\n        variables = c(\"IMR_F\", \"IMR_M\")\n) %>% \n    mutate(female = imr_f,\n           male = imr_m)\ninf_mort %>% \n    pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"count\") %>% \n    ggplot(aes(x = factor(sex), y = count)) +\n    geom_col() +\n    facet_grid(name ~ year) +\n    labs(x = \"year\", y = \"deaths per 1000 population\")\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\n# a color palette in red with 10% classes \n# max % AfrAm rounded up to the nearest 10\nmyMax <- (ctdat$pct_black %>% max(na.rm = TRUE) + 10) %>% round(0)\n# bins for color\nbins <- seq(0, myMax, by = 10)\n# palette with bins and % AfrAm\nmyPal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ myPal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # add the legend using the palette and % AfrAm\n    addLegend(\n        position = \"bottomright\", pal = myPal, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()\n# get the tracts\ntgtracts_kc_2019 <- tigris::tracts(state = \"WA\", county = \"King\", year = 2019, progress_bar = FALSE)\n# project the coordinates to WGS84 for mapping\ntgtracts_kc_2019 %<>%  st_transform(4326)\n\n# the leaflet map\nm <- leaflet(height = \"500\") %>%\n    addPolygons(\n        data = ctdat,\n        stroke = TRUE,\n        color = \"red\",\n        weight = 7,\n        fill = FALSE\n    ) %>%\n    addPolygons(\n        data = tgtracts_kc_2019,\n        stroke = TRUE,\n        color = \"black\",\n        weight = 2,\n        fill = FALSE\n    ) %>%\n    addLegend(\n        colors = c(\"red\", \"black\"),\n        labels = c(\"tidyverse generalized\", \"tigris detailed\")\n    ) %>%\n    addTiles() %>%\n    setView(lng = -122.3603, lat = 47.62231, zoom = 13)\n\nm\nctdat_mv <- ctdat %>%\n    mutate(afram_white = (p_n_aframE / p_n_whiteE) %>% round(2))\n\nmapview(ctdat_mv,\n        zcol = \"afram_white\",\n        popup = popupTable(ctdat_mv,\n            zcol = c(\"p_n_aframE\", \"p_n_whiteE\")\n        )\n    )\nprint(ctdat[1,])\nst_geometry(ctdat$geometry)[[1]] %>% st_as_text() %>% str_replace_all(pattern = \", \", replacement = \"\\n\") %>% cat()\nctdat1 <- ctdat %>% head(1)\n\npts <- st_coordinates(ctdat$geometry[1]) %>% \n    as_tibble()\n\nggplot() +\n    geom_sf(data = ctdat1) +\n    geom_point(data = pts, mapping = aes(x = X, y = Y)) +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n# get water and transform to WGS84\nwater_kc <- area_water(state = \"WA\", county = \"King\", year = 2019) %>% \n    st_transform(4326)\n\n# erase water from tracts\ntract_nowater <- ms_erase(tgtracts_kc_2019, water_kc) %>% \n    filter(GEOID != \"53033990100\")\n\n# download census variables\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat_nogeom <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = FALSE,\n    survey = \"acs5\",\n    progress_bar = FALSE\n)\n\n# join\nctdat_nowater <- tract_nowater %>% left_join(ctdat_nogeom, by = \"GEOID\")\n\n# write as a GPKG\n# an output dir\nmyDir <- \"//udrive.uw.edu/udrive/csde502_winter_2022/week03\"\nif(!dir.exists(myDir)){\n    dir.create(myDir)\n}\n# write tracts no water\nst_write(obj = ctdat_nowater, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"ctdat_nowater\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write water\nst_write(obj = water_kc, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"water_kc\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write tracts\nst_write(obj = tgtracts_kc_2019, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"tgtracts_kc_2019\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n\n# get water and transform to WGS84\nwater_kc <- area_water(state = \"WA\", county = \"King\", year = 2019) %>% \n    st_transform(4326)\n\n# erase water from tracts\ntract_nowater <- ms_erase(tgtracts_kc_2019, water_kc) %>% \n    filter(GEOID != \"53033990100\")\n\n# download census variables\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat_nogeom <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = FALSE,\n    survey = \"acs5\"\n)\n\n# join\nctdat_nowater <- tract_nowater %>% left_join(ctdat_nogeom, by = \"GEOID\")\n\n# write as a GPKG\n# an output dir\nmyDir <- \"//udrive.uw.edu/udrive/csde502_winter_2022/week03\"\nif(!dir.exists(myDir)){\n    dir.create(myDir)\n}\n# write tracts no water\nst_write(obj = ctdat_nowater, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"ctdat_nowater\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write water\nst_write(obj = water_kc, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"water_kc\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write tracts\nst_write(obj = tgtracts_kc_2019, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"tgtracts_kc_2019\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week3.html","id":"complete-rmd-code-3","chapter":"3 Week 3","heading":"3.6.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 3 {#week3}\n\n<style>\n.border1 {   \n    border-width: 1px;   \n    border-color: black;   \n    border-style: solid; } \n<\/style>\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\npacman::p_load(animation, captioner, idbr, htmltools, kableExtra, knitr, leaflet, leafem, leafpop, magrittr, mapview, pander, pander, psych, readstata13, rmapshaper, sf, stargazer, tidyverse, tidycensus, tigris)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\nThis session covers two basic areas: (1) downloading census and international data using `tidycensus`, `tigris`, and `idbr`, and (2) mapping and GIS analysis with `leaflet`, `mapview`, and `sf`.\n\nDownload the file [week03.Rmd](files/week03/week03.Rmd) and use that as the base. Change the second line in the YAML header so it uses your name and your web site. See [UW Students Web Server](https://students.washington.edu/) if you do not have a web site.\n\n<h2>Topics<\/h2>\n\n* [`tidycensus`](#tidycensus): Load US Census Boundary and Attribute Data as â€˜tidyverseâ€™ and â€˜sfâ€™-Ready Data Frames\n* [`tigris`](#tidycensus): Load Census TIGER/Line Shapefiles\n* [`idbr`](#idbr): R Interface to the US Census Bureau International Data Base API\n* [`leaflet`](#leaflet): Create Interactive Web Maps with the JavaScript â€˜Leafletâ€™ Library\n* [`mapview`](#mapview): Interactive Viewing of Spatial Data in R\n* [`sf`](#sf): Simple Features for R: Simple Features (GIS) for R\n\n## Getting US Census data with `tigris`, `tidycensus` {#tidycensus}\nDealing with US Census data can be overwhelming, particularly if using the raw text-based data. The Census Bureau has an API that allows more streamlined downloads of variables (as data frames) and geographies (as simple format shapes). It is necessary to get an API key, available for free. See [tidycensus](https://walker-data.com/tidycensus/) and  [tidycensus basic usage](https://walker-data.com/tidycensus/articles/basic-usage.html), and for a complete treatment, [Analyzing US Census Data](https://walker-data.com/census-r).\n\n`tidycensus` uses [`tigris`](https://www.rdocumentation.org/packages/tigris/versions/1.0), which downloads the geographic data portion of the census files.\n\nA simple example will download the variables representing the count of White, Black/African American, American Indian/Native American, and Asian persons from the American Community Survey (ACS) data for King County in 2019. \n\n### US Census API key installation\nFor this example to run, you need to have your US Census API key installed. run this code, but substituting your actual API key for the asterisks.\n\n```{r, eval=FALSE}\n# set the census API key and the persistent tigris cache location\ntidycensus::census_api_key(\"*****************\", install = TRUE)\ntigris::tigris_cache_dir(\"H:/tigris_cache\")\n```\n\n<tt>\n<div style='color: red;'>\nYour API key has been stored in your .Renviron and can be accessed by Sys.getenv(\"CENSUS_API_KEY\").<br>\nTo use now, restart R or run `readRenviron(\"~/.Renviron\")`\n<\/div>\n<\/tt>\n\nYou should enable the API key:\n\n```{r}\nreadRenviron(\"~/.Renviron\")\n```\n\nThe option `install = TRUE` writes a line in your `~/.Renviron` file (`~/` is shorthand for \"home directory\"; under Windows typically your `C:\\users\\username\\Documents` folder; under MacOS, typically `/home/username`). Similarly, `tigris_cahce_dir()` writes to the `~/.Renviron` file. For example my `.Renviron` file (`r figure_nums(name = \"apikey\", display = \"cite\")`) shows the API key and the persistent `tigris` cache folder.\n\n![](images/week03/2022-01-20 12_34_44-Window.png)\n\\    \n_`r figure_nums(name = \"apikey\", caption = \"Census API key stored in ~/.Renviron\")`_\n\nWith the API key installed, you can simply load the `tidycensus` package and download data. When R starts, it reads this file and creates system environment variables for the R session; in this case I'm setting two variables (TIGRIS_CACHE_DIR and CENSUS_API_KEY). You could set other system environment variables to be active in R by adding them to this file.\n\n### Census variables\nFirst, it should be noted that not all data products and variables are available for all census geographic units. See [Geography and variables in tidycensus](https://walker-data.com/census-r/an-introduction-to-tidycensus.html#geography-and-variables-in-tidycensus) for a list of which geographic units are available for different data products using `tidycensus`.\n\n`tidycensus` has a helper function for obtaining the lists of variables and their descriptions. This is necessary because the list of variables is quite long and the variable names are codes that are functionally unintelligible.\n\nCensus variable lists are obtained using the `load_variables()` function, which is used to specify the year, data set, and whether or not to cache results. Because the variable lists are large, it may make sense to cache the lists.\n\nHere we will list the variables for the 2019 ACS 5-year average data:\n\n```{r}\nv2019 <- load_variables(year = 2019, dataset = \"acs5\", cache = TRUE)\n```\n\nThe table, which has `r nrow(v2019)` records, can then be browsed using the function `View(v2019)`. Using the tabular view in this way makes it convenient to search for variable names or concepts using the filters. For example we can search for the term \"race\" in the `concept` field, as shown in (`r figure_nums(name = \"vnamesearch\", display = \"cite\")`).\n\n![](images/week03/2022-01-20 13_44_12-Window.png)\n\\    \n_`r figure_nums(name = \"vnamesearch\", caption = \"ACS 5 year variables\")`_\n\nHowever, this interface uses only free text searches and will match any record containing the search string, whether or not the search string is the word alone or the whole word. One can use more specific searches using R syntax, for example to list all variables tagged with the concept \"RACE\", filtering by the explicit string is more specific (\\@ref(tab:v2019tab)).\n\n```{r v2019tab}\nv2019 %>%\n    filter(concept == \"RACE\") %>%\n    kable(caption = 'ACS 5 year variables for the concept \"race\"') %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nThis shows that the variable for the count of all persons is `B02001_001` and the variables for White alone, Black alone, American Indian/Alaskan Native alone, Asian alone, and some other race alone are `B02001_002`, `B02001_003`, `B02001_004`, `B02001_005`, and `B02001_007`, respectively. One could also use regular expressions to search for desired patterns in the concept.\n\n### Downloading data\n`tidycensus` has two main functions, `get_decennial()` for downloading decennial data and `get_acs()` for downloading American Community Survey (ACS) data. The functions are quite similar in structure.\n\nHere we will define a set of variables using a named vector of variable names.\n\n```{r, warning=FALSE}\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n```\n\nThe \"named vector\" refers to the elements of the vector having names, for example, the first element below has the name `p_denom_race` and the value \"B02001_001\". This construction is used so that when the data are downloaded, the resultant data frame will have more readable names.\n \nNext, we will download the actual data. Here we will be downloading census tract level data for King County, WA, from the 5 year ACS estimates for the year ending in 2019. We also specify `options(tigris_use_cache=TRUE)` so that any shapefile data downloaded are cached and will not be re-downloaded if not necessary. Note in `r figure_nums(name = \"apikey\", display = \"cite\")` I had specified a location where I wanted my tigris cache to be located (`H:/tigris_cache`). Another important option is `output = \"wide\"`, which generates an output table with one record per census unit and columns representing the variables. A `tidy` output would present a \"long\" table with repeated records per census unit, one record per variable estimate.\n\n```{r, message=FALSE}\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)\n\nctdat %<>% st_transform(4326)\n```\n\n```\nGetting data from the 2015-2019 5-year ACS\nUsing FIPS code '53' for state 'WA'\nUsing FIPS code '033' for 'King County'\n```\n\nA few values are shown in Table \\@ref(tab:census). Because the ACS data include a margin of error (MOE), the estimate is represented with the variable name having the terminal character \"E\" and the MOE is represented with the variable name having the terminal character \"M\". The variables are shown with the names we specified earlier. Without the named vector, the downloaded variables would be given the raw variable names, which are generally not helpful. Note also because of the `geometry = TRUE` option, there is a `geometry` column containing geographic data. The \"wide\" format data are more amenable to applications requiring one record per census unit, because typically other census-unit level data are represented with one record per census unit, which allows for table joins, fro example in mapping applications.\n\n```{r census}\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nAn example of data downloaded in \"long\" format is shown in \\@ref(tab:censuslong). Here, the column `variable` indicates what measure is stored in the record, and `estimate` and `moe` present the data values for that particular variable $\\times$ census unit combination. Data in this format are more amenable to generating data summaries, rather than applications such as mapping.\n\n```{r censuslong}\n# get the data\nctdatlong <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"tidy\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)\n\nctdatlong %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA (long format)\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\n\n## Getting US Census International data with `idbr` {#idbr}\nThere is also an API for the US Census international data that can be accessed using the [`idbr`](https://cran.r-project.org/web/packages/idbr/index.html) package.\n\nYou will need to use your US Census API key to access the data using `idbr`. Here we set the key using the system environment variable so the API key is not stored in plain text:\n\n```{r}\n# the same census API key is used\nidb_api_key(Sys.getenv(\"CENSUS_API_KEY\"))\n```\n\nData are downloaded using the `get_idb()` function. Data can be obtained for one or more countries, years, variables, concepts (groups of variables), ages, sex (male or female), and low or high resolution (as part of the `geometry()` option. \n\n### IDB variables\n\nVariables and concepts can be listed using the `idb_variables()` and `idb_concepts()` functions, respectively. A more informative list (`r table_nums(name = \"idbrvar\", display = \"cite\")`) can be generated with the `variables5()` function.\n\n_`r table_nums(name = \"idbrvar\", caption = \"idbr variables\")`_\n\n```{r}\n# print the variables as a table\nvariables5 %>% DT::datatable()\n```\n\nThe basic use of `get_idb()` without specification of variables or concepts downloads population counts for specific one-year age classes for specific countries and years. Here we download the data representing China and India from 2000 and 2021.\n\n```{r pyramiddata}\n# get data only if necessary\nif(!exists(\"china_india_data\")){\n    china_india_data <- get_idb(\n        # from China and India\n        country = c(\"China\", \"India\"),\n        # years 2000 and 2021\n        year = c(2000, 2021),\n        # age range 0 to 100 years\n        age = 0:100,\n        # data for both sexes\n        sex = c(\"male\", \"female\")\n    )\n}\n```\n\nAnd generate a population pyramid for the two countries for the two years, using `ggplot()` with the `geom_col()` format and a grid of plots with `facet_grid()`.\n\n```{r pyramid, fig.cap=\"Population structure of\\nChina and Japan, 2000 and 2021\"}\nchina_india_data %>%\n    # multiply male population by -1 to graph to the left of 0\n    mutate(pop = ifelse(sex == \"Male\", pop * -1, pop)) %>%\n    # plot with Y as age, color by sex\n    ggplot(aes(x = pop, y = as.factor(age), fill = sex)) +\n    # column plot\n    geom_col(width = 1) +\n    # minimal theme with no background annotations\n    theme_minimal(base_size = 15) +\n    # scale X with labels in the millions\n    scale_x_continuous(labels = function(x) paste0(abs(x / 1000000), \"m\")) +\n    # scale Y with breaks & labels every 10 years\n    scale_y_discrete(breaks = scales::pretty_breaks(n = 10)) +\n    # define the colors\n    scale_fill_manual(values = c(\"red\", \"gold\")) +\n    # set the labels\n    labs(\n        x = \"Population\",\n        y = \"Age\",\n        fill = \"\"\n    ) +\n    # facet by country and year\n    facet_grid(name ~ year)\n```\n\n\\@ref(fig:pyramid) shows that for both China and India from 2000 to 2021 a larger proportion of the population has moved from younger to older age classes. China has a much larger proportion in older age classes than does India, and China also has large variations in proportion of population by age class, whereas India has relatively little variability across year of age.\n\n### Downloading variables or concept groups\nData can be downloaded for specific variables in the `variables5` data frame in the `idbr` package. For example we can download female and male infant mortality rates per 1000 population (variables `IMR_F` and `IMR_M`) for India and China in 2000 and 2021:\n\n```{r}\ninf_mort <- get_idb(\n        # from China and India\n        country = c(\"China\", \"India\"),\n        # years 2000 and 2021\n        year = c(2000, 2021),\n        # infant mortality\n        variables = c(\"IMR_F\", \"IMR_M\")\n) %>% \n    mutate(female = imr_f,\n           male = imr_m)\n```\n\nWe then create a simple column graph from the data (\\@ref(fig:infmort)).\n\n```{r infmort, fig.cap=\"Infant mortality, China and Japan, 2000 and 2021\"}\ninf_mort %>% \n    pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"count\") %>% \n    ggplot(aes(x = factor(sex), y = count)) +\n    geom_col() +\n    facet_grid(name ~ year) +\n    labs(x = \"year\", y = \"deaths per 1000 population\")\n```\n\n\n## Mapping census data from `tidycensus` and `tigris` using `leaflet` {#leaflet}\n\nUsing the data downloaded in the [tidycensus](#tidycensus) section, we present a simple map is shown in \\@ref(fig:ct), with percent African American residents and tract identifier.\n\n```{r ct, fig.cap=\"Percent African American in census tracts in King County, 2019 ACS 5-year estimate\", warning=FALSE, message=FALSE}\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\n# a color palette in red with 10% classes \n# max % AfrAm rounded up to the nearest 10\nmyMax <- (ctdat$pct_black %>% max(na.rm = TRUE) + 10) %>% round(0)\n# bins for color\nbins <- seq(0, myMax, by = 10)\n# palette with bins and % AfrAm\nmyPal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ myPal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # add the legend using the palette and % AfrAm\n    addLegend(\n        position = \"bottomright\", pal = myPal, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()\n```\n\nOne thing to note is that the `tidyverse::get_...()` functions may not be downloading the most detailed GIS data. Here we compare the data obtained using `tigris::tracts()`, also for King County, WA in 2019 (\\@ref(fig:ctcompare)). First, the `tidycensus` map data are clipped at the shore line. Second, there are some differences in the shape and size of tracts in the downtown area. \n\n```{r ctcompare, fig.cap=\"tidyverse generalized tracts versus tigris detailed tracts\", warning=FALSE, message=FALSE}\n# get the tracts\ntgtracts_kc_2019 <- tigris::tracts(state = \"WA\", county = \"King\", year = 2019, progress_bar = FALSE)\n# project the coordinates to WGS84 for mapping\ntgtracts_kc_2019 %<>%  st_transform(4326)\n\n# the leaflet map\nm <- leaflet(height = \"500\") %>%\n    addPolygons(\n        data = ctdat,\n        stroke = TRUE,\n        color = \"red\",\n        weight = 7,\n        fill = FALSE\n    ) %>%\n    addPolygons(\n        data = tgtracts_kc_2019,\n        stroke = TRUE,\n        color = \"black\",\n        weight = 2,\n        fill = FALSE\n    ) %>%\n    addLegend(\n        colors = c(\"red\", \"black\"),\n        labels = c(\"tidyverse generalized\", \"tigris detailed\")\n    ) %>%\n    addTiles() %>%\n    setView(lng = -122.3603, lat = 47.62231, zoom = 13)\n\nm\n```\n\n## Mapping census data from `tidycensus` and `tigris` using `mapview` {#mapview}\n[`mapview`](https://r-spatial.github.io/mapview/) provides a fast and easy interface for creating interactive maps built on top of the `leaflet` framework. Whereas `leaflet` provides more fundamental controls over mapping, `mapview` will load layers with useful defaults. The map automatically includes the XY location of the mouse pointer at the top of the interface, choices for base map tiles, and when used with the `zcol` argument, color coding based on numerical or categorical variables in the data frame. Here we will create a `mapview` choropleth map of census tracts in King County displaying the ratio of African American to White population counts (`r figure_nums(name = \"ctmapview\", display = \"cite\")`). The `popup` argument is used to control which variables are shown in the popup that appears when a feature is clicked.\n\nNOTE: There is a problem with `mapview` implemented within R Markdown or Bookdown that does not allow the page to render with `mapview` code. Copy and run the code below. Unfortunately the map will not be rendered in these pages.\n\n```{r, eval=FALSE}\nctdat_mv <- ctdat %>%\n    mutate(afram_white = (p_n_aframE / p_n_whiteE) %>% round(2))\n\nmapview(ctdat_mv,\n        zcol = \"afram_white\",\n        popup = popupTable(ctdat_mv,\n            zcol = c(\"p_n_aframE\", \"p_n_whiteE\")\n        )\n    )\n```\n\n\\    \n_`r figure_nums(name = \"ctmapview\", caption = \"A mapview map of ratio of African American to White population counts in King County, 2019 ACS data\")`_\n\nFor more things you can do with `mapview` see [mapview](https://r-spatial.github.io/mapview), in particular, look at the \"Articles\" link at the top of the page.\n\n## Simple features: GIS in R {#sf}\nThe maps displayed in the sections on [`leaflet`](#leaflet) and [`mapview`](#mapview) are possible because they are using spatially explicit data. When we looked at the contents of the census tract data frames, there was a `geometry` column that contained specially formatted values. The format for these is a standard developed by the [Open Geospatial Consortium (OGC)](https://www.ogc.org/) and the [International Organization for Standardization (ISO)](https://www.iso.org/) . known as \"simple features\", and includes specifications for how to store and process data representing geographic features.\n\nWithin R, the most developed package is [`sf`: Simple Features for R](https://r-spatial.github.io/sf/). A full treatment is not possible in this course, but the reference for `sf` is a good start, as well as the book [Geocomputation with R](https://bookdown.org/robinlovelace/geocompr)\n\nGeographic objects are stored in standard format. For example, the first census tract is composed of a set of attributes as well as the geometry:\n\n```{r}\nprint(ctdat[1,])\n```\n\nThe geometry for this record is composed of a `MULTIPOLYGON`, that is a polygon that can consist of one or more parts (for example, the state of Washington could be represented as a single multipolygon where the main land mass as well as all of the islands are disjointed parts of the same polygon feature).\n\nThe first polygon consists of a set of vertices that define the shape of the polygon:\n\n```{r}\nst_geometry(ctdat$geometry)[[1]] %>% st_as_text() %>% str_replace_all(pattern = \", \", replacement = \"\\n\") %>% cat()\n```\n\nHere we extract the coordinates of vertices the polygon and plot them as points on top of the polygon\n\n```{r}\nctdat1 <- ctdat %>% head(1)\n\npts <- st_coordinates(ctdat$geometry[1]) %>% \n    as_tibble()\n\nggplot() +\n    geom_sf(data = ctdat1) +\n    geom_point(data = pts, mapping = aes(x = X, y = Y)) +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\nThe `sf` and package contains a plethora of analytic functions. Here we could the `st_difference()` function to erase water areas from the detailed census tract data we downloaded with `tigirs` earlier. Another package, [`mapshaper`](https://cran.r-project.org/web/packages/rmapshaper) has fewer functions, but upon experimentation, the `ms_erase()` function performed faster and better than `sf::st_difference()`, so we will use that instead.\n\nWe will start by downloading water areas, then perform the spatial overlay, then download the census values (without geometry) and finally join the geometry and census variables together and export to a [geopackage (GPKG) file](https://www.geopackage.org/). A geopackage is a GIS data format that can contain multiple data sources and does not suffer some of the built-in limitations of shapefiles.\n\n```{r, eval=FALSE}\n# get water and transform to WGS84\nwater_kc <- area_water(state = \"WA\", county = \"King\", year = 2019) %>% \n    st_transform(4326)\n\n# erase water from tracts\ntract_nowater <- ms_erase(tgtracts_kc_2019, water_kc) %>% \n    filter(GEOID != \"53033990100\")\n\n# download census variables\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat_nogeom <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = FALSE,\n    survey = \"acs5\",\n    progress_bar = FALSE\n)\n\n# join\nctdat_nowater <- tract_nowater %>% left_join(ctdat_nogeom, by = \"GEOID\")\n\n# write as a GPKG\n# an output dir\nmyDir <- \"//udrive.uw.edu/udrive/csde502_winter_2022/week03\"\nif(!dir.exists(myDir)){\n    dir.create(myDir)\n}\n# write tracts no water\nst_write(obj = ctdat_nowater, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"ctdat_nowater\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write water\nst_write(obj = water_kc, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"water_kc\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write tracts\nst_write(obj = tgtracts_kc_2019, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"tgtracts_kc_2019\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n\n```\n\n```{r, echo=FALSE}\n# get water and transform to WGS84\nwater_kc <- area_water(state = \"WA\", county = \"King\", year = 2019) %>% \n    st_transform(4326)\n\n# erase water from tracts\ntract_nowater <- ms_erase(tgtracts_kc_2019, water_kc) %>% \n    filter(GEOID != \"53033990100\")\n\n# download census variables\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n# get the data\nctdat_nogeom <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = FALSE,\n    survey = \"acs5\"\n)\n\n# join\nctdat_nowater <- tract_nowater %>% left_join(ctdat_nogeom, by = \"GEOID\")\n\n# write as a GPKG\n# an output dir\nmyDir <- \"//udrive.uw.edu/udrive/csde502_winter_2022/week03\"\nif(!dir.exists(myDir)){\n    dir.create(myDir)\n}\n# write tracts no water\nst_write(obj = ctdat_nowater, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"ctdat_nowater\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write water\nst_write(obj = water_kc, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"water_kc\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n# write tracts\nst_write(obj = tgtracts_kc_2019, dsn = file.path(myDir, \"ctdat_nowater.gpkg\"), layer = \"tgtracts_kc_2019\", append = TRUE, delete_layer = TRUE, quiet = TRUE)\n\n```\n\n\nThe GPKG layers are viewable in QGIS (`r figure_nums(name = \"tracts_qgis\", display = \"cite\")`, `r figure_nums(name = \"tracts_nowater_qgis\", display = \"cite\")`.\n\n![](images/week03/map_tracts.png)\n\\    \n_`r figure_nums(name = \"tracts_qgis\", caption = \"King County census tracts\")`_\n\n\n![](images/week03/map_tracts_nowater.png)\n\\    \n_`r figure_nums(name = \"tracts_nowater_qgis\", caption = \"King County census tracts with water erased\")`_\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week4.html","id":"week4","chapter":"4 Week 4","heading":"4 Week 4","text":"week’s topics cover functions sampling, latter including cursory treatment loops bootstrapping. revisit Ben’s code reading Human Mortality Human Fertility databases look use purrr::map() alternative () looping functions. Finally delve demogR demography packages analysis age-structured demographic models forecasting mortality, fertility, migration population data.R environmentsR functionsSampling RPackages running demographic analysis\ndemogR\ndemography\ndemogRdemographyDownload exercise_blank.Rmd template lesson.","code":""},{"path":"week4.html","id":"renviron","chapter":"4 Week 4","heading":"4.1 Environments","text":"Functions exist environments, “frames” collections containing objects including variables, functions, etc. global environment (.GlobalEnv) contains data, functions, current R session. objects can enumerated ls() function.reason environments mentioned time functions instantiate environments exist function running, function completed, environment removed memory. .","code":""},{"path":"week4.html","id":"rfunc","chapter":"4 Week 4","heading":"4.2 Functions","text":"Functions sets statements R grouped together perform specific task set tasks. Functions either built , included packages, user-defined. Functions used mainly simplify running series individual commands functions, situations process need run multiple times different inputs, control structures needed (e.g., looping, logical branching).","code":""},{"path":"week4.html","id":"function-components","chapter":"4 Week 4","heading":"4.2.1 Function Components","text":"different parts function :(Usually) Name: actual name function. stored R environment object name.(Optional) Arguments: Arguments specify inputs options function. function invoked, pass value argument. Arguments optional; , function may contain arguments. Also arguments can default values.Body: function body contains collection statements defines function .Return value: return value function last expression function body evaluated.Another important concept functions environments.","code":""},{"path":"week4.html","id":"name","chapter":"4 Week 4","heading":"4.2.1.1 Name","text":"functions created code formFor example, square vector numerical values:function name f_square.functions named, referred “anonymous” functions. example, functions can used within apply family functions. oprationalized example.lapply() function used apply function element list. example, last line code chunk :body function x[1], .e., obtain first element vector. natural language, translates “element list L, obtain first element vector x.” function named, hence “anonymous.”","code":"function_name <- function(argument(s)){\n    statement(s)\n}\nf_square <- function(x){\n    x^2\n}\n# create a list of three vectors of random numbers of different random lengths\n\n# set.seed() makes the random process reproducible.\nset.seed(10)\n# vector lengths\nv.len <- rnorm(n = 3, mean = 30, sd = 10) %>% round(0)\n\n# make the random vectors\nset.seed(5)\nv1 <- rnorm(n = v.len[1])\nset.seed(3)\nv2 <- rnorm(n = v.len[2])\nset.seed(6)\nv3 <- rnorm(n = v.len[3])\n\n# create the list\nL <- list(v1, v2, v3)\n\n# get the first value from each vector in the list\nlapply(X = L, FUN = function(x) {x[1]})## [[1]]\n## [1] -0.8408555\n## \n## [[2]]\n## [1] -0.9619334\n## \n## [[3]]\n## [1] 0.269606lapply(X = L, FUN = function(x) {x[1]})\n"},{"path":"week4.html","id":"arguments","chapter":"4 Week 4","heading":"4.2.1.2 Arguments","text":"functions require arguments. Arguments used instantiate variables within function’s environment can used later body function. argument named, name used within function local variable within function’s environment.Following example , f_square takes argument named “x” numeric vector., let’s modify function demonstrate within environment function, x variable using print(x):can try running original function using different () arguments:, using vector single NA numeric… vector contains numeric NA (first two elements numeric, third element NA automatically cast numeric):… null:… vector containing null:… argument :functions require arguments, e.g., get current date time:… try use argument get error:","code":"\nf_square_2 <- function(x){\n    message(\"input:\")\n    print(x)\n    message(\"output:\")\n    x^2\n}\n\nf_square_2(c(1,2,3))## input:## [1] 1 2 3## output:## [1] 1 4 9\nf_square(as.numeric(NA))## [1] NA\nf_square(c(1, 2, NA))## [1]  1  4 NA\nf_square(NULL)## numeric(0)\nf_square(c(1, 2, NULL))## [1] 1 4f_square()## Error in f_square() : argument \"x\" is missing, with no default\nSys.Date()## [1] \"2022-03-04\"\nSys.time()## [1] \"2022-03-04 00:43:11 PST\"Sys.Date(1)## Error in Sys.Date(1) : unused argument (1)"},{"path":"week4.html","id":"default-values-for-arguments","chapter":"4 Week 4","heading":"4.2.1.2.1 Default values for arguments","text":"want argument default value, specified listed arguments form argument = value.Following previous f_square_2() function, can set default value x 3:default argument set, function can run arguments, default substituted :meaningful example demonstrates stratification counts intensity bins using accelerometry data. using accelerometry one day’s data one subject study.cut points accelerometry identified 0, 2690, 6167, 9642 counts per minute, Sasaki et al. (2011).Sasaki JE, John D, Freedson PS. Validation comparison ActiGraph activity monitors. J Sci Med Sport. 2011;14(5):411-416. doi:10.1016/j.jsams.2011.04.003“variable vm3 vector magnitude measured accelerometer minute. Data: accelerometry.csv.following function codes intensity aforementioned cut points default using default labels:… run defaults tabulate minutes spent different PA levelsBut run different thresholds levels, SPLA = “sedentary/low physical activity” MVPA = “moderate--vigorous physical activity):","code":"\nf_square_3 <- function(x = 3){\n    x^2\n}\nf_square_3()## [1] 9\n# read the accelerometry data\nacc <- read.csv(\"files/accelerometry.csv\")\n\n# print first 6 lines\nhead(acc)##                 time_acc vm3\n## 1 2018-09-13 02:59:00-07   0\n## 2 2018-09-13 02:58:00-07   0\n## 3 2018-09-13 02:57:00-07   0\n## 4 2018-09-13 02:56:00-07   0\n## 5 2018-09-13 02:55:00-07   0\n## 6 2018-09-13 02:54:00-07   0\nf_acc_intensity <- function(x,\n                            cuts = c(\n                                -Inf,\n                                2690, 6167, 9642, Inf\n                            ),\n                            labels = c(\n                                \"sedentary/low\",\n                                \"moderate\", \"vigorous\", \"very vigorous\"\n                            )) {\n    cut(x = acc$vm3, breaks = cuts, labels = labels)\n}\n# recode\nacc$intens_default <- f_acc_intensity(acc$vm3)\n\n# tabulate\nacc %>% \n    group_by(intens_default) %>% \n    summarise(n = n())## # A tibble: 3 x 2\n##   intens_default     n\n##   <fct>          <int>\n## 1 sedentary/low   1435\n## 2 moderate           4\n## 3 vigorous           1\nacc$intens_2lev <- f_acc_intensity(x = acc$vm3,\n                                cuts = c(-Inf, 2690, Inf),\n                                labels = c(\"SLPA\", \"MVVPA\"))\nacc %>% \n    group_by(intens_2lev) %>% \n    summarise(n = n())## # A tibble: 2 x 2\n##   intens_2lev     n\n##   <fct>       <int>\n## 1 SLPA         1435\n## 2 MVVPA           5"},{"path":"week4.html","id":"the-...-argument","chapter":"4 Week 4","heading":"4.2.1.2.2 The ... argument","text":"functions known priori number set arguments, large number arguments passed another function ... argument used. cover , encouraged read : Use Dots Argument R; three-dots construct R.","code":""},{"path":"week4.html","id":"body","chapter":"4 Week 4","heading":"4.2.1.3 Body","text":"function’s body contains code perform purpose function. Following initial example, body function simplyThe body can simple complicated needs order achieve desired result.","code":"x^2"},{"path":"week4.html","id":"logical-testing-for-branching","chapter":"4 Week 4","heading":"4.2.2 Logical testing for branching","text":"Sometimes want vary code based condition. condition met, execute block code. condition met, condition met, execute code. complete tutorial, see R else elseif StatementFollowing previous f_square_2() function, can modify print input based logical argument verbose. code, verbose object set TRUE, text printed message well value supplied x. either case (verbose = TRUE verbose = FALSE), output value x^2 returned.run default option verbose = FALSE; final value x^2 output:… verbose = TRUE, additional text printed :additional ways use (), nested statements, using:alternative:additional condition check first condition met:","code":"\nf_square_4 <- function(x, verbose = FALSE){\n    # only run the next lines if verbose is true\n    if(verbose){\n        message(\"input:\")\n        print(x)\n        message(\"output:\")\n    }\n    x^2\n}\nf_square_4(x = c(1, 2, 3))## [1] 1 4 9\nf_square_4(x = c(1, 2, 3), verbose = TRUE)## input:## [1] 1 2 3## output:## [1] 1 4 9if(condition1){\n    if(condition2){\n        statement\n    }\n}if(condition){\n    statement1\n    statement2\n    ...\n} else {\n    statement3\n    statement4\n}\n...if(condition1){\n    statement1\n    statement2\n    ...\n} else if (condition2){\n    statement3\n    statement4\n} else {\n    statement5\n    statement6\n}\n..."},{"path":"week4.html","id":"return-value","chapter":"4 Week 4","heading":"4.2.3 Return value","text":"return value either last evaluated expression function object specified using return() function. functions intended return one value, convention last line function.original f_square() function, return value x^2 since return() value specified, e.g., vector one element:vector multiple elements:However, possible different outputs can produced function based logical testing, one can explicitly use return(object) code; time object output function stop. simple example explicitly specifying return values shown numerical comparison function:Based criteria number arguments relative value arguments x y, different outputs generated. examples running function:want handle expected error, can print informative message use return(invisible()), returns nothing (whereas return() results NULL object) e.g., without invisible():… invisible():","code":"\nf_square <- function(x){\n    x^2\n}\nf_square(3)## [1] 9\nf_square(c(1,2,3))## [1] 1 4 9\nf_compare <- function(x, y){\n    # either missing?\n    if(nargs() != 2)\n        return(\"invalid number of arguments\")\n    # numeric?\n    if(!is.numeric(x) | !is.numeric(y)){\n        return(sprintf(\"%s or %s is not numeric.\", x, y))\n    }\n    # comparisons follow\n    if(x > y){\n        return(sprintf(\"%s is greater than %s\", x, y))\n    } \n    if(x < y) {\n        return(sprintf(\"%s is less than %s\", x, y))\n    }\n    if(x == y){\n        return(sprintf(\"%s equals %s\", x, y))\n    }\n}\nf_compare(1)## [1] \"invalid number of arguments\"\nf_compare(1, 2)## [1] \"1 is less than 2\"\nf_compare(2, 1)## [1] \"2 is greater than 1\"\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return()\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")## Warning in f_readfile(\"foobar.txt\"): foobar.txt does not exist!## NULL\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return(invisible())\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")## Warning in f_readfile(\"foobar.txt\"): foobar.txt does not exist!"},{"path":"week4.html","id":"funcenviron","chapter":"4 Week 4","heading":"4.2.4 Function environments","text":"mentioned , functions instantiate environments exist function evaluated. means functions can include named variables name variable different environment. example function lists objects local global environments:function completes, objects local environment purged. running complicated function creates intermediate values want examine troubleshooting, can create environment .GlobalEnv (.e., overall environment R running), assign variable specific value environment created specifically examining intermediate products function:function runs, objects bar foobar placed foo environment. can examine :can view values:objects appear .GloalEnv, even though environment foo ; consider objects bar foobar “nested” environment foo nested .GlobalEnv.","code":"\n# declare a few variables\nx <- 1\ny <- \"hello\"\n\n# a simple function\nf <- function(x){\n    # create a local variable\n    y <- x + 2\n    # another function inside this function\n    g <- function(x){\n        x * 3\n    }\n    # what variables are in this environment?\n    print(\"----------\")\n    print(\"objects in this function's environment:\")\n    print(ls())\n    # what is in the global env?\n    print(\"----------\")\n    print(\"objects in the global environment:\")\n    print(ls(envir = .GlobalEnv))\n    # return the output of the function\n    print(\"----------\")\n    y\n}\n\nf(1)## [1] \"----------\"\n## [1] \"objects in this function's environment:\"\n## [1] \"g\" \"x\" \"y\"\n## [1] \"----------\"\n## [1] \"objects in the global environment:\"\n##  [1] \"acc\"             \"f\"               \"f_acc_intensity\" \"f_compare\"      \n##  [5] \"f_readfile\"      \"f_square\"        \"f_square_2\"      \"f_square_3\"     \n##  [9] \"f_square_4\"      \"figure_nums\"     \"fnamepath\"       \"L\"              \n## [13] \"table_nums\"      \"v.len\"           \"v1\"              \"v2\"             \n## [17] \"v3\"              \"x\"               \"y\"              \n## [1] \"----------\"## [1] 3\n# a function to show how we can assign\ng <- function(x){\n    # code for a bunch of complicated operations\n    # ...\n    # create environment \"foo\"\n    if(!exists(\"foo\")){\n        message(\"make foo\")\n        assign(x = \"foo\", value = new.env(), envir = .GlobalEnv)\n    }    \n    # generates an intermediate data frame named \"bar\"\n    bar <- head(iris)\n    # save to the foo env\n    assign(x = \"bar\", value = bar, envir = foo)\n    # more code to do more complicated stuff\n    # ...\n    foobar <- head(cars)\n    # also assign \n    assign(x = \"foobar\", value = foobar, envir = foo)\n    # yet more complicated stuff here\n    # ...\n}\n# run the function\ng()## make foo\n# what is in environment \"foo\"?\nls(envir = foo)## [1] \"bar\"    \"foobar\"\nprint(foo$bar)##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\nprint(foo$foobar)##   speed dist\n## 1     4    2\n## 2     4   10\n## 3     7    4\n## 4     7   22\n## 5     8   16\n## 6     9   10\nls(envir = .GlobalEnv)##  [1] \"acc\"             \"f\"               \"f_acc_intensity\" \"f_compare\"      \n##  [5] \"f_readfile\"      \"f_square\"        \"f_square_2\"      \"f_square_3\"     \n##  [9] \"f_square_4\"      \"figure_nums\"     \"fnamepath\"       \"foo\"            \n## [13] \"g\"               \"L\"               \"table_nums\"      \"v.len\"          \n## [17] \"v1\"              \"v2\"              \"v3\"              \"x\"              \n## [21] \"y\""},{"path":"week4.html","id":"looping","chapter":"4 Week 4","heading":"4.2.5 Looping","text":"Loops run want perform series tasks set objects.","code":""},{"path":"week4.html","id":"looping-with-for-loops","chapter":"4 Week 4","heading":"4.2.5.1 Looping with for() loops","text":"loop constructed using form …element represents variable value current iteration set group objects, elements vector listA simple examples follow.Print letter first 5 letters alphabet. example, iterated element letter, variable value letter iteration. built vector letters used. first iteration, = 1, second iteration,m = 2 .example, object takes integer values 1 10. Within loop, message printed includes term ^2, evaluates 1^2, 2^2, \\(\\dots\\), 10^2.similar approach, using numerical index referring position within vector. vector iterated 1:length(states_5), evaluates 1, 2, 3, 4, 5. iteration, print index iterator state name.example, use index position rows within data frame.iterate elements list, also including system run time wrapping loop system.time() call.","code":"for (element in set){\n    do something\n}\nfor (i in head(letters, 5)){\n    print(i)\n}## [1] \"a\"\n## [1] \"b\"\n## [1] \"c\"\n## [1] \"d\"\n## [1] \"e\"\nfor(i in 1:10){\n    message(paste(i, \"squared equals\", i^2))\n}## 1 squared equals 1## 2 squared equals 4## 3 squared equals 9## 4 squared equals 16## 5 squared equals 25## 6 squared equals 36## 7 squared equals 49## 8 squared equals 64## 9 squared equals 81## 10 squared equals 100\n# take the first 5 state names\nstates_5 <- head(state.name, 5)\n\n# iterate over those\nfor (i in 1:length(states_5)){\n    s <- states_5[i]\n    message(paste0(i, \": \", s))\n}## 1: Alabama## 2: Alaska## 3: Arizona## 4: Arkansas## 5: California\n# initialize a value to hold a sum\nmySum <- 0\n\n# create a data frame of 5 rows\ny <- iris %>% head(5)\n\n# loop\nfor(x in 1:nrow(y)){\n    message(paste(\"iteration:\", x))\n    # get the sepal length for this iteration\n    sl <- y$Sepal.Length[x]\n    # add to make a cumulative sum\n    mySum <- mySum + sl\n    # calculate the mean\n    myMean <- mySum / x\n    message(paste0(\"  sepal length = \", sl, \n                   \"; cumulative sum = \", mySum, \n                   \"; mean = \", myMean))\n  \n}## iteration: 1##   sepal length = 5.1; cumulative sum = 5.1; mean = 5.1## iteration: 2##   sepal length = 4.9; cumulative sum = 10; mean = 5## iteration: 3##   sepal length = 4.7; cumulative sum = 14.7; mean = 4.9## iteration: 4##   sepal length = 4.6; cumulative sum = 19.3; mean = 4.825## iteration: 5##   sepal length = 5; cumulative sum = 24.3; mean = 4.86\n# make it reproducible\nset.seed(5)\n\n# create a list\nL <- list(\n    v1 = rnorm(n = 10, mean = 1),\n    v2 = rpois(n = 20, lambda = 5),\n    v3 = runif(n = 25, min = 0, max = 10)\n)\n\n# run the loop\nsystem.time(\n    for(i in L){\n        print(mean(i))\n    }\n)## [1] 0.9211485\n## [1] 4.45\n## [1] 5.917916##    user  system elapsed \n##       0       0       0"},{"path":"week4.html","id":"alternatives-to-loops-apply.-lapply-tapply-sapply","chapter":"4 Week 4","heading":"4.2.5.2 Alternatives to loops: apply(). lapply(), tapply(), sapply()","text":"family functions (*apply()) R built iterate matrix, elements vectors lists.apply function performs function rows columns matrix. simple examples get sums rows columns matrix:lapply() function runs elements list. run analysis (mean vectors list L). output lapply() list number elements input; output elements also original list element names.Note difference system.time() using lapply(). general one always use *apply() functions rather loops possible. Loops better multi-step operations versus operations single matrices, vectors, lists.look help documentation tapply(), lapply(). also nice tutorial, Tutorial R Apply Family.","code":"\n# a matrix\n(m <- matrix(1:9, nrow = 3))##      [,1] [,2] [,3]\n## [1,]    1    4    7\n## [2,]    2    5    8\n## [3,]    3    6    9\n# row sums\nmessage(\"row sums\")## row sums\n(rs <- apply(X = m, MARGIN = 1, FUN = sum))## [1] 12 15 18\n# column sums\nmessage(\"column sums\")## column sums\n(cs <- apply(X = m, MARGIN = 2, FUN = sum))## [1]  6 15 24\nsystem.time(\n    Lmean <- lapply(X = L, FUN = mean)\n)##    user  system elapsed \n##       0       0       0\nLmean## $v1\n## [1] 0.9211485\n## \n## $v2\n## [1] 4.45\n## \n## $v3\n## [1] 5.917916"},{"path":"week4.html","id":"purrr","chapter":"4 Week 4","heading":"4.2.5.3 purrr","text":"purrr aims simplify looping, particularly multiple-step processes.main functions purrr map_*(), specific variants run data frames (map_dfr()), character vectors (map_chr()), logical (map_lgl()), integer (map_int()), double precision numeric (map_dbl()).Although full treatment purrr beyond scope, see great purrr tutorial worked examples","code":""},{"path":"week4.html","id":"efficient-download-of-census-data-using-purrr-and-tigris","chapter":"4 Week 4","heading":"4.2.5.3.1 Efficient download of census data using purrr and tigris","text":", following lessons using tigirs package downloading US Census TIGER/Line data, download counties states using purrr::map_dfr() export GPKG database.Figure 1 show counties displayed QGIS.\n Figure 1: Downloaded counties USThis process easily applied multiple years data different census units (block groups, blocks, tracts).","code":"\n# the tigris download function for counties\nf_county <- function(state_name, year = 2019){\n    # this downloads a single county\n    counties(state = state_name, year)\n}\n\n# the map_dfr() functionality is wrapped in here\nget_counties <- function(year = 2019) {\n    # the output is a data frame. input (.x) is the state name, the function (.f) is the county download\n    map_dfr(\n        # input is the built in vector \"state.name\"\n        .x = state.name,\n        # each iteration runs the f_county() function over the iteration's state\n        .f = function(x) {\n            f_county(state_name = x, year = year)\n        }\n    )\n}\n\n# run the function\nall_counties <- get_counties()\n\n# export to GPKG\nmyTmpDir <- tempdir()\nst_write(obj = all_counties, dsn = file.path(myTmpDir, \"counties.gpkg\"), layer = \"us_counties_2019\", delete_dsn = TRUE)## Deleting source `C:\\Temp\\6\\RtmpszyWZW/counties.gpkg' failed\n## Writing layer `us_counties_2019' to data source \n##   `C:\\Temp\\6\\RtmpszyWZW/counties.gpkg' using driver `GPKG'\n## Writing 3141 features with 17 fields and geometry type Multi Polygon."},{"path":"week4.html","id":"revisiting-bens-hmdhfdplus-example","chapter":"4 Week 4","heading":"4.2.5.3.2 Revisiting Ben’s HMDHFDplus example","text":"Let’s revisit Ben’s example using HMDHFDplusThe key piece iswhich constructs data frame iterating countries applying function read_hmd_country() download variable Mx_1x1. plot mortality data Australia Austria time series (Figure 2).\n Figure 2: Mortality data Australia Austria","code":"\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\ncountries <- HMDHFDplus::getHMDcountries()[1:2]\n\n# Function to download a specified HMD data set item for a single county\n# the country code is referenced as \"CNTRY\"\n# the \"item\" is the base name of the link with \".txt\" removed. For example,\n# https://www.mortality.org/hmd/ISR/STATS/Mx_1x1.txt\n#                                         Mx_1x1       <<- this is the item for 1 year x 1 year death rates\nread_hmd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHMDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\n# for speed in class we will use only two countries\ncountries <- HMDHFDplus::getHMDcountries()[1:2]\n\n# Download a data set iteratively for all countries using purrr::map()\n# In this case, age-specific mortality in 1-year periods x 1-year age groups\n# for all 1-year periods available\n# output is a data frame named \"mx_1x1\"\nmx_1x1 <- countries %>%\n    # Returns a list of data.frames, adding a column for country code to each\n    # the map() function performs a run of Ben's read_hmd_country() function for each listed country\n    purrr::map_dfr(function(country) {\n        # the item to read is 1 x 1 death rates\n        read_hmd_country(CNTRY = country, item = \"Mx_1x1\") %>%\n            # this adds the column \"country\" storing the country ISO code\n            dplyr::mutate(country = country)\n    }) %>%\n    # Phil added this to make it a tibble\n    tibble()purrr::map_dfr(function(country) {\n    # the item to read is 1 x 1 death rates\n    read_hmd_country(country, \"Mx_1x1\")\ntmx <- mx_1x1 %>% \n    group_by(Year, country) %>% \n    dplyr::summarise(mortality = sum(Total, na.rm = TRUE), .groups = \"keep\")\n\ntmx %>% ggplot(mapping = aes(x = Year, y = mortality)) +\n    geom_line() +\n    facet_grid(country ~ .) + \n    xlab(\"year\")"},{"path":"week4.html","id":"bootstrapping","chapter":"4 Week 4","heading":"4.2.5.4 Bootstrapping","text":"Bootstrapping used estimate characteristics population repeating large number random samples (replacement) calculating summary statistics set samples. reason replacement used sample represents “snapshot” population. number samples increases, summary continues approach true population characteristics.use simple example hypothetical population. idea male/female split , generate large number small-ish samples take mean.Back bootstrap: use 5,000 samples size 100 hypothetical population estimate proportion females.Using bootstrap results, can estimate 95% confidence interval around mean using Rmisc::CI() function, make density plot showing mean confidence interval (`r figure_nums(name = “bootstrat_plot,” display = “cite”)).\n Figure 3: Density plot bootstrappingIf already enumeration population, method unnecessary. However, survey-derived data generated samples. sample representative underlying population, sample can considered acceptable proxy.","code":"\n# create the population\n# 1 indicates female and 0 indicates male\npop <- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5))\n\n# initialize a vector\nF <- NULL\n\n# run the bootstrap\nfor (i in seq(from = 1, to = 5000, by = 1)){\n    # sample once\n    s <- sample(x = pop, size = 100, replace = TRUE)\n    # calculate percent female\n    p <- sum(s) / length(s)\n    # concatenate the result with the running result\n    F <- c(F, p)\n}\n\n# mean and standard deviation of the bootstrap\nmean(F)## [1] 0.602186\nsd(F)## [1] 0.04900736\n# 95% CI\nci_95 <- Rmisc::CI(x = F, ci = 0.95)\n\n# plot with 95 % CI\nplot(density(F), main = \"\")\nabline(v = ci_95, col=c(2,1,2))"},{"path":"week4.html","id":"rsampling","chapter":"4 Week 4","heading":"4.3 Sampling","text":"general topic sampling far greater can cover course. However, examples may helpful students little experience sampling.main R function sampling sample(), draws random sample vector data frame. Options sample() include size sample, whether replace sampled individuals pool, probability weight length (number rows) population sample drawn.","code":""},{"path":"week4.html","id":"sampling-with-replacement","chapter":"4 Week 4","heading":"4.3.1 Sampling with replacement","text":"Sampling replacement similar rolling die. roll die 1/6 probability coming value. example simulate rolling die 100,00 times:probability rolling two number row 1/6 \\(\\times\\) 1/6, \\(\\approx\\) 0.028","code":"\n# set.seed makes it so that random processes can be repeated with the same outputs\nset.seed(5)\n\n# create a vector to represent the faces of a die\nd <- 1:6\n\n# now make a sample of 100,000 rolls of the die, with replacement for independent rolls\ns <- sample(x = d, size = 100000, replace = TRUE)\n\n# tabulate the result\n(tbs <- table(s))## s\n##     1     2     3     4     5     6 \n## 16644 16856 16839 16705 16453 16503\n# proportions\n(prop.table(tbs))## s\n##       1       2       3       4       5       6 \n## 0.16644 0.16856 0.16839 0.16705 0.16453 0.16503"},{"path":"week4.html","id":"sampling-without-replacement","chapter":"4 Week 4","heading":"4.3.2 Sampling without replacement","text":"Sampling without replacement removes population individual sampled. example, probability selecting ace whole deck cards 4/52, \\(\\approx\\) 0.077. drew deck returned card back deck draw , samples independent. probability drawing two aces 4/52 \\(\\times\\) 4/52, \\(\\approx\\) 0.0059. example sampling replacement, similar rolling die.Performing sample without replacement, .e., finding ace, removing , sampling probability drawing two aces 4/52 \\(\\times\\) 3/51, \\(\\approx\\) 0.0045.design study person surveyed eligible surveyed , also example samping without replacement.population sufficient size relative sample, sampling without replacement lead nearly identical results.Let’s use example population 50,000 persons, 30,000 female 20,000 male. sample two persons replacement, probability female 30000/50000 \\(\\times\\) 30000/50000, 0.36.sample without replacement, probability selecting female first sample one 30000/50000, second sample 1 probability selecting female 29999/49999, joint probability \\(\\approx\\) 0.359995.","code":""},{"path":"week4.html","id":"demogpackages","chapter":"4 Week 4","heading":"4.4 R packages for demographic analysis","text":"always growing list available packages analysis R. briefly cover two packages demographic analysis.","code":""},{"path":"week4.html","id":"demogR","chapter":"4 Week 4","heading":"4.4.1 demogR","text":"Age-Structured Demographic ModelsThe demogR package provides number functions analysis age-structured demographic models. exercise look life.table() function creating life tables enumerated deaths mid-interval population estimates.follow example help page life.table(). example uses goodman data set, aggregate data Venezuela, Madagascar, USA 1965, 1966, 1967, respectively. table contains fields:age\nage classesven.nKx\nmid-year population structure Venezuelaven.nDx\nenumerated deaths Venezuelaven.bx\nenumerated births Venezuelamad.nKx\nmid-year population structure Madagascarmad.nDx\nenumerated deaths Madagascarmad.bx\nenumerated births Madagascarusa.nKx\nmid-year population structure United Statesusa.nDx\nenumerated deaths United Statesusa.bx\nenumerated births United StatesThe first step create life table , run least three arguments, x (age beginning age classes life table), nDx (deaths), nKx (population size). create life table using three countries’ data default Keyfitz Fleiger (kf) calculation type. Results Table 1.Table 1: Venezuela life table, Keyfitz Fleiger methodThe results nine output columns:x \nage beginning intervalnax\nperson-years lived dying interval x x+nnMx\nperiod central death ratenqx\nprobability death ages x x+nlx\nprobability survival exact age xndx\nproportion deaths occurring ages x x+nnLx\nperson-years lived interval x x+nTx\nperson-years life left cohort age xex\nlife expectancy age xFor example, life table estimates Venezuela 1965, probability reaching age 35 0.9, whereas reaching 80 probability 0.4. US 1967, respective probabilities 0.96 0.46, Madagascar 1966 probabilities 0.52 0.07.Another way look data plot life expectancy, shown Figure 4. difference Venezuela US less stark difference Madagascar two countries. 1966, woman Madagascar less 50% chance reaching age 40! One wonders life expectancies look like recent data.\n Figure 4: Life expectancy, Madagascar (1966), Venezuela (1965), USA (1967)","code":"\n# load the Goodman data from the demogR package\ndata(goodman)\n\n## default type=\"kf\", Venezuela data\nvlt <- with(goodman, life.table(x=age, nKx=ven.nKx, nDx=ven.nDx))\n\n## US life table\nult <- with(goodman, life.table(x=age, nKx=usa.nKx, nDx=usa.nDx))\n\n## Madagascar life table\nmlt <- with(goodman, life.table(x=age, nKx=mad.nKx, nDx=mad.nDx))\n\n# some values for the text\nvlx35 <- vlt %>% filter(x == 35) %>% pull(lx) %>% round(2)\nvlx80 <- vlt %>% filter(x == 80) %>% pull(lx) %>% round(2)\nulx35 <- ult %>% filter(x == 35) %>% pull(lx) %>% round(2)\nulx80 <- ult %>% filter(x == 80) %>% pull(lx) %>% round(2)\nmlx35 <- mlt %>% filter(x == 35) %>% pull(lx) %>% round(2)\nmlx80 <- mlt %>% filter(x == 80) %>% pull(lx) %>% round(2)\n\n# combine these\nlt <- bind_rows(vlt, ult, mlt)\nlt %>% kable() %>% \n    kable_styling(bootstrap_options =\n                      c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                  full_width = F, position = \"left\", font_size = 12, fixed_thead = T) %>% \n    pack_rows(group_label = \"Venezuela\", start_row = 1, end_row = 19) %>% \n    pack_rows(group_label = \"USA\", start_row = 20, end_row = 38) %>% \n    pack_rows(group_label = \"Madagascar\", start_row = 39, end_row = 57)\nlt %<>% mutate(\n    country = c(rep(\"VEN\", 19), rep(\"USA\", 19), rep(\"MDG\", 19))\n)\nggplot(data = lt, mapping = aes(x = x, y = lx, col = country))+\n    geom_line() +\n    xlab(\"age\") +\n    ylab(\"probability of surviving to age on X axis\")"},{"path":"week4.html","id":"demography","chapter":"4 Week 4","heading":"4.4.2 demography","text":"demography also contains large number functions demographic analysis. reference, see R intro demography package.look one example documentation.first step creating life table using lifetable() function. function requires data specific format, can provided package’s fr.mort data set. fr.mort data set? Let’s see:tells us time series females, males, persons, spanning years 1816 2006 covering ages 0 110.can delve deeper:see specific objects within data set. Let’s look . age:year:population data stored pop object, composed three matrices representing persons, females, males:matrices number rows columns, corresponding ages (0-110, 111 rows) years (1816-2006, columns). let’s look sample total, first 5 rows columns:shows example 1816 estimated 834354.6 persons less one year age.Output running lifetable() function can plotted. `r figure_nums(name = “france_ltplot,” display = “cite”) shows curves year using rainbow palette. interesting note earliest years time series positive life expectancies intermediate years particularly persons age 40.Figure 5: Life expectancy France 1816 2006Finally, let’s look life table 2005.output lifetable prints tabular format data frame various methods making nice looking tables work box. also means standard exporting functions write.csv() work. However, work specific objects returned function, can construct decent looking table.Rendered 2022-03-04 00:43:58","code":"france.lt <- lifetable(fr.mort)\nplot(france.lt)\nlt1990 <- print(lifetable(fr.mort,year=1990))\nfr.mort## Mortality data for FRATNP\n##     Series: total female male\n##     Years: 1816 - 2006\n##     Ages:  0 - 110\nattributes(fr.mort)## $names\n## [1] \"type\"   \"label\"  \"lambda\" \"year\"   \"age\"    \"rate\"   \"pop\"   \n## \n## $class\n## [1] \"demogdata\"\nfr.mort$age##   [1]   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n##  [19]  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n##  [37]  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n##  [55]  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n##  [73]  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n##  [91]  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n## [109] 108 109 110\nfr.mort$year##   [1] 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830\n##  [16] 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845\n##  [31] 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860\n##  [46] 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875\n##  [61] 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890\n##  [76] 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905\n##  [91] 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920\n## [106] 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935\n## [121] 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950\n## [136] 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965\n## [151] 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980\n## [166] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n## [181] 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006\nfr.mort$pop %>% names()## [1] \"total\"  \"female\" \"male\"\nfr.mort$pop$total[1:5, 1:5]##       1816     1817     1818     1819     1820\n## 0 834354.6 853197.1 831620.7 845830.8 905102.5\n## 1 782273.1 790396.6 758436.8 742192.0 748048.4\n## 2 714854.9 738047.1 747182.6 719243.2 712245.3\n## 3 686823.1 683758.6 707277.3 712488.9 692287.6\n## 4 674202.5 660565.5 669365.5 683663.9 687342.6\n# min and max years\ny0 <- min(fr.mort$year)\ny1 <- max(fr.mort$year)\n\n# make the life table and plot life expectancy graph\nfrance.lt <- lifetable(fr.mort)\nplot(france.lt)\n# create the life table\nlt_france_2005 <- lifetable(fr.mort,year=2005)\n\n# print using the native interface\nprint(lt_france_2005)## Period lifetable for FRATNP : total \n## \n## Year: 2005 \n##         mx     qx     lx     dx     Lx      Tx      ex\n## 0   0.0036 0.0036 1.0000 0.0036 0.9966 80.3450 80.3450\n## 1   0.0003 0.0003 0.9964 0.0003 0.9962 79.3484 79.6353\n## 2   0.0002 0.0002 0.9961 0.0002 0.9960 78.3522 78.6592\n## 3   0.0002 0.0002 0.9959 0.0002 0.9958 77.3562 77.6747\n## 4   0.0001 0.0001 0.9957 0.0001 0.9957 76.3604 76.6864\n## 5   0.0001 0.0001 0.9956 0.0001 0.9956 75.3647 75.6966\n## 6   0.0001 0.0001 0.9955 0.0001 0.9954 74.3691 74.7052\n## 7   0.0001 0.0001 0.9954 0.0001 0.9953 73.3737 73.7133\n## 8   0.0001 0.0001 0.9953 0.0001 0.9952 72.3783 72.7203\n## 9   0.0001 0.0001 0.9952 0.0001 0.9952 71.3831 71.7276\n## 10  0.0001 0.0001 0.9951 0.0001 0.9951 70.3879 70.7330\n## 11  0.0001 0.0001 0.9950 0.0001 0.9950 69.3928 69.7393\n## 12  0.0001 0.0001 0.9949 0.0001 0.9949 68.3979 68.7459\n## 13  0.0001 0.0001 0.9949 0.0001 0.9948 67.4030 67.7518\n## 14  0.0002 0.0002 0.9947 0.0002 0.9947 66.4082 66.7599\n## 15  0.0002 0.0002 0.9946 0.0002 0.9945 65.4135 65.7702\n## 16  0.0003 0.0003 0.9944 0.0003 0.9942 64.4190 64.7838\n## 17  0.0004 0.0004 0.9941 0.0004 0.9939 63.4248 63.8039\n## 18  0.0005 0.0005 0.9937 0.0005 0.9935 62.4310 62.8270\n## 19  0.0005 0.0005 0.9932 0.0005 0.9929 61.4375 61.8576\n## 20  0.0006 0.0006 0.9927 0.0006 0.9924 60.4446 60.8906\n## 21  0.0006 0.0006 0.9921 0.0006 0.9918 59.4522 59.9263\n## 22  0.0006 0.0006 0.9915 0.0006 0.9912 58.4604 58.9599\n## 23  0.0006 0.0006 0.9910 0.0006 0.9906 57.4691 57.9935\n## 24  0.0006 0.0006 0.9903 0.0006 0.9900 56.4785 57.0303\n## 25  0.0006 0.0006 0.9898 0.0006 0.9895 55.4884 56.0620\n## 26  0.0006 0.0006 0.9892 0.0006 0.9889 54.4990 55.0939\n## 27  0.0006 0.0006 0.9886 0.0006 0.9883 53.5101 54.1274\n## 28  0.0006 0.0006 0.9880 0.0006 0.9878 52.5217 53.1573\n## 29  0.0006 0.0006 0.9875 0.0006 0.9872 51.5340 52.1882\n## 30  0.0007 0.0007 0.9868 0.0007 0.9865 50.5468 51.2208\n## 31  0.0008 0.0008 0.9862 0.0008 0.9858 49.5603 50.2553\n## 32  0.0008 0.0008 0.9854 0.0008 0.9850 48.5745 49.2933\n## 33  0.0008 0.0008 0.9847 0.0008 0.9843 47.5895 48.3309\n## 34  0.0009 0.0009 0.9839 0.0009 0.9834 46.6052 47.3691\n## 35  0.0009 0.0009 0.9830 0.0009 0.9826 45.6218 46.4101\n## 36  0.0011 0.0011 0.9821 0.0010 0.9816 44.6392 45.4520\n## 37  0.0011 0.0011 0.9811 0.0011 0.9805 43.6576 44.4996\n## 38  0.0012 0.0012 0.9800 0.0012 0.9794 42.6771 43.5473\n## 39  0.0014 0.0014 0.9788 0.0013 0.9781 41.6977 42.6006\n## 40  0.0015 0.0015 0.9775 0.0015 0.9767 40.7195 41.6578\n## 41  0.0016 0.0016 0.9760 0.0016 0.9752 39.7428 40.7215\n## 42  0.0018 0.0018 0.9744 0.0017 0.9736 38.7676 39.7856\n## 43  0.0019 0.0019 0.9727 0.0019 0.9718 37.7941 38.8552\n## 44  0.0022 0.0022 0.9708 0.0022 0.9697 36.8223 37.9290\n## 45  0.0025 0.0025 0.9686 0.0024 0.9674 35.8526 37.0132\n## 46  0.0028 0.0028 0.9662 0.0027 0.9649 34.8851 36.1043\n## 47  0.0031 0.0030 0.9635 0.0029 0.9621 33.9202 35.2037\n## 48  0.0034 0.0034 0.9606 0.0033 0.9590 32.9582 34.3097\n## 49  0.0038 0.0038 0.9573 0.0036 0.9555 31.9992 33.4258\n## 50  0.0041 0.0040 0.9537 0.0039 0.9518 31.0437 32.5506\n## 51  0.0043 0.0043 0.9498 0.0041 0.9478 30.0919 31.6807\n## 52  0.0045 0.0045 0.9458 0.0042 0.9437 29.1441 30.8145\n## 53  0.0048 0.0048 0.9416 0.0045 0.9393 28.2004 29.9502\n## 54  0.0052 0.0052 0.9370 0.0049 0.9346 27.2611 29.0931\n## 55  0.0055 0.0054 0.9321 0.0051 0.9296 26.3265 28.2432\n## 56  0.0059 0.0059 0.9271 0.0054 0.9243 25.3969 27.3950\n## 57  0.0064 0.0064 0.9216 0.0059 0.9187 24.4726 26.5536\n## 58  0.0068 0.0068 0.9157 0.0062 0.9126 23.5539 25.7213\n## 59  0.0073 0.0073 0.9095 0.0066 0.9062 22.6413 24.8942\n## 60  0.0078 0.0078 0.9029 0.0070 0.8993 21.7351 24.0734\n## 61  0.0081 0.0080 0.8958 0.0072 0.8922 20.8357 23.2589\n## 62  0.0088 0.0088 0.8886 0.0078 0.8847 19.9435 22.4432\n## 63  0.0093 0.0093 0.8808 0.0082 0.8767 19.0588 21.6371\n## 64  0.0095 0.0094 0.8726 0.0082 0.8685 18.1821 20.8357\n## 65  0.0109 0.0108 0.8644 0.0094 0.8597 17.3135 20.0291\n## 66  0.0115 0.0114 0.8550 0.0098 0.8502 16.4538 19.2432\n## 67  0.0124 0.0124 0.8453 0.0104 0.8400 15.6036 18.4602\n## 68  0.0135 0.0134 0.8348 0.0112 0.8292 14.7636 17.6850\n## 69  0.0148 0.0147 0.8237 0.0121 0.8176 13.9344 16.9178\n## 70  0.0159 0.0158 0.8116 0.0128 0.8052 13.1168 16.1623\n## 71  0.0182 0.0181 0.7987 0.0144 0.7915 12.3116 15.4137\n## 72  0.0196 0.0195 0.7843 0.0153 0.7767 11.5201 14.6879\n## 73  0.0214 0.0212 0.7691 0.0163 0.7609 10.7434 13.9693\n## 74  0.0242 0.0239 0.7528 0.0180 0.7438  9.9824 13.2604\n## 75  0.0258 0.0255 0.7348 0.0187 0.7254  9.2386 12.5730\n## 76  0.0289 0.0285 0.7161 0.0204 0.7059  8.5132 11.8889\n## 77  0.0328 0.0323 0.6957 0.0225 0.6844  7.8074 11.2229\n## 78  0.0363 0.0356 0.6732 0.0240 0.6612  7.1229 10.5806\n## 79  0.0406 0.0398 0.6492 0.0258 0.6363  6.4617  9.9531\n## 80  0.0457 0.0447 0.6234 0.0279 0.6095  5.8254  9.3445\n## 81  0.0514 0.0501 0.5955 0.0298 0.5806  5.2159  8.7586\n## 82  0.0580 0.0563 0.5657 0.0319 0.5498  4.6353  8.1940\n## 83  0.0655 0.0634 0.5338 0.0338 0.5169  4.0856  7.6533\n## 84  0.0736 0.0710 0.5000 0.0355 0.4822  3.5686  7.1373\n## 85  0.0880 0.0842 0.4645 0.0391 0.4449  3.0864  6.6447\n## 86  0.0871 0.0834 0.4254 0.0355 0.4076  2.6415  6.2100\n## 87  0.1063 0.1009 0.3899 0.0394 0.3702  2.2339  5.7297\n## 88  0.1204 0.1135 0.3505 0.0398 0.3306  1.8637  5.3168\n## 89  0.1221 0.1150 0.3107 0.0357 0.2929  1.5330  4.9337\n## 90  0.1623 0.1501 0.2750 0.0413 0.2543  1.2402  4.5100\n## 91  0.1708 0.1574 0.2337 0.0368 0.2153  0.9858  4.2183\n## 92  0.1870 0.1711 0.1969 0.0337 0.1801  0.7705  3.9127\n## 93  0.2138 0.1931 0.1632 0.0315 0.1475  0.5904  3.6169\n## 94  0.2324 0.2082 0.1317 0.0274 0.1180  0.4430  3.3630\n## 95  0.2606 0.2305 0.1043 0.0240 0.0923  0.3250  3.1158\n## 96  0.2894 0.2528 0.0802 0.0203 0.0701  0.2327  2.8995\n## 97  0.3208 0.2764 0.0600 0.0166 0.0517  0.1626  2.7112\n## 98  0.3508 0.2985 0.0434 0.0130 0.0369  0.1109  2.5560\n## 99  0.3612 0.3059 0.0304 0.0093 0.0258  0.0740  2.4308\n## 100 0.4383 1.0000 0.0211 0.0211 0.0482  0.0482  2.2818\n# I looked at the individual vectors output from the lifetable function. These are the ones we want:\npositions <- c(1,3:10)\n\n# use lapply() across some of the list objects to\n#   get the object (a vector), that is the anonymous \"function(x) x\"\n# use \"do.call\" to do something to each of those vectors. that something is a \"cbind\"\n# turn it into a data frame and then a tibble\nlt_france_2005_df <- do.call(cbind, lapply(lt_france_2005[positions], function(x) x)) %>% \n    data.frame %>% tibble()\n\n# set the column names from the names of the vectors\ncolnames(lt_france_2005_df) <- names(lt_france_2005)[positions]\n\n# print a nice table\nlt_france_2005_df %>% kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\", font_size = 12, )"},{"path":"week4.html","id":"source-code-4","chapter":"4 Week 4","heading":"4.5 Source code","text":"File H:/csde502-winter-2022-main/04-week04.Rmd.","code":""},{"path":"week4.html","id":"r-code-used-in-this-document-4","chapter":"4 Week 4","heading":"4.5.1 R code used in this document","text":"","code":"\noptions(tigris_use_cache = TRUE)\npacman::p_load(demogR, demography, magrittr, knitr, kableExtra, readstata13, captioner,tigris, sf, tidyverse)\n\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\nf_square <- function(x){\n    x^2\n}\n# create a list of three vectors of random numbers of different random lengths\n\n# set.seed() makes the random process reproducible.\nset.seed(10)\n# vector lengths\nv.len <- rnorm(n = 3, mean = 30, sd = 10) %>% round(0)\n\n# make the random vectors\nset.seed(5)\nv1 <- rnorm(n = v.len[1])\nset.seed(3)\nv2 <- rnorm(n = v.len[2])\nset.seed(6)\nv3 <- rnorm(n = v.len[3])\n\n# create the list\nL <- list(v1, v2, v3)\n\n# get the first value from each vector in the list\nlapply(X = L, FUN = function(x) {x[1]})\nf_square_2 <- function(x){\n    message(\"input:\")\n    print(x)\n    message(\"output:\")\n    x^2\n}\n\nf_square_2(c(1,2,3))\nf_square(as.numeric(NA))\nf_square(c(1, 2, NA))\nf_square(NULL)\nf_square(c(1, 2, NULL))\nSys.Date()\nSys.time()\nf_square_3 <- function(x = 3){\n    x^2\n}\nf_square_3()\n# read the accelerometry data\nacc <- read.csv(\"files/accelerometry.csv\")\n\n# print first 6 lines\nhead(acc)\nf_acc_intensity <- function(x,\n                            cuts = c(\n                                -Inf,\n                                2690, 6167, 9642, Inf\n                            ),\n                            labels = c(\n                                \"sedentary/low\",\n                                \"moderate\", \"vigorous\", \"very vigorous\"\n                            )) {\n    cut(x = acc$vm3, breaks = cuts, labels = labels)\n}\n# recode\nacc$intens_default <- f_acc_intensity(acc$vm3)\n\n# tabulate\nacc %>% \n    group_by(intens_default) %>% \n    summarise(n = n())\nacc$intens_2lev <- f_acc_intensity(x = acc$vm3,\n                                cuts = c(-Inf, 2690, Inf),\n                                labels = c(\"SLPA\", \"MVVPA\"))\nacc %>% \n    group_by(intens_2lev) %>% \n    summarise(n = n())\nf_square_4 <- function(x, verbose = FALSE){\n    # only run the next lines if verbose is true\n    if(verbose){\n        message(\"input:\")\n        print(x)\n        message(\"output:\")\n    }\n    x^2\n}\nf_square_4(x = c(1, 2, 3))\nf_square_4(x = c(1, 2, 3), verbose = TRUE)\nf_square <- function(x){\n    x^2\n}\nf_square(3)\nf_square(c(1,2,3))\nf_compare <- function(x, y){\n    # either missing?\n    if(nargs() != 2)\n        return(\"invalid number of arguments\")\n    # numeric?\n    if(!is.numeric(x) | !is.numeric(y)){\n        return(sprintf(\"%s or %s is not numeric.\", x, y))\n    }\n    # comparisons follow\n    if(x > y){\n        return(sprintf(\"%s is greater than %s\", x, y))\n    } \n    if(x < y) {\n        return(sprintf(\"%s is less than %s\", x, y))\n    }\n    if(x == y){\n        return(sprintf(\"%s equals %s\", x, y))\n    }\n}\nf_compare(1)\n\nf_compare(1, 2)\n\nf_compare(2, 1)\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return()\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return(invisible())\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")\n# declare a few variables\nx <- 1\ny <- \"hello\"\n\n# a simple function\nf <- function(x){\n    # create a local variable\n    y <- x + 2\n    # another function inside this function\n    g <- function(x){\n        x * 3\n    }\n    # what variables are in this environment?\n    print(\"----------\")\n    print(\"objects in this function's environment:\")\n    print(ls())\n    # what is in the global env?\n    print(\"----------\")\n    print(\"objects in the global environment:\")\n    print(ls(envir = .GlobalEnv))\n    # return the output of the function\n    print(\"----------\")\n    y\n}\n\nf(1)\n# a function to show how we can assign\ng <- function(x){\n    # code for a bunch of complicated operations\n    # ...\n    # create environment \"foo\"\n    if(!exists(\"foo\")){\n        message(\"make foo\")\n        assign(x = \"foo\", value = new.env(), envir = .GlobalEnv)\n    }    \n    # generates an intermediate data frame named \"bar\"\n    bar <- head(iris)\n    # save to the foo env\n    assign(x = \"bar\", value = bar, envir = foo)\n    # more code to do more complicated stuff\n    # ...\n    foobar <- head(cars)\n    # also assign \n    assign(x = \"foobar\", value = foobar, envir = foo)\n    # yet more complicated stuff here\n    # ...\n}\n# run the function\ng()\n\n# what is in environment \"foo\"?\nls(envir = foo)\nprint(foo$bar)\nprint(foo$foobar)\nls(envir = .GlobalEnv)\nfor (i in head(letters, 5)){\n    print(i)\n}\nfor(i in 1:10){\n    message(paste(i, \"squared equals\", i^2))\n}\n# take the first 5 state names\nstates_5 <- head(state.name, 5)\n\n# iterate over those\nfor (i in 1:length(states_5)){\n    s <- states_5[i]\n    message(paste0(i, \": \", s))\n}\n# initialize a value to hold a sum\nmySum <- 0\n\n# create a data frame of 5 rows\ny <- iris %>% head(5)\n\n# loop\nfor(x in 1:nrow(y)){\n    message(paste(\"iteration:\", x))\n    # get the sepal length for this iteration\n    sl <- y$Sepal.Length[x]\n    # add to make a cumulative sum\n    mySum <- mySum + sl\n    # calculate the mean\n    myMean <- mySum / x\n    message(paste0(\"  sepal length = \", sl, \n                   \"; cumulative sum = \", mySum, \n                   \"; mean = \", myMean))\n  \n}\n# make it reproducible\nset.seed(5)\n\n# create a list\nL <- list(\n    v1 = rnorm(n = 10, mean = 1),\n    v2 = rpois(n = 20, lambda = 5),\n    v3 = runif(n = 25, min = 0, max = 10)\n)\n\n# run the loop\nsystem.time(\n    for(i in L){\n        print(mean(i))\n    }\n)\n# a matrix\n(m <- matrix(1:9, nrow = 3))\n\n\n# row sums\nmessage(\"row sums\")\n(rs <- apply(X = m, MARGIN = 1, FUN = sum))\n\n# column sums\nmessage(\"column sums\")\n(cs <- apply(X = m, MARGIN = 2, FUN = sum))\n\nsystem.time(\n    Lmean <- lapply(X = L, FUN = mean)\n)\n\nLmean\n# the tigris download function for counties\nf_county <- function(state_name, year = 2019){\n    # this downloads a single county\n    counties(state = state_name, year)\n}\n\n# the map_dfr() functionality is wrapped in here\nget_counties <- function(year = 2019) {\n    # the output is a data frame. input (.x) is the state name, the function (.f) is the county download\n    map_dfr(\n        # input is the built in vector \"state.name\"\n        .x = state.name,\n        # each iteration runs the f_county() function over the iteration's state\n        .f = function(x) {\n            f_county(state_name = x, year = year)\n        }\n    )\n}\n\n# run the function\nall_counties <- get_counties()\n\n# export to GPKG\nmyTmpDir <- tempdir()\nst_write(obj = all_counties, dsn = file.path(myTmpDir, \"counties.gpkg\"), layer = \"us_counties_2019\", delete_dsn = TRUE)\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\ncountries <- HMDHFDplus::getHMDcountries()[1:2]\n\n# Function to download a specified HMD data set item for a single county\n# the country code is referenced as \"CNTRY\"\n# the \"item\" is the base name of the link with \".txt\" removed. For example,\n# https://www.mortality.org/hmd/ISR/STATS/Mx_1x1.txt\n#                                         Mx_1x1       <<- this is the item for 1 year x 1 year death rates\nread_hmd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHMDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\n# for speed in class we will use only two countries\ncountries <- HMDHFDplus::getHMDcountries()[1:2]\n\n# Download a data set iteratively for all countries using purrr::map()\n# In this case, age-specific mortality in 1-year periods x 1-year age groups\n# for all 1-year periods available\n# output is a data frame named \"mx_1x1\"\nmx_1x1 <- countries %>%\n    # Returns a list of data.frames, adding a column for country code to each\n    # the map() function performs a run of Ben's read_hmd_country() function for each listed country\n    purrr::map_dfr(function(country) {\n        # the item to read is 1 x 1 death rates\n        read_hmd_country(CNTRY = country, item = \"Mx_1x1\") %>%\n            # this adds the column \"country\" storing the country ISO code\n            dplyr::mutate(country = country)\n    }) %>%\n    # Phil added this to make it a tibble\n    tibble()\ntmx <- mx_1x1 %>% \n    group_by(Year, country) %>% \n    dplyr::summarise(mortality = sum(Total, na.rm = TRUE), .groups = \"keep\")\n\ntmx %>% ggplot(mapping = aes(x = Year, y = mortality)) +\n    geom_line() +\n    facet_grid(country ~ .) + \n    xlab(\"year\")\n# create the population\n# 1 indicates female and 0 indicates male\npop <- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5))\n\n# initialize a vector\nF <- NULL\n\n# run the bootstrap\nfor (i in seq(from = 1, to = 5000, by = 1)){\n    # sample once\n    s <- sample(x = pop, size = 100, replace = TRUE)\n    # calculate percent female\n    p <- sum(s) / length(s)\n    # concatenate the result with the running result\n    F <- c(F, p)\n}\n\n# mean and standard deviation of the bootstrap\nmean(F)\nsd(F)\n# 95% CI\nci_95 <- Rmisc::CI(x = F, ci = 0.95)\n\n# plot with 95 % CI\nplot(density(F), main = \"\")\nabline(v = ci_95, col=c(2,1,2))\n# set.seed makes it so that random processes can be repeated with the same outputs\nset.seed(5)\n\n# create a vector to represent the faces of a die\nd <- 1:6\n\n# now make a sample of 100,000 rolls of the die, with replacement for independent rolls\ns <- sample(x = d, size = 100000, replace = TRUE)\n\n# tabulate the result\n(tbs <- table(s))\n\n# proportions\n(prop.table(tbs))\n# load the Goodman data from the demogR package\ndata(goodman)\n\n## default type=\"kf\", Venezuela data\nvlt <- with(goodman, life.table(x=age, nKx=ven.nKx, nDx=ven.nDx))\n\n## US life table\nult <- with(goodman, life.table(x=age, nKx=usa.nKx, nDx=usa.nDx))\n\n## Madagascar life table\nmlt <- with(goodman, life.table(x=age, nKx=mad.nKx, nDx=mad.nDx))\n\n# some values for the text\nvlx35 <- vlt %>% filter(x == 35) %>% pull(lx) %>% round(2)\nvlx80 <- vlt %>% filter(x == 80) %>% pull(lx) %>% round(2)\nulx35 <- ult %>% filter(x == 35) %>% pull(lx) %>% round(2)\nulx80 <- ult %>% filter(x == 80) %>% pull(lx) %>% round(2)\nmlx35 <- mlt %>% filter(x == 35) %>% pull(lx) %>% round(2)\nmlx80 <- mlt %>% filter(x == 80) %>% pull(lx) %>% round(2)\n\n# combine these\nlt <- bind_rows(vlt, ult, mlt)\nlt %>% kable() %>% \n    kable_styling(bootstrap_options =\n                      c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                  full_width = F, position = \"left\", font_size = 12, fixed_thead = T) %>% \n    pack_rows(group_label = \"Venezuela\", start_row = 1, end_row = 19) %>% \n    pack_rows(group_label = \"USA\", start_row = 20, end_row = 38) %>% \n    pack_rows(group_label = \"Madagascar\", start_row = 39, end_row = 57)\nlt %<>% mutate(\n    country = c(rep(\"VEN\", 19), rep(\"USA\", 19), rep(\"MDG\", 19))\n)\nggplot(data = lt, mapping = aes(x = x, y = lx, col = country))+\n    geom_line() +\n    xlab(\"age\") +\n    ylab(\"probability of surviving to age on X axis\")\nfrance.lt <- lifetable(fr.mort)\nplot(france.lt)\nlt1990 <- print(lifetable(fr.mort,year=1990))\nfr.mort\nattributes(fr.mort)\nfr.mort$age\nfr.mort$year\nfr.mort$pop %>% names()\nfr.mort$pop$total[1:5, 1:5]\n# min and max years\ny0 <- min(fr.mort$year)\ny1 <- max(fr.mort$year)\n\n# make the life table and plot life expectancy graph\nfrance.lt <- lifetable(fr.mort)\nplot(france.lt)\n# create the life table\nlt_france_2005 <- lifetable(fr.mort,year=2005)\n\n# print using the native interface\nprint(lt_france_2005)\n# I looked at the individual vectors output from the lifetable function. These are the ones we want:\npositions <- c(1,3:10)\n\n# use lapply() across some of the list objects to\n#   get the object (a vector), that is the anonymous \"function(x) x\"\n# use \"do.call\" to do something to each of those vectors. that something is a \"cbind\"\n# turn it into a data frame and then a tibble\nlt_france_2005_df <- do.call(cbind, lapply(lt_france_2005[positions], function(x) x)) %>% \n    data.frame %>% tibble()\n\n# set the column names from the names of the vectors\ncolnames(lt_france_2005_df) <- names(lt_france_2005)[positions]\n\n# print a nice table\nlt_france_2005_df %>% kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\", font_size = 12, )\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week4.html","id":"complete-rmd-code-4","chapter":"4 Week 4","heading":"4.5.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 4 {#week4}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\noptions(tigris_use_cache = TRUE)\npacman::p_load(demogR, demography, magrittr, knitr, kableExtra, readstata13, captioner,tigris, sf, tidyverse)\n\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\n<h2>Topics: Functions and sampling<\/h2>\nThis week's topics cover functions and sampling, the latter including a cursory treatment of loops and bootstrapping. We will revisit Ben's code for reading Human Mortality and Human Fertility databases to look at the use of `purrr::map()` as an alternative to `for()` looping in functions. Finally we will delve into `demogR` and `demography` packages for analysis of age-structured demographic models and forecasting mortality, fertility, migration and population data.\n\n* [R environments](#renviron)\n* [R functions](#rfunc)\n* [Sampling in R](#rsampling)\n* [Packages for running demographic analysis](#demogpackages)\n    * [`demogR`](#demogR)\n    * [`demography`](#demography)\n    \nDownload [exercise_blank.Rmd](files/exercise_blank.Rmd) as a template for this lesson.\n\n## Environments {#renviron}\nFunctions exist in `environments`, which are \"frames\" or collections containing objects including variables, functions, etc. There is a global environment (`.GlobalEnv`) that contains all of the data, functions, in the current R session. Those objects can be enumerated with the `ls()` function. \n\nThe reason environments are mentioned at this time is because functions instantiate environments that exist while the function is running, but once the function is completed, the environment is removed from memory. More on this [below](#funcenviron).\n\n## Functions {#rfunc}\nFunctions are sets of statements in R that are grouped together to perform a specific task or set of tasks. Functions are either built in, included in packages, or user-defined. Functions are used mainly to simplify running a series of individual commands or functions, for situations where the same process will need to be run multiple times on different inputs, or when control structures are needed (e.g., looping, logical branching).\n\n### Function Components\nThe different parts of a function are:\n\n1. (Usually) Name: This is the actual name of the function. It is stored in an R environment as an object with this name.\n1. (Optional) Arguments: Arguments specify the inputs or options to the function. When a function is invoked, you pass a value to the argument. Arguments are optional; that is, a function may contain no arguments. Also arguments can have default values.\n1. Body: The function body contains a collection of statements that defines what the function does.\n1. Return value: The return value of a function is the last expression in the function body to be evaluated.\n\nAnother important concept for functions is environments.\n\n#### Name\nMost functions are created with code of the form\n\n```\nfunction_name <- function(argument(s)){\n    statement(s)\n}\n```\n\nFor example, to square a vector of numerical values:\n\n```{r}\nf_square <- function(x){\n    x^2\n}\n```\n\nthe function name is `f_square`.\n\nSome functions are not named, and are referred to as \"anonymous\" functions. For example, functions can be used within the `apply` family of functions. Here is an oprationalized example.\n\n```{r}\n# create a list of three vectors of random numbers of different random lengths\n\n# set.seed() makes the random process reproducible.\nset.seed(10)\n# vector lengths\nv.len <- rnorm(n = 3, mean = 30, sd = 10) %>% round(0)\n\n# make the random vectors\nset.seed(5)\nv1 <- rnorm(n = v.len[1])\nset.seed(3)\nv2 <- rnorm(n = v.len[2])\nset.seed(6)\nv3 <- rnorm(n = v.len[3])\n\n# create the list\nL <- list(v1, v2, v3)\n\n# get the first value from each vector in the list\nlapply(X = L, FUN = function(x) {x[1]})\n```\n\nThe `lapply()` function is used to _apply_ a function to each element of a list. In this example, the last line of the code chunk is:\n\n```\nlapply(X = L, FUN = function(x) {x[1]})\n\n```\n\nin which the body of the function is `x[1]`, i.e., obtain the first element of a vector. In natural language, this translates to \"for each element of the list _L_, obtain the first element of vector _x_\". But the function itself is not named, and hence \"anonymous.\"\n\n#### Arguments\nMost functions require arguments. Arguments are used to instantiate variables within the function's environment that can be used later in the body of the function. Each argument is named, and the name is used within the function as a local variable within the function's environment.\n\nFollowing our example from above, `f_square` takes an argument named \"x\" that is a numeric vector.\n\nHere, let's modify the function to demonstrate that within the environment of the function, `x` is a variable by using `print(x)`:\n\n```{r}\nf_square_2 <- function(x){\n    message(\"input:\")\n    print(x)\n    message(\"output:\")\n    x^2\n}\n\nf_square_2(c(1,2,3))\n```\n\nWe can try running the original function using different (or no) arguments:\n\nHere, using a vector of a single NA numeric\n\n```{r}\nf_square(as.numeric(NA))\n```\n\n... or a vector that contains a numeric NA (with the first two elements being numeric, the third element `NA` is automatically cast as a numeric):\n\n```{r}\nf_square(c(1, 2, NA))\n```\n\n... or a null:\n\n```{r}\nf_square(NULL)\n```\n\n... or a vector containing a null:\n\n```{r}\nf_square(c(1, 2, NULL))\n```\n\n... or with no argument at all:\n\n```\nf_square()\n```\n\n<font color=\"red\">\n```\n## Error in f_square() : argument \"x\" is missing, with no default\n```\n<\/font>\n\nSome functions do not require arguments, e.g., to get the current date or time:\n\n```{r}\nSys.Date()\nSys.time()\n```\n\n... and if we try to use an argument we get an error:\n\n```\nSys.Date(1)\n```\n\n<font color=\"red\">\n```\n## Error in Sys.Date(1) : unused argument (1)\n```\n<\/font>\n\n##### Default values for arguments\nIf you want an argument to have a default value, it is specified in the listed arguments in the form `argument = value`. \n\nFollowing our previous `f_square_2()` function, we can set the default value of `x` to `3`:\n\n```{r}\nf_square_3 <- function(x = 3){\n    x^2\n}\n```\n\nBecause the default argument is set, the function can be run with no arguments, and the default will be substituted in:\n\n```{r}\nf_square_3()\n```\n\n\nA more meaningful example demonstrates stratification of counts into intensity bins using accelerometry data. We will be using accelerometry from one day's data from one subject in a study.\n\nThe cut points for accelerometry were identified at 0, 2690, 6167, and 9642 counts per minute, from Sasaki et al. (2011).\n\n*Sasaki JE, John D, Freedson PS. Validation and comparison of ActiGraph activity monitors. J Sci Med Sport. 2011;14(5):411-416. doi:10.1016/j.jsams.2011.04.003\"*\n\nThe variable `vm3` is the vector magnitude measured with the accelerometer for each minute. Data: [accelerometry.csv](files/accelerometry.csv).\n\n```{r}\n# read the accelerometry data\nacc <- read.csv(\"files/accelerometry.csv\")\n\n# print first 6 lines\nhead(acc)\n```\n\n\nThe following function codes intensity by the aforementioned cut points by default and using default labels:\n\n```{r}\nf_acc_intensity <- function(x,\n                            cuts = c(\n                                -Inf,\n                                2690, 6167, 9642, Inf\n                            ),\n                            labels = c(\n                                \"sedentary/low\",\n                                \"moderate\", \"vigorous\", \"very vigorous\"\n                            )) {\n    cut(x = acc$vm3, breaks = cuts, labels = labels)\n}\n```\n\n... and when run with the defaults to tabulate the minutes spent in different PA levels\n\n```{r}\n# recode\nacc$intens_default <- f_acc_intensity(acc$vm3)\n\n# tabulate\nacc %>% \n    group_by(intens_default) %>% \n    summarise(n = n())\n```\n\nBut we could run this with different thresholds and levels, where SPLA = \"sedentary/low physical activity\" and MVPA = \"moderate-to-very vigorous physical activity):\n\n```{r}\nacc$intens_2lev <- f_acc_intensity(x = acc$vm3,\n                                cuts = c(-Inf, 2690, Inf),\n                                labels = c(\"SLPA\", \"MVVPA\"))\nacc %>% \n    group_by(intens_2lev) %>% \n    summarise(n = n())\n```\n\n\n##### The `...` argument\nWhen functions do not have a known _a priori_ number or set of arguments, or when a large number of arguments is to be passed to another function the `...` argument is used. We will not cover this here, but you are encouraged to read more: [How to Use the Dots Argument in R](https://www.dummies.com/programming/r/how-to-use-the-dots-argument-in-r/); [The three-dots construct in R](https://www.r-bloggers.com/2013/01/the-three-dots-construct-in-r/).\n\n#### Body\nThe function's body contains all of the code to perform the purpose of the function. Following our initial example, the body of the function is simply \n\n```\nx^2\n```\n\nThe body can be as simple or complicated as it needs to be in order to achieve the desired result.\n\n### Logical testing for branching\nSometimes you want to vary what your code does based on some condition. If the condition is met, then execute a block of code. If the condition is not met, or some other condition is met, then execute other code. For a more complete tutorial, see [R if else elseif Statement](https://www.learnbyexample.org/r-if-else-elseif-statement/)\n\n\nFollowing our previous `f_square_2()` function, we can modify to print the input based on the logical argument `verbose`. In this code, if the `verbose` object is set to `TRUE`, some text is printed in a message as well as the value that was supplied for `x`. In either case (`verbose = TRUE` or `verbose = FALSE`), the output value of `x^2` is returned.\n\n```{r, collapse=TRUE}\nf_square_4 <- function(x, verbose = FALSE){\n    # only run the next lines if verbose is true\n    if(verbose){\n        message(\"input:\")\n        print(x)\n        message(\"output:\")\n    }\n    x^2\n}\n```\n\nHere we run with the default option `verbose = FALSE`; only the final value `x^2` is in the output:\n\n```{r}\nf_square_4(x = c(1, 2, 3))\n```\n\n... and with `verbose = TRUE`, additional text is printed :\n\n```{r}\nf_square_4(x = c(1, 2, 3), verbose = TRUE)\n```\n\nThere are additional ways to use `if()`, as nested statements, using:\n\n```\nif(condition1){\n    if(condition2){\n        statement\n    }\n}\n```\n\nOr with an alternative:\n\n```\nif(condition){\n    statement1\n    statement2\n    ...\n} else {\n    statement3\n    statement4\n}\n...\n```\n\nOr with an additional condition to check if the first condition is not met:\n\n```\nif(condition1){\n    statement1\n    statement2\n    ...\n} else if (condition2){\n    statement3\n    statement4\n} else {\n    statement5\n    statement6\n}\n...\n```\n\n### Return value\nThe return value is either the last evaluated expression in the function or an object specified using the `return()` function. For functions that are intended to return only one value, by convention that is the last line in the function.\n\nIn our original `f_square()` function, the return value is `x^2` since no other `return()` value was specified, e.g., for a vector of one element:\n\n```{r}\nf_square <- function(x){\n    x^2\n}\nf_square(3)\n```\n\nor a vector with multiple elements:\n\n```{r}\nf_square(c(1,2,3))\n```\n\nHowever, if it is possible that different outputs can be produced by a function based on some logical testing, one can explicitly use `return(object)` in the code; at that time the object will be output and the function will stop. A simple example of explicitly specifying return values is shown in this numerical comparison function:\n\n```{r}\nf_compare <- function(x, y){\n    # either missing?\n    if(nargs() != 2)\n        return(\"invalid number of arguments\")\n    # numeric?\n    if(!is.numeric(x) | !is.numeric(y)){\n        return(sprintf(\"%s or %s is not numeric.\", x, y))\n    }\n    # comparisons follow\n    if(x > y){\n        return(sprintf(\"%s is greater than %s\", x, y))\n    } \n    if(x < y) {\n        return(sprintf(\"%s is less than %s\", x, y))\n    }\n    if(x == y){\n        return(sprintf(\"%s equals %s\", x, y))\n    }\n}\n```\n\nBased on criteria such as the number of arguments or the relative value of the arguments `x` and `y`, different outputs are generated. Here are a few examples running the function:\n\n```{r}\nf_compare(1)\n\nf_compare(1, 2)\n\nf_compare(2, 1)\n```\n\nIf you want to handle an expected error, you can print an informative message and use `return(invisible())`, which returns nothing at all (whereas `return()` results in a `NULL` object) e.g., here without `invisible()`:\n\n```{r}\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return()\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")\n```\n\n... and with `invisible()`:\n\n```{r}\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return(invisible())\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")\n```\n\n### Function environments {#funcenviron}\nAs mentioned before, functions instantiate environments that exist only while the function is being evaluated. This means that functions can include named variables that have the same name as a variable in a different environment. For example here is a function that only lists what objects are in the local and global environments:\n\n```{r}\n# declare a few variables\nx <- 1\ny <- \"hello\"\n\n# a simple function\nf <- function(x){\n    # create a local variable\n    y <- x + 2\n    # another function inside this function\n    g <- function(x){\n        x * 3\n    }\n    # what variables are in this environment?\n    print(\"----------\")\n    print(\"objects in this function's environment:\")\n    print(ls())\n    # what is in the global env?\n    print(\"----------\")\n    print(\"objects in the global environment:\")\n    print(ls(envir = .GlobalEnv))\n    # return the output of the function\n    print(\"----------\")\n    y\n}\n\nf(1)\n```\n\nOnce the function completes, all objects in its local environment are purged. If you are running a complicated function that creates intermediate values that you want to examine for troubleshooting, you can create an environment in the `.GlobalEnv` (i.e., the overall environment in which R is running), and then assign a variable with a specific value to that environment created specifically for examining the intermediate products of the function:\n\n```{r}\n# a function to show how we can assign\ng <- function(x){\n    # code for a bunch of complicated operations\n    # ...\n    # create environment \"foo\"\n    if(!exists(\"foo\")){\n        message(\"make foo\")\n        assign(x = \"foo\", value = new.env(), envir = .GlobalEnv)\n    }    \n    # generates an intermediate data frame named \"bar\"\n    bar <- head(iris)\n    # save to the foo env\n    assign(x = \"bar\", value = bar, envir = foo)\n    # more code to do more complicated stuff\n    # ...\n    foobar <- head(cars)\n    # also assign \n    assign(x = \"foobar\", value = foobar, envir = foo)\n    # yet more complicated stuff here\n    # ...\n}\n```\n\nWhen the function runs, the objects `bar` and `foobar` are placed in the `foo` environment. We can examine those:\n\n```{r}\n# run the function\ng()\n\n# what is in environment \"foo\"?\nls(envir = foo)\n```\n\nAnd we can view their values:\n\n```{r}\nprint(foo$bar)\n```\n\n```{r}\nprint(foo$foobar)\n```\n\nBut those objects will not appear in the `.GloalEnv`, even though the environment `foo` does; you could consider that the objects `bar` and `foobar` are \"nested\" in environment `foo` which is itself nested in `.GlobalEnv`.\n\n```{r}\nls(envir = .GlobalEnv)\n```\n\n### Looping \nLoops are run when you want to perform a series of tasks over and over on a set of objects. \n\n#### Looping with `for()` loops\n A loop is constructed using the form ...\n\n```\nfor (element in set){\n    do something\n}\n```\n\nwhere `element` represents the variable value of the current iteration and `set` is a group of objects, such as elements in a vector or list\n\nA few simple examples follow.\n\nPrint each letter in the first 5 letters of the alphabet. In this example, the iterated element is a letter, and the variable `i` has the value of the letter in each iteration. The built in vector `letters` is used. So on the first iteration, `i = 1`, on the second iteration,m `i = 2` and so on.\n\n```{r}\nfor (i in head(letters, 5)){\n    print(i)\n}\n```\n\n\nIn this example, the object `i` takes on integer values 1 through 10. Within the loop, a message is printed that includes the term `i^2`, which evaluates to `1^2`, `2^2`, $\\dots$, `10^2`.\n\n```{r}\nfor(i in 1:10){\n    message(paste(i, \"squared equals\", i^2))\n}\n```\n\nHere is a similar approach, but using a numerical index referring to the position within a vector. The vector to be iterated over is `1:length(states_5)`, which evaluates to ``r 1:length(head(state.name, 5))``. In each iteration, we print the index of the iterator and the state name.\n\n```{r}\n# take the first 5 state names\nstates_5 <- head(state.name, 5)\n\n# iterate over those\nfor (i in 1:length(states_5)){\n    s <- states_5[i]\n    message(paste0(i, \": \", s))\n}\n```\n\nIn this example, we will use an index that is the position of rows within a data frame.\n\n```{r}\n# initialize a value to hold a sum\nmySum <- 0\n\n# create a data frame of 5 rows\ny <- iris %>% head(5)\n\n# loop\nfor(x in 1:nrow(y)){\n    message(paste(\"iteration:\", x))\n    # get the sepal length for this iteration\n    sl <- y$Sepal.Length[x]\n    # add to make a cumulative sum\n    mySum <- mySum + sl\n    # calculate the mean\n    myMean <- mySum / x\n    message(paste0(\"  sepal length = \", sl, \n                   \"; cumulative sum = \", mySum, \n                   \"; mean = \", myMean))\n  \n}\n```\n\nHere we will iterate over the elements of a list, also including the system run time by wrapping the loop in a `system.time()` call.\n\n```{r}\n# make it reproducible\nset.seed(5)\n\n# create a list\nL <- list(\n    v1 = rnorm(n = 10, mean = 1),\n    v2 = rpois(n = 20, lambda = 5),\n    v3 = runif(n = 25, min = 0, max = 10)\n)\n\n# run the loop\nsystem.time(\n    for(i in L){\n        print(mean(i))\n    }\n)\n```\n\n#### Alternatives to loops: `apply()`. `lapply()`, `tapply()`, `sapply()`\nThere is a family of functions (`*apply()`) in R that are built to iterate over a matrix, or elements of vectors or lists.\n\nThe `apply` function performs a function over the rows or columns of a matrix. Here are some simple examples that get the sums of the rows and columns of a matrix:\n\n```{r}\n# a matrix\n(m <- matrix(1:9, nrow = 3))\n\n\n# row sums\nmessage(\"row sums\")\n(rs <- apply(X = m, MARGIN = 1, FUN = sum))\n\n# column sums\nmessage(\"column sums\")\n(cs <- apply(X = m, MARGIN = 2, FUN = sum))\n\n```\n\nThe `lapply()` function runs over elements of a list. Here we will run the same analysis as before (mean of the vectors in list `L`). The output of `lapply()` is a list with the same number of elements as the input; the output elements also have the original list element names.\n\n```{r}\nsystem.time(\n    Lmean <- lapply(X = L, FUN = mean)\n)\n\nLmean\n```\n\nNote the difference in `system.time()` when using `lapply()`. In general one should always use the `*apply()` functions rather than loops if possible. Loops are better for multi-step operations versus operations on single matrices, vectors, or lists.\n\nYou should look up the help documentation for `tapply()`, `lapply()`. There is also a nice tutorial, [Tutorial on the R Apply Family](https://www.datacamp.com/community/tutorials/r-tutorial-apply-family).\n\n#### `purrr` \n`purrr` aims to simplify looping, particularly for multiple-step processes.\n\nThe main functions in `purrr` are `map_*()`, with specific variants to be run on data frames (`map_dfr()`), character vectors (`map_chr()`), logical (`map_lgl()`), integer (`map_int()`), and double precision numeric (`map_dbl()`).\n\nAlthough a full treatment of `purrr` is beyond our scope, see a [great `purrr` tutorial with worked examples](https://jennybc.github.io/purrr-tutorial.)\n\n##### Efficient download of census data using `purrr` and `tigris`\n\nHere, following on the lessons from using the `tigirs` package for downloading US Census TIGER/Line data, we will download all counties for all states using `purrr::map_dfr()` and export to a GPKG database.\n\n```{r}\n# the tigris download function for counties\nf_county <- function(state_name, year = 2019){\n    # this downloads a single county\n    counties(state = state_name, year)\n}\n\n# the map_dfr() functionality is wrapped in here\nget_counties <- function(year = 2019) {\n    # the output is a data frame. input (.x) is the state name, the function (.f) is the county download\n    map_dfr(\n        # input is the built in vector \"state.name\"\n        .x = state.name,\n        # each iteration runs the f_county() function over the iteration's state\n        .f = function(x) {\n            f_county(state_name = x, year = year)\n        }\n    )\n}\n\n# run the function\nall_counties <- get_counties()\n\n# export to GPKG\nmyTmpDir <- tempdir()\nst_write(obj = all_counties, dsn = file.path(myTmpDir, \"counties.gpkg\"), layer = \"us_counties_2019\", delete_dsn = TRUE)\n```\n\nIn `r figure_nums(name = \"countymap\", display = \"cite\")` we show the counties displayed in QGIS.\n\n![](images/week04/2022-01-26 23_42_02-Window.png)\n\\    \n_`r figure_nums(name = \"countymap\", caption = \"Downloaded counties for the US\")`_\n\nThis process could easily be applied to multiple years of data or different census units (block groups, blocks, tracts).\n\n##### Revisiting Ben's HMDHFDplus example\nLet's revisit Ben's [example using HMDHFDplus](#benhmdhfdplus)\n\n```{r}\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\ncountries <- HMDHFDplus::getHMDcountries()[1:2]\n\n# Function to download a specified HMD data set item for a single county\n# the country code is referenced as \"CNTRY\"\n# the \"item\" is the base name of the link with \".txt\" removed. For example,\n# https://www.mortality.org/hmd/ISR/STATS/Mx_1x1.txt\n#                                         Mx_1x1       <<- this is the item for 1 year x 1 year death rates\nread_hmd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHMDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n\n# Help function to list the available countries\n# this generates a vector of all country abbreviations\n# for speed in class we will use only two countries\ncountries <- HMDHFDplus::getHMDcountries()[1:2]\n\n# Download a data set iteratively for all countries using purrr::map()\n# In this case, age-specific mortality in 1-year periods x 1-year age groups\n# for all 1-year periods available\n# output is a data frame named \"mx_1x1\"\nmx_1x1 <- countries %>%\n    # Returns a list of data.frames, adding a column for country code to each\n    # the map() function performs a run of Ben's read_hmd_country() function for each listed country\n    purrr::map_dfr(function(country) {\n        # the item to read is 1 x 1 death rates\n        read_hmd_country(CNTRY = country, item = \"Mx_1x1\") %>%\n            # this adds the column \"country\" storing the country ISO code\n            dplyr::mutate(country = country)\n    }) %>%\n    # Phil added this to make it a tibble\n    tibble()\n```\n\nThe key piece here is \n\n```\npurrr::map_dfr(function(country) {\n    # the item to read is 1 x 1 death rates\n    read_hmd_country(country, \"Mx_1x1\")\n```\n\nwhich constructs a data frame by iterating over `countries` and applying the function `read_hmd_country()` to download the variable `Mx_1x1`. Here we plot mortality data from Australia and Austria over the time series (`r figure_nums(name = \"aus_aut_mort\", display = \"cite\")`).\n\n```{r}\ntmx <- mx_1x1 %>% \n    group_by(Year, country) %>% \n    dplyr::summarise(mortality = sum(Total, na.rm = TRUE), .groups = \"keep\")\n\ntmx %>% ggplot(mapping = aes(x = Year, y = mortality)) +\n    geom_line() +\n    facet_grid(country ~ .) + \n    xlab(\"year\")\n```\n\\    \n*`r figure_nums(name = \"aus_aut_mort\", caption = \"Mortality data from Australia and Austria\")`*\n\n#### Bootstrapping \nBootstrapping is used to estimate the characteristics of a population by repeating a large number of random samples (with replacement) and then calculating summary statistics on the set of samples. The reason replacement is used is that each sample represents a \"snapshot\" of the population. As the number of samples increases, the summary continues to approach the true population characteristics.\n\nWe will use a simple example from a hypothetical population. If we had no idea what the male/female split was, we could generate a large number of small-ish samples and the take the mean.\n\nBack to the bootstrap: we will use 5,000 samples of size 100 from our hypothetical population to estimate the proportion of females.\n\n```{r}\n# create the population\n# 1 indicates female and 0 indicates male\npop <- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5))\n\n# initialize a vector\nF <- NULL\n\n# run the bootstrap\nfor (i in seq(from = 1, to = 5000, by = 1)){\n    # sample once\n    s <- sample(x = pop, size = 100, replace = TRUE)\n    # calculate percent female\n    p <- sum(s) / length(s)\n    # concatenate the result with the running result\n    F <- c(F, p)\n}\n\n# mean and standard deviation of the bootstrap\nmean(F)\nsd(F)\n```\n\nUsing the bootstrap results, we can estimate the 95% confidence interval around the mean using the `Rmisc::CI()` function, and make a density plot showing the mean and the confidence interval (`r figure_nums(name = \"bootstrat_plot\", display = \"cite\")).\n\n```{r}\n# 95% CI\nci_95 <- Rmisc::CI(x = F, ci = 0.95)\n\n# plot with 95 % CI\nplot(density(F), main = \"\")\nabline(v = ci_95, col=c(2,1,2))\n```\n\\    \n*`r figure_nums(name = \"bootstrat_plot\", caption = \"Density plot from bootstrapping\")`*\n\nIf we already had an enumeration of the population, this method would be unnecessary. However, most survey-derived data are generated from samples. If the sample is representative of the underlying population,  the sample can be considered an acceptable proxy.\n\n\n## Sampling {#rsampling}\nThe general topic of sampling is far greater than what we can cover in this course. However, a few examples may be helpful for students who have little experience in sampling.\n\nThe main R function for sampling is `sample()`, which draws a random sample from a vector or data frame. Options for `sample()` include the size of the sample, whether or not to replace sampled individuals to the pool, and a probability weight of the same length (or number of rows) as the population from which the sample is drawn.\n\n### Sampling with replacement\nSampling with replacement is similar to rolling a die. Each roll of the die has a 1/6 probability of coming up with each value. For example we simulate rolling a die 100,00 times:\n\n```{r}\n# set.seed makes it so that random processes can be repeated with the same outputs\nset.seed(5)\n\n# create a vector to represent the faces of a die\nd <- 1:6\n\n# now make a sample of 100,000 rolls of the die, with replacement for independent rolls\ns <- sample(x = d, size = 100000, replace = TRUE)\n\n# tabulate the result\n(tbs <- table(s))\n\n# proportions\n(prop.table(tbs))\n```\n\nThe probability of rolling two of the same number in a row is 1/6 $\\times$ 1/6, or $\\approx$ 0.028\n\n### Sampling without replacement\nSampling without replacement removes from the population the individual that was sampled. For example, the probability of selecting an ace from a whole deck of cards is 4/52, or $\\approx$ 0.077. If we drew once from the deck and returned the card back to the deck to draw again, both samples would be independent. The probability of drawing two aces would be 4/52 $\\times$ 4/52, or $\\approx$ 0.0059. _That_ is an example of sampling _with_ replacement, similar to rolling a die.\n\nPerforming the same sample _without_ replacement, i.e., finding an ace, removing it, and then sampling again would have a probability of drawing two aces being 4/52 $\\times$ 3/51, or $\\approx$ `r round((4/52) * (3/51), 4)`.\n\nIf you were to design an study in which once a person was surveyed once they would not be eligible to be surveyed again, that would also be an example of samping *without* replacement.\n\nFor a population of sufficient size relative to the sample, sampling with or without replacement will lead to nearly identical results.\n\nLet's use an example of a population of 50,000 persons, where 30,000 are female and 20,000 are male. If we were to sample two persons with replacement, the probability that they would both be female would be 30000/50000 $\\times$ 30000/50000, or 0.36.\n\nIf we sample without replacement, the probability of selecting a female in the first sample of one would be 30000/50000, and the second sample of 1 would have a probability of selecting a female 29999/49999, with a joint probability of $\\approx$ 0.359995.\n\n## R packages for demographic analysis {#demogpackages}\nThere is always a growing list of available packages for analysis in R. Here we will briefly cover two packages for demographic analysis.\n\n### `demogR` {#demogR}\nAge-Structured Demographic Models\n\nThe [`demogR`](https://cran.r-project.org/web/packages/demogR/) package provides a number of functions for analysis of age-structured demographic models. In this exercise we will look at the `life.table()` function for creating life tables from enumerated deaths and mid-interval population estimates.\n\nWe will follow the example from the help page on `life.table()`. The example uses the `goodman` data set, which has aggregate data from Venezuela, Madagascar, and the USA from 1965, 1966, and 1967, respectively. The table contains these fields:\n\n* age\\\nage classes\n* ven.nKx\\\nmid-year population structure for Venezuela\n* ven.nDx\\\nenumerated deaths for Venezuela\n* ven.bx\\\nenumerated births for Venezuela\n* mad.nKx\\\nmid-year population structure for Madagascar\n* mad.nDx\\\nenumerated deaths for Madagascar\n* mad.bx\\\nenumerated births for Madagascar\n* usa.nKx\\\nmid-year population structure for the United States\n* usa.nDx\\\nenumerated deaths for the United States\n* usa.bx\\\nenumerated births for the United States\n\nThe first step is to create the life table itself, which should be run with at least three arguments, `x` (age at the beginning of the age classes of the life table), `nDx` (deaths), and `nKx` (population size). We will create the life table using the three countries' data and the default Keyfitz and Fleiger (`kf`) calculation type. Results are in `r table_nums(name = \"kf\", display = \"cite\")`.\n\n```{r, warning=FALSE}\n# load the Goodman data from the demogR package\ndata(goodman)\n\n## default type=\"kf\", Venezuela data\nvlt <- with(goodman, life.table(x=age, nKx=ven.nKx, nDx=ven.nDx))\n\n## US life table\nult <- with(goodman, life.table(x=age, nKx=usa.nKx, nDx=usa.nDx))\n\n## Madagascar life table\nmlt <- with(goodman, life.table(x=age, nKx=mad.nKx, nDx=mad.nDx))\n\n# some values for the text\nvlx35 <- vlt %>% filter(x == 35) %>% pull(lx) %>% round(2)\nvlx80 <- vlt %>% filter(x == 80) %>% pull(lx) %>% round(2)\nulx35 <- ult %>% filter(x == 35) %>% pull(lx) %>% round(2)\nulx80 <- ult %>% filter(x == 80) %>% pull(lx) %>% round(2)\nmlx35 <- mlt %>% filter(x == 35) %>% pull(lx) %>% round(2)\nmlx80 <- mlt %>% filter(x == 80) %>% pull(lx) %>% round(2)\n\n# combine these\nlt <- bind_rows(vlt, ult, mlt)\n```\n\n*`r table_nums(name = \"kf\", caption = \"Venezuela life table, Keyfitz and Fleiger method\")`*\n\n```{r, warning=FALSE}\nlt %>% kable() %>% \n    kable_styling(bootstrap_options =\n                      c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                  full_width = F, position = \"left\", font_size = 12, fixed_thead = T) %>% \n    pack_rows(group_label = \"Venezuela\", start_row = 1, end_row = 19) %>% \n    pack_rows(group_label = \"USA\", start_row = 20, end_row = 38) %>% \n    pack_rows(group_label = \"Madagascar\", start_row = 39, end_row = 57)\n```\n\nThe results have nine output columns:\n\n1. x\\   \nage at the beginning of the interval\n1. nax\\\nperson-years lived by those dying in the interval x to x+n\n1. nMx\\\nperiod central death rate\n1. nqx\\\nprobability of death between ages x and x+n\n1. lx\\\nprobability of survival to exact age x\n1. ndx\\\nproportion of deaths occurring between ages x and x+n\n1. nLx\\\nperson-years lived in the interval x to x+n\n1. Tx\\\nperson-years of life left in the cohort at age x\n1. ex\\\nlife expectancy at age x\n\nFor example, the life table estimates in Venezuela in 1965, a probability of reaching the age of 35 was `r vlx35`, whereas reaching 80 had a probability of `r vlx80`. In the US in 1967, the respective probabilities were `r ulx35` and `r ulx80`, and in Madagascar in 1966 the probabilities were `r mlx35` and `r mlx80`.\n\nAnother way to look at the data is to plot the life expectancy, shown in `r figure_nums(name = \"demogrltplot\", display = \"cite\")`. The difference between Venezuela and the US were less stark than the difference between Madagascar and the other two countries. In 1966, a woman from Madagascar had a less than 50% chance of reaching age 40! One wonders what these life expectancies look like with more recent data.\n\n```{r}\nlt %<>% mutate(\n    country = c(rep(\"VEN\", 19), rep(\"USA\", 19), rep(\"MDG\", 19))\n)\nggplot(data = lt, mapping = aes(x = x, y = lx, col = country))+\n    geom_line() +\n    xlab(\"age\") +\n    ylab(\"probability of surviving to age on X axis\")\n```\n\\    \n*`r figure_nums(name = \"demogrltplot\", caption = \"Life expectancy, Madagascar (1966), Venezuela (1965), USA (1967)\")`*\n\n### `demography` {#demography}\nThe [`demography`](https://cran.r-project.org/web/packages/demography/index.html) also contains a large number of functions for demographic analysis. For other reference, see [An R intro to the demography package](https://rpubs.com/Timexpo/487053).\n\nWe will look at one example from the documentation.\n\n```{md}\nfrance.lt <- lifetable(fr.mort)\nplot(france.lt)\nlt1990 <- print(lifetable(fr.mort,year=1990))\n```\n\nThe first step is creating the life table using the `lifetable()` function. The function requires data of a specific format, which can be provided in the package's `fr.mort` data set. What is in the `fr.mort` data set? Let's see:\n\n```{r}\nfr.mort\n```\n\nThis tells us there were time series for females, males, and all persons, spanning years 1816 to 2006 and covering ages 0 to 110.\n\nWe can delve deeper:\n\n```{r}\nattributes(fr.mort)\n```\n\nHere we see there are specific objects within the data set. Let's look at some of them. `age`:\n\n```{r}\nfr.mort$age\n```\n\n`year`:\n\n```{r}\nfr.mort$year\n```\n\nThe population data are stored in the `pop` object, which is composed of three matrices representing all persons, females, and males:\n\n```{r}\nfr.mort$pop %>% names()\n```\n\nEach of these matrices has the same number of rows and columns, corresponding to the ages (0-110, 111 rows) and years (1816-2006, columns). Here let's look at a sample of the total, the first 5 rows and columns:\n\n```{r}\nfr.mort$pop$total[1:5, 1:5]\n```\n\nThis shows for example in 1816 there were estimated to be `r prettyNum(fr.mort$pop$total[1, 1])` persons less than one year of age.\n\nOutput from running the `lifetable()` function can be plotted. `r figure_nums(name = \"france_ltplot\", display = \"cite\") shows curves for each year using a rainbow palette. It is interesting to note that the earliest years in the time series had more positive life expectancies than some of the intermediate years particularly for persons below the age of 40.\n\n```{r}\n# min and max years\ny0 <- min(fr.mort$year)\ny1 <- max(fr.mort$year)\n\n# make the life table and plot life expectancy graph\nfrance.lt <- lifetable(fr.mort)\nplot(france.lt)\n```\n*`r figure_nums(name = \"france_ltplot\", paste(\"Life expectancy in France from\", y0, \"to\", y1))`*\n\nFinally, let's look at the life table from 2005. \n\n```{r}\n# create the life table\nlt_france_2005 <- lifetable(fr.mort,year=2005)\n\n# print using the native interface\nprint(lt_france_2005)\n```\nThe output of `lifetable` prints in a tabular format but is not a data frame and so the various methods of making nice looking tables do not work out of the box. This also means standard exporting functions such as `write.csv()` will not work. However, with some work the specific objects returned from the function, we can construct a decent looking table.\n\n```{r, message=FALSE, warning=FALSE}\n# I looked at the individual vectors output from the lifetable function. These are the ones we want:\npositions <- c(1,3:10)\n\n# use lapply() across some of the list objects to\n#   get the object (a vector), that is the anonymous \"function(x) x\"\n# use \"do.call\" to do something to each of those vectors. that something is a \"cbind\"\n# turn it into a data frame and then a tibble\nlt_france_2005_df <- do.call(cbind, lapply(lt_france_2005[positions], function(x) x)) %>% \n    data.frame %>% tibble()\n\n# set the column names from the names of the vectors\ncolnames(lt_france_2005_df) <- names(lt_france_2005)[positions]\n\n# print a nice table\nlt_france_2005_df %>% kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\", font_size = 12, )\n```\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week5.html","id":"week5","chapter":"5 Week 5","heading":"5 Week 5","text":"week covering two topics:Human Fertility Database (age-specific rates summary indicators)Git","code":""},{"path":"week5.html","id":"hmdrevisit","chapter":"5 Week 5","heading":"5.1 Human Fertility Database (age-specific rates and summary indicators)","text":"CSDE 533 looking Human Fertility Database (HFD). brief section cover HFD bit detail Week 2","code":""},{"path":"week5.html","id":"country-code-abbreviations","chapter":"5 Week 5","heading":"5.1.1 Country code abbreviations","text":"order download data using HMDHFDplus::readHFDweb() two key pieces information needed, country abbreviation coded item name.First, able deal country abbreviations. HMDHFDplus package function getHFDcountries() returns abbreviations shown Human Fertility Collection Country / area codes. However, country codes ISO standards. next block code generate tibble country abbreviations country names used HFD (Table 1). help formulating download function.Table 1: HFD countries: codes names","code":"\nlibrary(ISOcodes)\nlibrary(HMDHFDplus)\n\n# HFD country codes\nhfdcodes <- getHFDcountries() %>% tibble(ccode = .)\n\n# ISO country codes\nisocodes <- ISO_3166_1 %>% tibble() %>% select(ccode = Alpha_3, Name)\n\n# join ISO codes with country names\nhfdcodes %<>% left_join(isocodes, by = \"ccode\")\n\n# there are some countries in the HFD that do not use standard 3 character ISO codes\nhfdcodes %>% filter(is.na(Name))## # A tibble: 8 x 2\n##   ccode   Name \n##   <chr>   <chr>\n## 1 FRATNP  <NA> \n## 2 DEUTNP  <NA> \n## 3 DEUTW   <NA> \n## 4 DEUTE   <NA> \n## 5 GBR_NP  <NA> \n## 6 GBRTENW <NA> \n## 7 GBR_SCO <NA> \n## 8 GBR_NIR <NA>\n# update those\nhfdcodes %<>% \n    mutate(Name = \n        case_when(ccode == \"FRATNP\" ~  \"France\",\n                  ccode == \"DEUTNP\" ~  \"Germany\",\n                  ccode == \"DEUTE\" ~   \"East Germany\",\n                  ccode == \"DEUTW\" ~   \"West Germany\",\n                  ccode == \"GBR_NP\" ~  \"United Kingdom\", \n                  ccode == \"GBRTENW\" ~ \"England and Wales\",\n                  ccode == \"GBR_SCO\" ~ \"Scotland\",\n                  ccode == \"GBR_NIR\" ~ \"Northern Ireland\",\n                  TRUE ~ Name)\n    )\nhfdcodes %>% \n    kable() %>% \n    kable_styling(bootstrap_options =\n                      c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                  font_size = 12,\n                  full_width = F, position = \"left\")"},{"path":"week5.html","id":"hfd-items","chapter":"5 Week 5","heading":"5.1.2 HFD items","text":"download data using HMDHFDplus::readHFDweb(), necessary specify item name. example thee HFD page Unites States America, first item listed total number live births birth orders combined 1933 2019; URL www.humanfertility.org/cgi-bin/getfile.plx?f=USA\\20210422totbirthsRR.txt (item name underlined).Using Ben’s HFD code template, can download item several countries.First, create generic function download HFD data country item:create function download item set countriesFinally, run function download one item set countries:Let’s make graph (Figure 1).\n Figure 1: Live births x 1 million: Japan, Lithuania, USA (note non-standardized Y scale)","code":"\n# a function to read HFD for one country and one item\nread_hfd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHFDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n# Download a data set iteratively for all named countries using purrr::map()\nread_hfd_countries_item <- function(countries, item){\n    countries %>%\n        # Returns a list of data.frames, adding a column for country code to each\n        # the map() function performs a run of Ben's read_hmd_country() \n        #   function for each listed country\n        purrr::map_dfr(function(ccode) {\n            # the item to read is 1 x 1 death rates\n            read_hfd_country(ccode, item) %>%\n                # this adds the column \"country\" storing the country ISO code\n                dplyr::mutate(ccode = ccode)\n        }) %>%\n        # Phil added this to make it a tibble\n        tibble() %>% \n        # and add country name\n        left_join(hfdcodes, by = \"ccode\")\n}\nCNTRIES <- hfdcodes %>% \n    filter(Name %in% c(\"United States\", \"Lithuania\", \"Japan\")) %>% \n    pull(ccode)\n\ntotbirthsRR_USA_LTU_JPN <- read_hfd_countries_item(countries = CNTRIES, item = \"totbirthsRR\")\ntotbirthsRR_USA_LTU_JPN %>% \n    mutate(TotalM = Total / 1000000) %>% \n    ggplot( \n       mapping = aes(x = Year, y = TotalM)) +\n    geom_line() +\n    facet_wrap(~Name, ncol = 1, scales = \"free_y\") +\n    ylab(\"live births\") +\n    xlab(\"year\")"},{"path":"week5.html","id":"git","chapter":"5 Week 5","heading":"5.2 Git","text":"section brief introduction Git, free open source version control system text-based files. Much material lesson derived Software Carpentry Git tutorial.","code":""},{"path":"week5.html","id":"why-use-version-control","chapter":"5 Week 5","heading":"5.2.1 Why use version control?","text":"Version control simply control various versions documents. context code-based research using text files .R, .Rmd, .tex, .sql, ., simplest level, version control means ability track changes files. advanced levels, able revert previous versions, collaborate others know , merge together edits made one personWe covered one form version control previous assignment section document File systems. version control system simply keeping copies existing files naming new files according temporal sequence, date suggested method nomenclature.keeping backup, dated copies files necessarily bad approach, suffers major limitations, including:relies saving different versions file, can lead proliferation filesit often easy know changes made version versionJorge Cham’s (Piled Higher Deeper) comic points happens typical graduate student’s “final” version:","code":""},{"path":"week5.html","id":"why-use-git","chapter":"5 Week 5","heading":"5.2.2 Why use Git?","text":"Version controls systems use since early 1980s. Commonly used applications RCS (Revision Control System), CVS (Concurrent Versions System), SVN (Subversion). However, require centralized servers, limited capabilities, free.Git multiple advantages:freesupports complex work flows branching, merging, etc., allowing multiple collaborators work set files timedoes require centralized server (version control can managed completely within single computer)\npossible use online repositories, Github.com\npossible use online repositories, Github.comcan used within RStudiohas large community users (.e., free advice)","code":""},{"path":"week5.html","id":"limitations-of-version-control-systems","chapter":"5 Week 5","heading":"5.2.3 Limitations of version control systems","text":"Although version control systems quite useful, potential drawbacks.requires learning yet another somewhat-complicated systemrequires mindfulness\nrecorded changes best performed interactively\ncan “undo” changes committed\nrecorded changes best performed interactivelycan “undo” changes committeddesigned text files; deal binary files, e.g., Word formats","code":""},{"path":"week5.html","id":"a-brief-git-tutorial","chapter":"5 Week 5","heading":"5.2.4 A brief Git tutorial","text":"using basic functions Git building Rmd file.","code":""},{"path":"week5.html","id":"setting-up-git-in-rstudio","chapter":"5 Week 5","heading":"5.2.4.1 Setting up Git in RStudio","text":"working CSDE Terminal Server 4 (see Getting started Terminal Server 4).Start RStudio open web browser.","code":""},{"path":"week5.html","id":"creating-a-repository","chapter":"5 Week 5","heading":"5.2.4.2 Creating a repository","text":"Using web browser, go Github.com create repository named git_r.Make repository public add README file.Switch back RStudio select File > New Project choice project types, select Version Control. streamline process linking RStudio project Github.Choose Git type version control.Enter complete URL new Git repository. project directly name automatically set base name pf URL. , enter git_r.need define local file system project files stored, click Browse navigate H: drive (note UDrive).specified repository URL, project directory name, parent directory project directory, click Create Project.","code":""},{"path":"week5.html","id":"tracking-changes","chapter":"5 Week 5","heading":"5.2.4.3 Tracking changes","text":"One files change week_01.Rmd, download main folder project.first file make changes README.md.Add text explaining purpose repository serves.Save changes README.md file. see updates Git tab, click Refresh listing button. may need frequently file changes frequent. Note status files change files saved.see blue “M” next README.md file. Click check box Staged prepare commit changes file prepare push remote server.Click Commit new window open. deletions shown light red background. Additions shown light green background, text changed white background.Enter explanatory text Commit message panel. message help identify historical commits. explanatory text succinctly describe changes made.idea make commits time substantially changed code. wait long commits, number changes single commit may unmanageable. commits made frequently, number commits may become unmanageable. Think similarly often might make new version document.Next, perform initial pull/push. recommended multi-user environments perform pull online repository pushing. lets download local file system files updated others.Git tab, click Pull icon.Since changes made online files, see message “Already date.”Next, click Push icon upload changed files.point process establishing connection Github, may get popups asking sign . happens, proceed authorization.authorization completed, push proceed. screen look different, last line text shows truncated version unique hash (identifier) push transaction. unique hash allow download previous versions file case made commits pushes caused unintended consequences.refresh page repository, see updates made README.md file. basic process updating files, committing changes, pushing Github.Perform steps (click Staged Commit week_01.Rmd). new file Github repository, committed, show green since text added.Repeat pull/push cycle refresh browser show file added online Github repository.click file name see contents.Let’s make changes file. Back RStudio, add list packages load line 51.Change description line 122 readand change code chunk add two additional points text popups point markers. chunk contain following code:Save edits file tap “knit” button enter console prompt rmarkdown::render(\"week_01.Rmd\") generate HTML file. see now three point markers, hover markers see name popup.","code":"library(htmltools) # popup on Leaflet map... for a Leaflet map that has the Space Needle, Savery Hall, and the Woodland Park Zoo.# the Space Needle\nsnxy <- data.frame(name = \"Space Needle\", x = -122.3493, y = 47.6205)\nspace_needle <- st_as_sf(snxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# Savery Hall\nshxy <- data.frame(name = \"Savery Hall\", x = -122.3083, y = 47.6572)\nsavery_hall <- st_as_sf(shxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# the Woodland Park Zoo\nzooxy <- data.frame(name = \"Woodland Park Zoo\", x = -122.3543, y = 47.6685)\nwp_zoo <- st_as_sf(zooxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# rbind() to put two points in one data frame\npts <- rbind(space_needle, savery_hall, wp_zoo)\n\n# a leaflet\nm <- leaflet() %>% \n    addTiles() %>% \n    addCircleMarkers(data = pts, label = ~htmlEscape(name))\nm"},{"path":"week5.html","id":"git-bash-shell","chapter":"5 Week 5","heading":"5.2.4.4 Git bash shell","text":"Another interface can use Git bash shell. open shell, click Tools > Shell.GUI commands used RStudio available shell. fact, little functionality Git available within RStudio. take full advantage Git, necessary use shell. number excellent tutorials use shell. now introductory lesson, focus mainly RStudio interface,shell set project folder; can enter e.g., cd /H/git_r (note corresponds Windows folder H:\\git_r).prompt, enter git status. show status files, case showing week_01.Rmd modified, files tracked.","code":""},{"path":"week5.html","id":"ignoring-specific-files","chapter":"5 Week 5","heading":"5.2.4.5 Ignoring specific files","text":"Sometimes interested particular files committed pushed repository. version control, interested managing code used create outputs rather outputs , idea code, can recreate outputs.files can ignored, specified .gitignore file. Open file add line *.html. tells Git bother managing HTML files (assumption output rendering Rmd files).Save .gitignore file re-run git status shell (tapping arrow key keyboard tapping Enter). see HTML file show list changed untracked files.Add line *.Rproj .gitignore file–file necessary repository.Likewise, refresh Git tab RStudio, HTML file longer listed.perform tasks shell. Enter add .gitignore add week_01.Rmd. equivalent clicking Staged check box RStudio.Refreshing Git tab RStudio show two files staged. demonstrates RStudio Git environment date changes made using Git shell, vice versa.","code":""},{"path":"week5.html","id":"exploring-file-change-history","chapter":"5 Week 5","heading":"5.2.4.6 Exploring file change history","text":"Click Commit prepare commit changes (addition .gitignore changes week_01.Rmd).previously mentioned, deleted lines shown light red, added lines light green, unchanged lines highlighting. Click entry week_01.Rmd changes apparent. Line numbers far left original line numbers. next column right shows updated line numbers.allows compare currently saved version previous version file.Committing changes shell done enteringgit commit -m \"somecomment\"effect clicking Commit RStudio entering comment.Note made initial user configurations, Git print informative text identity. avoid tag future commits, use git config --global commands, e.g.,git config --global user.name \"Full Name\" git config --global user.email \"myemailaddress@mydomain\"commit performed, either RStudio GUI shell, can verify files listed possibly staged.Perform another pull/push cycle refresh web browser. Click commit comment.see changes two files last commit/push. .gitignore file lines green, indicating new respect repository. file week_01.Rmd shows changes Github saw local view pushing commit server.","code":""},{"path":"week5.html","id":"restoring-a-previous-version","chapter":"5 Week 5","heading":"5.2.4.7 Restoring a previous version","text":"good tracked changes revert previous version file? make intentional bad edits file, commit push, retrieve previous version file. version can recovered. Note mean can recover edits file. means can recover changed commits. example, made commit/push noon, made lot changes saved file multiple times 5 PM made commit/push, two versions file available Git, one committed noon, one committed 5 PM. reason worth making commit/push cycles every time thing might want revert previous version.intentional bad change week_01.Rmd complete removal code produces Leaflet map. See following image.Perform standard cycle: stage, commit (snarky comment), pull, push.see large swath deleted linesBack Github, find click file name.file contents show recent saved version (missing Leaflet map lines). Click History link, show commits.Click commit followed questionable advice advisor.missing lines evident. like go back version large deletion lines.Identify previous commit click clipboard icon left first characters commit hash. copy hash, necessary restoring version.Back shell, enterwhere ***** hash. display encoded instructions changes made file. Now enterwhere ***** hash.applies changes file commit represented hash. see text present commit, includes deleted Leaflet map.restore previous version new file, enterThis prints contents previously committed file redirects output named file > sign.open file, see restored text.","code":"git show *****git show *****:week_01.Rmdgit show *****:week_01.Rmd > week_01_someadditionaldescription.Rmd"},{"path":"week5.html","id":"conclusion","chapter":"5 Week 5","heading":"5.2.4.8 Conclusion","text":"brief introduction main functionality Git RStudio Github. expect perform even modest amount coding, benefit Git way keep track work, collaborate others, avoid programming disasters due inadvertent deletion overwriting files.Rendered 2022-03-04 00:44:14","code":""},{"path":"week5.html","id":"source-code-5","chapter":"5 Week 5","heading":"5.3 Source code","text":"File H:/csde502-winter-2022-main/05-week05.Rmd.","code":""},{"path":"week5.html","id":"r-code-used-in-this-document-5","chapter":"5 Week 5","heading":"5.3.1 R code used in this document","text":"","code":"\npacman::p_load(ISOcodes, tidyverse, magrittr, knitr, kableExtra, readstata13, HMDHFDplus, captioner)\n\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\nlibrary(ISOcodes)\nlibrary(HMDHFDplus)\n\n# HFD country codes\nhfdcodes <- getHFDcountries() %>% tibble(ccode = .)\n\n# ISO country codes\nisocodes <- ISO_3166_1 %>% tibble() %>% select(ccode = Alpha_3, Name)\n\n# join ISO codes with country names\nhfdcodes %<>% left_join(isocodes, by = \"ccode\")\n\n# there are some countries in the HFD that do not use standard 3 character ISO codes\nhfdcodes %>% filter(is.na(Name))\n\n# update those\nhfdcodes %<>% \n    mutate(Name = \n        case_when(ccode == \"FRATNP\" ~  \"France\",\n                  ccode == \"DEUTNP\" ~  \"Germany\",\n                  ccode == \"DEUTE\" ~   \"East Germany\",\n                  ccode == \"DEUTW\" ~   \"West Germany\",\n                  ccode == \"GBR_NP\" ~  \"United Kingdom\", \n                  ccode == \"GBRTENW\" ~ \"England and Wales\",\n                  ccode == \"GBR_SCO\" ~ \"Scotland\",\n                  ccode == \"GBR_NIR\" ~ \"Northern Ireland\",\n                  TRUE ~ Name)\n    )\nhfdcodes %>% \n    kable() %>% \n    kable_styling(bootstrap_options =\n                      c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                  font_size = 12,\n                  full_width = F, position = \"left\")\n# a function to read HFD for one country and one item\nread_hfd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHFDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n# Download a data set iteratively for all named countries using purrr::map()\nread_hfd_countries_item <- function(countries, item){\n    countries %>%\n        # Returns a list of data.frames, adding a column for country code to each\n        # the map() function performs a run of Ben's read_hmd_country() \n        #   function for each listed country\n        purrr::map_dfr(function(ccode) {\n            # the item to read is 1 x 1 death rates\n            read_hfd_country(ccode, item) %>%\n                # this adds the column \"country\" storing the country ISO code\n                dplyr::mutate(ccode = ccode)\n        }) %>%\n        # Phil added this to make it a tibble\n        tibble() %>% \n        # and add country name\n        left_join(hfdcodes, by = \"ccode\")\n}\nCNTRIES <- hfdcodes %>% \n    filter(Name %in% c(\"United States\", \"Lithuania\", \"Japan\")) %>% \n    pull(ccode)\n\ntotbirthsRR_USA_LTU_JPN <- read_hfd_countries_item(countries = CNTRIES, item = \"totbirthsRR\")\ntotbirthsRR_USA_LTU_JPN %>% \n    mutate(TotalM = Total / 1000000) %>% \n    ggplot( \n       mapping = aes(x = Year, y = TotalM)) +\n    geom_line() +\n    facet_wrap(~Name, ncol = 1, scales = \"free_y\") +\n    ylab(\"live births\") +\n    xlab(\"year\")\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week5.html","id":"complete-rmd-code-5","chapter":"5 Week 5","heading":"5.3.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 5 {#week5}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\npacman::p_load(ISOcodes, tidyverse, magrittr, knitr, kableExtra, readstata13, HMDHFDplus, captioner)\n\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\n<style>\n.und {\n  text-decoration: underline;\n}\n<\/style>\n\n<h2>Topics: Human Fertility Database (age-specific rates and summary indicators); Git<\/h2>\n\nThis week we will be covering two topics:\n\n* [Human Fertility Database (age-specific rates and summary indicators)](#hmdrevisit)\n* [Git](#git)\n\n## Human Fertility Database (age-specific rates and summary indicators) {#hmdrevisit}\nCSDE 533 will be looking more at the Human Fertility Database (HFD). This brief section will cover the HFD in a bit more detail than in [Week 2](#datasets002)\n\n### Country code abbreviations\nIn order to download data using `HMDHFDplus::readHFDweb()` two key pieces of information are needed, the country abbreviation and the coded item name.\n\nFirst, we should be able to deal with country abbreviations. The `HMDHFDplus` package has the function `getHFDcountries()` that returns the abbreviations shown at [Human Fertility Collection Country / area codes](https://www.fertilitydata.org/cgi-bin/country_codes.php). However, some of the country codes are not ISO standards. This next block of code will generate a tibble with the country abbreviations and country names used in the HFD (`r table_nums(name = \"hfdcountries\", display = \"cite\")`). This will help with formulating the download function.\n\n```{r}\nlibrary(ISOcodes)\nlibrary(HMDHFDplus)\n\n# HFD country codes\nhfdcodes <- getHFDcountries() %>% tibble(ccode = .)\n\n# ISO country codes\nisocodes <- ISO_3166_1 %>% tibble() %>% select(ccode = Alpha_3, Name)\n\n# join ISO codes with country names\nhfdcodes %<>% left_join(isocodes, by = \"ccode\")\n\n# there are some countries in the HFD that do not use standard 3 character ISO codes\nhfdcodes %>% filter(is.na(Name))\n\n# update those\nhfdcodes %<>% \n    mutate(Name = \n        case_when(ccode == \"FRATNP\" ~  \"France\",\n                  ccode == \"DEUTNP\" ~  \"Germany\",\n                  ccode == \"DEUTE\" ~   \"East Germany\",\n                  ccode == \"DEUTW\" ~   \"West Germany\",\n                  ccode == \"GBR_NP\" ~  \"United Kingdom\", \n                  ccode == \"GBRTENW\" ~ \"England and Wales\",\n                  ccode == \"GBR_SCO\" ~ \"Scotland\",\n                  ccode == \"GBR_NIR\" ~ \"Northern Ireland\",\n                  TRUE ~ Name)\n    )\n```\n\n*`r table_nums(name = \"hfdcountries\", caption = \"HFD countries: codes and names\")`*\n\n```{r}\nhfdcodes %>% \n    kable() %>% \n    kable_styling(bootstrap_options =\n                      c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                  font_size = 12,\n                  full_width = F, position = \"left\")\n```\n\n### HFD items\nTo download data using `HMDHFDplus::readHFDweb()`, it is necessary to specify the item name. For example at thee HFD page [Unites States of America](https://www.humanfertility.org/cgi-bin/country.php?country=USA&tab=si), the first item listed is total number of live births for all birth orders combined between 1933 and 2019; the URL is **www.humanfertility.org/cgi-bin/getfile.plx?f=USA\\20210422\\USA<span class=\"und\">totbirthsRR<\/span>.txt** (where the item name is underlined).\n\nUsing Ben's HFD code as a template, we can download the same item for several countries.\n\nFirst, we create a generic function to download HFD data for a country and an item:\n\n```{r}\n# a function to read HFD for one country and one item\nread_hfd_country <- function(CNTRY, item) {\n  HMDHFDplus::readHFDweb(\n    # the country from the function call\n    CNTRY = CNTRY,\n    # the item to download\n    item = item,\n    # the username from this key's record\n    username = keyring::key_list(\"human-mortality-database\")$username,\n    # the password for this key's record\n    password = keyring::key_get(\n      service = \"human-mortality-database\",\n      username = keyring::key_list(\"human-mortality-database\")$username\n    )\n  )\n}\n```\n\nWe then create a function to download an item for a set of countries\n\n```{r}\n# Download a data set iteratively for all named countries using purrr::map()\nread_hfd_countries_item <- function(countries, item){\n    countries %>%\n        # Returns a list of data.frames, adding a column for country code to each\n        # the map() function performs a run of Ben's read_hmd_country() \n        #   function for each listed country\n        purrr::map_dfr(function(ccode) {\n            # the item to read is 1 x 1 death rates\n            read_hfd_country(ccode, item) %>%\n                # this adds the column \"country\" storing the country ISO code\n                dplyr::mutate(ccode = ccode)\n        }) %>%\n        # Phil added this to make it a tibble\n        tibble() %>% \n        # and add country name\n        left_join(hfdcodes, by = \"ccode\")\n}\n```\n\nFinally, run the function to download one item for a set of countries:\n\n```{r}\nCNTRIES <- hfdcodes %>% \n    filter(Name %in% c(\"United States\", \"Lithuania\", \"Japan\")) %>% \n    pull(ccode)\n\ntotbirthsRR_USA_LTU_JPN <- read_hfd_countries_item(countries = CNTRIES, item = \"totbirthsRR\")\n```\n\nLet's make a graph from that (`r figure_nums(name = \"livebirths\", display = \"cite\")`).\n\n```{r}\ntotbirthsRR_USA_LTU_JPN %>% \n    mutate(TotalM = Total / 1000000) %>% \n    ggplot( \n       mapping = aes(x = Year, y = TotalM)) +\n    geom_line() +\n    facet_wrap(~Name, ncol = 1, scales = \"free_y\") +\n    ylab(\"live births\") +\n    xlab(\"year\")\n```\n\\    \n*`r figure_nums(name = \"livebirths\", caption = \"Live births x 1 million: Japan, Lithuania, USA (note non-standardized Y scale)\")`*\n\n## Git {#git}\n\nThis section is a brief introduction to [Git](https://git-scm.com/), the free and open source version control system for text-based files. Much of the material in this lesson is derived from the [Software Carpentry Git tutorial](https://swcarpentry.github.io/git-novice/).\n\n### Why use version control?\nVersion control is simply having control over various versions of your documents. In the context of code-based research using text files such as `.R`, `.Rmd`, `.tex`, `.sql`, `.do`, at the simplest level, version control means having the ability to track changes to your files. In more advanced levels, you should be able to revert to previous versions, collaborate with others and know who did what and when, or to merge together edits made by more than one person\n\nWe covered one form of version control in a previous assignment and in the section of this document on [File systems](#file-systems). The version control system was simply keeping copies of existing files and naming new files according to a temporal sequence, with date being the suggested method of nomenclature.\n\nWhile keeping backup, dated copies of files is not necessarily a bad approach, it suffers from a few major limitations, including:\n\n1. because it relies on saving different versions of a file, it can lead to a proliferation of files\n1. it is not often easy to know what changes were made from version to version\n\nJorge Cham's ([Piled Higher and Deeper](http://www.phdcomics.com)) comic points out what happens to a typical graduate student's \"final\" version:\n\n[![](images/week05/phd101212s.png)](http://www.phdcomics.com)\n\n### Why use Git?\nVersion controls systems have been in use since the early 1980s. Commonly used applications are RCS (Revision Control System), CVS (Concurrent Versions System), SVN (Subversion).  However, some of these require centralized servers, are limited in their capabilities, and are not free.\n\nGit has multiple advantages:\n\n* free\n* supports complex work flows with branching, merging, etc., allowing multiple collaborators to work on the same set of files at the same time\n* does not require a centralized server (version control can be managed completely within a single computer)\n    * it is possible to use online repositories, such as Github.com\n* can be used within RStudio\n* has a large community of users (i.e., free advice)\n\n### Limitations of version control systems\nAlthough version control systems are quite useful, there are some potential drawbacks.\n\n1. requires learning yet another somewhat-complicated system\n1. requires mindfulness\n    * recorded changes are best performed interactively\n    * can only \"undo\" changes that were committed\n1. designed for text files; cannot deal with binary files, e.g., Word or other formats\n\n### A brief Git tutorial\nHere we will be using the basic functions of Git while building up an Rmd file.\n\n#### Setting up Git in RStudio\nWe will be working on CSDE Terminal Server 4 (see [Getting started on Terminal Server 4](#getting-started-on-terminal-server-4)). \n\nStart RStudio and open a web browser.\n\n#### Creating a repository\nUsing the web browser, go to [Github.com](http://github.com) and create a repository named `git_r`.\n\n![](images/week05/2021-02-04_21_21_47.png)\n\nMake the repository public and add a README file.\n\n![](images/week05/2021-02-04_21_37_13.png)\n\nSwitch back to RStudio and select `File > New Project` and in the choice of project types, select `Version Control`. This will streamline the process of linking the RStudio project with Github.\n\n![](images/week05/2021-02-04_21_39_10.png)\n\nChoose `Git` as the type of version control.\n\n![](images/week05/2021-02-04_21_39_46.png)\n\nEnter the complete URL of your new Git repository. The project directly name should automatically be set as the base name pf the URL. If not, enter `git_r`.\n\n![](images/week05/2021-02-04_21_52_48.png)\n\nBecause we need to define where on the local file system the project files will be stored, click `Browse` and navigate to your `H:` drive (note that this is your UDrive).\n\n![](images/week05/2021-02-04_21_53_32.png)\n\nAfter you have specified the repository URL, project directory name, and parent directory of the project directory, click `Create Project`.\n\n![](images/week05/2021-02-04_21_54_04.png)\n\n#### Tracking changes\nOne of the files we will change is [week_01.Rmd](files/week_01.Rmd), so download this to the main folder of your project.\n\nThe first file we will make changes to is `README.md`.\n\nAdd some text explaining what purpose the repository serves.\n\n![](images/week05/2021-02-04_22_09_11.png)\n\nSave the changes to the README.md file. If you do not see updates in the Git tab, click the `Refresh listing` button. You may need to do this frequently if your file changes are frequent. Note the status of files will only change when the files are saved.\n\n![](images/week05/2021-02-04_22_37_42.png)\n\nYou should see a blue \"M\" next to the README.md file. Click the check box for `Staged` to prepare to commit the changes to the file and prepare to push to the remote server.\n\n![](images/week05/2021-02-04_22_11_45.png)\n\nClick `Commit` and a new window will open. Any deletions are shown with a light red background. Additions are shown with a light green background, and text that has not changed will have a white background.\n\nEnter some explanatory text in the `Commit message` panel. This message will help identify historical commits. The explanatory text should succinctly describe any changes you have made.\n\nThe idea is to make commits each time you have substantially changed your code. If you wait too long between commits, the number of changes in a single commit may be unmanageable. But if commits are made too frequently, the number of commits may become unmanageable. Think of this similarly to how often you might make a new version of a document.\n\n![](images/week05/2021-02-04_22_15_28.png)\n\nNext, we will perform an initial pull/push. It is recommended in multi-user environments to perform a pull from the online repository before pushing. This lets you download to your local file system any files that have been updated by others.\n\nIn the Git tab, click the `Pull` icon.\n\n![](images/week05/2021-02-04_22_17_19.png)\n\n\nSince no changes have been made to the online files, we see the message \"Already up to date\".\n\n![](images/week05/2021-02-04_22_17_41.png)\n\nNext, click the `Push` icon to upload any changed files.\n\n![](images/week05/2021-02-04_22_17_58.png)\n\nAt some point in the process of establishing the connection to Github, you may get some popups asking you to sign in. If this happens, proceed with the authorization.\n\n![](images/week05/2021-02-04_22_19_18.png)\n\n![](images/week05/2021-02-04_22_19_59.png)\n\n![](images/week05/2021-02-04_22_20_08.png)\n\nWhen the authorization is completed, the push will proceed. Your screen will look different, but the last line of text here shows a truncated version of the unique hash (identifier) of the push transaction. This unique hash will allow you to download previous versions of the file in case you made commits and pushes that caused unintended consequences.\n\n![](images/week05/2021-02-04_22_20_32.png)\n\nIf you refresh the page for your repository, you should see the updates you made to the README.md file. This is the basic process for updating files, committing changes, and pushing to Github.\n\n![](images/week05/2021-02-04_22_21_18.png)\n\n\nPerform the same steps (click `Staged` then `Commit` for week_01.Rmd). Because this is a new file that was not in the Github repository, when it is committed, it will show in all green since all of the text has been added. \n\n![](images/week05/2021-02-04_22_46_24.png)\n\nRepeat the pull/push cycle and then refresh your browser to show that the file was added to the online Github repository.\n\n![](images/week05/2021-02-04_22_48_45.png)\n\nIf you click the file name you will see the contents.\n\n![](images/week05/2021-02-04_22_49_07.png)\n\nLet's make some changes to this file. Back in RStudio, add to the list of packages to load at line 51.\n\n```\nlibrary(htmltools) # popup on Leaflet map\n```\n\nChange the description at line 122 to read \n\n```\n... for a Leaflet map that has the Space Needle, Savery Hall, and the Woodland Park Zoo.\n```\n\nand change the code chunk to add two additional points and text popups for the point markers. The chunk should contain the following code:\n\n```\n# the Space Needle\nsnxy <- data.frame(name = \"Space Needle\", x = -122.3493, y = 47.6205)\nspace_needle <- st_as_sf(snxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# Savery Hall\nshxy <- data.frame(name = \"Savery Hall\", x = -122.3083, y = 47.6572)\nsavery_hall <- st_as_sf(shxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# the Woodland Park Zoo\nzooxy <- data.frame(name = \"Woodland Park Zoo\", x = -122.3543, y = 47.6685)\nwp_zoo <- st_as_sf(zooxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# rbind() to put two points in one data frame\npts <- rbind(space_needle, savery_hall, wp_zoo)\n\n# a leaflet\nm <- leaflet() %>% \n    addTiles() %>% \n    addCircleMarkers(data = pts, label = ~htmlEscape(name))\nm\n```\n\nSave the edits to the file and then tap the \"knit\" button or enter at the console prompt `rmarkdown::render(\"week_01.Rmd\")` to generate the HTML file. You should see that now there are three point markers, and if you hover over any of the markers you will see the name popup.\n\n![](images/week05/2021-02-04_22_32_50.png)\n\n#### Git bash shell\n\nAnother interface you can use is the Git bash shell. To open the shell, click `Tools > Shell`. \n\n![](images/week05/2021-02-04_22_01_34.png) \n\nAll of the GUI commands we have used in RStudio are available in the shell. In fact, very little of the functionality of Git is available within RStudio. To take full advantage of Git, it is necessary to use the shell. There are a number of excellent tutorials on the use of the shell. For now because this is an introductory lesson, we will focus mainly on the RStudio interface,\n\nThe shell should be set to the project folder; if not you can enter e.g., `cd /H/git_r` (note that this corresponds to the Windows folder `H:\\git_r`).\n\nAt the prompt, enter `git status`. This will show the status of all files, in this case showing that `week_01.Rmd` has been modified, and that there are some files that are not being tracked.\n\n![](images/week05/2021-02-04_23_36_02.png)\n\n#### Ignoring specific files\nSometimes we are not interested in particular files being committed or pushed to the repository. For version control, we are interested in managing the code that is used to create outputs rather than the outputs themselves, with the idea being that if you have the code, you can recreate any outputs.\n\nSo there are files that can be ignored, which are specified in the `.gitignore` file. Open the file and add the line `*.html`. This tells Git not to bother managing HTML files (under the assumption that these are the output of rendering Rmd files).\n\n![](images/week05/2021-02-04_23_40_15.png)\n\nSave the `.gitignore` file and re-run `git status` at the shell (by tapping the up arrow key on your keyboard and tapping Enter). You should see that the HTML file does not show up in the list of changed or untracked files.\n\n![](images/week05/2021-02-04_23_42_51.png)\n\nAdd the line `*.Rproj` to the `.gitignore` file--this file should not be necessary in the repository.\n\nLikewise, if you refresh the Git tab in RStudio, the HTML file is no longer listed.\n\n![](images/week05/2021-02-04_23_43_13.png)\n\nWe will perform a few more tasks with the shell. Enter `add .gitignore` and `add week_01.Rmd`. This is the equivalent of clicking the `Staged` check box in RStudio.\n\n![](images/week05/2021-02-04_23_45_14.png)\n\nRefreshing the Git tab in RStudio will show that these two files are staged. This demonstrates that the RStudio Git environment is up to date with any changes made using the Git shell, and vice versa.\n\n![](images/week05/2021-02-04_23_45_37.png)\n\n\n#### Exploring file change history\nClick `Commit` to prepare to commit the changes (addition of `.gitignore` and the changes to `week_01.Rmd`).\n\nAs previously mentioned, deleted lines are shown in light red, added lines in light green, and unchanged lines with no highlighting. Click the entry for `week_01.Rmd` and the changes are apparent. Line numbers on the far left are the original line numbers. The next column to the right shows updated line numbers.\n\nThis allows you to compare the currently saved version against the previous version of the file.\n\n![](images/week05/2021-02-04_23_48_02.png)\n\nCommitting changes with the shell is done by entering \n\n`\ngit commit -m \"somecomment\"\n`\n\nThis has the same effect as clicking `Commit` in RStudio and entering the comment.\n\nNote that if we have not made some initial user configurations, Git will print some informative text about your identity. To avoid this and to tag future commits, use the `git config --global` commands, e.g., \n\n`\ngit config --global user.name \"My Full Name\"\ngit config --global user.email \"myemailaddress@mydomain\"\n`\n\n![](images/week05/2021-02-04_23_51_55.png)\n\nOnce the commit is performed, either with the RStudio GUI or with the shell, you can verify that no files are listed to be possibly staged.\n\n![](images/week05/2021-02-04_23_53_10.png)\n\nPerform another pull/push cycle and then refresh your web browser. Click on the commit comment.\n\n![](images/week05/2021-02-05_00_10_46.png)\n\nYou will see the changes to the two files in the last commit/push. The `.gitignore` file has all of its lines in green, indicating they are all new with respect to the repository. The file `week_01.Rmd` shows the same changes on Github as we saw in the local view before pushing the commit to the server.\n\n\n![](images/week05/2021-02-05_00_12_20.png)\n\n#### Restoring a previous version\nWhat good are all of these tracked changes if we cannot revert to a previous version of a file? Here we will make some intentional bad edits to a file, commit and push, but then retrieve a previous version of the file. Any version can be recovered. Note that this does not mean you can recover any and all edits to a file. It only means you can recover what changed between commits. For example, if I made a commit/push at noon, then made a lot of changes and saved the file multiple times before 5 PM and then made a commit/push, there would only be two versions of the file available in Git, the one committed at noon, and the one committed at 5 PM. For this reason it is worth making commit/push cycles every time you thing you might want to revert to a previous version.\n\nThe intentional bad change to `week_01.Rmd` is the complete removal of the code that produces the Leaflet map. See the following image.\n\n![](images/week05/2021-02-05_00_13_13.png)\n\nPerform the standard cycle: stage, commit (with a snarky comment), pull, and push.\n\n![](images/week05/2021-02-05_00_14_07.png)\n\n![](images/week05/2021-02-05_00_14_24.png)\n\n![](images/week05/2021-02-05_00_16_23.png)\n\n![](images/week05/2021-02-05_00_17_10.png)\n\nYou should see the large swath of deleted lines\n\n![](images/week05/2021-02-05_00_21_01.png)\n\n\n![](images/week05/2021-02-05_00_22_10.png)\n\nBack in the Github, find and click the file name.\n\n![](images/week05/2021-02-05_00_24_21.png)\n\nThe file contents will show the most recent saved version (missing the Leaflet map lines). Click on the `History` link, which will show all of the commits.\n\n![](images/week05/2021-02-05_00_25_05.png)\n\nClick the commit where you followed the questionable advice from your advisor.\n\n![](images/week05/2021-02-05_00_25_23.png)\n\nThe missing lines are evident. What we would like to do is to go back to the version before the large deletion of lines.\n\n![](images/week05/2021-02-05_00_25_40.png)\n\nIdentify the previous commit and click the clipboard icon to the left of the first characters of the commit hash. This will copy the hash, which is necessary for restoring that version.\n\n![](images/week05/2021-02-05_00_39_46.png)\n\nBack in the shell, enter\n\n```\ngit show *****\n```\n\nwhere ***** is the hash. This will display encoded instructions for changes made to the file. Now enter\n\n```\ngit show *****:week_01.Rmd\n```\n\nwhere `*****` is the hash.\n\n![](images/week05/2021-02-05_00_40_36.png)\n\nThis applies the changes to the file for the commit represented by the hash. You will see the text that was present at that commit, which includes the deleted Leaflet map.\n\n![](images/week05/2021-02-05_00_40_59.png)\n\nTo restore this previous version to a new file, enter\n\n```\ngit show *****:week_01.Rmd > week_01_someadditionaldescription.Rmd\n```\n\nThis prints the contents of the previously committed file and redirects the output to the named file after the `>` sign.\n\n![](images/week05/2021-02-05_00_45_16.png)\n\nIf you open that file, you will see the restored text.\n\n![](images/week05/2021-02-05_00_46_04.png)\n\n#### Conclusion\nThis was a brief introduction to the main functionality of Git with RStudio and Github. If you expect to perform even a modest amount of coding, you could benefit from Git as a way to keep track of your work, collaborate with others, and avoid programming disasters due to inadvertent deletion of overwriting of files.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week6.html","id":"week6","chapter":"6 Week 6","heading":"6 Week 6","text":"week covering two topics:Cohort Component Method Population Projection (CCMPP)Add Health Study data: exploring variables data documentationFirst, download template Rmd file save course working folder week_06.Rmd. Make changes title author see fit.","code":""},{"path":"week6.html","id":"ccmpp","chapter":"6 Week 6","heading":"6.0.1 Cohort Component Method of Population Projection (CCMPP)","text":"ccmpp package implements cohort component method population projection (CCMPP) described section. follow first half excellent CCMPP vignette package, gives worked example projection Thailand population 1960 2000 using baseline population year 1960.suggested can use ccmpp package check work CSDE 533.Let’s start loading package. Loading package also exposes thailand_data thailand_initial_estimates data set.Let’s look Thailand data. shows object list:Looking structure str(), see composed one element named population. data.table, enhanced data frame.population data.table 136 rows 5 columns.population five year age classes sex years spanning 1970 2000. Table 1 shows first rows.Table 1: CCMPP Thailand dataThere also object thailand_initial_estimates. list:… composed 5 elements. elements names?type objects ? can use lapply() ().shows us elements data.table. Let’s perusing structure using str():help entry thailand_initial_estimates states list initial estimates ccmpp() input.According vignette,“[thailand_initial_estimates] summary Thailand example inputs look like. baseline population year 1960 includes female male populations five year age groups 80+. four inputs define population changes every five calendar years 1960 2000. survivorship ratios go age 85+ asfr estimates defined reproductive age groups age 15 50.”example can look sex ratio birth (male / female) five-year interval (Table 2).Table 2: Thailand sex-ratio birth, 1960-2000For run CCMPP use suggested settings, comments line code. See documentation ccmpp() details.now run ccmpp() function generate population projectionIn order make graph roughly matching one vignette, add new column ageclass concatenating start end ages reordering factor based age_start column.Also can change maximum age class level “80 plus” without hard coding string “80.”Finally, make graph plotting population year, stratified sex age class.","code":"\nlibrary(demCore)\nis(demCore::thailand_data)## [1] \"list\"   \"vector\"\nstr(demCore::thailand_data)## List of 1\n##  $ population:Classes 'data.table' and 'data.frame': 136 obs. of  5 variables:\n##   ..$ year     : int [1:136] 1970 1970 1970 1970 1970 1970 1970 1970 1970 1970 ...\n##   ..$ sex      : chr [1:136] \"female\" \"female\" \"female\" \"female\" ...\n##   ..$ age_start: num [1:136] 0 5 10 15 20 25 30 35 40 45 ...\n##   ..$ age_end  : num [1:136] 5 10 15 20 25 30 35 40 45 50 ...\n##   ..$ value    : num [1:136] 3097000 2660000 2229000 1817000 1507000 ...\n##   ..- attr(*, \".internal.selfref\")=<externalptr>\ndim(demCore::thailand_data)## NULL\ndemCore::thailand_data$population %>%\n    head() %>%\n    kable() %>%\n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12,\n        full_width = F, position = \"left\"\n    )\nis(thailand_initial_estimates)## [1] \"list\"   \"vector\"\nnames(demCore::thailand_initial_estimates)## [1] \"srb\"           \"asfr\"          \"baseline\"      \"survival\"     \n## [5] \"net_migration\"\nlapply(demCore::thailand_initial_estimates, FUN = function(x) (is(x)))## $srb\n## [1] \"data.table\" \"data.frame\" \"list\"       \"oldClass\"   \"vector\"    \n## \n## $asfr\n## [1] \"data.table\" \"data.frame\" \"list\"       \"oldClass\"   \"vector\"    \n## \n## $baseline\n## [1] \"data.table\" \"data.frame\" \"list\"       \"oldClass\"   \"vector\"    \n## \n## $survival\n## [1] \"data.table\" \"data.frame\" \"list\"       \"oldClass\"   \"vector\"    \n## \n## $net_migration\n## [1] \"data.table\" \"data.frame\" \"list\"       \"oldClass\"   \"vector\"\nstr(demCore::thailand_initial_estimates)## List of 5\n##  $ srb          :Classes 'data.table' and 'data.frame':  8 obs. of  3 variables:\n##   ..$ year_start: num [1:8] 1960 1965 1970 1975 1980 ...\n##   ..$ year_end  : num [1:8] 1965 1970 1975 1980 1985 ...\n##   ..$ value     : num [1:8] 1.11 1.08 1.07 1.05 1.04 ...\n##   ..- attr(*, \".internal.selfref\")=<externalptr> \n##   ..- attr(*, \"sorted\")= chr [1:2] \"year_start\" \"year_end\"\n##  $ asfr         :Classes 'data.table' and 'data.frame':  56 obs. of  5 variables:\n##   ..$ year_start: num [1:56] 1960 1960 1960 1960 1960 ...\n##   ..$ year_end  : num [1:56] 1965 1965 1965 1965 1965 ...\n##   ..$ age_start : num [1:56] 15 20 25 30 35 40 45 15 20 25 ...\n##   ..$ age_end   : num [1:56] 20 25 30 35 40 45 50 20 25 30 ...\n##   ..$ value     : num [1:56] 0.0518 0.2402 0.2888 0.2721 0.2122 ...\n##   ..- attr(*, \".internal.selfref\")=<externalptr> \n##   ..- attr(*, \"sorted\")= chr [1:4] \"year_start\" \"year_end\" \"age_start\" \"age_end\"\n##  $ baseline     :Classes 'data.table' and 'data.frame':  34 obs. of  5 variables:\n##   ..$ year     : int [1:34] 1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n##   ..$ sex      : chr [1:34] \"female\" \"female\" \"female\" \"female\" ...\n##   ..$ age_start: num [1:34] 0 5 10 15 20 25 30 35 40 45 ...\n##   ..$ age_end  : num [1:34] 5 10 15 20 25 30 35 40 45 50 ...\n##   ..$ value    : num [1:34] 2338000 1857000 1543000 1287000 1250000 ...\n##   ..- attr(*, \".internal.selfref\")=<externalptr> \n##  $ survival     :Classes 'data.table' and 'data.frame':  288 obs. of  6 variables:\n##   ..$ year_start: num [1:288] 1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n##   ..$ year_end  : num [1:288] 1965 1965 1965 1965 1965 ...\n##   ..$ sex       : chr [1:288] \"female\" \"female\" \"female\" \"female\" ...\n##   ..$ age_start : num [1:288] 0 5 10 15 20 25 30 35 40 45 ...\n##   ..$ age_end   : num [1:288] 5 10 15 20 25 30 35 40 45 50 ...\n##   ..$ value     : num [1:288] 0.914 0.961 0.99 0.992 0.988 ...\n##   ..- attr(*, \".internal.selfref\")=<externalptr> \n##   ..- attr(*, \"sorted\")= chr [1:5] \"year_start\" \"year_end\" \"sex\" \"age_start\" ...\n##  $ net_migration:Classes 'data.table' and 'data.frame':  272 obs. of  6 variables:\n##   ..$ year_start: num [1:272] 1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n##   ..$ year_end  : num [1:272] 1965 1965 1965 1965 1965 ...\n##   ..$ sex       : chr [1:272] \"female\" \"female\" \"female\" \"female\" ...\n##   ..$ age_start : num [1:272] 0 5 10 15 20 25 30 35 40 45 ...\n##   ..$ age_end   : num [1:272] 5 10 15 20 25 30 35 40 45 50 ...\n##   ..$ value     : num [1:272] 0 0 0 0 0 0 0 0 0 0 ...\n##   ..- attr(*, \".internal.selfref\")=<externalptr> \n##   ..- attr(*, \"sorted\")= chr [1:5] \"year_start\" \"year_end\" \"sex\" \"age_start\" ...\ndemCore::thailand_initial_estimates$srb %>% \n    kable() %>% \n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12,\n        full_width = F, position = \"left\"\n    )    \n# the settings for this run of ccmpp\nthailand_settings <- list(\n    # start of each calendar year, i.e., year_start\n    years = seq(1960, 1995, 5),\n    # use both sexes\n    sexes = c(\"female\", \"male\"),\n    # ages being projected\n    ages = seq(0, 80, 5),\n    # ages for which mortality parameter estimates are available\n    ages_mortality = seq(0, 85, 5),\n    # assumed female fertility ages\n    ages_asfr = seq(15, 45, 5)\n)\nthailand_population <- ccmpp(\n  inputs = demCore::thailand_initial_estimates,\n  settings = thailand_settings\n)\nthailand_population %<>%\n    mutate(ageclass = factor(str_c(age_start, age_end, sep = \" to \") %>%\n        fct_reorder(., age_start)))\n# max label\nmaxlev <- length(levels(thailand_population$ageclass))\n\n# current max level\ncurrmaxlev <- levels(thailand_population$ageclass)[maxlev]\n\n# substitute\nupdatemaxlev <- currmaxlev %>% \n    str_replace(pattern = \"to Inf\",\n                replacement = \"plus\")\n\n# update\nlevels(thailand_population$ageclass)[maxlev] <- updatemaxlev\nggplot(data = thailand_population,\n       mapping = aes(x = year, y = value)) +\n    geom_line() +\n    # this stratifies the graph by sex and age class\n    facet_grid(ageclass ~ sex, scales = \"free_y\", \n               labeller = labeller(age = thailand_population$age_class)) +\n    # do not use a constant Y scale otherwise the older age classes would look flat.\n    # and show the Y axis values with commas\n    scale_y_continuous(labels = label_number(big.mark = \",\")) +\n    # change the axis labels\n    xlab(\"Year\") +\n    ylab(\"Population\")"},{"path":"week6.html","id":"addhealthmetadata","chapter":"6 Week 6","heading":"6.0.2 The Add Health study data","text":"Add Health web site describes study:Initiated 1994 supported five program project grants Eunice Kennedy Shriver National Institute Child Health Human Development (NICHD) co-funding 23 federal agencies foundations, Add Health largest, comprehensive, nationally-representative longitudinal survey adolescents ever undertaken. Beginning -school questionnaire administered nationally representative sample students grades 7-12, study followed series -home interviews conducted 1995, 1996, 2001-02, 2008, 2016-18. Add Health participants now full-fledged adults, aged 33-44, soon moving midlife. years, Add Health added substantial amount additional data users, including contextual data communities states participants reside, genomic data range biological health markers participants, parental survey data.public-use data contain subset records variables restricted-use full data set. full data set requires lengthy application process meeting specific security standards. CSDE copy tables restricted-use data set UW Data Collaborative.using Wave 1 public-use Add Health data remainder term. week briefly delve documentation see data set use supported documentation.Add Health data well documented. PDFs contain verbatim text survey questions, range encoded answers, count tabulations responses.revisit documentation later lesson.","code":""},{"path":"week6.html","id":"data-sets","chapter":"6 Week 6","heading":"6.0.2.1 Data sets","text":"two data sets using AHwave1_v1.dta.zip 21600-0001-Data.dta.zip. already folder data working directory, create first, download file folder.Note code examples run without modification, assumption data downloaded unzipped sub-folder named data within current working directory. can find current working directory entering getwd() R prompt.Stata files. Stata files version 12 can read foreign::read.dta(), version 13 require haven::read_dta() readstata13::read.dta13().One benefits Stata file formats, compared e.g., CSV Excel, Stata files can contain metadata variables. imported data frames often cryptically coded variable names, extensive labels. labels generally contain descriptions variables. R import process can expose labels, making data easy interpret.","code":""},{"path":"week6.html","id":"ahwave1_v1.dta","chapter":"6 Week 6","heading":"6.0.2.1.1 AHwave1_v1.dta","text":"AHwave1_v1.dta Stata version 13 file. look two import options.","code":""},{},{},{"path":"week6.html","id":"data.dta","chapter":"6 Week 6","heading":"6.0.2.1.2 21600-0001-Data.dta","text":"21600-0001-Data.dta much larger data set. count records, columns AHwave1_v1.dta.fact, AHwave1_v1.dta seems subset 21600-0001-Data.dta. can show lower-casing column names using select() named columns. identical() function can used determine contents two objects exactly .can build similar table metadata, time function:","code":"\n# unzip and read in the larger data set\nif(file.exists(\"data/21600-0001-Data.dta.zip\") & !file.exists(\"data/21600-0001-Data.dta\")){\n    unzip(zipfile = \"data/21600-0001-Data.dta.zip\", exdir = \"data\")\n}\n\n# because this is a big file we might want to check if it has been read\nif(!exists(\"data_21600_0001\")){\n    data_21600_0001 <- haven::read_dta(file = \"data/21600-0001-Data.dta\")\n}\n\n# dimensions of the two\ndim(AHwave1_v1_haven)## [1] 6504  103\ndim(data_21600_0001)## [1] 6504 2794\n# lowercase the column names\ncolnames(data_21600_0001) %<>% str_to_lower()\n\n# select() some columns of the same name\ndat <- data_21600_0001 %>% \n    select(colnames(AHwave1_v1_haven))\n\n# identical?\nidentical(dat, AHwave1_v1_haven)## [1] TRUE\n# if(file.exists(\"data/AHwave1_v1.dta\")){\n#     file.remove(\"data/AHwave1_v1.dta\")\n# }\n# a generic(?) function to generate metadata for a Stata file read by haven::read_dta()\n# x is a data frame from haven::read_dta\nf_haven_stata_metadata <- function(x){\n    # variable names\n    varname <- colnames(x)\n    # labels\n    varlabel <- x %>% \n        lapply(., function(x) attributes(x)$label) %>% \n        unlist()\n    # format\n    varformat <- x %>% \n        lapply(., function(x) attributes(x)$format.stata) %>%\n        unlist()\n    # values\n    varvalues <- x %>% \n        lapply(., function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")  \n    \n    bind_cols(varname = varname, \n              varlabel = varlabel, \n              varformat = varformat,\n              varvalues = varvalues)\n}\n\n# generate the metadata\ndata_21600_0001_metadata <- f_haven_stata_metadata(data_21600_0001)\n\n# print the metadata table as a DT::datatable\nDT::datatable(data_21600_0001_metadata)"},{"path":"week6.html","id":"searching-through-documentation","chapter":"6 Week 6","heading":"6.0.2.2 Searching through documentation","text":"Good data sets good documentation. Sometimes documentation voluminous, case Add Health data. voluminous metadata, good approaches finding interested without opening PDF file, reading table contents, searching string matches, etc.?section cover two tools make searching PDF files less onerous efficient. two utilities pdfgrep pdftools::pdf_text()","code":""},{"path":"week6.html","id":"pdfgrep","chapter":"6 Week 6","heading":"6.0.2.2.1 pdfgrep","text":"grep string-matching utility developed mainly UNIX, now available common operating systems. also implemented base R function grep(). name comes ed text editor command g/re/p (\\(\\underline{g}\\)lobally search \\(\\underline{r}\\)egular \\(\\underline{e}\\)xpression \\(\\underline{p}\\)rint matching lines), typically used print line number text file containing search pattern.familiar regular expressions plan computational social sciences, sooner learn, better. See R help topic base::regex().won’t covering grep general regular expressions detail, introduce regular expression logic pdfgrep.Start installing version pdfgrep. three implementations, one Mac two Windows. demo today use Cygwin version. native Windows version powerful/customizable Cygwin version also likely comparable Mac version. Note: pdfgrep work PDF files contain text. PDFs composed solely scanned images contain text therefore searchable using regular expressions.pdfgrep native Windowspdfgrep Cygwin Windows; Cygwin highly recommended Windows users–creates UNIX-like environment offers many data processing tools.pdfgrep MacIf Terminal Server 4 5 let’s try using Cygwin. Download cygwin64.zip unzip root level H: drive. see something like :\nDouble-click shortcut mintty.exe open Cygwin terminal. see security warning, click Run.zipped file containing metadata files public use Add Health data available add_health_wave1_metadata.zip. Download file unzip appropriate location.","code":""},{},{"path":"week6.html","id":"pdftoolspdf_text","chapter":"6 Week 6","heading":"6.0.2.2.2 pdftools::pdf_text()","text":"Staying completely within R, can perform similar searches PDF files. start pdftools::pdf_text(), converts PDFs text vectors, page converted one vector element. can piped text-matching functions, base::grep() stringr::str_match() (stringr loaded tidyverse).Unlike pdfgrep, can serially search set files directory, pdf_text() requires additional work function processes one file. example mimics searching case-insensitive regular expression black set PDFs.create function searches single PDF loop function set PDFs specified folder, returning file name list, pattern searched , page number match, whether search case sensitive .","code":"\n# a function to get matching strings in a PDF, ignore case\nf_pdf_str_match <- function(x, pat, ignore.case = TRUE){\n    # convert the PDF to text\n    mytext <- pdf_text(x)\n    # pattern\n    if(ignore.case){\n        mypat <- regex(pat, ignore_case = TRUE)\n    } else {\n        mypat <- pat\n    }\n    # match strings = pages\n    pages <- str_which(string = mytext, pattern = mypat)\n    if(length(pages) == 0){\n        return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case))\n    }\n    # create a data frame\n    data.frame(fname = x, pat, page_num = pages, ignore.case)\n}\n\n# a list of my PDFs\nmypdfs <- list.files(path = \"data/metadata/Wave1_InHome_Codebooks\", \n                     pattern = \"*.pdf$\", \n                     ignore.case = TRUE,\n                     full.names = TRUE)\n\n# an empty data frame\nx <- NULL\n\n# run each one\nfor(i in mypdfs){\n    x <- rbind(x, f_pdf_str_match(i, \"black\", ignore.case = TRUE))\n}\n\n# ignore NAs\nx %>% filter(!is.na(page_num))##                                                fname   pat page_num ignore.case\n## 1  data/metadata/Wave1_InHome_Codebooks/INH01PUB.PDF black        7        TRUE\n## 2  data/metadata/Wave1_InHome_Codebooks/INH01PUB.PDF black        9        TRUE\n## 3  data/metadata/Wave1_InHome_Codebooks/INH25PUB.PDF black       13        TRUE\n## 4  data/metadata/Wave1_InHome_Codebooks/INH25PUB.PDF black       56        TRUE\n## 5  data/metadata/Wave1_InHome_Codebooks/INH25PUB.PDF black       96        TRUE\n## 6  data/metadata/Wave1_InHome_Codebooks/INH26PUB.PDF black       13        TRUE\n## 7  data/metadata/Wave1_InHome_Codebooks/INH26PUB.PDF black       43        TRUE\n## 8  data/metadata/Wave1_InHome_Codebooks/INH26PUB.PDF black       69        TRUE\n## 9  data/metadata/Wave1_InHome_Codebooks/INH26PUB.PDF black       98        TRUE\n## 10 data/metadata/Wave1_InHome_Codebooks/INH26PUB.PDF black      120        TRUE\n## 11 data/metadata/Wave1_InHome_Codebooks/INH26PUB.PDF black      143        TRUE\n## 12 data/metadata/Wave1_InHome_Codebooks/SECTAPUB.PDF black        3        TRUE\n## 13 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black        2        TRUE\n## 14 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       28        TRUE\n## 15 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       31        TRUE\n## 16 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       33        TRUE\n## 17 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       37        TRUE\n## 18 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       39        TRUE\n## 19 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       41        TRUE\n## 20 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       43        TRUE\n## 21 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       46        TRUE\n## 22 data/metadata/Wave1_InHome_Codebooks/W1NDXPUB.PDF black       48        TRUE"},{"path":"week6.html","id":"conclusion-1","chapter":"6 Week 6","heading":"6.0.3 Conclusion","text":"use data sets metadata next several lessons. methods presented today’s lesson increase efficiency reduce busy-work.Rendered 2022-03-04 00:44:27","code":""},{"path":"week6.html","id":"source-code-6","chapter":"6 Week 6","heading":"6.1 Source code","text":"File H:/csde502-winter-2022-main/06-week06.Rmd.","code":""},{"path":"week6.html","id":"r-code-used-in-this-document-6","chapter":"6 Week 6","heading":"6.1.1 R code used in this document","text":"","code":"\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    readstata13,\n    haven,\n    pdftools,\n    captioner,\n    dplyr, \n    magrittr,\n    scales\n)\n\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\nlibrary(demCore)\nis(demCore::thailand_data)\nstr(demCore::thailand_data)\ndim(demCore::thailand_data)\ndemCore::thailand_data$population %>%\n    head() %>%\n    kable() %>%\n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12,\n        full_width = F, position = \"left\"\n    )\n    \nis(thailand_initial_estimates)\nnames(demCore::thailand_initial_estimates)\nlapply(demCore::thailand_initial_estimates, FUN = function(x) (is(x)))\nstr(demCore::thailand_initial_estimates)\ndemCore::thailand_initial_estimates$srb %>% \n    kable() %>% \n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12,\n        full_width = F, position = \"left\"\n    )    \n# the settings for this run of ccmpp\nthailand_settings <- list(\n    # start of each calendar year, i.e., year_start\n    years = seq(1960, 1995, 5),\n    # use both sexes\n    sexes = c(\"female\", \"male\"),\n    # ages being projected\n    ages = seq(0, 80, 5),\n    # ages for which mortality parameter estimates are available\n    ages_mortality = seq(0, 85, 5),\n    # assumed female fertility ages\n    ages_asfr = seq(15, 45, 5)\n)\nthailand_population <- ccmpp(\n  inputs = demCore::thailand_initial_estimates,\n  settings = thailand_settings\n)\nthailand_population %<>%\n    mutate(ageclass = factor(str_c(age_start, age_end, sep = \" to \") %>%\n        fct_reorder(., age_start)))\n# max label\nmaxlev <- length(levels(thailand_population$ageclass))\n\n# current max level\ncurrmaxlev <- levels(thailand_population$ageclass)[maxlev]\n\n# substitute\nupdatemaxlev <- currmaxlev %>% \n    str_replace(pattern = \"to Inf\",\n                replacement = \"plus\")\n\n# update\nlevels(thailand_population$ageclass)[maxlev] <- updatemaxlev\nggplot(data = thailand_population,\n       mapping = aes(x = year, y = value)) +\n    geom_line() +\n    # this stratifies the graph by sex and age class\n    facet_grid(ageclass ~ sex, scales = \"free_y\", \n               labeller = labeller(age = thailand_population$age_class)) +\n    # do not use a constant Y scale otherwise the older age classes would look flat.\n    # and show the Y axis values with commas\n    scale_y_continuous(labels = label_number(big.mark = \",\")) +\n    # change the axis labels\n    xlab(\"Year\") +\n    ylab(\"Population\")\n# unzip the file\nif(file.exists(\"data/AHwave1_v1.dta.zip\") & !file.exists(\"data/AHwave1_v1.dta\")){\n    unzip(zipfile = \"data/AHwave1_v1.dta.zip\", exdir = \"data\")\n}\n\n# read the data\nAHwave1_v1_haven <- haven::read_dta(file = \"data/AHwave1_v1.dta\")\nstr(AHwave1_v1_haven$imonth)\nhead(AHwave1_v1_haven$bio_sex)\nattributes(AHwave1_v1_haven$h1gi1m)\nAHwave1_v1_haven_metadata <- bind_cols(\n    # variable name\n    varname = colnames(AHwave1_v1_haven),\n    # label\n    varlabel = lapply(AHwave1_v1_haven, function(x) attributes(x)$label) %>% \n        unlist(),\n    # format\n    varformat = lapply(AHwave1_v1_haven, function(x) attributes(x)$format.stata) %>%\n        unlist(),\n    # values\n    varvalues = lapply(AHwave1_v1_haven, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(AHwave1_v1_haven_metadata)\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\")\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\", generate.factors = TRUE, nonint.factors = TRUE)\nAHwave1_v1_rs13_metadata <- bind_cols(\n    varname = colnames(AHwave1_v1_rs13),\n    varlabel = attributes(AHwave1_v1_rs13)$var.labels,\n    varformat = attributes(AHwave1_v1_rs13)$formats\n)\n\n# value ranges; need to do this separately because those variables with no value labels were not accounted for\nvarvalues <- bind_cols(\n    varname = names(attributes(AHwave1_v1_rs13)$label.table) %>% tolower,\n    vals = attributes(AHwave1_v1_rs13)$label.table %>% \n    lapply(., function(x) names(x)) %>% \n    as.character() %>% \n    str_remove_all(\"^c\\\\(|\\\\)$\"))\n\n# join\nAHwave1_v1_rs13_metadata %<>% \n    left_join(varvalues, by = \"varname\")\n\nDT::datatable(AHwave1_v1_rs13_metadata)\nhead(x = AHwave1_v1_rs13$imonth, n = 6)\nAHwave1_v1_rs13 %>% \n    head(10) %>% \n    filter(imonth == \"(6) June\") %>% \n    select(aid, imonth, iday)\nlevels(AHwave1_v1_rs13$imonth) %>% t() %>% t()\nhead(AHwave1_v1_haven$imonth)\nAHwave1_v1_haven %>% \n    head(10) %>% \n    filter(imonth == 6) %>% \n    select(aid, imonth, iday)\n# unzip and read in the larger data set\nif(file.exists(\"data/21600-0001-Data.dta.zip\") & !file.exists(\"data/21600-0001-Data.dta\")){\n    unzip(zipfile = \"data/21600-0001-Data.dta.zip\", exdir = \"data\")\n}\n\n# because this is a big file we might want to check if it has been read\nif(!exists(\"data_21600_0001\")){\n    data_21600_0001 <- haven::read_dta(file = \"data/21600-0001-Data.dta\")\n}\n\n# dimensions of the two\ndim(AHwave1_v1_haven)\ndim(data_21600_0001)\n# lowercase the column names\ncolnames(data_21600_0001) %<>% str_to_lower()\n\n# select() some columns of the same name\ndat <- data_21600_0001 %>% \n    select(colnames(AHwave1_v1_haven))\n\n# identical?\nidentical(dat, AHwave1_v1_haven)\n# if(file.exists(\"data/AHwave1_v1.dta\")){\n#     file.remove(\"data/AHwave1_v1.dta\")\n# }\n# a generic(?) function to generate metadata for a Stata file read by haven::read_dta()\n# x is a data frame from haven::read_dta\nf_haven_stata_metadata <- function(x){\n    # variable names\n    varname <- colnames(x)\n    # labels\n    varlabel <- x %>% \n        lapply(., function(x) attributes(x)$label) %>% \n        unlist()\n    # format\n    varformat <- x %>% \n        lapply(., function(x) attributes(x)$format.stata) %>%\n        unlist()\n    # values\n    varvalues <- x %>% \n        lapply(., function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")  \n    \n    bind_cols(varname = varname, \n              varlabel = varlabel, \n              varformat = varformat,\n              varvalues = varvalues)\n}\n\n# generate the metadata\ndata_21600_0001_metadata <- f_haven_stata_metadata(data_21600_0001)\n\n# print the metadata table as a DT::datatable\nDT::datatable(data_21600_0001_metadata)\n\n# a function to get matching strings in a PDF, ignore case\nf_pdf_str_match <- function(x, pat, ignore.case = TRUE){\n    # convert the PDF to text\n    mytext <- pdf_text(x)\n    # pattern\n    if(ignore.case){\n        mypat <- regex(pat, ignore_case = TRUE)\n    } else {\n        mypat <- pat\n    }\n    # match strings = pages\n    pages <- str_which(string = mytext, pattern = mypat)\n    if(length(pages) == 0){\n        return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case))\n    }\n    # create a data frame\n    data.frame(fname = x, pat, page_num = pages, ignore.case)\n}\n\n# a list of my PDFs\nmypdfs <- list.files(path = \"data/metadata/Wave1_InHome_Codebooks\", \n                     pattern = \"*.pdf$\", \n                     ignore.case = TRUE,\n                     full.names = TRUE)\n\n# an empty data frame\nx <- NULL\n\n# run each one\nfor(i in mypdfs){\n    x <- rbind(x, f_pdf_str_match(i, \"black\", ignore.case = TRUE))\n}\n\n# ignore NAs\nx %>% filter(!is.na(page_num))\n\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week6.html","id":"complete-rmd-code-6","chapter":"6 Week 6","heading":"6.1.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 6 {#week6}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    readstata13,\n    haven,\n    pdftools,\n    captioner,\n    dplyr, \n    magrittr,\n    scales\n)\n\nfigure_nums <- captioner(prefix = \"Figure\")\ntable_nums <- captioner(prefix = \"Table\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n<h2>Topics: Cohort Component Method of Population Projection; Add Health Study data (exploring variables and data documentation)<\/h2>\n\nThis week we will be covering two topics:\n\n* [Cohort Component Method of Population Projection (CCMPP)](#ccmpp)\n* [Add Health Study data: exploring variables and data documentation](#addhealthmetadata)\n\nFirst, download the [template Rmd file](files/template.Rmd) and save it in your course working folder as `week_06.Rmd`. Make changes to the title and author as you see fit.\n\n\n### Cohort Component Method of Population Projection (CCMPP) {#ccmpp}\nThe `ccmpp` package implements the cohort component method of population projection (CCMPP) described in this section. We will follow the first half of the excellent [CCMPP vignette](https://ihmeuw-demographics.github.io/demCore/articles/ccmpp.html) for this package, which gives a worked example of projection Thailand population from 1960 through 2000 using a baseline population for the year 1960.\n\nIt has been suggested that you can use the `ccmpp` package to check your work in CSDE 533.\n\nLet's start by loading the package. Loading the package also exposes the `thailand_data` and `thailand_initial_estimates` data set.\n\n```{r, message=FALSE, warning=FALSE}\nlibrary(demCore)\n```\n\nLet's look at the Thailand data. This shows the object is a list:\n\n```{r}\nis(demCore::thailand_data)\n```\n\nLooking at the structure with `str()`, we see it is composed of only one element named `population`. This is a [`data.table`](https://cran.r-project.org/web/packages/data.table/), which is an enhanced data frame. \n\n```{r}\nstr(demCore::thailand_data)\n```\n\nThe `population` `data.table` has `r nrow(demCore::thailand_data$population)` rows and `r ncol(demCore::thailand_data$population)` columns. \n\n```{r}\ndim(demCore::thailand_data)\n```\n\nThis is the population of five year age classes by sex for years spanning `r min(thailand_data$population$year)` to `r max(thailand_data$population$year)`. `r table_nums(name = \"tldata\", display = \"cite\")` shows the first few rows.\n\n*`r table_nums(name = \"tldata\", caption = \"CCMPP Thailand data\")`*\n\n```{r}\ndemCore::thailand_data$population %>%\n    head() %>%\n    kable() %>%\n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12,\n        full_width = F, position = \"left\"\n    )\n    \n```\n\nThere is also an object `thailand_initial_estimates`. It is a list:\n\n```{r}\nis(thailand_initial_estimates)\n```\n\n... that is composed of `r length(thailand_initial_estimates)` elements. Do the elements have names?\n\n```{r}\nnames(demCore::thailand_initial_estimates)\n```\n\nWhat type of objects are they? We can use `lapply()` and `is()`.\n\n```{r}\nlapply(demCore::thailand_initial_estimates, FUN = function(x) (is(x)))\n```\n\nThis shows us each of the elements is a `data.table`. Let's perusing the structure using `str()`:\n\n```{r}\nstr(demCore::thailand_initial_estimates)\n```\n\nThe help entry for `thailand_initial_estimates` states that it is a list of initial estimates for each `ccmpp()` input. \n\nAccording to the vignette,\n\n> \"[thailand_initial_estimates] is a summary of what the Thailand example inputs look like. The baseline population is for the year 1960 and includes both female and male populations for five year age groups up to 80+. The other four inputs define how the population changes every five calendar years between 1960 and 2000. The survivorship ratios go up to age 85+ while the asfr estimates are defined for the reproductive age groups between age 15 and 50.\"\n\nFor example we can look at the sex ratio at birth (male / female) for each five-year interval (`r table_nums(name = \"tldatasrb\", display = \"cite\")`).\n\n*`r table_nums(name = \"tldatasrb\", caption = \"Thailand sex-ratio at birth, 1960-2000\")`*\n\n```{r}\ndemCore::thailand_initial_estimates$srb %>% \n    kable() %>% \n    kable_styling(\n        bootstrap_options =\n            c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        font_size = 12,\n        full_width = F, position = \"left\"\n    )    \n```\n\nFor this run of CCMPP we will use the suggested settings, with comments in line with the code. See the documentation for `ccmpp()` for details.\n\n```{r, fig.width=3, fig.height=15}\n# the settings for this run of ccmpp\nthailand_settings <- list(\n    # start of each calendar year, i.e., year_start\n    years = seq(1960, 1995, 5),\n    # use both sexes\n    sexes = c(\"female\", \"male\"),\n    # ages being projected\n    ages = seq(0, 80, 5),\n    # ages for which mortality parameter estimates are available\n    ages_mortality = seq(0, 85, 5),\n    # assumed female fertility ages\n    ages_asfr = seq(15, 45, 5)\n)\n```\n\nWe now run the `ccmpp()` function to generate a population projection\n\n```{r, fig.width=3, fig.height=15}\nthailand_population <- ccmpp(\n  inputs = demCore::thailand_initial_estimates,\n  settings = thailand_settings\n)\n```\n\nIn order to make a graph roughly matching the one in the vignette, we add a new column `ageclass` by concatenating the start and end ages and reordering the factor based on the `age_start` column.\n\n```{r, fig.width=3, fig.height=15}\nthailand_population %<>%\n    mutate(ageclass = factor(str_c(age_start, age_end, sep = \" to \") %>%\n        fct_reorder(., age_start)))\n```\n\nAlso we can change the maximum age class level to \"80 plus\" without hard coding in the string \"80\".\n\n```{r, fig.width=4, fig.height=15}\n# max label\nmaxlev <- length(levels(thailand_population$ageclass))\n\n# current max level\ncurrmaxlev <- levels(thailand_population$ageclass)[maxlev]\n\n# substitute\nupdatemaxlev <- currmaxlev %>% \n    str_replace(pattern = \"to Inf\",\n                replacement = \"plus\")\n\n# update\nlevels(thailand_population$ageclass)[maxlev] <- updatemaxlev\n```\n\nFinally, make a graph plotting population against year, stratified by sex and age class.\n\n```{r, fig.width=5, fig.height=15}\nggplot(data = thailand_population,\n       mapping = aes(x = year, y = value)) +\n    geom_line() +\n    # this stratifies the graph by sex and age class\n    facet_grid(ageclass ~ sex, scales = \"free_y\", \n               labeller = labeller(age = thailand_population$age_class)) +\n    # do not use a constant Y scale otherwise the older age classes would look flat.\n    # and show the Y axis values with commas\n    scale_y_continuous(labels = label_number(big.mark = \",\")) +\n    # change the axis labels\n    xlab(\"Year\") +\n    ylab(\"Population\")\n```\n\n\n### The Add Health study data {#addhealthmetadata}\nThe Add Health [web site](https://data.cpc.unc.edu/projects/2/view) describes the study:\n\n> Initiated in 1994 and supported by five program project grants from the Eunice Kennedy Shriver National Institute of Child Health and Human Development (NICHD) with co-funding from 23 other federal agencies and foundations, Add Health is the largest, most comprehensive, nationally-representative longitudinal survey of adolescents ever undertaken. Beginning with an in-school questionnaire administered to a nationally representative sample of students in grades 7-12, the study followed up with a series of in-home interviews conducted in 1995, 1996, 2001-02, 2008, and 2016-18. Add Health participants are now full-fledged adults, aged 33-44, and will soon be moving into midlife. Over the years, Add Health has added a substantial amount of additional data for users, including contextual data on the communities and states in which participants reside, genomic data and a range of biological health markers of participants, and parental survey data.\n\nThe public-use data contain a subset of records and variables from the restricted-use full data set. The full data set requires a lengthy application process and meeting specific security standards. [CSDE](https://csde.washington.edu/) has a copy of most of the tables in the restricted-use data set on the [UW Data Collaborative](https://dcollab.uw.edu/data/add-health/).\n\nWe will be using the Wave 1 public-use Add Health data for most of the remainder of the term. This week we will briefly delve into the documentation and see how the data set use is supported by the documentation.\n\nThe Add Health data are very well documented. The PDFs contain the verbatim text of the survey questions, the range of encoded answers, and count tabulations of responses.\n\nWe will revisit the documentation later in this lesson.\n\n#### Data sets\nThe two data sets we will be using are [AHwave1_v1.dta.zip](data/AHwave1_v1.dta.zip) and [21600-0001-Data.dta.zip](data/21600-0001-Data.dta.zip). If you do not already have a folder `data` in your working directory, create it first, then download each file to that folder.\n\n:::{.rmdnote}\nNote for the code examples to run without modification, the assumption is that the data have been downloaded and unzipped in a sub-folder named `data` within the current working directory. You can find out what the current working directory is by entering `getwd()` at the R prompt.\n:::\n\nBoth of these are Stata files. Stata files version 12 and below can be read with `foreign::read.dta()`, but version 13 and up require `haven::read_dta()` or `readstata13::read.dta13()`.\n\nOne of the benefits of the Stata file formats, as compared to e.g., CSV or Excel, is that the Stata files can contain metadata about the variables. The imported data frames themselves often have cryptically coded variable names, but more extensive ***labels***. The labels generally contain descriptions of the variables. The R import process can expose those labels, making the data more easy to interpret.\n\n##### `AHwave1_v1.dta`\n`AHwave1_v1.dta` is a Stata version 13 file. Here we will look at the two import options.\n\n###### `haven::read_dta()`\n`haven::read_dta()` will read the data in as a data frame. The following code will unzip an existing `data/AHwave1_v1.dta.zip` file and then read the unzipped file.\n\n```{r}\n# unzip the file\nif(file.exists(\"data/AHwave1_v1.dta.zip\") & !file.exists(\"data/AHwave1_v1.dta\")){\n    unzip(zipfile = \"data/AHwave1_v1.dta.zip\", exdir = \"data\")\n}\n\n# read the data\nAHwave1_v1_haven <- haven::read_dta(file = \"data/AHwave1_v1.dta\")\n```\n\nEach labeled variable has attributes can be perused by listing structure. Here we look at the `imonth` variable:\n\n```{r}\nstr(AHwave1_v1_haven$imonth)\n```\n\nAnother way to peruse a variable is to view the first few values (e.g., `head()`), here for the `bio_sex` variable:\n\n```{r}\nhead(AHwave1_v1_haven$bio_sex)\n```\n\nOne can also list the attributes of the variable itself, which provides a more complete and verbose listing of the variable label, data format, class, and value labels. Here for the variable `h1gi1m`:\n\n```{r}\nattributes(AHwave1_v1_haven$h1gi1m)\n```\n\nWe can see that the variable has attributes `label` (a more verbose label for the variable itself), `format.stata` (data format for the column), `class` (showing the column is a `haven_labelled` `vector` stored in `double precision` format), and `labels` showing the translation of variable values and more descriptive labels.\n\nIn order to access the metadata as a single object, one can use the `lapply()` function, because the data frame can also be treated as a list. Here, each variable has its name, label, data format, and labels extracted to a single data frame and presented as a `DT::datatable`. This provides the metadata in a format that is probably easier to use than the PDF documentation. \n\n```{r}\nAHwave1_v1_haven_metadata <- bind_cols(\n    # variable name\n    varname = colnames(AHwave1_v1_haven),\n    # label\n    varlabel = lapply(AHwave1_v1_haven, function(x) attributes(x)$label) %>% \n        unlist(),\n    # format\n    varformat = lapply(AHwave1_v1_haven, function(x) attributes(x)$format.stata) %>%\n        unlist(),\n    # values\n    varvalues = lapply(AHwave1_v1_haven, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(AHwave1_v1_haven_metadata)\n```\n\nCan you think about writing a generic function for pulling metadata from `dta` files using `haven::read_dta`?\n\n###### `readstata13::read.dta13()`\n`readstata13::read.dta13()` will similarly read the data as a data frame. There are a number of different options for converting factors, so if you are dealing with a lot of Stata files you may want to become familiar with some of these options.\n\nFor example, using all default options kicks out some warnings about double precision coding and missing factor labels. _[Note: to hide these warnings, for better or worse (i.e., you might not want to hide them), use the code chunk option `warning=FALSE`]._\n\n```{r}\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\")\n```\n\n```{r}\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\", generate.factors = TRUE, nonint.factors = TRUE)\n```\n\nMetadata can be generated similarly by binding columns representing variable names, labels, and formats:\n\n```{r}\nAHwave1_v1_rs13_metadata <- bind_cols(\n    varname = colnames(AHwave1_v1_rs13),\n    varlabel = attributes(AHwave1_v1_rs13)$var.labels,\n    varformat = attributes(AHwave1_v1_rs13)$formats\n)\n\n# value ranges; need to do this separately because those variables with no value labels were not accounted for\nvarvalues <- bind_cols(\n    varname = names(attributes(AHwave1_v1_rs13)$label.table) %>% tolower,\n    vals = attributes(AHwave1_v1_rs13)$label.table %>% \n    lapply(., function(x) names(x)) %>% \n    as.character() %>% \n    str_remove_all(\"^c\\\\(|\\\\)$\"))\n\n# join\nAHwave1_v1_rs13_metadata %<>% \n    left_join(varvalues, by = \"varname\")\n\nDT::datatable(AHwave1_v1_rs13_metadata)\n```\n\nThe default conversion creates factors, so the tables _may_ be easy to read/interpret ...\n\n```{r}\nhead(x = AHwave1_v1_rs13$imonth, n = 6)\n```\n\n... but programming with this data frame will require more work because the factors would  need to be explicitly named, e.g. in the `filter()`,\n\n```{r}\nAHwave1_v1_rs13 %>% \n    head(10) %>% \n    filter(imonth == \"(6) June\") %>% \n    select(aid, imonth, iday)\n```\n\nBecause the factors are really just labelled numbers, one could use the numeric values, but care needs to be taken:\n\n```{r}\nlevels(AHwave1_v1_rs13$imonth) %>% t() %>% t()\n```\n\nBecause not all months are represented in the data, the numerical value of the month may not be what you expect. For example, the 4th month factor level/label is \"(6) June\" rather than \"(4) April\".\n\nCompare this with the results from `haven::read_dta()`. The values are not factors, but labelled double-precision numbers where the integer value is the month:\n\n```{r}\nhead(AHwave1_v1_haven$imonth)\n```\n\nTo perform a similar `filter()` & `select()` operation with the `haven` version is much more straightforward:\n\n```{r}\nAHwave1_v1_haven %>% \n    head(10) %>% \n    filter(imonth == 6) %>% \n    select(aid, imonth, iday)\n```\n\n**Which approach do you prefer?**\n\n##### `21600-0001-Data.dta`\n`21600-0001-Data.dta` is a much larger data set. It has the same count of records, but more columns than `AHwave1_v1.dta`.\n\n```{r}\n# unzip and read in the larger data set\nif(file.exists(\"data/21600-0001-Data.dta.zip\") & !file.exists(\"data/21600-0001-Data.dta\")){\n    unzip(zipfile = \"data/21600-0001-Data.dta.zip\", exdir = \"data\")\n}\n\n# because this is a big file we might want to check if it has been read\nif(!exists(\"data_21600_0001\")){\n    data_21600_0001 <- haven::read_dta(file = \"data/21600-0001-Data.dta\")\n}\n\n# dimensions of the two\ndim(AHwave1_v1_haven)\ndim(data_21600_0001)\n```\n\nIn fact, `AHwave1_v1.dta` seems to be a subset of `21600-0001-Data.dta`. We can show this by lower-casing the column names and then using a `select()` for the same named columns. The `identical()` function can be used to determine if the contents of two objects are exactly the same.\n\n```{r}\n# lowercase the column names\ncolnames(data_21600_0001) %<>% str_to_lower()\n\n# select() some columns of the same name\ndat <- data_21600_0001 %>% \n    select(colnames(AHwave1_v1_haven))\n\n# identical?\nidentical(dat, AHwave1_v1_haven)\n# if(file.exists(\"data/AHwave1_v1.dta\")){\n#     file.remove(\"data/AHwave1_v1.dta\")\n# }\n```\n\nWe can build a similar table of metadata, but this time as a function:\n\n```{r}\n# a generic(?) function to generate metadata for a Stata file read by haven::read_dta()\n# x is a data frame from haven::read_dta\nf_haven_stata_metadata <- function(x){\n    # variable names\n    varname <- colnames(x)\n    # labels\n    varlabel <- x %>% \n        lapply(., function(x) attributes(x)$label) %>% \n        unlist()\n    # format\n    varformat <- x %>% \n        lapply(., function(x) attributes(x)$format.stata) %>%\n        unlist()\n    # values\n    varvalues <- x %>% \n        lapply(., function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")  \n    \n    bind_cols(varname = varname, \n              varlabel = varlabel, \n              varformat = varformat,\n              varvalues = varvalues)\n}\n\n# generate the metadata\ndata_21600_0001_metadata <- f_haven_stata_metadata(data_21600_0001)\n\n# print the metadata table as a DT::datatable\nDT::datatable(data_21600_0001_metadata)\n\n```\n\n#### Searching through documentation\nGood data sets have good documentation. Sometimes the documentation is voluminous, as is the case for the Add Health data. With voluminous metadata, are there good approaches to finding what you are interested in without opening each PDF file, reading the table of contents, searching for string matches, etc.?\n\nThis section will cover two tools to make searching through PDF files less onerous and more efficient. The two utilities are `pdfgrep` and `pdftools::pdf_text()`\n\n##### `pdfgrep`\n`grep` is a string-matching utility developed mainly for UNIX, now available for all common operating systems. It is also implemented in base R with the function `grep()`. The name comes from the [ed text editor](https://en.wikipedia.org/wiki/Ed_(text_editor)) command g/re/p ($\\underline{g}$lobally search for a $\\underline{r}$egular $\\underline{e}$xpression and $\\underline{p}$rint matching lines), typically used to print the line number of a text file containing the search pattern. \n\nIf you are not familiar with regular expressions and you plan on doing computational social sciences, the sooner you learn, the better. See the R help topic for `base::regex()`.\n\nWe won't be covering `grep` in general here or regular expressions in detail, but will introduce some of the regular expression logic in `pdfgrep`. \n\nStart by installing a version of `pdfgrep`. These are three implementations, one for Mac and two for Windows. The demo today will use the Cygwin version. The native Windows version is not as powerful/customizable as the Cygwin version and will also likely be more comparable with the Mac version. ___Note:___ `pdfgrep` will only work on PDF files that contain text. PDFs that are composed solely from scanned images contain no text and are therefore not searchable using regular expressions.\n\n[pdfgrep for native Windows](https://soft.rubypdf.com/software/pdfgrep-windows-version)\n\n[pdfgrep for Cygwin under Windows](https://cygwin.com/cgi-bin2/package-cat.cgi?file=x86%2Fpdfgrep%2Fpdfgrep-1.4.1-1&grep=pdfgrep); Cygwin is highly recommended for Windows users--it creates a UNIX-like environment that offers many data processing tools.\n\n[pdfgrep for Mac](http://macappstore.org/pdfgrep/)\n\n:::{.rmdnote}\nIf you are on Terminal Server 4 or 5 let's try using Cygwin. Download [cygwin64.zip](http://gismo.gis.washington.edu/phurvitz/csde502_winter_2022/cygwin64.zip) and unzip it at the root level of your H: drive. You should see something like this:\n\n![](images/week06/2022-02-11_08_39_49-cygwin64.png)\nDouble-click the shortcut to `mintty.exe` to open a Cygwin terminal. If you see a security warning, click `Run`.\n:::\n\nA zipped file containing the metadata files for the public use Add Health data is available as [add_health_wave1_metadata.zip](data/add_health_wave1_metadata.zip). Download the file and unzip it in an appropriate location.\n\n###### A few use examples\n_[Note: the images below may be hard to read; clicking them will open them in full-size; click with the middle mouse button to open in a new tab.]_\n\nHere we will search through the entire set of PDF files for the regular expression `black`. First, in your Cygwin terminal (or your regular terminal if you are on a Mac), let's list the PDF files using\n\n`\ncd /H/csde502_winter_2022/Wave1_InHome_Codebooks\nls *.pdf\n`\n\n[![](images/week06/2021-02-11_21_31_11-_cygdrive_L.png)](images/week06/2021-02-11_21_31_11-_cygdrive_L.png)\n\n\nThe syntax for the search is \n\n`\npdfgrep black *.pdf\n`\n\n[![](images/week06/2021-02-11_21_45_41-_cygdrive_L.png)](images/week06/2021-02-11_21_45_41-_cygdrive_L.png)\n\n*This appears to run very slowly on TS4 and TS5 ... run the command and we will come back to the terminal in a few minutes.*\n\nThis prints the file name and the matching text of each PDF containing the regular expression `black`. Suppose we wanted to search for `black` or `Black` or `BLACK`? Use the flag `-i` which is short for case $\\underline{i}$nsensitive.\n\n`\npdfgrep -i black *.pdf\n`\n\n[![](images/week06/2021-02-11_21_47_06-_cygdrive_L.png)](images/week06/2021-02-11_21_47_06-_cygdrive_L.png)\n\nThis shows all files that contain `black` in any case combination. \n\nWe might want to know where to look (i.e., page number) in the file. Using the `-n` flag prints the page $\\underline{n}$umber.\n\n[![](images/week06/2021-02-11_21_47_38-_cygdrive_L.png)](images/week06/2021-02-11_21_47_38-_cygdrive_L.png)\n\nSeeing that there are several matches in `inh25pub.pdf`, the first match on page 13, let's view that:\n\n[![](images/week06/2021-02-11_22_16_08-inh25pub.pdf.png)](images/week06/2021-02-11_22_16_08-inh25pub.pdf.png)\n\nLet's look for another pattern, the word `recreation` in any case combination and also printing page numbers:\n\n`\npdfgrep -n -i recreation *.pdf\n`\n\n[![](images/week06/2021-02-11_21_48_14-_cygdrive_L.png)](images/week06/2021-02-11_21_48_14-_cygdrive_L.png)\n\nSeeing the matches, we might want to narrow the search to include only \"social or recreation\"al activity. Here, the regular expression is `social.*recreation`, where the `.*` regexp translates to \"any number of any characters.\"\n\n\n[![](images/week06/2021-02-11_21_48_34-_cygdrive_L.png)](images/week06/2021-02-11_21_48_34-_cygdrive_L.png)\n\n\nWe will perform one more pattern match. Suppose we were interested in whether subjects were  tired or stressed. The regexp pattern `\"pat1|pat2\"` (note the quotes and the vertical bar). The quotes indicate to the shell that [this is not a pipe](#magrittr), but part of the regexp. The vertical bar functions as an \"or\" as it does in logical criteria in R syntax.\n\nHere the full expression to show those metadata files that match either of these patterns.\n\n`\npdfgrep -i \"tired|stress\" *.pdf\n`\n\n[![](images/week06/2021-02-11_21_54_04-_cygdrive_L.png)](images/week06/2021-02-11_21_54_04-_cygdrive_L.png)\n\n___Why___, you may ask, if we created those fancy metadata tables from the data, would we want to search for specific strings in the PDF documentation? Because the full documentation is likely to provide more complete explanations, whereas the metadata created from the data labels is only a brief description.\n\n##### `pdftools::pdf_text()`\nStaying completely within R, we can perform similar searches through PDF files. We start with `pdftools::pdf_text()`, which converts PDFs to text vectors, where each page is converted to one vector element. This can be piped through text-matching functions, such as `base::grep()` or `stringr::str_match()` (`stringr` is loaded by `tidyverse`).\n\nUnlike `pdfgrep`, which can serially search through a set of files in a directory, `pdf_text()` requires additional work because the function processes one file. Here is an example that mimics searching for the case-insensitive regular expression `black` in the set of PDFs.\n\nWe create a function that searches through a single PDF and then loop the function over the set of PDFs in a specified folder, returning the file name list, the pattern we searched on, the page number with the match, and whether the search was case sensitive or not.\n\n```{r}\n# a function to get matching strings in a PDF, ignore case\nf_pdf_str_match <- function(x, pat, ignore.case = TRUE){\n    # convert the PDF to text\n    mytext <- pdf_text(x)\n    # pattern\n    if(ignore.case){\n        mypat <- regex(pat, ignore_case = TRUE)\n    } else {\n        mypat <- pat\n    }\n    # match strings = pages\n    pages <- str_which(string = mytext, pattern = mypat)\n    if(length(pages) == 0){\n        return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case))\n    }\n    # create a data frame\n    data.frame(fname = x, pat, page_num = pages, ignore.case)\n}\n\n# a list of my PDFs\nmypdfs <- list.files(path = \"data/metadata/Wave1_InHome_Codebooks\", \n                     pattern = \"*.pdf$\", \n                     ignore.case = TRUE,\n                     full.names = TRUE)\n\n# an empty data frame\nx <- NULL\n\n# run each one\nfor(i in mypdfs){\n    x <- rbind(x, f_pdf_str_match(i, \"black\", ignore.case = TRUE))\n}\n\n# ignore NAs\nx %>% filter(!is.na(page_num))\n\n```\n\n### Conclusion\nWe will use these data sets and metadata for the next several lessons. The methods presented in today's lesson should increase efficiency and reduce busy-work.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week7.html","id":"week7","chapter":"7 Week 7","heading":"7 Week 7","text":"week’s lesson provide background variable creation tabulation variables.First, download template file save course working folder week_07.Rmd. Make changes title author see fit. Also make sure packages loaded:","code":"pacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    readstata13,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)"},{"path":"week7.html","id":"creating-value-labels","chapter":"7 Week 7","heading":"7.1 Creating value labels","text":"“Labeled” data important documentation data sets. labels can apply different objects, e.g., columns (saw column labels used “decode” data set AHwave1_v1.dta, Section 1.6), individual values variables, e.g., attribute labels variable h1gi1m:Consider difference different file formats. save data set, CSV file RDS file:read back investigate structure. using temporary folder, specified using tmpdir() function. time R session started, unique temporary folder used. session used create document, temporary dir C:\\653A.First, read CSV format:kind object ?simple data frame. attributes data set ? list attributes enumerate first 6 elements attribute:three attributes, names, individual column names; class, indicating data frame, row.names, case serial number 1 .. n.columns attributes?, columns attributes.Now read RDS file:kind object ?data frame–example tidyr subclass tibble; see documentation.attributes data set ?overall attributes similar basic data frame, overall data set label, National Longitudinal Study Adolescent Adult Health (Add Health), 1994-200 (sic).can also look attributes specific columns, h1gi1m:see original column attributes preserved data set saved RDS format.Importantly, saving data set CSV format loses built-metadata, whereas saving RDS format maintains built-metadata. plain text formats, metadata maintained; formats, worth determining whether metadata maintained. metadata maintained file structure data set, important maintain metadata external format (e.g., text, PDF). Note CSV format lingua franca data transfer, readable software, whereas RDS format may readable software R.","code":"\nif (!exists(\"AHwave1_v1_haven\")) {\n    AHwave1_v1_haven <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n}\nattributes(AHwave1_v1_haven$h1gi1m)$labels %>%\n    t() %>%\n    t()##               [,1]\n## (1) January      1\n## (2) February     2\n## (3) March        3\n## (4) April        4\n## (5) May          5\n## (6) June         6\n## (7) July         7\n## (8) August       8\n## (9) September    9\n## (10) October    10\n## (11) November   11\n## (12) December   12\n## (96) Refused    96\n# temp dir\nmytempdir <- tempdir()\n\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"), row.names = FALSE)\nsaveRDS(object = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\nAHwave1_v1_haven_csv <- read.csv(file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"))\nis(AHwave1_v1_haven_csv)## [1] \"data.frame\" \"list\"       \"oldClass\"   \"vector\"\nAHwave1_v1_haven_csv %>%\n    attributes() %>%\n    map(~ head(.))## $names\n## [1] \"aid\"     \"imonth\"  \"iday\"    \"iyear\"   \"bio_sex\" \"h1gi1m\" \n## \n## $class\n## [1] \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\nAHwave1_v1_haven_csv$h1gi1m %>%\n    attributes()## NULL\nAHwave1_v1_haven_rds <- readRDS(file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\nis(AHwave1_v1_haven_rds)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\" \"list\"       \"oldClass\"  \n## [6] \"vector\"\nAHwave1_v1_haven_rds %>%\n    attributes() %>%\n    map(~ head(.))## $class\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\n## \n## $label\n## [1] \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-200\"\n## \n## $names\n## [1] \"aid\"     \"imonth\"  \"iday\"    \"iyear\"   \"bio_sex\" \"h1gi1m\"\nAHwave1_v1_haven_rds$h1gi1m %>%\n    attributes()## $label\n## [1] \"S1Q1 BIRTH MONTH-W1\"\n## \n## $format.stata\n## [1] \"%13.0f\"\n## \n## $class\n## [1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n## \n## $labels\n##   (1) January  (2) February     (3) March     (4) April       (5) May \n##             1             2             3             4             5 \n##      (6) June      (7) July    (8) August (9) September  (10) October \n##             6             7             8             9            10 \n## (11) November (12) December  (96) Refused \n##            11            12            96"},{"path":"week7.html","id":"creating-factor-variables","chapter":"7 Week 7","heading":"7.1.1 Creating factor variables","text":"Factor variables used R store categorical variables. categorical variables can nominal, value distinct ordered, race, classified asWhiteBlack/African AmericanAmerican IndianAsian/Pacific IslanderotherFactor variables can ordered, difference amount intensity, self-reported health status:ExcellentVery goodGoodFairPoorOrdinal variables may may equal intervals; example, “distance” excellent good health may represent “distance” difference good fair health.Structurally, factor variables stored integers can linked text labels. Operationally, use factor variables important statistical modeling, variables handled correctly categorical.Factor variables created using factor() as_factor() functions. convert self-reported general health variable (h1gh1) factor. First, let’s look variable:shows values 1 6 8, coding indicated labels attribute. Using head() also reveals structure variable, including label variable well coding variable values:convert variable factor:result? can see first values; head() presents values well levels.Although levels numerical order, meaningful labels. use labels = argument assign labels level. Simultaneously, factor ordered order alphanumeric ordering attributes, can set ordering based attributes. Finally, reverse order levels better health higher position order.[Note ordering alphanumeric, one enter list values ... labels = c(\"label1\", \"label2, ..., \"labeln\"), ordered = TRUE ... enforce correct ordering.]Let’s compare two variables simple tabulation. “raw” variable:“raw” variable shows labeled, double precision variable (<dbl+lbl>).Now factor variable:counts , factor variable, <ord> additionally indicates ordering health levels. Note order different (1) Excellent highest numerical value–, statistical model, “Excellent” greater value “Poor.”Bar plots also show difference raw factor variables. Figure 1 presents bar plot raw variable.Figure 1: Bar plot raw h1gh1 valuesBecause numerical values special meaning, bar plot uses default method displaying axes. Figure 2 shows bar plot created factor variable, informative labels correct position axes.Figure 2: Bar plot h1gh1 values factorsOne potential sides using factor variables using text values requires additional code. example, select (filter()) subset records, two methods. first method uses label. case factor ordered, possible use ordinal comparison. records self-reported health less equal “good” selected. tabulation shows “Excellent” records selected.method use as_numeric() specify underlying numerical values. case, value 6 indicated good, can filter health %>% .numeric() <= 6. However, critically important factor levels values known; original variable h1gh1, “good” value 2, re-ordered factor variable, “good” value 6.Using unordered factor variables shows coding generally involved specifying values filter() statements. example, let’s create factor variable interviewer’s observed single race variable:Suppose wanted make subset White Black records, syntax methods:, value explicitly named, using | “” operatorA different approach uses str_detect() regular expression match values obsrace contain strings white black upper/lower case combination.Finally, know numeric values representing factors, can use directly, using requisite care identifying numeric values proxying factor levels:first method verbose, requires code, probably easiest read. two methods may easier code (.e., fewer keystrokes), seem difficult read. often trade-writing code quickly written less easy read versus code methodically written easier read., care needs taken saving data set file. factor text labels, written text default output CSV file. read back , treated character values rather ordered factors. example, health variable created ordered factor:cycled write/read CSV cycle, variable maintained factor.Additional work needed re-establish factor. Fortunately, alphanumeric sorting order character strings also logical order (.e., (1) comes (2) alphanumeric order).Without numeric values preceding text (e.g., (1), (2), …), ordering need explicitly set. example, vector desired sorting order\"Excellent\", \"good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"know\"sorts \"Excellent\", \"good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"know\"proper order self-reported health.use specified labels, need include desired order. create vector specified labels descending order matching numeric values (.e., 1 = “Excellent,” 2 = “good,” etc.), specify vector labels argument:save data set RDS, factor structures maintained; see factor levels exactly set earlier.","code":"\nAHwave1_v1_haven$h1gh1 %>%\n    attributes()## $label\n## [1] \"S3Q1 GENERAL HEALTH-W1\"\n## \n## $format.stata\n## [1] \"%14.0f\"\n## \n## $class\n## [1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n## \n## $labels\n##  (1) Excellent  (2) Very good       (3) Good       (4) Fair       (5) Poor \n##              1              2              3              4              5 \n##    (6) Refused (8) Don't know \n##              6              8\nhead(AHwave1_v1_haven$h1gh1)## <labelled<double>[6]>: S3Q1 GENERAL HEALTH-W1\n## [1] 3 4 4 4 3 3\n## \n## Labels:\n##  value          label\n##      1  (1) Excellent\n##      2  (2) Very good\n##      3       (3) Good\n##      4       (4) Fair\n##      5       (5) Poor\n##      6    (6) Refused\n##      8 (8) Don't know\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1)\n# look at the first few values of the factor variable\nhead(AHwave1_v1_haven$health)## [1] 3 4 4 4 3 3\n## Levels: 1 2 3 4 5 6 8\n# extract the labels from the column attribute\nhealth_levels <- AHwave1_v1_haven$h1gh1 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# create the factor variable and re-level it in reverse order\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1,\n    labels = health_levels,\n    ordered = TRUE\n) %>%\n    fct_relevel(rev)\n# \"raw\" variable\n(tab_h1gh1 <- AHwave1_v1_haven %>%\n    group_by(h1gh1) %>%\n    summarise(n = n()))## # A tibble: 7 x 2\n##                h1gh1     n\n##            <dbl+lbl> <int>\n## 1 1 [(1) Excellent]   1847\n## 2 2 [(2) Very good]   2608\n## 3 3 [(3) Good]        1605\n## 4 4 [(4) Fair]         408\n## 5 5 [(5) Poor]          28\n## 6 6 [(6) Refused]        3\n## 7 8 [(8) Don't know]     5\n# factor variable\n(tab_health <- AHwave1_v1_haven %>%\n    group_by(health) %>%\n    summarise(n = n()))## # A tibble: 7 x 2\n##   health             n\n##   <ord>          <int>\n## 1 (8) Don't know     5\n## 2 (6) Refused        3\n## 3 (5) Poor          28\n## 4 (4) Fair         408\n## 5 (3) Good        1605\n## 6 (2) Very good   2608\n## 7 (1) Excellent   1847\nggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\nggplot(data = tab_health, mapping = aes(x = health, y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\n# filter for Excellent or Very good\ny <- AHwave1_v1_haven %>%\n    filter(health <= \"(2) Very good\")\n\n# tabulate\ny %>%\n    group_by(health) %>%\n    summarise(n = n())## # A tibble: 6 x 2\n##   health             n\n##   <ord>          <int>\n## 1 (8) Don't know     5\n## 2 (6) Refused        3\n## 3 (5) Poor          28\n## 4 (4) Fair         408\n## 5 (3) Good        1605\n## 6 (2) Very good   2608\nx <- AHwave1_v1_haven %>%\n    filter(health %>% as.numeric() <= 6)\n\n# tabulate\nx %>%\n    group_by(health) %>%\n    summarise(n = n())## # A tibble: 6 x 2\n##   health             n\n##   <ord>          <int>\n## 1 (8) Don't know     5\n## 2 (6) Refused        3\n## 3 (5) Poor          28\n## 4 (4) Fair         408\n## 5 (3) Good        1605\n## 6 (2) Very good   2608\n# number of labels\nnlabs <- length(unique(AHwave1_v1_haven$h1gi9))\n\n# get the values, \"as.numeric()\"\nobsrace_values <- AHwave1_v1_haven$h1gi9 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\n# get the labels, names()\nobsrace_labels <- AHwave1_v1_haven$h1gi9 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# create the factor\nAHwave1_v1_haven$obsrace <- factor(AHwave1_v1_haven$h1gi9,\n    levels = obsrace_values,\n    labels = obsrace_labels\n)\ndat_wb1 <- AHwave1_v1_haven %>%\n    filter(obsrace == \"(1) White\" |\n        obsrace == \"(2) Black/African American\")\n\ndat_wb1 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())## # A tibble: 2 x 2\n##   obsrace                        n\n##   <fct>                      <int>\n## 1 (1) White                   4291\n## 2 (2) Black/African American  1601\ndat_wb2 <- AHwave1_v1_haven %>%\n    filter(str_detect(obsrace, regex(\"white|black\", ignore_case = TRUE)))\n\ndat_wb2 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())## # A tibble: 2 x 2\n##   obsrace                        n\n##   <fct>                      <int>\n## 1 (1) White                   4291\n## 2 (2) Black/African American  1601\ndat_wb3 <- AHwave1_v1_haven %>%\n    filter(obsrace %>% as.numeric() %in% c(1, 2))\n\ndat_wb3 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())## # A tibble: 2 x 2\n##   obsrace                        n\n##   <fct>                      <int>\n## 1 (1) White                   4291\n## 2 (2) Black/African American  1601\nstr(AHwave1_v1_haven$health)##  Ord.factor w/ 7 levels \"(8) Don't know\"<..: 5 4 4 4 5 5 4 7 6 6 ...\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.csv\"), row.names = FALSE)\n\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\nstr(y$health)##  chr [1:6504] \"(3) Good\" \"(4) Fair\" \"(4) Fair\" \"(4) Fair\" \"(3) Good\" ...\ny$health <- factor(y$health,\n    labels = y$health %>% unique() %>% sort(),\n    ordered = TRUE\n) %>% fct_rev()\n\nhead(y$health)## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good\n## 7 Levels: (8) Don't know < (6) Refused < (5) Poor < (4) Fair < ... < (1) Excellent\nhealth2labels <- c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\")\n\ny$health2 <- factor(y$h1gh1,\n    labels = health2labels, \n    ordered = TRUE\n) %>% fct_rev()\n\nhead(y$health2)## [1] Good Fair Fair Fair Good Good\n## 7 Levels: Don't know < Refused < Poor < Fair < Good < ... < Excellent\nwrite_rds(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.Rds\"))\n\nz <- readRDS(file = file.path(mytempdir, \"foo.Rds\"))\n\nhead(z$health)## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good\n## 7 Levels: (8) Don't know < (6) Refused < (5) Poor < (4) Fair < ... < (1) Excellent"},{"path":"week7.html","id":"creating-attributes","chapter":"7 Week 7","heading":"7.1.2 Creating attributes","text":"addition creating factors, can serve capacity self-documenting (.e., value labels least somewhat self-explanatory), can create attributes seen Stata .dta files.Let’s start CSV file, know stripped descriptive attributes:First, attribute data frame (overall data frame label attribute):… can verify:Next, attributes health obsrace variables, documenting variables values. , health set factor using sorted unique values health CSV file. factor ordered reversed “Excellent” health highest value.create obsrace factor inherent value hierarchy, make ordered factor. convert factor use statistical models.Verify created:caveats apply saving data frame files, respect various attributes attributes saved restored write/read cycle.","code":"\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\ny %>%\n    attributes() %>%\n    map(~ head(.))## $names\n## [1] \"aid\"     \"imonth\"  \"iday\"    \"iyear\"   \"bio_sex\" \"h1gi1m\" \n## \n## $class\n## [1] \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\nattributes(y)$label <- \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\ny %>%\n    attributes() %>%\n    extract(\"label\")## $label\n## [1] \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\n# label for health\nattributes(y$health)$label <- \"General health from public Add Health Wave 1 Section 3 question 1\"\n\n# labels for health\nhealthlevels <- unique(y$health) %>%\n    sort()\n\n# values for health\nattributes(y$health)$levels <- healthlevels\n\n# create the factor \"health\" with appropriate levels, order it and reverse the levels\n#   so that Excellent is highest\ny %<>% mutate(\n    health =\n        factor(health, levels = healthlevels, ordered = TRUE) %>%\n            fct_rev()\n)\n# label for obsrace\nattributes(y$obsrace)$label <- \"Interviewer observation of race from public Add Health Wave 1 Section 1 question 9\"\n\n# obsrace levels\nobsracelevels <- unique(y$obsrace) %>%\n    sort()\n\n# values  for obsrace\nattributes(y$obsrace)$levels <- obsracelevels\n\n# create a factor\ny %<>% mutate(\n    obsrace = factor(obsrace, levels = obsracelevels)\n)\ny$health %>% attributes()## $levels\n## [1] \"(8) Don't know\" \"(6) Refused\"    \"(5) Poor\"       \"(4) Fair\"      \n## [5] \"(3) Good\"       \"(2) Very good\"  \"(1) Excellent\" \n## \n## $class\n## [1] \"ordered\" \"factor\"\nhead(y$health)## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good\n## 7 Levels: (8) Don't know < (6) Refused < (5) Poor < (4) Fair < ... < (1) Excellent\ny$obsrace %>% attributes()## $levels\n## [1] \"(1) White\"                           \"(2) Black/African American\"         \n## [3] \"(3) American Indian/Native American\" \"(4) Asian/Pacific Islander\"         \n## [5] \"(5) Other\"                           \"(6) Refused\"                        \n## [7] \"(8) Don't know\"                     \n## \n## $class\n## [1] \"factor\"\nhead(y$obsrace)## [1] (2) Black/African American (2) Black/African American\n## [3] (1) White                  (2) Black/African American\n## [5] (2) Black/African American (2) Black/African American\n## 7 Levels: (1) White ... (8) Don't know"},{"path":"week7.html","id":"tabulation","chapter":"7 Week 7","heading":"7.2 Tabulation","text":"seen examples tabulation previous exercises (Sections 1.6.2.5, 2.2.4, 4.2.1.2.1). section give complete treatment using Add Health data example.","code":""},{"path":"week7.html","id":"raw-counts","chapter":"7 Week 7","heading":"7.2.1 Raw counts","text":"basic tabulations simply give count observations different strata. strata can based numeric ratio interval data, using functions cut() BAMMtools::getJenksBreaks(), nominal data (Add Health interviewer’s observation respondents’ single race), ordinal data (self-reported health status). use examples type data.First, code load full Add Health data set, includes additional variables present data set used previously.metadata (variable names labels) presented Table 1.Table 1: Add Health large table variable names labels Let’s look body mass index (BMI) data, uses weight height values. find variables representing weight height metadata . need determine invalid values:First, need select variables representing feet inches, filter invalid heights (> 90) weights (> 900) identified , finally calculate height m, weight kg, BMI (\\(\\frac{weight}{height^2}\\)). future use also select self-reported health interviewer observed race factors.histogram (Figure 3 shows distribution BMI respondents vertical lines 5th 85th percentile. range generally considered “normal” “healthy” according CDC, although sample varying age, sex, height, weight ranges, difficult interpret. Nevertheless cut points can serve purpose demonstration. Figure 3: Histogram BMI Add Health cohortWe assign BMI class using cut points, cut() breaks minimum, 5%, 85%, maximum BMI, also assign labels set ordering:tabulation count respondents weight class can generated base R function table() dplyr functions group_by() summarise() (Table 2.Table 2: Count BMI class, Add Health cohortFor variables already nominal ordinal factors, tabulations can made directly. converted factors, correct labels show, rather simple numeric values. tabulations also presented descending order label level. Tabulation self-reported health Table 3 race observed interviewer Table 4.Table 3: Count self-reported health class, Add Health cohortExcellent\ngood\nGood\nFair\nPoor\nDon’t know\nTable 4: Count interviewer-observed race, Add Health cohortWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nRefused\nDon’t know\n","code":"\n# download and unzip the larger data set\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n\n# zip file in $temp -- basename gets just the file name from the URL and not the URL path;\n#   file.path stitches the tempdir() path to the file name\nzipfile <- file.path(mytempdir, basename(myUrl))\n\n# dta file in $temp\ndtafile <- tools::file_path_sans_ext(zipfile)\n\n# check if the dta file exists\nif (!file.exists(dtafile)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    if (file.exists(zipfile)) {\n        unzip(zipfile = zipfile, exdir = mytempdir)\n    }\n}\n\n# if the data set has not been read, read it in\nif (!exists(\"ahcomplete\")) {\n    ahcomplete <- haven::read_dta(dtafile)\n}\n# lowercase column names\ncolnames(ahcomplete) %<>% str_to_lower()\n# create a data frame of the variable names and labels\nahcomplete_metadata <- bind_cols(\n    varname = colnames(ahcomplete),\n    varlabel = ahcomplete %>% map(~ attributes(.)$label) %>% unlist()\n)\n\n# print the table with DT::datatable for interactive display\nDT::datatable(ahcomplete_metadata)\nattributes(ahcomplete$h1gh59a)$labels##      (4) 4 feet      (5) 5 feet      (6) 6 feet    (96) Refused (98) Don't know \n##               4               5               6              96              98\nattributes(ahcomplete$h1gh59b)$labels##        (0) 0 inches          (1) 1 inch        (2) 2 inches        (3) 3 inches \n##                   0                   1                   2                   3 \n##        (4) 4 inches        (5) 5 inches        (6) 6 inches        (7) 7 inches \n##                   4                   5                   6                   7 \n##        (8) 8 inches        (9) 9 inches      (10) 10 inches      (11) 11 inches \n##                   8                   9                  10                  11 \n##        (96) Refused     (98) Don't know (99) Not applicable \n##                  96                  98                  99\nattributes(ahcomplete$h1gh60)$labels##        (996) Refused     (998) Don't know (999) Not applicable \n##                  996                  998                  999\n# make the data frame\nhtwt <- ahcomplete %>%\n    # select columns\n    select(\n        feet = h1gh59a,\n        inches = h1gh59b,\n        weight_lb = h1gh60,\n        health = h1gh1,\n        obsrace = h1gi9\n    ) %>%\n    # filter for valid values\n    filter(feet < 90 & inches < 90 & weight_lb < 900) %>%\n    # calculate metric units and BMI\n    mutate(\n        height_m = (feet * 12 + inches) / 39.37008,\n        weight_kg = weight_lb / 2.205,\n        BMI = weight_kg / height_m^2\n    )\n\n# factor: get values and labels\nhealthvals <- htwt$health %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\nhealthlabs <- htwt$health %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\nracevals <- htwt$obsrace %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\nracelabs <- htwt$obsrace %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# package the data frame up\nhtwt %<>%\n    mutate(\n        health = factor(health,\n            levels = healthvals,\n            labels = healthlabs\n        ),\n        obsrace = factor(obsrace,\n            levels = racevals,\n            labels = racelabs\n        )\n    )\n# get the 5th & 85th percentile\nbmibreaks <- quantile(x = htwt$BMI, probs = c(0.05, 0.85))\nggplot(htwt, aes(x = BMI)) +\n    geom_histogram(bins = 30) +\n    geom_vline(xintercept = bmibreaks)\nhtwt %<>%\n    mutate(bmiclass = cut(\n        x = BMI,\n        breaks = c(min(BMI), bmibreaks, max(BMI)),\n        labels = c(\"underweight\", \"normal\", \"overweight\"),\n        include.lowest = TRUE\n    ) %>%\n        factor(ordered = TRUE))\n# base R\ntable(htwt$bmiclass, useNA = \"ifany\")## \n## underweight      normal  overweight \n##         324        5023         944\n# tidyR\nhtwt %>%\n    group_by(bmiclass) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(full_width = FALSE, position = \"left\", \n                  bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\nhtwt %>%\n    group_by(health) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\nhtwt %>%\n    group_by(obsrace) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )"},{"path":"week7.html","id":"proportionspercentages","chapter":"7 Week 7","heading":"7.2.2 Proportions/percentages","text":"Proportions percentages can added tabulations greater interpretability. Using base R, prop_table() function can used wrapper around table() generate proportions, optionally multiplying 100 generate percentage. Remember round needed. example:surprisingly, BMI classes show 5% underweight 15% overweight, stratification defined.tidyR version requires bit coding provides readable output. percent sign special character, enclose back ticks, %. generate tabulation observed race (Table 4).Table 5: Count interviewer-observed race, Add Health cohortWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nRefused\nDon’t know\n","code":"\nround(prop.table(table(htwt$bmiclass)), 2)## \n## underweight      normal  overweight \n##        0.05        0.80        0.15\nround(prop.table(table(htwt$bmiclass)) * 100, 0)## \n## underweight      normal  overweight \n##           5          80          15\nhtwt %>%\n    group_by(obsrace) %>%\n    summarise(n = n()) %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )"},{"path":"week7.html","id":"stratified-tabulation","chapter":"7 Week 7","heading":"7.2.3 Stratified tabulation","text":"Tabulations can generated using multiple variables. examine BMI race well BMI health. percentages sum 100 based order grouping., see relative percent underweight, normal, overweight within race class (Table 6).Table 6: Count interviewer-observed race BMI class, Add Health cohortWhite\nWhite\nWhite\nBlack/African American\nBlack/African American\nBlack/African American\nAmerican Indian/Native American\nAmerican Indian/Native American\nAmerican Indian/Native American\nAsian/Pacific Islander\nAsian/Pacific Islander\nAsian/Pacific Islander\n\n\n\nRefused\nDon’t know\ntable can also presented grouped rows. code generates named\nvector count observed race BMI classThe groups used pack_rows() function grouped rows (Table 7).Table 7: Count interviewer-observed race BMI class, Add Health cohort, percent raceWhite\nWhite\nWhite\nBlack/African American\nBlack/African American\nBlack/African American\nAmerican Indian/Native American\nAmerican Indian/Native American\nAmerican Indian/Native American\nAsian/Pacific Islander\nAsian/Pacific Islander\nAsian/Pacific Islander\n\n\n\nRefused\nDon’t know\nsee relative percent different race groups within BMI class (Table 8.Table 8: Count interviewer-observed race BMI class, Add Health cohort, percent BMI classWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nRefused\nDon’t know\nWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nEven though n values two tables (e.g., underweight \\(\\times\\) White n = 234), percentages different due grouping. , percent underweight persons among White race stratum different percent White persons within underweight stratum. Proper grouping critical answer specific questions data.Another way understand data, preferred , make graph. example, BMI race facet grid bar graph (rfigure_nums(name = “bmibarfacet,” display = “cite”)`). Figure 4: BMI class race, Add Health cohortOr stacked bar graph (Figure 5) Figure 5: BMI class race, Add Health cohortRendered 2022-03-04 00:44:42","code":"\nhtwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\n# create the row groupings\n(obsrace <- htwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    deframe())##                           (1) White          (2) Black/African American \n##                                   3                                   3 \n## (3) American Indian/Native American          (4) Asian/Pacific Islander \n##                                   3                                   3 \n##                           (5) Other                         (6) Refused \n##                                   3                                   1 \n##                      (8) Don't know \n##                                   1\nhtwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>% \n    kable %>% \n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>% \n    pack_rows(index = obsrace)    \nhtwt %>%\n    group_by(\n        bmiclass,\n        obsrace\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(full_width = FALSE, position = \"left\",\n                          bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n)\nbmi_race <- htwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    filter(!str_detect(obsrace, regex(\"refused|know\", ignore_case = TRUE)))\n\nggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n    facet_grid(~obsrace) +\n    xlab(\"BMI class\")\nggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    scale_fill_discrete(name = \"BMI class\") +\n    xlab(\"observed race\")\n    #theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))"},{"path":"week7.html","id":"source-code-7","chapter":"7 Week 7","heading":"7.3 Source code","text":"File H:/csde502-winter-2022-main/07-week07.Rmd.","code":""},{"path":"week7.html","id":"r-code-used-in-this-document-7","chapter":"7 Week 7","heading":"7.3.1 R code used in this document","text":"","code":"\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    readstata13,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\nif (!exists(\"AHwave1_v1_haven\")) {\n    AHwave1_v1_haven <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n}\nattributes(AHwave1_v1_haven$h1gi1m)$labels %>%\n    t() %>%\n    t()\n# temp dir\nmytempdir <- tempdir()\n\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"), row.names = FALSE)\nsaveRDS(object = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\nAHwave1_v1_haven_csv <- read.csv(file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"))\nis(AHwave1_v1_haven_csv)\nAHwave1_v1_haven_csv %>%\n    attributes() %>%\n    map(~ head(.))\nAHwave1_v1_haven_csv$h1gi1m %>%\n    attributes()\nAHwave1_v1_haven_rds <- readRDS(file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\nis(AHwave1_v1_haven_rds)\nAHwave1_v1_haven_rds %>%\n    attributes() %>%\n    map(~ head(.))\nAHwave1_v1_haven_rds$h1gi1m %>%\n    attributes()\nAHwave1_v1_haven$h1gh1 %>%\n    attributes()\nhead(AHwave1_v1_haven$h1gh1)\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1)\n# look at the first few values of the factor variable\nhead(AHwave1_v1_haven$health)\n# extract the labels from the column attribute\nhealth_levels <- AHwave1_v1_haven$h1gh1 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# create the factor variable and re-level it in reverse order\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1,\n    labels = health_levels,\n    ordered = TRUE\n) %>%\n    fct_relevel(rev)\n# \"raw\" variable\n(tab_h1gh1 <- AHwave1_v1_haven %>%\n    group_by(h1gh1) %>%\n    summarise(n = n()))\n# factor variable\n(tab_health <- AHwave1_v1_haven %>%\n    group_by(health) %>%\n    summarise(n = n()))\nggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\nggplot(data = tab_health, mapping = aes(x = health, y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\n# filter for Excellent or Very good\ny <- AHwave1_v1_haven %>%\n    filter(health <= \"(2) Very good\")\n\n# tabulate\ny %>%\n    group_by(health) %>%\n    summarise(n = n())\nx <- AHwave1_v1_haven %>%\n    filter(health %>% as.numeric() <= 6)\n\n# tabulate\nx %>%\n    group_by(health) %>%\n    summarise(n = n())\n# number of labels\nnlabs <- length(unique(AHwave1_v1_haven$h1gi9))\n\n# get the values, \"as.numeric()\"\nobsrace_values <- AHwave1_v1_haven$h1gi9 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\n# get the labels, names()\nobsrace_labels <- AHwave1_v1_haven$h1gi9 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# create the factor\nAHwave1_v1_haven$obsrace <- factor(AHwave1_v1_haven$h1gi9,\n    levels = obsrace_values,\n    labels = obsrace_labels\n)\ndat_wb1 <- AHwave1_v1_haven %>%\n    filter(obsrace == \"(1) White\" |\n        obsrace == \"(2) Black/African American\")\n\ndat_wb1 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())\ndat_wb2 <- AHwave1_v1_haven %>%\n    filter(str_detect(obsrace, regex(\"white|black\", ignore_case = TRUE)))\n\ndat_wb2 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())\ndat_wb3 <- AHwave1_v1_haven %>%\n    filter(obsrace %>% as.numeric() %in% c(1, 2))\n\ndat_wb3 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())\nstr(AHwave1_v1_haven$health)\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.csv\"), row.names = FALSE)\n\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\nstr(y$health)\ny$health <- factor(y$health,\n    labels = y$health %>% unique() %>% sort(),\n    ordered = TRUE\n) %>% fct_rev()\n\nhead(y$health)\nhealth2labels <- c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\")\n\ny$health2 <- factor(y$h1gh1,\n    labels = health2labels, \n    ordered = TRUE\n) %>% fct_rev()\n\nhead(y$health2)\nwrite_rds(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.Rds\"))\n\nz <- readRDS(file = file.path(mytempdir, \"foo.Rds\"))\n\nhead(z$health)\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\ny %>%\n    attributes() %>%\n    map(~ head(.))\nattributes(y)$label <- \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\ny %>%\n    attributes() %>%\n    extract(\"label\")\n# label for health\nattributes(y$health)$label <- \"General health from public Add Health Wave 1 Section 3 question 1\"\n\n# labels for health\nhealthlevels <- unique(y$health) %>%\n    sort()\n\n# values for health\nattributes(y$health)$levels <- healthlevels\n\n# create the factor \"health\" with appropriate levels, order it and reverse the levels\n#   so that Excellent is highest\ny %<>% mutate(\n    health =\n        factor(health, levels = healthlevels, ordered = TRUE) %>%\n            fct_rev()\n)\n# label for obsrace\nattributes(y$obsrace)$label <- \"Interviewer observation of race from public Add Health Wave 1 Section 1 question 9\"\n\n# obsrace levels\nobsracelevels <- unique(y$obsrace) %>%\n    sort()\n\n# values  for obsrace\nattributes(y$obsrace)$levels <- obsracelevels\n\n# create a factor\ny %<>% mutate(\n    obsrace = factor(obsrace, levels = obsracelevels)\n)\ny$health %>% attributes()\nhead(y$health)\n\ny$obsrace %>% attributes()\nhead(y$obsrace)\n# download and unzip the larger data set\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n\n# zip file in $temp -- basename gets just the file name from the URL and not the URL path;\n#   file.path stitches the tempdir() path to the file name\nzipfile <- file.path(mytempdir, basename(myUrl))\n\n# dta file in $temp\ndtafile <- tools::file_path_sans_ext(zipfile)\n\n# check if the dta file exists\nif (!file.exists(dtafile)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    if (file.exists(zipfile)) {\n        unzip(zipfile = zipfile, exdir = mytempdir)\n    }\n}\n\n# if the data set has not been read, read it in\nif (!exists(\"ahcomplete\")) {\n    ahcomplete <- haven::read_dta(dtafile)\n}\n# lowercase column names\ncolnames(ahcomplete) %<>% str_to_lower()\n# create a data frame of the variable names and labels\nahcomplete_metadata <- bind_cols(\n    varname = colnames(ahcomplete),\n    varlabel = ahcomplete %>% map(~ attributes(.)$label) %>% unlist()\n)\n\n# print the table with DT::datatable for interactive display\nDT::datatable(ahcomplete_metadata)\nattributes(ahcomplete$h1gh59a)$labels\nattributes(ahcomplete$h1gh59b)$labels\nattributes(ahcomplete$h1gh60)$labels\n# make the data frame\nhtwt <- ahcomplete %>%\n    # select columns\n    select(\n        feet = h1gh59a,\n        inches = h1gh59b,\n        weight_lb = h1gh60,\n        health = h1gh1,\n        obsrace = h1gi9\n    ) %>%\n    # filter for valid values\n    filter(feet < 90 & inches < 90 & weight_lb < 900) %>%\n    # calculate metric units and BMI\n    mutate(\n        height_m = (feet * 12 + inches) / 39.37008,\n        weight_kg = weight_lb / 2.205,\n        BMI = weight_kg / height_m^2\n    )\n\n# factor: get values and labels\nhealthvals <- htwt$health %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\nhealthlabs <- htwt$health %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\nracevals <- htwt$obsrace %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\nracelabs <- htwt$obsrace %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# package the data frame up\nhtwt %<>%\n    mutate(\n        health = factor(health,\n            levels = healthvals,\n            labels = healthlabs\n        ),\n        obsrace = factor(obsrace,\n            levels = racevals,\n            labels = racelabs\n        )\n    )\n# get the 5th & 85th percentile\nbmibreaks <- quantile(x = htwt$BMI, probs = c(0.05, 0.85))\nggplot(htwt, aes(x = BMI)) +\n    geom_histogram(bins = 30) +\n    geom_vline(xintercept = bmibreaks)\nhtwt %<>%\n    mutate(bmiclass = cut(\n        x = BMI,\n        breaks = c(min(BMI), bmibreaks, max(BMI)),\n        labels = c(\"underweight\", \"normal\", \"overweight\"),\n        include.lowest = TRUE\n    ) %>%\n        factor(ordered = TRUE))\n# base R\ntable(htwt$bmiclass, useNA = \"ifany\")\n# tidyR\nhtwt %>%\n    group_by(bmiclass) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(full_width = FALSE, position = \"left\", \n                  bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\nhtwt %>%\n    group_by(health) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\nhtwt %>%\n    group_by(obsrace) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\nround(prop.table(table(htwt$bmiclass)), 2)\n\nround(prop.table(table(htwt$bmiclass)) * 100, 0)\nhtwt %>%\n    group_by(obsrace) %>%\n    summarise(n = n()) %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\nhtwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\n# create the row groupings\n(obsrace <- htwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    deframe())\nhtwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>% \n    kable %>% \n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>% \n    pack_rows(index = obsrace)    \nhtwt %>%\n    group_by(\n        bmiclass,\n        obsrace\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(full_width = FALSE, position = \"left\",\n                          bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n)\nbmi_race <- htwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    filter(!str_detect(obsrace, regex(\"refused|know\", ignore_case = TRUE)))\n\nggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n    facet_grid(~obsrace) +\n    xlab(\"BMI class\")\nggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    scale_fill_discrete(name = \"BMI class\") +\n    xlab(\"observed race\")\n    #theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week7.html","id":"complete-rmd-code-7","chapter":"7 Week 7","heading":"7.3.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 7 {#week7}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    readstata13,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n}\n```\n\n<h2>Topic: Add Health data: variable creation and tabulation<\/h2>\nThis week's lesson will provide more background on variable creation and tabulation of variables.\n\nFirst, download the [template file](https://raw.githubusercontent.com/CSDE-UW/csde502-winter-2022/master/docs/files/template.Rmd) and save it in your course working folder as `week_07.Rmd`. Make changes to the title and author as you see fit. Also make sure these packages are loaded:\n\n```\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    readstata13,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)\n```\n\n## Creating value labels\n\"Labeled\" data are important for documentation of data sets. The labels can apply to different objects, e.g., columns (as we saw in the column labels used to \"decode\" the data set in `AHwave1_v1.dta`, Section \\@ref(tidyverse)), or to individual values of variables, e.g., the attribute `labels` of the variable `h1gi1m`:\n\n```{r}\nif (!exists(\"AHwave1_v1_haven\")) {\n    AHwave1_v1_haven <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n}\nattributes(AHwave1_v1_haven$h1gi1m)$labels %>%\n    t() %>%\n    t()\n```\n\nConsider the difference between different file formats. Here we will save the data set, once as a CSV file and once an RDS file:\n\n```{r}\n# temp dir\nmytempdir <- tempdir()\n\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"), row.names = FALSE)\nsaveRDS(object = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\n```\n\nThen we will read them back in and investigate their structure. Here we are using a temporary folder, specified using the `tmpdir()` function. Each time an R session is started, a unique temporary folder is used. For the session used to create this document, the temporary dir is `r mytempdir`. \n\nFirst, read the CSV format:\n\n```{r}\nAHwave1_v1_haven_csv <- read.csv(file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"))\n```\n\nWhat kind of object is this?\n\n```{r}\nis(AHwave1_v1_haven_csv)\n```\n\nIt is a simple data frame. What attributes does this data set have? Here we list the attributes and enumerate the first 6 elements of each attribute:\n\n```{r}\nAHwave1_v1_haven_csv %>%\n    attributes() %>%\n    map(~ head(.))\n```\n\nThere are three attributes, `names`, which are the individual column names; `class`, indicating this is a data frame, and `row.names`, in this case a serial number 1 .. n.\n\nDo the columns have any attributes?\n\n```{r}\nAHwave1_v1_haven_csv$h1gi1m %>%\n    attributes()\n```\n\nNo, the columns have no attributes.\n\nNow we will read in the RDS file:\n\n```{r}\nAHwave1_v1_haven_rds <- readRDS(file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\n```\n\nWhat kind of object is this?\n\n```{r}\nis(AHwave1_v1_haven_rds)\n```\n\nIt is a data frame--but an example of the `tidyr` subclass `tibble`; see the [documentation](https://www.rdocumentation.org/packages/tibble).\n\nWhat attributes does this data set have?\n\n```{r}\nAHwave1_v1_haven_rds %>%\n    attributes() %>%\n    map(~ head(.))\n```\n\nThe overall attributes are similar to the basic data frame, but there is an overall data set label, ``r AHwave1_v1_haven_rds %>% attributes() %>% extract(\"label\")`` (*sic*).\n\nWe can also look at the attributes of specific columns, here for `h1gi1m`:\n\n```{r}\nAHwave1_v1_haven_rds$h1gi1m %>%\n    attributes()\n```\n\nHere we see that all of the original column attributes were preserved when the data set was saved in RDS format.\n\n**Importantly**, saving a data set in CSV format loses any built-in metadata, whereas saving in RDS format maintains the built-in metadata. For other plain text formats, metadata will not be maintained; for other formats, it is worth determining whether such metadata are maintained. If metadata are not maintained in the file structure of the data set, it will be important to maintain the metadata in an external format (e.g., text, PDF). Note that the CSV format is the *lingua franca* of data transfer, and should be readable by any software, whereas the RDS format may not be readable by software other than R.\n\n### Creating factor variables\nFactor variables are used in R to store categorical variables. These categorical variables can be nominal, in which each value is distinct and *not* ordered, such as race, classified as \n\n* White\n* Black/African American\n* American Indian\n* Asian/Pacific Islander\n* other\n\nFactor variables can be ordered, where there is a difference in amount or intensity, such as self-reported health status:\n\n1. Excellent\n1. Very good\n1. Good\n1. Fair\n1. Poor\n\nOrdinal variables may or may not have equal intervals; for example, the \"distance\" between excellent and good health may not represent the same \"distance\" as the difference between good and fair health.\n\nStructurally, factor variables are stored as integers that can be linked to text labels. Operationally, __the use of factor variables is important in statistical modeling, so that the variables are handled correctly as being categorical__.\n\nFactor variables are created using the `factor()` or `as_factor()` functions. Here we will convert the self-reported general health variable (`h1gh1`) to a factor. First, let's look at the variable:\n\n```{r}\nAHwave1_v1_haven$h1gh1 %>%\n    attributes()\n```\n\nThis shows that there are values 1 through 6 and 8, with coding indicated in the `labels` attribute. Using `head()` also reveals the structure of the variable, including the label for the variable itself as well as the coding of the variable values:\n\n```{r}\nhead(AHwave1_v1_haven$h1gh1)\n```\n\n\nHere we convert the variable to a factor:\n\n```{r}\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1)\n```\n\nWhat is the result? We can see from the first few values; `head()` presents the values as well as the levels.\n\n```{r}\n# look at the first few values of the factor variable\nhead(AHwave1_v1_haven$health)\n```\n\nAlthough the levels are in numerical order, there are no meaningful labels. We use the `labels = ` argument to assign labels to each level. Simultaneously, because the factor is ordered in the same order as the alphanumeric ordering of the attributes, we can set the ordering based on those attributes. Finally, we reverse the order of the levels so that better health has a higher position in the order.\n\n```{r}\n# extract the labels from the column attribute\nhealth_levels <- AHwave1_v1_haven$h1gh1 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# create the factor variable and re-level it in reverse order\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1,\n    labels = health_levels,\n    ordered = TRUE\n) %>%\n    fct_relevel(rev)\n```\n\n_[Note that if the ordering is not alphanumeric, one should enter the list of values as `... labels = c(\"label1\", \"label2, ..., \"labeln\"), ordered = TRUE ...` to enforce correct ordering.]_\n\nLet's compare the two variables through simple tabulation. Here is the \"raw\" variable:\n\n```{r}\n# \"raw\" variable\n(tab_h1gh1 <- AHwave1_v1_haven %>%\n    group_by(h1gh1) %>%\n    summarise(n = n()))\n```\n\nThe \"raw\" variable shows that it is a labeled, double precision variable (`<dbl+lbl>`). \n\nNow the factor variable:\n\n```{r}\n# factor variable\n(tab_health <- AHwave1_v1_haven %>%\n    group_by(health) %>%\n    summarise(n = n()))\n```\n\nThe counts are the same, but for the factor variable, the `<ord>` additionally indicates the ordering of health levels. Note that the order is different because `(1) Excellent` should have the highest numerical value--that is, in a statistical model, \"Excellent\" should have a greater value than \"Poor\".\n\nBar plots also show the difference between the raw and factor variables. `r figure_nums(name = \"barplotraw\", display = \"cite\")` presents a bar plot from the raw variable. \n\n```{r, warning=FALSE, message=FALSE}\nggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\n```\n\n*`r figure_nums(name = \"barplotraw\", caption = \"Bar plot from raw h1gh1 values\")`*\n\nBecause the numerical values have no special meaning, the bar plot uses its default method of displaying the axes. `r figure_nums(name = \"barplotfac\", display = \"cite\")` shows the bar plot created with the factor variable, with informative labels at the correct position on the axes.\n\n```{r}\nggplot(data = tab_health, mapping = aes(x = health, y = n)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\n```\n\n*`r figure_nums(name = \"barplotfac\", caption = \"Bar plot from h1gh1 values as factors\")`*\n\n\nOne of the potential down sides to using factor variables is that using the text values requires additional code. For example, to select (`filter()`) a subset of records, there are two methods. The first method uses the label. In this case because the factor is ordered, it is possible to use an ordinal comparison. Any records with self-reported health less than or equal to \"Very good\" are selected. The tabulation shows that no \"Excellent\" records were selected.\n\n```{r}\n# filter for Excellent or Very good\ny <- AHwave1_v1_haven %>%\n    filter(health <= \"(2) Very good\")\n\n# tabulate\ny %>%\n    group_by(health) %>%\n    summarise(n = n())\n```\n\nThe other method is to use `as_numeric()` to specify the underlying numerical values. In this case, because the value of 6 indicated `Very good`, we can filter for `health %>% as.numeric() <= 6`.  However, it is critically important that the factor levels and values are known; in the original variable `h1gh1`, \"Very good\" had a value of 2, but in the re-ordered factor variable, \"Very good\" has a value of 6.\n\n```{r}\nx <- AHwave1_v1_haven %>%\n    filter(health %>% as.numeric() <= 6)\n\n# tabulate\nx %>%\n    group_by(health) %>%\n    summarise(n = n())\n```\n\nUsing unordered factor variables shows that more coding is generally involved in specifying values in `filter()` statements. For example, let's create a factor variable for the interviewer's observed single race variable:\n\n```{r}\n# number of labels\nnlabs <- length(unique(AHwave1_v1_haven$h1gi9))\n\n# get the values, \"as.numeric()\"\nobsrace_values <- AHwave1_v1_haven$h1gi9 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\n# get the labels, names()\nobsrace_labels <- AHwave1_v1_haven$h1gi9 %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# create the factor\nAHwave1_v1_haven$obsrace <- factor(AHwave1_v1_haven$h1gi9,\n    levels = obsrace_values,\n    labels = obsrace_labels\n)\n```\n\nSuppose we wanted to make a subset of only White and Black records, there are a few syntax methods:\n\nHere, each value is explicitly named, using the `|` \"or\" operator \n\n```{r}\ndat_wb1 <- AHwave1_v1_haven %>%\n    filter(obsrace == \"(1) White\" |\n        obsrace == \"(2) Black/African American\")\n\ndat_wb1 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())\n```\n\nA different approach uses `str_detect()` with a regular expression to match any values of `obsrace` that contain the strings `white` or `black` in any upper/lower case combination.\n\n```{r}\ndat_wb2 <- AHwave1_v1_haven %>%\n    filter(str_detect(obsrace, regex(\"white|black\", ignore_case = TRUE)))\n\ndat_wb2 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())\n```\n\nFinally, if we know the numeric values representing the factors, we can use those directly, using requisite care in identifying the numeric values proxying for the factor levels:\n\n```{r}\ndat_wb3 <- AHwave1_v1_haven %>%\n    filter(obsrace %>% as.numeric() %in% c(1, 2))\n\ndat_wb3 %>%\n    group_by(obsrace) %>%\n    summarise(n = n())\n```\n\nThe first method is the most verbose, requires the most code, and is probably the easiest to read. The other two methods may be easier to code (i.e., fewer keystrokes), but seem to be more difficult to read. There is often a trade-off between writing code that is quickly written and less easy to read versus code that is more methodically written but easier to read. \n\nAs above, care needs to be taken in saving the data set to a file. If the factor has text labels, those will be written as text by default to an output CSV file. When they are read back in, they will be treated as character values rather than ordered factors. For example, the `health` variable we created is an ordered factor:\n\n```{r}\nstr(AHwave1_v1_haven$health)\n```\n\nBut when cycled through a write/read CSV cycle, the variable is not maintained as a factor.\n\n```{r}\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.csv\"), row.names = FALSE)\n\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\nstr(y$health)\n```\n\nAdditional work would be needed to re-establish it as a factor. Fortunately, the alphanumeric sorting order of the character strings is also the logical order (i.e., `(1)` comes before `(2)` in alphanumeric order).\n\n```{r}\ny$health <- factor(y$health,\n    labels = y$health %>% unique() %>% sort(),\n    ordered = TRUE\n) %>% fct_rev()\n\nhead(y$health)\n```\n\nWithout the numeric values preceding the text (e.g., `(1)`, `(2)`, ...), the ordering would need to be explicitly set. For example, the vector in desired sorting order \n\n`\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\"` \n\nsorts as \n\n`\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\"`\n\nwhich is not the proper order of self-reported health.\n\nTo use our own specified labels, we need to include those in the desired order. Here we create a vector with specified labels in descending order matching the numeric values (i.e., 1 = \"Excellent\", 2 = \"Very good\", etc.), and then specify that vector in the `labels` argument:\n\n```{r}\nhealth2labels <- c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\")\n\ny$health2 <- factor(y$h1gh1,\n    labels = health2labels, \n    ordered = TRUE\n) %>% fct_rev()\n\nhead(y$health2)\n```\n\nIf you save the data set as RDS, the factor and other structures are maintained; here we see the factor levels are exactly as we set them earlier.\n\n```{r}\nwrite_rds(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.Rds\"))\n\nz <- readRDS(file = file.path(mytempdir, \"foo.Rds\"))\n\nhead(z$health)\n```\n\n### Creating attributes\nIn addition to creating factors, which can serve in some capacity as self-documenting (i.e., the value labels should be at least somewhat self-explanatory), we can create attributes as we have seen with the Stata `.dta` files.\n\nLet's start with the CSV file, which we know was stripped of its descriptive attributes:\n\n```{r}\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\ny %>%\n    attributes() %>%\n    map(~ head(.))\n```\n\nFirst, an attribute of the data frame itself (the overall data frame `label` attribute):\n\n```{r}\nattributes(y)$label <- \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\n```\n\n... which we can verify:\n\n```{r}\ny %>%\n    attributes() %>%\n    extract(\"label\")\n```\n\nNext, attributes for the `health` and `obsrace` variables, documenting the variables and values. Here, for `health` we set this up as a factor using the sorted unique values of `health` from the CSV file. The factor is ordered and then reversed so that \"Excellent\" health has the highest value.\n\n```{r}\n# label for health\nattributes(y$health)$label <- \"General health from public Add Health Wave 1 Section 3 question 1\"\n\n# labels for health\nhealthlevels <- unique(y$health) %>%\n    sort()\n\n# values for health\nattributes(y$health)$levels <- healthlevels\n\n# create the factor \"health\" with appropriate levels, order it and reverse the levels\n#   so that Excellent is highest\ny %<>% mutate(\n    health =\n        factor(health, levels = healthlevels, ordered = TRUE) %>%\n            fct_rev()\n)\n```\n\nWe create the `obsrace` factor but because there is no inherent value hierarchy, we do not make this an ordered factor. We convert it to a factor for use in statistical models.\n\n```{r}\n# label for obsrace\nattributes(y$obsrace)$label <- \"Interviewer observation of race from public Add Health Wave 1 Section 1 question 9\"\n\n# obsrace levels\nobsracelevels <- unique(y$obsrace) %>%\n    sort()\n\n# values  for obsrace\nattributes(y$obsrace)$levels <- obsracelevels\n\n# create a factor\ny %<>% mutate(\n    obsrace = factor(obsrace, levels = obsracelevels)\n)\n```\n\nVerify these were created:\n\n```{r}\ny$health %>% attributes()\nhead(y$health)\n\ny$obsrace %>% attributes()\nhead(y$obsrace)\n```\n\nThe same caveats apply to saving the data frame to files, with respect to the various attributes and which attributes are saved and restored after a write/read cycle.\n\n## Tabulation\nWe have seen a few examples of tabulation in previous exercises (Sections \\@ref(summarizingaggregating-data), \\@ref(rmdtables), \\@ref(default-values-for-arguments)). This section will give a more complete treatment using the Add Health data as an example.\n\n### Raw counts\nThe most basic tabulations simply give the count of observations in different strata. Those strata can be based on numeric ratio or interval data, using functions such as `cut()` or `BAMMtools::getJenksBreaks()`, nominal data (such as the Add Health interviewer's observation of respondents' single race), or ordinal data (such as the self-reported health status). We will use examples of each type of data.\n\nFirst, this code will load the full Add Health data set, which includes additional variables not present in the data set we have used previously.\n\n```{r}\n# download and unzip the larger data set\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n\n# zip file in $temp -- basename gets just the file name from the URL and not the URL path;\n#   file.path stitches the tempdir() path to the file name\nzipfile <- file.path(mytempdir, basename(myUrl))\n\n# dta file in $temp\ndtafile <- tools::file_path_sans_ext(zipfile)\n\n# check if the dta file exists\nif (!file.exists(dtafile)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    if (file.exists(zipfile)) {\n        unzip(zipfile = zipfile, exdir = mytempdir)\n    }\n}\n\n# if the data set has not been read, read it in\nif (!exists(\"ahcomplete\")) {\n    ahcomplete <- haven::read_dta(dtafile)\n}\n# lowercase column names\ncolnames(ahcomplete) %<>% str_to_lower()\n```\n\nThe metadata (variable names and labels) are presented in `r table_nums(name = \"ahcompletemeta\", display = \"cite\")`.\n\n*`r table_nums(name = \"ahcompletemeta\", caption = \"Add Health large table variable names and labels\")`*\n\n```{r}\n# create a data frame of the variable names and labels\nahcomplete_metadata <- bind_cols(\n    varname = colnames(ahcomplete),\n    varlabel = ahcomplete %>% map(~ attributes(.)$label) %>% unlist()\n)\n\n# print the table with DT::datatable for interactive display\nDT::datatable(ahcomplete_metadata)\n```\n\n\\  \n\nLet's look at body mass index (BMI) data, which uses weight and height values. We find the variables representing weight and height from the metadata above. We need to determine if there are any invalid values:\n\n```{r}\nattributes(ahcomplete$h1gh59a)$labels\nattributes(ahcomplete$h1gh59b)$labels\nattributes(ahcomplete$h1gh60)$labels\n```\n\nFirst, we need to select the variables representing feet and inches, then filter out invalid heights (> 90) and weights (> 900) identified above, and finally calculate height in m, weight in kg, and BMI ($\\frac{weight}{height^2}$). For future use we will also select self-reported health and interviewer observed race as factors.\n\n```{r}\n# make the data frame\nhtwt <- ahcomplete %>%\n    # select columns\n    select(\n        feet = h1gh59a,\n        inches = h1gh59b,\n        weight_lb = h1gh60,\n        health = h1gh1,\n        obsrace = h1gi9\n    ) %>%\n    # filter for valid values\n    filter(feet < 90 & inches < 90 & weight_lb < 900) %>%\n    # calculate metric units and BMI\n    mutate(\n        height_m = (feet * 12 + inches) / 39.37008,\n        weight_kg = weight_lb / 2.205,\n        BMI = weight_kg / height_m^2\n    )\n\n# factor: get values and labels\nhealthvals <- htwt$health %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\nhealthlabs <- htwt$health %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\nracevals <- htwt$obsrace %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    as.numeric()\n\nracelabs <- htwt$obsrace %>%\n    attributes() %>%\n    extract2(\"labels\") %>%\n    names()\n\n# package the data frame up\nhtwt %<>%\n    mutate(\n        health = factor(health,\n            levels = healthvals,\n            labels = healthlabs\n        ),\n        obsrace = factor(obsrace,\n            levels = racevals,\n            labels = racelabs\n        )\n    )\n```\n\nA histogram (`r figure_nums(name = \"bmihist\", display = \"cite\")` shows the distribution of BMI for the respondents with vertical lines at the 5th and 85th percentile. This range is generally considered \"normal\" or \"healthy\" according to the CDC, although for a sample with varying age, sex, height, and weight ranges, it is difficult to interpret. Nevertheless the cut points can serve the purpose of demonstration.\n\n```{r}\n# get the 5th & 85th percentile\nbmibreaks <- quantile(x = htwt$BMI, probs = c(0.05, 0.85))\nggplot(htwt, aes(x = BMI)) +\n    geom_histogram(bins = 30) +\n    geom_vline(xintercept = bmibreaks)\n```\n\n\\    \n*`r figure_nums(name = \"bmihist\", caption = \"Histogram of BMI for Add Health cohort\")`*\n\nWe assign the BMI class using these cut points, with `cut()` breaks at the minimum, 5%, 85%, and maximum BMI, and also assign labels and set ordering:\n\n```{r}\nhtwt %<>%\n    mutate(bmiclass = cut(\n        x = BMI,\n        breaks = c(min(BMI), bmibreaks, max(BMI)),\n        labels = c(\"underweight\", \"normal\", \"overweight\"),\n        include.lowest = TRUE\n    ) %>%\n        factor(ordered = TRUE))\n```\n\nThe tabulation of count of respondents by weight class can be generated with the base R function `table()` or `dplyr` functions `group_by()` and `summarise()` (`r table_nums(name = \"bmiclass\", display = \"cite\")`.\n\n```{r}\n# base R\ntable(htwt$bmiclass, useNA = \"ifany\")\n```\n\n*`r table_nums(name = \"bmiclass\", caption = \"Count by BMI class, Add Health cohort\")`*\n\n```{r}\n# tidyR\nhtwt %>%\n    group_by(bmiclass) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(full_width = FALSE, position = \"left\", \n                  bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n```\n\nFor variables that are already nominal or ordinal factors, tabulations can be made directly. Because these were converted to factors, the correct labels will show, rather than simple numeric values. The tabulations will also be presented in descending order by label or level. Tabulation of self-reported health is in `r table_nums(name = \"healthclass\", display = \"cite\")` and by race observed by interviewer in `r table_nums(name = \"obsraceclass\", display = \"cite\")`.\n\n*`r table_nums(name = \"healthclass\", caption = \"Count by self-reported health class, Add Health cohort\")`*\n\n```{r}\nhtwt %>%\n    group_by(health) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\n```\n\n*`r table_nums(name = \"obsraceclass\", caption = \"Count by interviewer-observed race, Add Health cohort\")`*\n\n```{r}\nhtwt %>%\n    group_by(obsrace) %>%\n    summarise(n = n()) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\n```\n\n### Proportions/percentages\nProportions and percentages can be added to tabulations for greater interpretability. Using base R, the `prop_table()` function can be used as a wrapper around `table()` to generate proportions, optionally multiplying by 100 to generate a percentage. Remember to round as needed. For example:\n\n```{r}\nround(prop.table(table(htwt$bmiclass)), 2)\n\nround(prop.table(table(htwt$bmiclass)) * 100, 0)\n```\n\nNot surprisingly, the BMI classes show 5% underweight and 15% overweight, because that is how the stratification was defined.\n\nThe `tidyR` version requires a bit more coding but provides a more readable output. Because the percent sign is a special character, we enclose it in back ticks, ``%``. Here we generate a tabulation of observed race (`r table_nums(name = \"obsraceclass\", display = \"cite\")`).\n\n*`r table_nums(name = \"obsraceclasspct\", caption = \"Count by interviewer-observed race, Add Health cohort\")`*\n\n```{r}\nhtwt %>%\n    group_by(obsrace) %>%\n    summarise(n = n()) %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\n```\n\n### Stratified tabulation\nTabulations can be generated using multiple variables. Here we will examine BMI and race as well as BMI and health. The percentages sum to 100 based on the order of the grouping.\n\nHere, we see the relative percent of underweight, normal, and overweight within each race class (`r table_nums(name = \"obsracebmiclass\", display = \"cite\")`).\n\n*`r table_nums(name = \"obsracebmiclass\", caption = \"Count by interviewer-observed race and BMI class, Add Health cohort\")`*\n\n```{r}\nhtwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    )\n```\n\nThe table can also be presented with grouped rows. This code generates a named\nvector of the count of observed race by BMI class\n\n```{r}\n# create the row groupings\n(obsrace <- htwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    deframe())\n```\n\nThe groups are then used in the `pack_rows()` function for grouped rows (`r table_nums(name = \"obsracebmiclasspct\", display = \"cite\")`).\n\n*`r table_nums(name = \"obsracebmiclasspct\", caption = \"Count by interviewer-observed race and BMI class, Add Health cohort, percent by race\")`*\n\n```{r}\nhtwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>% \n    kable %>% \n    kable_styling(\n        full_width = FALSE, position = \"left\",\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n    ) %>% \n    pack_rows(index = obsrace)    \n```\n\n\nAnd here we see the relative percent of different race groups within each BMI class (`r table_nums(name = \"obsbmiraceclasspct\", display = \"cite\")`. \n\n*`r table_nums(name = \"obsbmiraceclasspct\", caption = \"Count by interviewer-observed race and BMI class, Add Health cohort, percent by BMI class\")`*\n\n```{r}\nhtwt %>%\n    group_by(\n        bmiclass,\n        obsrace\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    mutate(`%` = `%` %>% round(1)) %>%\n    kable() %>%\n    kable_styling(full_width = FALSE, position = \"left\",\n                          bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")\n)\n```\n\nEven though the `n` values are the same in the two tables (e.g., underweight $\\times$ White n = `r htwt %>% filter(str_detect(obsrace, \"White\") & str_detect(bmiclass, \"under\")) %>% nrow()`), the percentages are different due to grouping. That is, the percent of underweight persons among the White race stratum is different from the percent of White persons within the underweight stratum. Proper grouping is critical to answer specific questions about the data.\n\nAnother way to understand the data, preferred by some, would be to make a graph. For example, BMI by race as a facet grid bar graph (`r `figure_nums(name = \"bmibarfacet\", display = \"cite\")`).\n\n```{r}\nbmi_race <- htwt %>%\n    group_by(\n        obsrace,\n        bmiclass\n    ) %>%\n    summarise(n = n(), .groups = \"drop_last\") %>%\n    mutate(`%` = n / sum(n) * 100) %>%\n    filter(!str_detect(obsrace, regex(\"refused|know\", ignore_case = TRUE)))\n\nggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n    facet_grid(~obsrace) +\n    xlab(\"BMI class\")\n```\n\n\\    \n\n*`r figure_nums(name = \"bmibarfacet\", caption = \"BMI class by race, Add Health cohort\")`*\n\nOr as a stacked bar graph (`r figure_nums(name = \"bmibarstack\", display = \"cite\")`)\n\n```{r}\nggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    scale_fill_discrete(name = \"BMI class\") +\n    xlab(\"observed race\")\n    #theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n```\n\n\\    \n*`r figure_nums(name = \"bmibarstack\", caption = \"BMI class by race, Add Health cohort\")`*\n\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week8.html","id":"week8","chapter":"8 Week 8","heading":"8 Week 8","text":"week’s lesson provide background variable creation scale scoring. scale scoring exercise used create single variable represents well respondents overall subset questions.First, download template file save course working folder week_08.Rmd. Make changes title author see fit. Also load following packages:","code":"pacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)"},{"path":"week8.html","id":"scale-scoring","chapter":"8 Week 8","heading":"8.1 Scale scoring","text":"using data Knowledge Quiz. Download open 21600-0001-Codebook_Questionnaire.pdf new window tab go page 203, search string Section 19: Knowledge Quiz.using file AHwave1_v1.dta, downloaded read following code chunk, along presentation column names, labels, values Table 1.Table 1: Metadata AHwave1_v1.dtaQuestions H1KQ1A, H1KQ2A, …, H1KQ10A factual questions contraception administered participants \\(\\ge\\) age 15. creating single score sums correct answers across questions participant \\(\\ge\\) age 15. set questions paired, question “” factual portion “b” level confidence, want questions column names ending “.”","code":"\ndat <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\nmetadata <- bind_cols(\n    # variable name\n    varname = colnames(dat),\n    # label\n    varlabel = lapply(dat, function(x) attributes(x)$label) %>% \n        unlist(),\n    # values\n    varvalues = lapply(dat, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(metadata)"},{"path":"week8.html","id":"selecting-specific-columns","chapter":"8 Week 8","heading":"8.1.1 Selecting specific columns","text":"several ways selecting desired columns new data frame. two immediate objectives: filter greater 15 years age, select desired columns.age cutoff can seen value labels, show responses H1KQ1a value 7 represent less 15 years old.brute force approach filter select:Although 10 columns name pattern, 30 50? want enter column name separately. tedious, always possibility making keyboarding mistake.Instead brute force approach, can use matches() function regular expression. regular expression ^h1kq.*$, translates “start string, match h1kq, number characters, followed end string.”check processes yielded result:","code":"\nattributes(dat$h1kq1a)$labels##                           (1) True     (2) False <the correct answer> \n##                                  1                                  2 \n##                        (6) Refused (7) Legitimate skip (less than 15) \n##                                  6                                  7 \n##                     (8) Don't know                 (9) Not applicable \n##                                  8                                  9\n# create a data frame of some columns and age >= 15\nmydat_bruteforce <- dat %>% \n    # drop those under 15 y\n    filter(h1kq1a != 7) %>% \n    # get answers\n    select(\n        aid, # subject ID\n        h1kq1a,\n        h1kq2a,\n        h1kq3a,\n        h1kq4a,\n        h1kq5a,\n        h1kq6a,\n        h1kq7a,\n        h1kq8a,\n        h1kq9a,\n        h1kq10a\n    )\nmydat <- dat %>% \n    filter(h1kq1a != 7) %>% \n    select(\n        aid,\n        matches(\"h1kq.*a\")\n    )\nidentical(mydat_bruteforce, mydat)## [1] TRUE"},{"path":"week8.html","id":"comparing-participant-answers-to-correct-answers","chapter":"8 Week 8","heading":"8.1.2 Comparing participant answers to correct answers","text":"Now data frame limited participants correct age range questions want, need set tests whether questions answered correctly . metadata can see questions, correct answer (1) true , correct answer (2) false.need look questions metadata create vector correct answers. example, PDF see correct answer H1KQ1A (2) false.now need compare vector vector constructed answers mydat. approaches taken. brute force approach use loop iterate record answers, record iterate answer. need iterate nrow mydat rows ncol(mydat) - 1 columns.took 23.4 s run. low performance algorithm visiting every cell comparing one--rotating value correct answer vector correct answers. object required handled separately RAM process continues.Another approach uses plyr::adply(), runs function set rows. plyr package contains set tools splitting data, applying functions, recombining.adply() version takes far less coding, still took 22.9 s run.Yet another different approach compares data frame participant answers vector correct answers. correct answers vector get recycled values processed. problem method comparison runs columns rather across rows.following hypothetical data set demonstrates problem. Table 2 shows pattern “correct” values, Table 3 shows table responses.Table 2: pattern “correct” values\nTable 8.1: pattern “correct” values\nTable 3: table responses\nTable 8.2: table responses\ncan test whether pattern correct answers (pat1) matches first row data (d1[1,]). first row data seems match: Table 4.Table 4: Matches first row\nTable 8.3: Matches first row\nNext test whether pattern matches entire table (d1 == pat1). patterns match overall table might expected (Table 5).Table 5: Unexpected pattern matches\nTable 8.4: Unexpected pattern matches\norder match pattern row, transpose required. following code performs transpose, pattern match, re-transpose, results Table 6.Table 6: Expected pattern matches\nTable 8.5: Expected pattern matches\ntrick use transpose (t()) swap rows columns. unlist() enforce correct ordering. running comparison, data transposed recreate original structure.method took 0.01 s complete.Yet another method similarly uses double transpose method.method took 0.01 s complete.Finally, use tidyverse approach, using pmap() purrr. commands shown series step demonstrated separately. First use pmap(~c(...)) effectively creates list element vector answers single row, .e., list element responses single participant. drop aid column present correct answers. Also head() run first 6 rows.use pmap(~c(...)==correct) compare participant’s answers correct answers, resulting list element whether participant’s answers correct (also running first 6 records).wrap things , run entire data set, converting output matrix.pmap() method took 15.361 seconds run, much better methods.Finally, use base::sweep() method, can used compare vector rows columns data frame. order use function, data frame needs number rows (columns) comparison vector. additional rows columns need stripped. may additional columns (e.g., aid), must removed running sweep(), added back . Additionally, result sweep() matrix, needs converted data frame greater functionality.sweep() method took 0.014 s.check methods gave identical answers. compares ans_loop outputs methods (Table 7). exercise intended show frequently many different ways achieve end goal, methods efficient others. One can always take subset data test different methods fastest run times running time-consuming process complete data set.Table 7: Run times row-matching correct answers","code":"\n# the correct answers from viewing the metadata\ncorrect <- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) \n\n# make a named vector of the answers using the selected column names\nnames(correct) <- str_subset(string = names(mydat),\n                             pattern = \"h1kq.*a\")\n\nprint(correct)##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       2       1       2       2       2       2       2       1       2       2\n# time this\nt0 <- Sys.time()\n\n# make an output\nans_loop <- NULL\n\n# iterate over rows\n#testing:\n#for(i in 1:3){ \nfor(i in 1:nrow(mydat)){\n    # init a vector\n    Q <- NULL\n    # iterate over columns, ignoring the first \"aid\" column\n    for(j in 2:ncol(mydat)){\n        # get the value of the answer\n        ans_subj <- mydat[i, j]\n        # get the correct answer\n        ans_actual <- correct[j - 1]\n        # compare\n        cmp <- ans_actual == ans_subj\n        # append\n        Q <- c(Q, cmp)\n    }\n    # append\n    ans_loop <- rbind(ans_loop, Q)\n}\n\n# package it up nicely\nans_loop %<>% data.frame()\ncolnames(ans_loop) <- names(correct)\nrow.names(ans_loop) <- NULL\n\n# timing\nt1 <- Sys.time()\nruntime_loop <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n# time this\nt0 <- Sys.time()\n\nans_adply <- mydat %>% \n    select(-1) %>% \n    plyr::adply(.margins = 1, \n                function(x) x == correct)\n\n# add the aid column\nans_adply <- data.frame(aid = mydat$aid, ans_adply)\n\nt1 <- Sys.time()\nruntime_adply <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n# make a pattern to match against\npat1 <- c(1, 2, 3, 4)\nnames(pat1) <- paste(\"question\", 1:4, sep=\"_\")\n\npat1 %>% \n    t() %>% \n    data.frame() %>% \n    kable(caption = 'A pattern of \"correct\" values') %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n# make a data frame to process\nd1 <- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %>% \n    data.frame()\nnames(d1) <- names(pat1)\n\nd1 %>% \n    kable(caption = \"A table of responses\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n(pat1 == d1[1,]) %>% \n    kable(caption = \"Matches for the first row\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n(d1 == pat1) %>% \n    kable(caption = \"Unexpected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n# transpose, check for matching and transpose back\n(d1 %>% t() == pat1) %>% \n    t() %>% \n    kable(caption = \"Expected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n# time this\nt0 <- Sys.time()\n# transpose and compare\nans_unlist <- mydat %>%\n    select(-1) %>% \n    t(.) %>% \n    unlist(.) == correct\n\n# re-transpose and make a data frame\nans_unlist %<>% \n    t(.) %>% \n    data.frame()\n\n# column names\ncolnames(ans_unlist) <- names(correct)\n\n# aid\nans_unlist %<>% \n    mutate(aid = mydat$aid) %>% \n    select(aid, everything())\n\nt1 <- Sys.time()\nruntime_unlist <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n# time this\nt0 <- Sys.time()\n# strip the ID column and transpose\nz <- mydat %>% \n    select(-1) %>% \n    t() \n\n# compare, transpose, and make a data frame\nans_tranpose <- (z == correct) %>% \n    t(.) %>% \n    data.frame() %>% \n    mutate(aid = mydat$aid) %>% \n    select(aid, everything())    \n\nt1 <- Sys.time()\nruntime_transpose <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\nmydat %>% \n    select(-aid) %>% \n    head() %>% \n    pmap(~c(...))## [[1]]\n## <labelled<double>[10]>: S19Q1A SPERM DIES W/I 6 HOURS-W1\n##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       2       2       1       2       1       1       1       1       2       8 \n## \n## Labels:\n##  value                              label\n##      1                           (1) True\n##      2     (2) False <the correct answer>\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\n## \n## [[2]]\n## <labelled<double>[10]>: S19Q1A SPERM DIES W/I 6 HOURS-W1\n##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       2       2       1       1       2       2       2       1       2       2 \n## \n## Labels:\n##  value                              label\n##      1                           (1) True\n##      2     (2) False <the correct answer>\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\n## \n## [[3]]\n## <labelled<double>[10]>: S19Q1A SPERM DIES W/I 6 HOURS-W1\n##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       1       1       1       8       1       2       1       1       2       1 \n## \n## Labels:\n##  value                              label\n##      1                           (1) True\n##      2     (2) False <the correct answer>\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\n## \n## [[4]]\n## <labelled<double>[10]>: S19Q1A SPERM DIES W/I 6 HOURS-W1\n##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       2       2       2       2       2       1       1       1       2       1 \n## \n## Labels:\n##  value                              label\n##      1                           (1) True\n##      2     (2) False <the correct answer>\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\n## \n## [[5]]\n## <labelled<double>[10]>: S19Q1A SPERM DIES W/I 6 HOURS-W1\n##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       2       2       1       2       2       2       2       2       2       1 \n## \n## Labels:\n##  value                              label\n##      1                           (1) True\n##      2     (2) False <the correct answer>\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\n## \n## [[6]]\n## <labelled<double>[10]>: S19Q1A SPERM DIES W/I 6 HOURS-W1\n##  h1kq1a  h1kq2a  h1kq3a  h1kq4a  h1kq5a  h1kq6a  h1kq7a  h1kq8a  h1kq9a h1kq10a \n##       2       1       1       2       2       2       2       1       2       1 \n## \n## Labels:\n##  value                              label\n##      1                           (1) True\n##      2     (2) False <the correct answer>\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\nmydat %>% \n    select(-aid) %>% \n    head() %>% \n    pmap(~c(...)==correct)## [[1]]\n##  [1]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE\n## \n## [[2]]\n##  [1]  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n## \n## [[3]]\n##  [1] FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE\n## \n## [[4]]\n##  [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE\n## \n## [[5]]\n##  [1]  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n## \n## [[6]]\n##  [1]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\nt0 <- Sys.time()\nans_pmap <- mydat %>% \n    select(-aid) %>% \n    pmap(~c(...)==correct) %>% \n    do.call(\"rbind\", .) %>% \n    data.frame()\n# column names from mydat without the \"aid\" column\nnames(ans_pmap) <- names(mydat)[2:ncol(mydat)]\nt1 <- Sys.time()\nruntime_pmap <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\nt0 <- Sys.time()\nans_sweep <- mydat %>%\n    # drop the aid column\n    select(-aid) %>% \n    # run the sweep\n    sweep(x = ., MARGIN = 2, STATS = correct, FUN = \"==\") %>% \n    # convert to data frame\n    data.frame()\nt1 <- Sys.time()\nruntime_sweep <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\n# make a data frame summarizing the results of each method\n# methods\nmethod <- c(\"loop\", \"adply\", \"transpose\", \"unlist\", \"pmap\")\n# run times\nrun_time <- c(runtime_loop, runtime_adply, runtime_transpose, runtime_unlist, runtime_pmap) %>% round(2)\n# comparisons\nmatch <- Vectorize(identical, 'x')(list(ans_loop, ans_adply, ans_tranpose, ans_unlist, ans_pmap), ans_loop)\n\n# a single data frame\ncomparisons <- data.frame(method, run_time, match) %>% \n    arrange(run_time)\n\n# print\ncomparisons %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") "},{"path":"week8.html","id":"scoring-across-columns","chapter":"8 Week 8","heading":"8.1.3 Scoring across columns","text":"Now data frame indicating participant whether answered question correctly, can total number correct answers participant. rowSums() function allows sums across rows. logical values automatically converted numerical values (TRUE = 1; FALSE = 0), sums provide total number correct answers per participant. Also data frame consists answers 1 .. 10, can use unqualified rowSums(), otherwise necessary specify columns included either position column name.also bring subject identifier (aid) back reorder columns select(). Note specified aid total h1kqNa_sum columns, can use everything() select remainder columns.show differences total score sex, can join main data back using aid identifier create simple graph. Figure 8.1 shows females males overall higher counts correct scores Knowledge Quiz.\nFigure 8.1: Histogram count correct answers Knowledge Quiz stratified sex respondent\n","code":"\nans_loop %<>%\n    # calculate the rowSums\n    mutate(h1kqNa_sum = rowSums(.)) %>% \n    # bring the ID back in\n    mutate(aid = mydat$aid) %>% \n    # reorder columns\n    select(aid, h1kqNa_sum, everything())\nans_loop %<>% \n    left_join(dat, by = \"aid\") %>% \n    mutate(\n        sex = case_when(\n            bio_sex == 1 ~ 'male',\n            bio_sex == 2 ~ 'female'\n        )\n    )\n\nggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+\n    geom_bar() +\n    facet_grid(sex ~ .) + \n    xlab(\"correct answers on Knowledge Quiz\") +\n    scale_x_continuous(breaks=0:10)"},{"path":"week8.html","id":"reordering-values","chapter":"8 Week 8","heading":"8.2 Reordering values","text":"Sometimes variables provided reverse order might want. example, answers pertaining confidence Knowledge Quiz specific order:come scale score , better valued 4 1 row-wise sums yield higher values confident many answers (ignoring answers scaled, .e., refused, skipped, don’t know, applicable). One use existing values, interpretation overall confidence score might difficult, confidence lowest overall score.Changing values quite straightforward. case_when() function can used. case_when() uses structure var == input_value ~ output_value, var column name, input_value selected value, output_value reassigned value. additional cases addressed specifically can handled TRUE ~ output_value.Let’s see values look like now. first records reordering:… first records reordering:bit awkward perform kind reordering operation multiple columns. One might tempted use brute force method copy/paste/edit large set case_when() functions column, tedious error-prone.Using mutate_at() function can help use regular expression pattern matching column names. function performed multiple columns. use similar regular expression find columns representing confidence answers Knowledge Quiz (h1kq.*b = “starts h1kq, numbner characters, b”) perform operation columns names matching regular expression pattern. use dot (.) shorthand “current object” case specified column virtual loop columns matching name pattern.sake comparison show single bit code acted multiple columns. Two variables shown Table 8, frequencies original confidence values (orig) reordered confidence values (modified).Table 8: Confidence correctness answerFor example, original value 1 count 1070 transformed value 4 count. Now values reordered, can used multiple-column scale scoring demonstrated .Rendered 2022-03-04 00:45:48","code":"\nattributes(dat$h1kq1b)$labels %>% t() %>% t() %>% data.frame()##                                    .\n## (1) Very                           1\n## (2) Moderately                     2\n## (3) Slightly                       3\n## (4) Not at all                     4\n## (6) Refused                        6\n## (7) Legitimate skip (less than 15) 7\n## (8) Don't know                     8\n## (9) Not applicable                 9\n# for comparison, make a backup data frame\ndatbak <- dat2 <- dat\n\n# reassign values\ndat %<>% \n    mutate(h1kq1b = \n               case_when(\n                   # main changes\n                   h1kq1b == 4 ~ 1,\n                   h1kq1b == 3 ~ 2,\n                   h1kq1b == 2 ~ 3,\n                   h1kq1b == 1 ~ 4,\n                   # anything that is not in the above list gets its original value\n                   TRUE ~ as.numeric(h1kq1b))\n               )\nhead(datbak$h1kq1b)## <labelled<double>[6]>: S19Q1B CONFIDENT 1A IS CORRECT-W1\n## [1] 1 3 2 3 1 7\n## \n## Labels:\n##  value                              label\n##      1                           (1) Very\n##      2                     (2) Moderately\n##      3                       (3) Slightly\n##      4                     (4) Not at all\n##      6                        (6) Refused\n##      7 (7) Legitimate skip (less than 15)\n##      8                     (8) Don't know\n##      9                 (9) Not applicable\nhead(dat$h1kq1b)## [1] 4 2 3 2 4 7\ndat2 %<>% \n    mutate_at(.vars = vars(matches(\"h1kq.*b\")),\n             list(\n                  ~case_when(\n                      . == 4 ~ 1,\n                      . == 3 ~ 2,\n                      . == 2 ~ 3,\n                      . == 1 ~ 4,\n                      TRUE ~ as.numeric(.)\n                  )\n             )   \n    )\norig1 <- table(datbak$h1kq1b) %>% data.frame()\n\nmod1 <- table(dat$h1kq1b) %>% data.frame()\n\norig2 <- table(datbak$h1kq2b) %>% data.frame()\n\nmod2 <- table(dat$h1kq2b) %>% data.frame()\nreordered <- cbind(orig1, mod1, orig2, mod2)\n\nreordered %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") %>% \n    add_header_above(rep(c(\"original\" = 2, \"modified\" = 2), 2)) %>% \n    add_header_above(c(\"h1kq1b\" = 4, \"h1kq2b\" = 4))"},{"path":"week8.html","id":"source-code-8","chapter":"8 Week 8","heading":"8.3 Source code","text":"File H:/csde502-winter-2022-main/08-week08.Rmd.","code":""},{"path":"week8.html","id":"r-code-used-in-this-document-8","chapter":"8 Week 8","heading":"8.3.1 R code used in this document","text":"","code":"\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n} else {\n    fnamepath <- \"\"\n}\ndat <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\nmetadata <- bind_cols(\n    # variable name\n    varname = colnames(dat),\n    # label\n    varlabel = lapply(dat, function(x) attributes(x)$label) %>% \n        unlist(),\n    # values\n    varvalues = lapply(dat, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(metadata)\nattributes(dat$h1kq1a)$labels\n# create a data frame of some columns and age >= 15\nmydat_bruteforce <- dat %>% \n    # drop those under 15 y\n    filter(h1kq1a != 7) %>% \n    # get answers\n    select(\n        aid, # subject ID\n        h1kq1a,\n        h1kq2a,\n        h1kq3a,\n        h1kq4a,\n        h1kq5a,\n        h1kq6a,\n        h1kq7a,\n        h1kq8a,\n        h1kq9a,\n        h1kq10a\n    )\nmydat <- dat %>% \n    filter(h1kq1a != 7) %>% \n    select(\n        aid,\n        matches(\"h1kq.*a\")\n    )\nidentical(mydat_bruteforce, mydat)\n# the correct answers from viewing the metadata\ncorrect <- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) \n\n# make a named vector of the answers using the selected column names\nnames(correct) <- str_subset(string = names(mydat),\n                             pattern = \"h1kq.*a\")\n\nprint(correct)\n# time this\nt0 <- Sys.time()\n\n# make an output\nans_loop <- NULL\n\n# iterate over rows\n#testing:\n#for(i in 1:3){ \nfor(i in 1:nrow(mydat)){\n    # init a vector\n    Q <- NULL\n    # iterate over columns, ignoring the first \"aid\" column\n    for(j in 2:ncol(mydat)){\n        # get the value of the answer\n        ans_subj <- mydat[i, j]\n        # get the correct answer\n        ans_actual <- correct[j - 1]\n        # compare\n        cmp <- ans_actual == ans_subj\n        # append\n        Q <- c(Q, cmp)\n    }\n    # append\n    ans_loop <- rbind(ans_loop, Q)\n}\n\n# package it up nicely\nans_loop %<>% data.frame()\ncolnames(ans_loop) <- names(correct)\nrow.names(ans_loop) <- NULL\n\n# timing\nt1 <- Sys.time()\nruntime_loop <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n# time this\nt0 <- Sys.time()\n\nans_adply <- mydat %>% \n    select(-1) %>% \n    plyr::adply(.margins = 1, \n                function(x) x == correct)\n\n# add the aid column\nans_adply <- data.frame(aid = mydat$aid, ans_adply)\n\nt1 <- Sys.time()\nruntime_adply <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n# make a pattern to match against\npat1 <- c(1, 2, 3, 4)\nnames(pat1) <- paste(\"question\", 1:4, sep=\"_\")\n\npat1 %>% \n    t() %>% \n    data.frame() %>% \n    kable(caption = 'A pattern of \"correct\" values') %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n# make a data frame to process\nd1 <- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %>% \n    data.frame()\nnames(d1) <- names(pat1)\n\nd1 %>% \n    kable(caption = \"A table of responses\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n(pat1 == d1[1,]) %>% \n    kable(caption = \"Matches for the first row\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n(d1 == pat1) %>% \n    kable(caption = \"Unexpected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n# transpose, check for matching and transpose back\n(d1 %>% t() == pat1) %>% \n    t() %>% \n    kable(caption = \"Expected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n# time this\nt0 <- Sys.time()\n# transpose and compare\nans_unlist <- mydat %>%\n    select(-1) %>% \n    t(.) %>% \n    unlist(.) == correct\n\n# re-transpose and make a data frame\nans_unlist %<>% \n    t(.) %>% \n    data.frame()\n\n# column names\ncolnames(ans_unlist) <- names(correct)\n\n# aid\nans_unlist %<>% \n    mutate(aid = mydat$aid) %>% \n    select(aid, everything())\n\nt1 <- Sys.time()\nruntime_unlist <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n# time this\nt0 <- Sys.time()\n# strip the ID column and transpose\nz <- mydat %>% \n    select(-1) %>% \n    t() \n\n# compare, transpose, and make a data frame\nans_tranpose <- (z == correct) %>% \n    t(.) %>% \n    data.frame() %>% \n    mutate(aid = mydat$aid) %>% \n    select(aid, everything())    \n\nt1 <- Sys.time()\nruntime_transpose <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\nmydat %>% \n    select(-aid) %>% \n    head() %>% \n    pmap(~c(...))\nmydat %>% \n    select(-aid) %>% \n    head() %>% \n    pmap(~c(...)==correct)\nt0 <- Sys.time()\nans_pmap <- mydat %>% \n    select(-aid) %>% \n    pmap(~c(...)==correct) %>% \n    do.call(\"rbind\", .) %>% \n    data.frame()\n# column names from mydat without the \"aid\" column\nnames(ans_pmap) <- names(mydat)[2:ncol(mydat)]\nt1 <- Sys.time()\nruntime_pmap <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\nt0 <- Sys.time()\nans_sweep <- mydat %>%\n    # drop the aid column\n    select(-aid) %>% \n    # run the sweep\n    sweep(x = ., MARGIN = 2, STATS = correct, FUN = \"==\") %>% \n    # convert to data frame\n    data.frame()\nt1 <- Sys.time()\nruntime_sweep <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\n# make a data frame summarizing the results of each method\n# methods\nmethod <- c(\"loop\", \"adply\", \"transpose\", \"unlist\", \"pmap\")\n# run times\nrun_time <- c(runtime_loop, runtime_adply, runtime_transpose, runtime_unlist, runtime_pmap) %>% round(2)\n# comparisons\nmatch <- Vectorize(identical, 'x')(list(ans_loop, ans_adply, ans_tranpose, ans_unlist, ans_pmap), ans_loop)\n\n# a single data frame\ncomparisons <- data.frame(method, run_time, match) %>% \n    arrange(run_time)\n\n# print\ncomparisons %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") \nans_loop %<>%\n    # calculate the rowSums\n    mutate(h1kqNa_sum = rowSums(.)) %>% \n    # bring the ID back in\n    mutate(aid = mydat$aid) %>% \n    # reorder columns\n    select(aid, h1kqNa_sum, everything())\nans_loop %<>% \n    left_join(dat, by = \"aid\") %>% \n    mutate(\n        sex = case_when(\n            bio_sex == 1 ~ 'male',\n            bio_sex == 2 ~ 'female'\n        )\n    )\n\nggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+\n    geom_bar() +\n    facet_grid(sex ~ .) + \n    xlab(\"correct answers on Knowledge Quiz\") +\n    scale_x_continuous(breaks=0:10)\nattributes(dat$h1kq1b)$labels %>% t() %>% t() %>% data.frame()\n# for comparison, make a backup data frame\ndatbak <- dat2 <- dat\n\n# reassign values\ndat %<>% \n    mutate(h1kq1b = \n               case_when(\n                   # main changes\n                   h1kq1b == 4 ~ 1,\n                   h1kq1b == 3 ~ 2,\n                   h1kq1b == 2 ~ 3,\n                   h1kq1b == 1 ~ 4,\n                   # anything that is not in the above list gets its original value\n                   TRUE ~ as.numeric(h1kq1b))\n               )\nhead(datbak$h1kq1b)\nhead(dat$h1kq1b)\ndat2 %<>% \n    mutate_at(.vars = vars(matches(\"h1kq.*b\")),\n             list(\n                  ~case_when(\n                      . == 4 ~ 1,\n                      . == 3 ~ 2,\n                      . == 2 ~ 3,\n                      . == 1 ~ 4,\n                      TRUE ~ as.numeric(.)\n                  )\n             )   \n    )\norig1 <- table(datbak$h1kq1b) %>% data.frame()\n\nmod1 <- table(dat$h1kq1b) %>% data.frame()\n\norig2 <- table(datbak$h1kq2b) %>% data.frame()\n\nmod2 <- table(dat$h1kq2b) %>% data.frame()\nreordered <- cbind(orig1, mod1, orig2, mod2)\n\nreordered %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") %>% \n    add_header_above(rep(c(\"original\" = 2, \"modified\" = 2), 2)) %>% \n    add_header_above(c(\"h1kq1b\" = 4, \"h1kq2b\" = 4))\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"week8.html","id":"complete-rmd-code-8","chapter":"8 Week 8","heading":"8.3.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Week 8 {#week8}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- current_input(dir = TRUE)\n} else {\n    fnamepath <- \"\"\n}\n```\n\n<h2>Topic: Add Health data: variable creation and scale scoring<\/h2>\nThis week's lesson will provide more background on variable creation and scale scoring. The scale scoring exercise will be used to create a single variable that represents how well respondents did overall on a subset of questions.\n\nFirst, download the [template file](https://raw.githubusercontent.com/CSDE-UW/csde502-winter-2022/master/docs/files/template.Rmd) and save it in your course working folder as `week_08.Rmd`. Make changes to the title and author as you see fit. Also load the following packages:\n\n```\npacman::p_load(\n    tidyverse,\n    magrittr,\n    knitr,\n    kableExtra,\n    haven,\n    pdftools,\n    curl,\n    ggplot2,\n    captioner\n)\n```\n\n## Scale scoring\nWe will be using data from the Knowledge Quiz. Download or open [21600-0001-Codebook_Questionnaire.pdf](http://staff.washington.edu/phurvitz/csde502_winter_2021/data/metadata/Wave1_Comprehensive_Codebook/21600-0001-Codebook_Questionnaire.pdf) in a new window or tab and go to page 203, or search for the string `Section 19: Knowledge Quiz`.\n\nWe will be using the file `AHwave1_v1.dta`, which is downloaded and read in the following code chunk, along with presentation of the column names, labels, and values in `r table_nums(name = \"metadata\", display = \"cite\")`.\n\n*`r table_nums(name = \"metadata\", caption = \"Metadata for AHwave1_v1.dta\")`*\n\n```{r}\ndat <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\nmetadata <- bind_cols(\n    # variable name\n    varname = colnames(dat),\n    # label\n    varlabel = lapply(dat, function(x) attributes(x)$label) %>% \n        unlist(),\n    # values\n    varvalues = lapply(dat, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(metadata)\n```\n\nQuestions `H1KQ1A`, `H1KQ2A`, ..., `H1KQ10A` are factual questions about contraception that are administered to participants $\\ge$ age 15. We will be creating a single score that sums up all the correct answers across these questions for each participant $\\ge$ age 15. Because the set of questions is paired, with question \"a\" being the factual portion and \"b\" being the level of confidence, we want only those questions with column names ending with \"a\".\n\n### Selecting specific columns\nThere are several ways of selecting the desired columns into a new data frame. There are two immediate objectives: filter for only those greater than 15 years of age, and select the desired columns.\n\nThe age cutoff can be seen in the value labels, which show that responses to `H1KQ1a` of value `7` represent those who are less than 15 years old.\n\n```{r}\nattributes(dat$h1kq1a)$labels\n```\n\nHere is brute force approach to the filter and select:\n\n```{r}\n# create a data frame of some columns and age >= 15\nmydat_bruteforce <- dat %>% \n    # drop those under 15 y\n    filter(h1kq1a != 7) %>% \n    # get answers\n    select(\n        aid, # subject ID\n        h1kq1a,\n        h1kq2a,\n        h1kq3a,\n        h1kq4a,\n        h1kq5a,\n        h1kq6a,\n        h1kq7a,\n        h1kq8a,\n        h1kq9a,\n        h1kq10a\n    )\n```\n\nAlthough there were only 10 columns with this name pattern, what if there had been 30 or 50? You would not want to have to enter each column name separately. Not only would this be tedious, there would always be the possibility of making a keyboarding mistake.\n\nInstead of the brute force approach, we can use the `matches()` function with a regular expression. The regular expression here is `^h1kq.*a$`, which translates to \"at the start of the string, match `h1kq`, then any number of any characters, then `a` followed by the end of the string\".\n\n```{r}\nmydat <- dat %>% \n    filter(h1kq1a != 7) %>% \n    select(\n        aid,\n        matches(\"h1kq.*a\")\n    )\n```\n\nWe check that both processes yielded the same result:\n\n```{r}\nidentical(mydat_bruteforce, mydat)\n```\n\n### Comparing participant answers to correct answers\n\nNow that we have a data frame limited to the participants in the correct age range and only the questions we want, we need to set up tests for whether the questions were answered correctly or not. From the metadata we can see that for some questions, the correct answer was `(1) true` and for some, the correct answer was `(2) false`.\n\nWe need to look at questions in the metadata to create a vector of correct answers. For example, in the PDF see that the correct answer for `H1KQ1A` was `(2) false`. \n\n```{r}\n# the correct answers from viewing the metadata\ncorrect <- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) \n\n# make a named vector of the answers using the selected column names\nnames(correct) <- str_subset(string = names(mydat),\n                             pattern = \"h1kq.*a\")\n\nprint(correct)\n```\n\nWhat we now need to do is compare this vector to a vector constructed of the answers in `mydat`. There are a few approaches that could be taken. A brute force approach could use a loop to iterate over each record in the answers, and for each record to iterate over each answer. This would need to iterate over `nrow mydat` rows and `ncol(mydat)` - 1 columns.\n\n```{r}\n# time this\nt0 <- Sys.time()\n\n# make an output\nans_loop <- NULL\n\n# iterate over rows\n#testing:\n#for(i in 1:3){ \nfor(i in 1:nrow(mydat)){\n    # init a vector\n    Q <- NULL\n    # iterate over columns, ignoring the first \"aid\" column\n    for(j in 2:ncol(mydat)){\n        # get the value of the answer\n        ans_subj <- mydat[i, j]\n        # get the correct answer\n        ans_actual <- correct[j - 1]\n        # compare\n        cmp <- ans_actual == ans_subj\n        # append\n        Q <- c(Q, cmp)\n    }\n    # append\n    ans_loop <- rbind(ans_loop, Q)\n}\n\n# package it up nicely\nans_loop %<>% data.frame()\ncolnames(ans_loop) <- names(correct)\nrow.names(ans_loop) <- NULL\n\n# timing\nt1 <- Sys.time()\nruntime_loop <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n```\n\nIt took `r runtime_loop` s to run. This low performance is because the algorithm is visiting every cell and comparing one-by-on with a rotating value for the correct answer from the vector of correct answers. Each object is required to be handled separately in RAM as the process continues.\n\nAnother approach uses `plyr::adply()`, which runs a function over a set of rows. The [`plyr`](https://www.rdocumentation.org/packages/plyr/) package contains a set of tools for splitting data, applying functions, and recombining.\n\n```{r}\n# time this\nt0 <- Sys.time()\n\nans_adply <- mydat %>% \n    select(-1) %>% \n    plyr::adply(.margins = 1, \n                function(x) x == correct)\n\n# add the aid column\nans_adply <- data.frame(aid = mydat$aid, ans_adply)\n\nt1 <- Sys.time()\nruntime_adply <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n```\n\nThe `adply()` version takes far less coding, but still took `r runtime_adply` s to run.\n\nYet another different approach compares the data frame of participant answers to the vector of correct answers. The correct answers vector will get recycled until all values have been processed. The problem with this method is that the comparison runs down columns rather than across rows. \n\nThe following hypothetical data set demonstrates the problem. `r table_nums(name = \"pat1vector\", display = \"cite\")` shows a pattern of \"correct\" values, and `r table_nums(name = \"d1dataframe\", display = \"cite\")` shows a table of responses.\n\n*`r table_nums(name = \"pat1vector\", caption = 'A pattern of \"correct\" values')`*\n\n```{r pat1vector}\n# make a pattern to match against\npat1 <- c(1, 2, 3, 4)\nnames(pat1) <- paste(\"question\", 1:4, sep=\"_\")\n\npat1 %>% \n    t() %>% \n    data.frame() %>% \n    kable(caption = 'A pattern of \"correct\" values') %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n*`r table_nums(name = \"d1dataframe\", caption = \"A table of responses\")`*\n```{r d1dataframe}\n# make a data frame to process\nd1 <- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %>% \n    data.frame()\nnames(d1) <- names(pat1)\n\nd1 %>% \n    kable(caption = \"A table of responses\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nWe can test whether the pattern of correct answers (`pat1`) matches the first row of data (`d1[1,]`). The first row of data seems to match: `r table_nums(name = \"patmatchonerow\", display = \"cite\")`. \n\n*`r table_nums(name = \"patmatchonerow\", caption = \"Matches for the first row\")`*\n```{r patmatchonerow}\n(pat1 == d1[1,]) %>% \n    kable(caption = \"Matches for the first row\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n```\n\nNext we test whether the pattern matches the entire table (`d1 == pat1`). The patterns do not match the overall table as might be expected (`r table_nums(name = \"patmatchdfbad\", display = \"cite\")`). \n\n*`r table_nums(name = \"patmatchdfbad\", caption = \"Unexpected pattern matches\")`*\n```{r patmatchdfbad}\n(d1 == pat1) %>% \n    kable(caption = \"Unexpected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nIn order to match the pattern to each row, a transpose is required. The following code performs the transpose, pattern match, and re-transpose, with results in `r table_nums(name = \"patmatchdfgood\", display = \"cite\")`.\n\n*`r table_nums(name = \"patmatchdfgood\", caption = \"Expected pattern matches\")`*\n```{r patmatchdfgood}\n# transpose, check for matching and transpose back\n(d1 %>% t() == pat1) %>% \n    t() %>% \n    kable(caption = \"Expected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n```\n\nSo the trick is to use a transpose (`t()`) to swap rows and columns. Then `unlist()` will enforce the correct ordering. After running the comparison, the data are transposed again to recreate the original structure.\n\n```{r}\n# time this\nt0 <- Sys.time()\n# transpose and compare\nans_unlist <- mydat %>%\n    select(-1) %>% \n    t(.) %>% \n    unlist(.) == correct\n\n# re-transpose and make a data frame\nans_unlist %<>% \n    t(.) %>% \n    data.frame()\n\n# column names\ncolnames(ans_unlist) <- names(correct)\n\n# aid\nans_unlist %<>% \n    mutate(aid = mydat$aid) %>% \n    select(aid, everything())\n\nt1 <- Sys.time()\nruntime_unlist <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n```\n\nThis method took `r runtime_unlist` s to complete.\n\nYet another method similarly uses the double transpose method.\n\n```{r}\n# time this\nt0 <- Sys.time()\n# strip the ID column and transpose\nz <- mydat %>% \n    select(-1) %>% \n    t() \n\n# compare, transpose, and make a data frame\nans_tranpose <- (z == correct) %>% \n    t(.) %>% \n    data.frame() %>% \n    mutate(aid = mydat$aid) %>% \n    select(aid, everything())    \n\nt1 <- Sys.time()\nruntime_transpose <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n```\n\nThis method took `r runtime_transpose` s to complete.\n\nFinally, we will use a `tidyverse` approach, using `pmap()` from `purrr`. The commands will be shown as a series where each step is demonstrated separately. First we use `pmap(~c(...))` which effectively creates a list where each element is a the vector of answers from a single row, i.e., each list element is the responses from a single participant. Here we drop the `aid` column because it is not present in the correct answers. Also a `head()` will run on only the first 6 rows.\n\n```{r}\nmydat %>% \n    select(-aid) %>% \n    head() %>% \n    pmap(~c(...))\n```\n\nWe then use `pmap(~c(...)==correct)` to compare each participant's answers against the `correct` answers, resulting in a list where each element is whether the participant's answers were correct (also running on only the first 6 records).\n\n```{r}\nmydat %>% \n    select(-aid) %>% \n    head() %>% \n    pmap(~c(...)==correct)\n```\n\nTo wrap things up, we run on the entire data set, converting the output to a matrix.\n\n```{r}\nt0 <- Sys.time()\nans_pmap <- mydat %>% \n    select(-aid) %>% \n    pmap(~c(...)==correct) %>% \n    do.call(\"rbind\", .) %>% \n    data.frame()\n# column names from mydat without the \"aid\" column\nnames(ans_pmap) <- names(mydat)[2:ncol(mydat)]\nt1 <- Sys.time()\nruntime_pmap <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\n```\n\nThe `pmap()` method took `r runtime_pmap` seconds to run, not much better that the other methods.\n\nFinally, we will use the `base::sweep()` method, which can be used to compare a vector against all rows or columns in a data frame. In order to use this function, the data frame needs to have the same number of rows (or columns) as the comparison vector. So any additional rows or columns need to be stripped. Because we may have additional columns (e.g., `aid`), those must be removed before running `sweep()`, then added back in again. Additionally, the result of `sweep()` is a matrix, so it needs to be converted to a data frame for greater functionality.\n\n```{r}\nt0 <- Sys.time()\nans_sweep <- mydat %>%\n    # drop the aid column\n    select(-aid) %>% \n    # run the sweep\n    sweep(x = ., MARGIN = 2, STATS = correct, FUN = \"==\") %>% \n    # convert to data frame\n    data.frame()\nt1 <- Sys.time()\nruntime_sweep <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\n```\n\nThe `sweep()` method took `r runtime_sweep` s.\n\nWe should check that the methods all gave identical answers. This compares `ans_loop` with each of the outputs of the other methods (`r table_nums(name = \"runtimes\", display = \"cite\")`). The exercise is intended to show that there are frequently many different ways to achieve the same end goal, and some methods are more efficient than others. One can always take a subset of data and test different methods for the fastest run times before running a time-consuming process on a complete data set.\n\n*`r table_nums(name = \"runtimes\", caption = \"Run times of row-matching to correct answers\")`*\n\n```{r}\n# make a data frame summarizing the results of each method\n# methods\nmethod <- c(\"loop\", \"adply\", \"transpose\", \"unlist\", \"pmap\")\n# run times\nrun_time <- c(runtime_loop, runtime_adply, runtime_transpose, runtime_unlist, runtime_pmap) %>% round(2)\n# comparisons\nmatch <- Vectorize(identical, 'x')(list(ans_loop, ans_adply, ans_tranpose, ans_unlist, ans_pmap), ans_loop)\n\n# a single data frame\ncomparisons <- data.frame(method, run_time, match) %>% \n    arrange(run_time)\n\n# print\ncomparisons %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") \n```\n\n### Scoring across columns{#scoring-across-columns}\nNow that we have a data frame indicating for each participant whether they answered each question correctly, we can total the number of correct answers for each participant. The `rowSums()` function allows sums across rows. Because the logical values are automatically converted to numerical values (TRUE = 1; FALSE = 0), the sums provide the total number of correct answers per participant. Also because the data frame only consists of answers 1 .. 10, we can use an unqualified `rowSums()`, otherwise it would be necessary to specify which columns would be included by either position or column name.\n\nWe also bring the subject identifier (`aid`) back in and reorder the columns with `select()`. Note that after the specified `aid` and total `h1kqNa_sum` columns, we can use `everything()` to select the remainder of the columns.\n\n```{r}\nans_loop %<>%\n    # calculate the rowSums\n    mutate(h1kqNa_sum = rowSums(.)) %>% \n    # bring the ID back in\n    mutate(aid = mydat$aid) %>% \n    # reorder columns\n    select(aid, h1kqNa_sum, everything())\n```\n\nTo show differences in total score by sex, we can join the main data back using the `aid` identifier and create a simple graph. Figure \\@ref(fig:hist) shows that more females than males had overall higher counts of correct scores on the Knowledge Quiz. \n\n```{r hist, fig.cap=\"Histogram of count of correct answers on Knowledge Quiz stratified by sex of respondent\", warning=FALSE}\nans_loop %<>% \n    left_join(dat, by = \"aid\") %>% \n    mutate(\n        sex = case_when(\n            bio_sex == 1 ~ 'male',\n            bio_sex == 2 ~ 'female'\n        )\n    )\n\nggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+\n    geom_bar() +\n    facet_grid(sex ~ .) + \n    xlab(\"correct answers on Knowledge Quiz\") +\n    scale_x_continuous(breaks=0:10)\n```\n\n\n\n## Reordering values\nSometimes variables are provided in the reverse order of what you might want. For example, the answers pertaining to confidence in the Knowledge Quiz are in this specific order:\n\n```{r}\nattributes(dat$h1kq1b)$labels %>% t() %>% t() %>% data.frame()\n```\n\nTo come up with a scale score for these, it would be better to have `Very` valued as a `4` and `Not at all` as a `1` so that row-wise sums would yield higher values for those who were more confident in many answers (ignoring answers that cannot be scaled, i.e., refused, skipped, don't know, not applicable). One could use the existing values, but then the interpretation of an overall confidence score might be difficult, with the most confidence for the lowest overall score.\n\nChanging these values is quite straightforward. The `case_when()` function can be used. `case_when()` uses the structure `var == input_value ~ output_value`, where `var` is the column name, `input_value` is the selected value, and `output_value` is the reassigned value. Any additional cases that were not addressed specifically can be handled with `TRUE ~ output_value`.\n\n```{r}\n# for comparison, make a backup data frame\ndatbak <- dat2 <- dat\n\n# reassign values\ndat %<>% \n    mutate(h1kq1b = \n               case_when(\n                   # main changes\n                   h1kq1b == 4 ~ 1,\n                   h1kq1b == 3 ~ 2,\n                   h1kq1b == 2 ~ 3,\n                   h1kq1b == 1 ~ 4,\n                   # anything that is not in the above list gets its original value\n                   TRUE ~ as.numeric(h1kq1b))\n               )\n```\n\nLet's see what these values look like now. The first records before reordering:\n\n```{r}\nhead(datbak$h1kq1b)\n```\n\n... and the first few records after reordering:\n\n```{r}\nhead(dat$h1kq1b)\n```\n\nIt is a bit more awkward to perform this kind of reordering operation on multiple columns. One might be tempted to use a brute force method by copy/paste/edit to have a large set of `case_when()` functions for each column, but this would be tedious and error-prone. \n\nUsing the `mutate_at()` function can help through the use of regular expression pattern matching for column names. The same function will be performed on multiple columns. Here we use a similar regular expression to find the columns representing confidence in answers to the Knowledge Quiz (`h1kq.*b` = \"starts with `h1kq`, then has any numbner of characters, then has a `b`\") to perform the operation on any columns with names matching the regular expression pattern. The use of the dot (`.`) is shorthand for \"the current object\" which in this case is the specified column in a virtual loop over columns matching in name with the pattern. \n\n```{r, warning=FALSE}\ndat2 %<>% \n    mutate_at(.vars = vars(matches(\"h1kq.*b\")),\n             list(\n                  ~case_when(\n                      . == 4 ~ 1,\n                      . == 3 ~ 2,\n                      . == 2 ~ 3,\n                      . == 1 ~ 4,\n                      TRUE ~ as.numeric(.)\n                  )\n             )   \n    )\n```\n\nFor the sake of comparison to show that the single bit of code acted on multiple columns. Two variables are shown in `r table_nums(name = \"reordering\", display = \"cite\")`, with the frequencies of the original confidence values (`orig`) and the reordered confidence values (`modified`).\n\n```{r}\norig1 <- table(datbak$h1kq1b) %>% data.frame()\n\nmod1 <- table(dat$h1kq1b) %>% data.frame()\n\norig2 <- table(datbak$h1kq2b) %>% data.frame()\n\nmod2 <- table(dat$h1kq2b) %>% data.frame()\n```\n\n*`r table_nums(name = \"reordering\", caption = \"Confidence in correctness of answer\")`*\n```{r}\nreordered <- cbind(orig1, mod1, orig2, mod2)\n\nreordered %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") %>% \n    add_header_above(rep(c(\"original\" = 2, \"modified\" = 2), 2)) %>% \n    add_header_above(c(\"h1kq1b\" = 4, \"h1kq2b\" = 4))\n```\n\nFor example, the original value of `1` had a count of `r reordered[1,2]` but the transformed value is `4` with the same count. Now that the values are reordered, they can be used in multiple-column scale scoring as demonstrated above.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### R code used in this document\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"},{"path":"week9.html","id":"week9","chapter":"9 Week 9","heading":"9 Week 9","text":"week’s lesson cover set miscellaneous data processing topics can useful different situations.Mostly set coded examples explanations","code":""},{"path":"week9.html","id":"substituting-text","chapter":"9 Week 9","heading":"9.1 Substituting text","text":"","code":""},{"path":"week9.html","id":"paste-paste0","chapter":"9 Week 9","heading":"9.1.1 paste(), paste0()","text":"Pasting text allows substitute variables within text string. example, running long loop series files want know file name loop iteration .function paste() combines set strings adds space strings, e.g., combining first values LETTERS letters built-vectors:whereas paste0 add spaces:code uses function tempdir() specify folder automatically generated per R session; rendering book, location C:\\Temp\\6\\RtmpGs1PWG almost certainly different session. code downloads unzips file quickfox tempdir() location. zip file contains separate file word phrase “quick brown fox jumps lazy dog.” code uses loop paste0() show contents separate file along file name.","code":"\npaste(LETTERS[1], letters[1])## [1] \"A a\"\npaste0(LETTERS[1], letters[1])## [1] \"Aa\"\n# zip file\nzipfile <- file.path(tempdir(), \"quickfox.zip\")\n\n# download\ncurl_download(url = \"http://staff.washington.edu/phurvitz/csde502_winter_2021/files/quickfox.zip\", destfile = zipfile)\n\n# unzip\nunzip(zipfile = zipfile, overwrite = TRUE, exdir = tempdir())\n\n# files in the zip file\nfnames <- unzip(zipfile = file.path(tempdir(), \"quickfox.zip\"), list = TRUE) %>%\n    pull(Name) %>%\n    file.path(tempdir(), .)\n\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name with a forward slash\n    fname <- fnames[i] %>% normalizePath(winslash = \"/\")\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()` and a tab\n    mystr <- paste0(mytext, \"\\t\", i, \" of \", length(fnames), \"; file = \", fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    message(mystr)\n}## the  1 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0017e602b137e88.txt## quick    2 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0027e604fa83778.txt## brown    3 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0037e60bc634af.txt## fox  4 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0047e60195772f.txt## jumps    5 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0057e60229c264.txt## over 6 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0067e606cfd4207.txt## the  7 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0077e601b5b742d.txt## lazy 8 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0087e604c1a30c5.txt## dog  9 of 9; file = C:/Temp/6/RtmpGs1PWG/str_0097e6038323213.txt"},{"path":"week9.html","id":"sprintf","chapter":"9 Week 9","heading":"9.1.2 sprintf()","text":"sprintf() can used format text. just examples. result formatted text string.","code":""},{"path":"week9.html","id":"formatting-numerical-values","chapter":"9 Week 9","heading":"9.1.2.1 Formatting numerical values","text":"Leading zerosNumeric values can formatted character strings specific number decimal places leading zeros. example, ZIP codes imported CSV files often converted integers. following code chunk converts numerical ZIP code-like values text values correct format.Bad ZIP codes; 5-digit numerical values read double-precision numbers, leading zeros dropped:Good ZIP codes:sprintf() format %05d indicates input string less 5 characters length, make output string 5 characters pad left zeros.Decimal placesNumerical values different numbers decimal places can rendered specific number decimal places.Note distinct round(), results numeric vector:Commas spaces large numbers\nParticularly narrative, including formatted numbers important readability based audience. , prettyNum() can used. examples:literal text:appears :example, used inline code: “\\(\\pi\\) multiplied rformat(1e+8, scientific = FALSE)` equals approximately 314,159,265.358979.”","code":"\n# some numerical ZIP codes\n(zip_bad <- data.frame(id = 1:3, zipcode = c(90201, 02134, 00501)))##   id zipcode\n## 1  1   90201\n## 2  2    2134\n## 3  3     501\n# fix them up\n(zip_good <- zip_bad %>%\n    mutate(\n        zipcode = sprintf(\"%05d\", zipcode)\n    ))##   id zipcode\n## 1  1   90201\n## 2  2   02134\n## 3  3   00501\n# numbers with a variety of decimal places\nv <- c(1.2, 2.345, 1e+5 + 00005)\n\n# four fixed decimal places\nv %>% sprintf(\"%0.4f\", .)## [1] \"1.2000\"      \"2.3450\"      \"100005.0000\"\n# round to 4 places\nv %>% round(., 4)## [1]      1.200      2.345 100005.000\n# a big number\nbignum <- pi * 1e+08 \n\n# commas\n(us_format <- bignum %>% \n        prettyNum(big.mark = \",\", digits = 15)) %>% \n    paste(\"US:\", .)## [1] \"US: 314,159,265.358979\"\n# spaces, common Euro format\n(euro_format1 <- bignum %>% \n        prettyNum(big.mark = \" \", digits = 15, decimal.mark = \",\")) %>% \n    paste(\"some Europe:\", .)## [1] \"some Europe: 314 159 265,358979\"\n# other Euro format\n(euro_format2 <- bignum %>% prettyNum(big.mark = \"'\", digits = 15, decimal.mark = \",\")) %>% \n    paste(\"other Europe:\", .)## [1] \"other Europe: 314'159'265,358979\"For example, used in inline code: \n\"$\\pi$ multiplied by 100000000 \nequals approximately 314,159,265.358979.\""},{"path":"week9.html","id":"string-substitutions","chapter":"9 Week 9","heading":"9.1.2.2 String substitutions","text":"sprintf() can also used achieve substitution file reading loop . %s substituted order position arguments following string. Also note \\t inserts TAB character.","code":"\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name\n    fname <- fnames[i]\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()`\n    mystr <- sprintf(\"%s\\t%s of %s:\\t%s\\n\", mytext, i, length(fnames), fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    cat(mystr)\n}## the  1 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0017e602b137e88.txt\n## quick    2 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0027e604fa83778.txt\n## brown    3 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0037e60bc634af.txt\n## fox  4 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0047e60195772f.txt\n## jumps    5 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0057e60229c264.txt\n## over 6 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0067e606cfd4207.txt\n## the  7 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0077e601b5b742d.txt\n## lazy 8 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0087e604c1a30c5.txt\n## dog  9 of 9: C:\\Temp\\6\\RtmpGs1PWG/str_0097e6038323213.txt"},{"path":"week9.html","id":"str_replace-str_replace_all","chapter":"9 Week 9","heading":"9.1.3 str_replace(), str_replace_all()","text":"stringr functions str_replace() str_replace_all() can used substitute specific strings strings. example, might create generic function run set subject IDs generates file subject.","code":"\nsubjects <- c(\"a1\", \"b2\", \"c3\")\n\nf <- function(id) {\n    # create an output file name by substituting in the subject ID\n    outfname <- file.path(tempdir(), \"xIDx.csv\") %>% \n        str_replace(pattern = \"xIDx\", id)\n    # ... do a bunch of stuff, for example\n    val <- rnorm(1)\n    # write the file\n    message(paste0(\"writing subject \", id, \"'s data to \", outfname))\n    write.csv(x = val, file = outfname)\n}\n\nfor (i in subjects) {\n    f(i)\n}## writing subject a1's data to C:\\Temp\\6\\RtmpGs1PWG/a1.csv## writing subject b2's data to C:\\Temp\\6\\RtmpGs1PWG/b2.csv## writing subject c3's data to C:\\Temp\\6\\RtmpGs1PWG/c3.csv"},{"path":"week9.html","id":"showing-progress","chapter":"9 Week 9","heading":"9.2 Showing progress","text":"text-based progress bar can shown using txtProgressBar(). run loop reading text files, rather printing loop iteration file names, show progress bar file contents. text printed console (unlike demonstrated cat()), progress bar print several lines.generally recommended put progress bar R Markdown document since output usually read static file. However, progress bars may helpful shiny R Markdown documents process take longer seconds.implementations progress bars, see progress: Terminal Progress Bars.","code":"\nn_fnames <- length(fnames)\n# create progress bar\npb <- txtProgressBar(min = 0, max = n_fnames, style = 3)## \n  |                                                                            \n  |                                                                      |   0%\nfor (i in 1:n_fnames) {\n    # delay a bit\n    Sys.sleep(0.1)\n    # update progress bar\n    setTxtProgressBar(pb, i)\n    # read and print from the file\n    txt <- scan(fnames[i], what = \"character\", quiet = TRUE)\n    cat(\"\\n\", txt, \"\\n\")\n}## \n  |                                                                            \n  |========                                                              |  11%\n##  the \n## \n  |                                                                            \n  |================                                                      |  22%\n##  quick \n## \n  |                                                                            \n  |=======================                                               |  33%\n##  brown \n## \n  |                                                                            \n  |===============================                                       |  44%\n##  fox \n## \n  |                                                                            \n  |=======================================                               |  56%\n##  jumps \n## \n  |                                                                            \n  |===============================================                       |  67%\n##  over \n## \n  |                                                                            \n  |======================================================                |  78%\n##  the \n## \n  |                                                                            \n  |==============================================================        |  89%\n##  lazy \n## \n  |                                                                            \n  |======================================================================| 100%\n##  dog\nclose(pb)"},{"path":"week9.html","id":"turning-text-into-code-evalparsetext-some-string","chapter":"9 Week 9","heading":"9.3 Turning text into code: eval(parse(text = \"some string\"))","text":"Sometimes may variables whose values want use command function. example, suppose wanted write set files, one ZIP code data frame, file name including ZIP code. want use column name zipcode, want actual values column.can generate string represents command using kind text substitution sprintf(). loop processes ZIP code record, pull()ing ZIP code value iteration. write.csv() command generated iteration, setting output file name include current iteration’s ZIP code.Finally, last step iteration eval(parse(text = cmd)) executes cmd string command.","code":"\nverbose = TRUE\nfor (i in zip_good %>% pull(zipcode)) {\n    # do some stuff\n    vals <- rnorm(n = 3)\n    y <- bind_cols(zipcode = i, v = vals)\n    # a writing command using sprintf() to substitute %s = ZIP code\n    cmd <- sprintf(\"write.csv(x = y, file = file.path(tempdir(), '%s.csv'), row.names = FALSE)\", i)\n    \n    # show what the command is\n    if(verbose){\n        cat(cmd, \"\\n\")\n    }\n\n    # this runs the command\n    eval(parse(text = cmd))\n}## write.csv(x = y, file = file.path(tempdir(), '90201.csv'), row.names = FALSE) \n## write.csv(x = y, file = file.path(tempdir(), '02134.csv'), row.names = FALSE) \n## write.csv(x = y, file = file.path(tempdir(), '00501.csv'), row.names = FALSE)"},{"path":"week9.html","id":"sql-in-r-with-rsqlite-and-sqldf","chapter":"9 Week 9","heading":"9.4 SQL in R with RSQLite and sqldf","text":"Sometimes R’s syntax processing data can difficult confusing. programmers familiar structured query language (SQL), possible run SQL statements within R using supported database back end (default SQLite) sqldf() function.example, mean sepal length species built-iris data set can obtained, presented Tables 9.1 9.2.\nTable 9.1: Mean sepal length iris data set\nequivalent tidyverse \nTable 9.2: Mean sepal length iris data set (tidyverse approach)\n","code":"\nlibrary(sqldf)\n\nsqlc <- '\nselect\n    \"Species\" as species\n    , avg(\"Sepal.Length\") as mean_sepal_length\n    , avg(\"Sepal.Width\") as mean_sepal_width\nfrom iris\ngroup by \"Species\";'\n\niris_summary <- sqldf(x = sqlc)\n\niris_summary %>%\n    kable(caption = \"Mean sepal length from the iris data set\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\niris_summary2 <- iris %>% \n    group_by(Species) %>% \n    summarise(\n        mean_sepal_length = mean(Sepal.Length),\n        mean_sepal_width = mean(Sepal.Width)) %>% \n    select(species = Species, everything())\n\niris_summary2 %>%\n    kable(caption = \"Mean sepal length from the iris data set (tidyverse approach)\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")"},{"path":"week9.html","id":"downloading-files-from-password-protected-web-sites","chapter":"9 Week 9","heading":"9.5 Downloading files from password-protected web sites","text":"web sites protected simple username/password protection. example, try opening http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv. username/password pair csde/502, allow see contents web folder.try downloading file R, get error password supplied.However, username password can supplied part URL, . username password supplied, cached site duration R session (try running , succeed without password).","code":"\ntry(\n    read.csv(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)## Warning in file(file, \"rt\"): cannot open URL 'http://staff.washington.edu/\n## phurvitz/csde502_winter_2021/password_protected/foo.csv': HTTP status was '401\n## Unauthorized'## Error in file(file, \"rt\") : cannot open the connection\ntry(\n    read.csv(\"http://csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)##   id zipcode\n## 1  1    2134"},{"path":"week9.html","id":"dates-and-time-stamps-posixct-and-lubridate","chapter":"9 Week 9","heading":"9.6 Dates and time stamps: POSIXct and lubridate","text":"R uses POSIX-style time stamps, stored internally number fractional seconds January 1, 1970. imperative control time stamps commensurate temporal accuracy precision data. example, measurement years residence, precision substantially important. measurement chemical reactions, fractional seconds may important. applications merging body-worn sensor data GPS units accelerometers estimating physical activity occurs, minutes error can result statistically significant mis-estimations.example, can see numeric value seconds options(digits = 22); Sys.time() %>% .numeric().time stamps text format, can converted POSIX time stamps, e.g., supposed time Neil Armstrong stepped moon:Formats can specified using specific codes, see strptime().lubridate package large number functions handling date time stamps. example, want convert time stamp current time zone different time zone, first get current timeAnd convert UTC:show different format:","code":"\noptions(digits = 22)\nSys.time() %>% as.numeric()## [1] 1646383554.5991089\n(eagle <- as.POSIXct(x = \"7/20/69 10:56 PM\", tz = \"CST6CDT\", format = \"%m/%d/%y %H:%M\"))## [1] \"1969-07-20 10:56:00 CDT\"\nlibrary(lubridate)\n# set the option for fractional seconds\noptions(digits.secs = 3)\n(now <- Sys.time() %>% \n        strptime(\"%Y-%m-%d %H:%M:%OS\"))## [1] \"2022-03-04 00:45:54.671 PST\"\n# show this at time zone UTC\n(with_tz(time = now, tzone = \"UTC\"))## [1] \"2022-03-04 08:45:54.671 UTC\"\n# in different format\nnow %>% \n    format(\"%A, %B %d, %Y %l:%m %p %Z\")## [1] \"Friday, March 04, 2022 12:03 AM PST\""},{"path":"week9.html","id":"timing-with-sys.time-and-difftime","chapter":"9 Week 9","heading":"9.7 Timing with Sys.time() and difftime()","text":"easy determine long process takes using sequential Sys.time() calls, one one process, getting difference difftime(). example,difftime() can also forced report time difference units choice. difftime() 5-second delay created :… time since Eagle landed now:order report intervals years, use lubridate::time_length():","code":"\n# mark time and run a process\nt0 <- Sys.time()\n# delay 5 seconds\nSys.sleep(5)\n# mark the time now that the 5 second delay has run\nt1 <- Sys.time()\n\n# difftime() unqualified will make its best decision about what to print\n(difftime(time1 = t1, time2 = t0))## Time difference of 5.005143 secs\n# time between moon step and now-ish\n(difftime(time1 = t0, time2 = eagle))## Time difference of 19219.7 days\n(difftime(time1 = t1, time2 = t0, units = \"secs\") %>% \n     as.numeric()) %>% round(0)## [1] 5\n(difftime(time1 = t1, time2 = t0, units = \"mins\") %>% \n        as.numeric()) %>% round(2)## [1] 0.08\n(difftime(time1 = t1, time2 = t0, units = \"hours\") %>% \n        as.numeric()) %>% round(4)## [1] 0.0014\n(difftime(time1 = t1, time2 = t0, units = \"days\") %>% \n        as.numeric()) %>% round(6)## [1] 5.8e-05\n(difftime(time1 = t1, time2 = eagle, units = \"secs\") %>% \n     as.numeric())## [1] 1660582200\n(difftime(time1 = t1, time2 = eagle, units = \"mins\") %>% \n        as.numeric())## [1] 27676370\n(difftime(time1 = t1, time2 = eagle, units = \"hours\") %>% \n        as.numeric())## [1] 461272.8\n(difftime(time1 = t1, time2 = eagle, units = \"days\") %>% \n        as.numeric())## [1] 19219.7\n(time_length(x = difftime(time1 = t1, time2 = eagle), unit = \"years\") %>% \n        as.numeric() %>% round(1))## [1] 52.6"},{"path":"week9.html","id":"faster-files-with-fst","chapter":"9 Week 9","heading":"9.8 Faster files with fst()","text":"fst package great rapid reading writing data frames. format can also result much smaller file sizes using compression. examine large Add Health file. First, download, unzip, read necessary:took 30.5 s write 41823590 bytes CSV, 0.3 s write 19064839 bytes FST file (default compression amount 50). Reading speeds comparable.noted file attributes saved FST format therefore used caution highly attributed data set (e.g., Stata DTA file extensive labeling, data frame lot customized attribute labels). lose attributes! data sets simple structure, including factors, FST format good option. little work, attributes data frame saved list (e.g., .RData file along .fst file) applied .fst file loaded.","code":"\nlibrary(fst)\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n# zip file in $temp\nzipfile <- file.path(tempdir(), basename(myUrl))\n# download\ncurl_download(url = myUrl, destfile = zipfile)\n# dta file in $temp\ndtafname <- tools::file_path_sans_ext(zipfile)\n# check if the dta file exists\nif (!file.exists(dtafname)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    unzip(zipfile = zipfile, exdir = tempdir())\n}\n\n# read the file\ndat <- read_dta(dtafname)\n\n# save as a CSV, along with timing\nt0 <- Sys.time()\ncsvfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"csv\")\nwrite.csv(x = dat, file = csvfname, row.names = FALSE)\nt1 <- Sys.time()\ncsvwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)\n\n# file size\ncsvsize <- file.info(csvfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\n\n# save as FST, along with timing\nt0 <- Sys.time()\nfstfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"fst\")\nwrite.fst(x = dat, path = fstfname)\nt1 <- Sys.time()\n\n# file size\nfstsize <- file.info(fstfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\nfstwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)"},{"path":"week9.html","id":"load-us-census-boundary-and-attribute-data-as-tidyverse-and-sf-ready-data-frames-tigris-tidycensus","chapter":"9 Week 9","heading":"9.9 Load US Census Boundary and Attribute Data as ‘tidyverse’ and ‘sf’-Ready Data Frames: tigris, tidycensus","text":"[covered previously, included quick recap; skip RVerbalExpressions.]Dealing US Census data can overwhelming, particularly using raw text-based data. Census Bureau API allows streamlined downloads variables (data frames) geographies (simple format shapes). necessary get API key, available free. See tidycensus tidycensus basic usage.tidycensus uses tigris, downloads geographic data portion census files.","code":""},{"path":"week9.html","id":"download-data","chapter":"9 Week 9","heading":"9.9.1 Download data","text":"simple example download variables representing count White, Black/African American, American Indian/Native American, Asian persons American Community Survey (ACS) data King County 2019. example run, need US Census API key installed, e.g.,\ntidycensus::census_api_key(“*****************,” install = TRUE)\nAPI key stored .Renviron can accessed Sys.getenv(“CENSUS_API_KEY”).\nuse now, restart R run readRenviron(\"~/.Renviron\")\n\nlabels census API :values shown Table 3.2\nTable 3.2: Selected census tract variables 5-year ACS 2019 King County, WA\n","code":"\"Estimate!!Total\"                                         \n\"Estimate!!Total!!White alone\"                            \n\"Estimate!!Total!!Black or African American alone\"        \n\"Estimate!!Total!!American Indian and Alaska Native alone\"\n\"Estimate!!Total!!Asian alone\" \nlibrary(tidycensus)\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\",\n    progress_bar = FALSE\n)\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")"},{"path":"week9.html","id":"mapping-census-data","chapter":"9 Week 9","heading":"9.9.2 Mapping census data","text":"leaflet simple map shown 3.3, percent African American residents tract identifier.\nFigure 3.3: Percent African American census tracts King County, 2019 ACS 5-year estimate\n","code":"\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(sf)\n\n# define the CRS\nst_crs(ctdat) <- 4326\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\nbins <- 0:50\npal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\nbins2 <- seq(0, 50, by = 10)\npal2 <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins2\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ pal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # legend\n    addLegend(\n        position = \"bottomright\", pal = pal2, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()"},{"path":"week9.html","id":"creating-population-pyramids-from-census-data","chapter":"9 Week 9","heading":"9.9.3 Creating population pyramids from census data","text":"See Estimates population characteristics.Refer also back CSDE 533 Week 2 age structure; Week 7 interpreting age structure.","code":""},{"path":"week9.html","id":"rverbalexpressions","chapter":"9 Week 9","heading":"9.10 Easier regular expressions with RVerbalExpressions","text":"Regular expressions powerful take time trial--error master. RVerbalExpresions package can used easily generate regular expressions. See help rx() associated functions.examples show two constructions regular expressions matching two similar different URLs. First build regex using easy--understand controls:regex used try matching two URLs:can try slightly different regex pattern. former pattern used less strict rx_maybe(\"www.\"), whereas following pattern uses strict rx_find(\"www.\").","code":"\nlibrary(RVerbalExpressions)\n# a pattern\nx <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_maybe(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(x)## [1] \"^(http)(s)?(\\\\://)(www\\\\.)?([^ ]*)$\"\n# search for a pattern in some URLs\nurls <- c(\n    \"http://www.google.com\",\n    \"http://staff.washington.edu/phurvitz/csde502_winter_2021/\"\n)\ngrepl(pattern = x, x = urls)## [1] TRUE TRUE\n# a different pattern\ny <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_find(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(y)## [1] \"^(http)(s)?(\\\\://)(www\\\\.)([^ ]*)$\"\n# search for a pattern in the two URLs, matches one, does not match the other\ngrepl(pattern = y, x = urls)## [1]  TRUE FALSE"},{"path":"week9.html","id":"quick-copy-from-excel-windows-only","chapter":"9 Week 9","heading":"9.11 Quick copy from Excel (Windows only)","text":"Windows, possible copy selected cells Excel worksheet directly R. endorsement using Excel, cases Excel may able produce quick data don’t want develop ways.demonstration, can use analysis.xlsx. Download open file. Select copy block cells. shown selection cells copied example.code shows data can copied. Windows clipboard can used “file” read.table() tab-delimited function.","code":"\nxlsclip <- read.table(file = \"clipboard\", sep = \"\\t\", header = TRUE)\n\nxlsclip %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\"\n    )"},{"path":"week9.html","id":"running-system-commands","chapter":"9 Week 9","heading":"9.12 Running system commands","text":"R can run arbitrary system commands normally run terminal command window. system() function used run commands, optionally results returned character vector. Mac Linux, usage quite straightforward, example, list files specific directory:Windows, takes bit extra code. requires prefix cmd /c system() call command . Also backslashes path names need specified double-backslashes R.running programs utilities executed terminal command window, can helpful. Use intern = TRUE return results command object R environment.","code":"tempdirfiles <- system(\"ls $TEMP\", intern = TRUE)\n# R prefers and automatically generates forward slashes\ntmpdir <- dirname(tempdir())\n\n# what is the OS\nos <- .Platform$OS.type\n\n# construct a system command\n# under Windows\nif (os == \"windows\") {\n    # under Windows, path delimiters are backslashes so need to be rendered in R as double backslashes\n    tmpdir %<>% str_replace_all(\"/\", \"\\\\\\\\\")\n    # formulate the command\n    cmd <- sprintf(\"cmd /c dir %s\", tmpdir)\n    # run the command\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}\n\n# under *NIX\nif (os == \"unix\") {\n    cmd <- sprintf(\"ls %s\", tmpdir)\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}"},{"path":"week9.html","id":"code-styling","chapter":"9 Week 9","heading":"9.13 Code styling","text":"Good code meet least two functional requirements getting job done able able read. Code gets job done easy read cause problems later try figure something.styler package can help clean code conforms specific style tidyverse style guide. styler can integrated RStudio interactive use. can reformat selected code, entire file, entire project. example shown:lintr also useful identifying potential style errors.","code":""},{"path":"week9.html","id":"session-information","chapter":"9 Week 9","heading":"9.14 Session information","text":"may helpful troubleshooting complete documentation report complete session information. example, sometimes outdated versions packages may contain errors. session information printed sessionInfo().","code":"\nsessionInfo()## R version 4.1.2 (2021-11-01)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows Server x64 (build 17763)\n## \n## Matrix products: default\n## \n## locale:\n## [1] LC_COLLATE=English_United States.1252 \n## [2] LC_CTYPE=English_United States.1252   \n## [3] LC_MONETARY=English_United States.1252\n## [4] LC_NUMERIC=C                          \n## [5] LC_TIME=English_United States.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] RVerbalExpressions_0.1.0 sf_1.0-5                 htmltools_0.5.2         \n##  [4] leaflet_2.0.4.1          tidycensus_1.1           fst_0.9.4               \n##  [7] lubridate_1.8.0          sqldf_0.4-11             RSQLite_2.2.9           \n## [10] gsubfn_0.7               proto_1.0.0              curl_4.3.2              \n## [13] haven_2.4.3              kableExtra_1.3.4.9000    knitr_1.37              \n## [16] magrittr_2.0.1           forcats_0.5.1            stringr_1.4.0           \n## [19] dplyr_1.0.7              purrr_0.3.4              readr_2.0.2             \n## [22] tidyr_1.1.4              tibble_3.1.6             ggplot2_3.3.5           \n## [25] tidyverse_1.3.1         \n## \n## loaded via a namespace (and not attached):\n##  [1] fs_1.5.0           bit64_4.0.5        RColorBrewer_1.1-2 webshot_0.5.2     \n##  [5] httr_1.4.2         tools_4.1.2        backports_1.3.0    bslib_0.3.1       \n##  [9] rgdal_1.5-27       utf8_1.2.2         R6_2.5.1           KernSmooth_2.23-20\n## [13] DBI_1.1.2          colorspace_2.0-2   sp_1.4-6           withr_2.4.3       \n## [17] tidyselect_1.1.1   downlit_0.4.0      bit_4.0.4          compiler_4.1.2    \n## [21] chron_2.3-56       cli_3.1.0          rvest_1.0.2        xml2_1.3.2        \n## [25] bookdown_0.24.4    sass_0.4.0         scales_1.1.1       classInt_0.4-3    \n## [29] proxy_0.4-26       rappdirs_0.3.3     systemfonts_1.0.3  digest_0.6.29     \n## [33] foreign_0.8-81     rmarkdown_2.12     svglite_2.0.0      pkgconfig_2.0.3   \n## [37] dbplyr_2.1.1       fastmap_1.1.0      highr_0.9          htmlwidgets_1.5.4 \n## [41] rlang_0.4.12       readxl_1.3.1       rstudioapi_0.13    farver_2.1.0      \n## [45] jquerylib_0.1.4    generics_0.1.1     jsonlite_1.7.3     crosstalk_1.2.0   \n## [49] Rcpp_1.0.8         munsell_0.5.0      fansi_1.0.2        lifecycle_1.0.1   \n## [53] stringi_1.7.5      yaml_2.2.1         maptools_1.1-2     grid_4.1.2        \n## [57] blob_1.2.2         parallel_4.1.2     crayon_1.5.0       lattice_0.20-45   \n## [61] hms_1.1.1          pillar_1.7.0       uuid_1.0-3         tcltk_4.1.2       \n## [65] reprex_2.0.1       glue_1.6.0         evaluate_0.15      data.table_1.14.2 \n## [69] modelr_0.1.8       vctrs_0.3.8        tzdb_0.2.0         cellranger_1.1.0  \n## [73] gtable_0.3.0       assertthat_0.2.1   cachem_1.0.6       xfun_0.29         \n## [77] broom_0.7.10       e1071_1.7-9        class_7.3-19       viridisLite_0.4.0 \n## [81] tigris_1.5         memoise_2.0.1      units_0.7-2        ellipsis_0.3.2"},{"path":"week9.html","id":"commenting-out-rmdhtml-code","chapter":"9 Week 9","heading":"9.15 Commenting out Rmd/HTML code","text":"comment entire parts Rmd appear rendered HTML, use HTML comments, specified delimiters <!-- -->. example, see anything two blocks angle brackets HTML output, look complete code Rmd file generated document (), get treat.Rendered 2022-03-04 00:46:39.09509-week09.Rmd","code":"\ncat(readLines(con = \"09-week09.Rmd\"), sep = \"\\n\")# Week 9 {#week9}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(haven)\nlibrary(curl)\nlibrary(ggplot2)\n\n# URL home\nurlhome <- \"\"\n```\n\n<h2>Topic: Miscellaneous data processing <\/h2>\nThis week's lesson will cover a set of miscellaneous data processing topics that can be useful in different situations.\n\nMostly this is a set of coded examples with explanations\n\n## Substituting text\n\n### `paste()`, `paste0()`\n\nPasting text allows you to substitute variables within a text string. For example, if you are running a long loop over a series of files and you want to know which file name and loop iteration you are on. \n\nThe function `paste()` combines a set of strings and adds a space between the strings, e.g., combining the first values from the `LETTERS` and the `letters` built-in vectors:\n\n```{r}\npaste(LETTERS[1], letters[1])\n```\n\nwhereas `paste0` does not add spaces:\n\n```{r}\npaste0(LETTERS[1], letters[1])\n```\n\nThe code below uses the function `tempdir()` to specify a folder that is automatically generated per R session; for this rendering of the book, the location was ``r tempdir()`` but will almost certainly be different for your session. The code downloads and unzips the file [quickfox](files/quickfox.zip) to the `tempdir()` location. The zip file contains a separate file for each word in the phrase \"the quick brown fox jumps over the lazy dog\". The code then uses a loop and `paste0()` to show the contents of each separate file along with its file name.\n\n```{r}\n# zip file\nzipfile <- file.path(tempdir(), \"quickfox.zip\")\n\n# download\ncurl_download(url = \"http://staff.washington.edu/phurvitz/csde502_winter_2021/files/quickfox.zip\", destfile = zipfile)\n\n# unzip\nunzip(zipfile = zipfile, overwrite = TRUE, exdir = tempdir())\n\n# files in the zip file\nfnames <- unzip(zipfile = file.path(tempdir(), \"quickfox.zip\"), list = TRUE) %>%\n    pull(Name) %>%\n    file.path(tempdir(), .)\n\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name with a forward slash\n    fname <- fnames[i] %>% normalizePath(winslash = \"/\")\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()` and a tab\n    mystr <- paste0(mytext, \"\\t\", i, \" of \", length(fnames), \"; file = \", fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    message(mystr)\n}\n```\n\n\n### `sprintf()`\n`sprintf()` can be used to format text. Here are just a few examples. The result is a formatted text string.\n\n#### Formatting numerical values\n<u>Leading zeros<\/u>\n\nNumeric values can be formatted as character strings with a specific number of decimal places or leading zeros. For example, ZIP codes imported from CSV files often are converted to integers. The following code chunk converts some numerical ZIP code-like values to text values with the correct format.\n\nBad ZIP codes; the 5-digit numerical values are read in as double-precision numbers, so the leading zeros are dropped:\n```{r}\n# some numerical ZIP codes\n(zip_bad <- data.frame(id = 1:3, zipcode = c(90201, 02134, 00501)))\n```\n\nGood ZIP codes:\n```{r}\n# fix them up\n(zip_good <- zip_bad %>%\n    mutate(\n        zipcode = sprintf(\"%05d\", zipcode)\n    ))\n```\n\nThe `sprintf()` format `%05d` indicates that if the input string is less than 5 characters in length, then make the output string 5 characters and pad on the left with zeros.\n\n<u>Decimal places<\/u>\n\nNumerical values with different numbers of decimal places can be rendered with a specific number of decimal places. \n\n```{r}\n# numbers with a variety of decimal places\nv <- c(1.2, 2.345, 1e+5 + 00005)\n\n# four fixed decimal places\nv %>% sprintf(\"%0.4f\", .)\n```\n\nNote that this is distinct from `round()`, which results in a numeric vector:\n\n```{r}\n# round to 4 places\nv %>% round(., 4)\n```\n\n<u>Commas or spaces for large numbers<\/u>\nParticularly in the narrative, including formatted numbers is important for readability based on the audience. For this, `prettyNum()` can be used. Here are a few examples:\n\n```{r}\n# a big number\nbignum <- pi * 1e+08 \n\n# commas\n(us_format <- bignum %>% \n        prettyNum(big.mark = \",\", digits = 15)) %>% \n    paste(\"US:\", .)\n\n# spaces, common Euro format\n(euro_format1 <- bignum %>% \n        prettyNum(big.mark = \" \", digits = 15, decimal.mark = \",\")) %>% \n    paste(\"some Europe:\", .)\n\n# other Euro format\n(euro_format2 <- bignum %>% prettyNum(big.mark = \"'\", digits = 15, decimal.mark = \",\")) %>% \n    paste(\"other Europe:\", .)\n\n```\n\nThis literal text:\n\n```\nFor example, used in inline code: \n\"$\\pi$ multiplied by `r format(1e+8, scientific = FALSE)` \nequals approximately `r us_format`.\"\n```\nappears as:\n\nFor example, used in inline code: \"$\\pi$ multiplied by `r `format(1e+8, scientific = FALSE)` equals approximately `r us_format`.\"\n\n\n#### String substitutions\n`sprintf()` can also be used to achieve the same substitution in the file reading loop above. Each `%s` is substituted in order of the position of the arguments following the string. Also note that `\\t` inserts a `TAB` character.\n\n```{r}\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name\n    fname <- fnames[i]\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()`\n    mystr <- sprintf(\"%s\\t%s of %s:\\t%s\\n\", mytext, i, length(fnames), fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    cat(mystr)\n}\n```\n\n### `str_replace()`, `str_replace_all()`\nThe `stringr` functions `str_replace()` and `str_replace_all()` can be used to substitute specific strings in other strings. For example, we might create a generic function to run over a set of subject IDs that generates a file for each subject.\n\n```{r}\nsubjects <- c(\"a1\", \"b2\", \"c3\")\n\nf <- function(id) {\n    # create an output file name by substituting in the subject ID\n    outfname <- file.path(tempdir(), \"xIDx.csv\") %>% \n        str_replace(pattern = \"xIDx\", id)\n    # ... do a bunch of stuff, for example\n    val <- rnorm(1)\n    # write the file\n    message(paste0(\"writing subject \", id, \"'s data to \", outfname))\n    write.csv(x = val, file = outfname)\n}\n\nfor (i in subjects) {\n    f(i)\n}\n```\n\n## Showing progress\nA text-based progress bar can be shown using `txtProgressBar()`. Here we run the same loop for reading the text files, but rather than printing the loop iteration and file names, we show the progress bar and the file contents. If no text is printed to the console (unlike what is demonstrated below with `cat()`), the progress bar will not print on several lines.\n\nIt is generally not recommended to put a progress bar in an R Markdown document since the output is usually read as a static file. However, progress bars may be helpful in `shiny` R Markdown documents if a process will take longer than a few seconds.\n\n```{r}\nn_fnames <- length(fnames)\n# create progress bar\npb <- txtProgressBar(min = 0, max = n_fnames, style = 3)\nfor (i in 1:n_fnames) {\n    # delay a bit\n    Sys.sleep(0.1)\n    # update progress bar\n    setTxtProgressBar(pb, i)\n    # read and print from the file\n    txt <- scan(fnames[i], what = \"character\", quiet = TRUE)\n    cat(\"\\n\", txt, \"\\n\")\n}\nclose(pb)\n```\n\nFor other implementations of progress bars, see [progress: Terminal Progress Bars\n](https://cran.r-project.org/web/packages/progress).\n\n## Turning text into code: `eval(parse(text = \"some string\"))`\nSometimes you may have variables whose values that you want to use in a command or function. For example, suppose you wanted to write a set of files, one for each ZIP code in a data frame, with a file name including the ZIP code. We would not want to use the column name `zipcode`, but we want the actual values in the column. \n\nWe can generate a string that represents a command using the same kind of text substitution as above with `sprintf()`. The loop processes each ZIP code record, `pull()`ing the ZIP code value at each iteration. A `write.csv()` command is generated for each iteration, setting the output file name to include the current iteration's ZIP code.\n\nFinally, the last step in each iteration is `eval(parse(text = cmd))` which executes the `cmd` string as a command.\n\n```{r}\nverbose = TRUE\nfor (i in zip_good %>% pull(zipcode)) {\n    # do some stuff\n    vals <- rnorm(n = 3)\n    y <- bind_cols(zipcode = i, v = vals)\n    # a writing command using sprintf() to substitute %s = ZIP code\n    cmd <- sprintf(\"write.csv(x = y, file = file.path(tempdir(), '%s.csv'), row.names = FALSE)\", i)\n    \n    # show what the command is\n    if(verbose){\n        cat(cmd, \"\\n\")\n    }\n\n    # this runs the command\n    eval(parse(text = cmd))\n}\n```\n\n## SQL in R with `RSQLite` and `sqldf`\nSometimes R's syntax for processing data can be difficult and confusing. For programmers who are familiar with structured query language (SQL), it is possible to run SQL statements within R using a supported database back end (by default SQLite) and the `sqldf()` function.\n\nFor example, the mean sepal length by species from the built-in `iris` data set can be obtained, presented in Tables \\@ref(tab:iris) and \\@ref(tab:iris2).\n\n```{r iris, message=FALSE}\nlibrary(sqldf)\n\nsqlc <- '\nselect\n    \"Species\" as species\n    , avg(\"Sepal.Length\") as mean_sepal_length\n    , avg(\"Sepal.Width\") as mean_sepal_width\nfrom iris\ngroup by \"Species\";'\n\niris_summary <- sqldf(x = sqlc)\n\niris_summary %>%\n    kable(caption = \"Mean sepal length from the iris data set\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nThis would be equivalent in `tidyverse` as \n\n```{r iris2, message=FALSE}\niris_summary2 <- iris %>% \n    group_by(Species) %>% \n    summarise(\n        mean_sepal_length = mean(Sepal.Length),\n        mean_sepal_width = mean(Sepal.Width)) %>% \n    select(species = Species, everything())\n\niris_summary2 %>%\n    kable(caption = \"Mean sepal length from the iris data set (tidyverse approach)\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n\n\n## Downloading files from password-protected web sites\nSome web sites are protected by simple username/password protection. For example, try opening http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv. The username/password pair is csde/502, which will allow you to see the contents of the web folder.\n\nIf you try downloading the file through R, you will get an error because no password is supplied.\n\n```{r}\ntry(\n    read.csv(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)\n```\n\nHowever, the username and password can be supplied as part of the URL, as below. When the username and password are supplied, they will be cached for that site for the duration of the R session (so if you try running this again, you will succeed without a password).\n\n```{r}\ntry(\n    read.csv(\"http://csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)\n```\n\n\n## Dates and time stamps: `POSIXct` and `lubridate`\nR uses POSIX-style time stamps, which are stored internally as the number of fractional seconds from January 1, 1970. It is imperative that the control over time stamps is commensurate with the temporal accuracy and precision  your data. For example, in the measurement of years of residence, precision is not substantially important. For measurement of chemical reactions, fractional seconds may be very important. For applications such as merging body-worn sensor data from GPS units and accelerometers for estimating where and when physical activity occurs, minutes of error can result in statistically significant mis-estimations.\n\nFor example, you can see the numeric value of these seconds as `options(digits = 22); Sys.time() %>% as.numeric()`.\n\n```{r}\noptions(digits = 22)\nSys.time() %>% as.numeric()\n```\n\nIf you have time stamps in text format, they can be converted to POSIX time stamps, e.g., the supposed time Neil Armstrong stepped on the moon:\n\n```{r}\n(eagle <- as.POSIXct(x = \"7/20/69 10:56 PM\", tz = \"CST6CDT\", format = \"%m/%d/%y %H:%M\"))\n```\n\nFormats can be specified using specific codes, see `strptime()`.\n\nThe `lubridate` package has a large number of functions for handling date and time stamps. For example, if you want to convert a time stamp in the current time zone to a different time zone, first we get the current time\n\n```{r, message=FALSE}\nlibrary(lubridate)\n# set the option for fractional seconds\noptions(digits.secs = 3)\n(now <- Sys.time() %>% \n        strptime(\"%Y-%m-%d %H:%M:%OS\"))\n```\n\nAnd convert to UTC:\n\n```{r}\n# show this at time zone UTC\n(with_tz(time = now, tzone = \"UTC\"))\n```\n\nor show in a different format:\n\n```{r}\n# in different format\nnow %>% \n    format(\"%A, %B %d, %Y %l:%m %p %Z\")\n```\n\n```{r, echo=FALSE}\n# reset the digits\noptions(digits = 7)\n```\n\n## Timing with `Sys.time()` and `difftime()`\nIt is easy to determine how long a process takes by using sequential `Sys.time()` calls, one before and one after the process, and getting the difference with `difftime()`. For example, \n\n```{r}\n# mark time and run a process\nt0 <- Sys.time()\n# delay 5 seconds\nSys.sleep(5)\n# mark the time now that the 5 second delay has run\nt1 <- Sys.time()\n\n# difftime() unqualified will make its best decision about what to print\n(difftime(time1 = t1, time2 = t0))\n\n# time between moon step and now-ish\n(difftime(time1 = t0, time2 = eagle))\n```\n\n`difftime()` can also be forced to report the time difference in the units of choice. Here is the `difftime()` from the 5-second delay we created above:\n\n```{r}\n(difftime(time1 = t1, time2 = t0, units = \"secs\") %>% \n     as.numeric()) %>% round(0)\n(difftime(time1 = t1, time2 = t0, units = \"mins\") %>% \n        as.numeric()) %>% round(2)\n(difftime(time1 = t1, time2 = t0, units = \"hours\") %>% \n        as.numeric()) %>% round(4)\n(difftime(time1 = t1, time2 = t0, units = \"days\") %>% \n        as.numeric()) %>% round(6)\n```\n\n... and the time since the Eagle had landed to now:\n\n```{r}\n(difftime(time1 = t1, time2 = eagle, units = \"secs\") %>% \n     as.numeric())\n(difftime(time1 = t1, time2 = eagle, units = \"mins\") %>% \n        as.numeric())\n(difftime(time1 = t1, time2 = eagle, units = \"hours\") %>% \n        as.numeric())\n(difftime(time1 = t1, time2 = eagle, units = \"days\") %>% \n        as.numeric())\n```\n\nIn order to report intervals as years, use `lubridate::time_length()`:\n\n```{r}\n(time_length(x = difftime(time1 = t1, time2 = eagle), unit = \"years\") %>% \n        as.numeric() %>% round(1))\n```\n\n## Faster files with `fst()`\nThe `fst` package is great for rapid reading and writing of data frames. The format can also result in much smaller file sizes using compression. Here we will examine the large Add Health file. First, a download, unzip, and read as necessary:\n\n```{r}\nlibrary(fst)\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n# zip file in $temp\nzipfile <- file.path(tempdir(), basename(myUrl))\n# download\ncurl_download(url = myUrl, destfile = zipfile)\n# dta file in $temp\ndtafname <- tools::file_path_sans_ext(zipfile)\n# check if the dta file exists\nif (!file.exists(dtafname)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    unzip(zipfile = zipfile, exdir = tempdir())\n}\n\n# read the file\ndat <- read_dta(dtafname)\n\n# save as a CSV, along with timing\nt0 <- Sys.time()\ncsvfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"csv\")\nwrite.csv(x = dat, file = csvfname, row.names = FALSE)\nt1 <- Sys.time()\ncsvwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)\n\n# file size\ncsvsize <- file.info(csvfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\n\n# save as FST, along with timing\nt0 <- Sys.time()\nfstfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"fst\")\nwrite.fst(x = dat, path = fstfname)\nt1 <- Sys.time()\n\n# file size\nfstsize <- file.info(fstfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\nfstwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)\n```\n\nIt took `r csvwrite_time` s to write `r csvsize` bytes as CSV, and `r fstwrite_time` s to write `r fstsize` bytes as a FST file (with the default compression amount of 50). Reading speeds are comparable.\n\n___It should be noted___ that some file attributes will not be saved in FST format and therefore it should be used with caution if you have a highly attributed data set (e.g., a Stata DTA file with extensive labeling, or a data frame with a lot of customized attribute labels). You will lose those attributes! But for data sets with a simple structure, including factors, the FST format is a good option. With a little work, the attributes of a data frame could be saved as a list (e.g., as an `.RData` file along with the `.fst` file) and then applied after the `.fst` file is loaded.\n\n## Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready Data Frames: `tigris`, `tidycensus`\n\n*[This has been covered previously, but is included here as a quick recap; skip to [RVerbalExpressions](#rverbalexpressions).]*\n\nDealing with US Census data can be overwhelming, particularly if using the raw text-based data. The Census Bureau has an API that allows more streamlined downloads of variables (as data frames) and geographies (as simple format shapes). It is necessary to get an API key, available for free. See [tidycensus](https://walker-data.com/tidycensus/) and  [tidycensus basic usage](https://walker-data.com/tidycensus/articles/basic-usage.html).\n\n`tidycensus` uses [`tigris`](https://www.rdocumentation.org/packages/tigris/versions/1.0), which downloads the geographic data portion of the census files.\n\n### Download data\nA simple example will download the variables representing the count of White, Black/African American, American Indian/Native American, and Asian persons from the American Community Survey (ACS) data for King County in 2019. For this example to run, you need to have your US Census API key installed, e.g., \n\n<tt>\ntidycensus::census_api_key(\"*****************\", install = TRUE)<br>\n<font color=\"red\">\nYour API key has been stored in your .Renviron and can be accessed by Sys.getenv(\"CENSUS_API_KEY\").<br>\nTo use now, restart R or run `readRenviron(\"~/.Renviron\")`\n<\/font>\n<\/tt>\n\nThe labels from the census API are:\n\n```\n\"Estimate!!Total\"                                         \n\"Estimate!!Total!!White alone\"                            \n\"Estimate!!Total!!Black or African American alone\"        \n\"Estimate!!Total!!American Indian and Alaska Native alone\"\n\"Estimate!!Total!!Asian alone\" \n```\n\n```{r, warning=FALSE, message=FALSE}\nlibrary(tidycensus)\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\",\n    progress_bar = FALSE\n)\n```\n\nA few values are shown in Table \\@ref(tab:census)\n\n```{r census}\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n### Mapping census data \nA `leaflet` simple map is shown in \\@ref(fig:ct), with percent African American residents and tract identifier.\n\n```{r ct, fig.cap=\"Percent African American in census tracts in King County, 2019 ACS 5-year estimate\", warning=FALSE, message=FALSE}\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(sf)\n\n# define the CRS\nst_crs(ctdat) <- 4326\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\nbins <- 0:50\npal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\nbins2 <- seq(0, 50, by = 10)\npal2 <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins2\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ pal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # legend\n    addLegend(\n        position = \"bottomright\", pal = pal2, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()\n```\n\n### Creating population pyramids from census data\nSee [Estimates of population characteristics](https://walker-data.com/tidycensus/articles/other-datasets.html#estimates-of-population-characteristics-1).\n\nRefer also back to CSDE 533 Week 2 age structure; Week 7 interpreting age structure.\n\n## Easier regular expressions with `RVerbalExpressions` {#rverbalexpressions}\n\nRegular expressions are powerful but take some time and trial-and-error to master. The `RVerbalExpresions` package can be used to more easily generate regular expressions. See the help for `rx()` and associated functions.\n\nThese examples show two constructions of regular expressions for matching two similar but different URLs. First we build a regex using easy-to-understand controls:\n\n```{r}\nlibrary(RVerbalExpressions)\n# a pattern\nx <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_maybe(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(x)\n```\n\nThat regex is then used to try matching against two URLs:\n\n```{r}\n# search for a pattern in some URLs\nurls <- c(\n    \"http://www.google.com\",\n    \"http://staff.washington.edu/phurvitz/csde502_winter_2021/\"\n)\ngrepl(pattern = x, x = urls)\n```\n\nWe can try a slightly different regex pattern. The former pattern used the less strict `rx_maybe(\"www.\")`, whereas the following pattern uses the more strict `rx_find(\"www.\")`.\n\n```{r}\n# a different pattern\ny <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_find(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(y)\n\n# search for a pattern in the two URLs, matches one, does not match the other\ngrepl(pattern = y, x = urls)\n```\n\n## Quick copy from Excel (Windows only)\nUnder Windows, it is possible to copy selected cells from an Excel worksheet directly to R. This is not an endorsement for using Excel, but there are some cases in which Excel may be able to produce some quick data that you don't want to develop in other ways.\n\nAs a demonstration, you can use [analysis.xlsx](files/words_analysis.xlsx). Download and open the file. Select and copy a block of cells. Here is shown a selection of cells that was copied for this example. \n\n![](images/week09/excel.png)\n\nThe code below shows how the data can be copied. The Windows clipboard can be used as a \"file\" in the `read.table()` tab-delimited function.\n\n```{r, echo=FALSE}\nxlsclip <- fst::read.fst(\"files/xlsclip.fst\")\n```\n\n```{r, eval=FALSE}\nxlsclip <- read.table(file = \"clipboard\", sep = \"\\t\", header = TRUE)\n\nxlsclip %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\"\n    )\n```\n\n```{r, echo=FALSE}\nxlsclip %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\"\n    )\n```\n\n## Running system commands\nR can run arbitrary system commands that you would normally run in a terminal or command window. The `system()` function is used to run commands, optionally with the results returned as a character vector. Under Mac and Linux, the usage is quite straightforward, for example, to list files in a specific directory:\n\n```\ntempdirfiles <- system(\"ls $TEMP\", intern = TRUE)\n```\n\nUnder Windows, it takes a bit of extra code. To do the same requires the prefix `cmd /c` in the `system()` call before the command itself. Also any backslashes in path names need to be specified as double-backslashes for R.\n\n```{r}\n# R prefers and automatically generates forward slashes\ntmpdir <- dirname(tempdir())\n\n# what is the OS\nos <- .Platform$OS.type\n\n# construct a system command\n# under Windows\nif (os == \"windows\") {\n    # under Windows, path delimiters are backslashes so need to be rendered in R as double backslashes\n    tmpdir %<>% str_replace_all(\"/\", \"\\\\\\\\\")\n    # formulate the command\n    cmd <- sprintf(\"cmd /c dir %s\", tmpdir)\n    # run the command\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}\n\n# under *NIX\nif (os == \"unix\") {\n    cmd <- sprintf(\"ls %s\", tmpdir)\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}\n```\n\nIf you are running other programs or utilities that are executed in a terminal or command window, this can be very helpful. Use `intern = TRUE` to return the results of the command as an object in the R environment.\n\n## Code styling\nGood code should meet at least the two functional requirements of getting the job done and being able able to read. Code that gets the job done but that is not easy to read will cause problems later when you try to figure out how or why you did something.\n\nThe [`styler`](https://github.com/r-lib/styler) package can help clean up your code so that it conforms to a specific style such as that in the [tidyverse style guide](https://style.tidyverse.org/). `styler` can be integrated into RStudio for interactive use. It can reformat selected code, an entire file, or an entire project. An example is shown:\n\n![](images/week09/styler_0.1.gif)\n\n[`lintr`](https://github.com/jimhester/lintr) is also useful for identifying potential style errors.\n\n## Session information\nIt may be helpful in troubleshooting or complete documentation to report the complete session information. For example, sometimes outdated versions of packages may contain errors. The session information is printed with `sessionInfo()`.\n\n```{r}\nsessionInfo()\n```\n\n## Commenting out Rmd/HTML code\nTo comment out entire parts of your Rmd so they do not appear in your rendered HTML, use HTML comments, which are specified with the delimiters `<!--` and `-->`. For example, you will not see anything between these two blocks of angle brackets in the HTML output, but if you look at the complete code for the Rmd file that generated this document (below), you will get a treat.\n\n<!--\nfrom https://www.gnu.org/fun/jokes/error-haiku.txt:\n\nIMAGINE IF INSTEAD OF CRYPTIC TEXT STRINGS,\nYOUR COMPUTER PRODUCED ERROR MESSAGES IN HAIKU...\n\n A file that big?\n It might be very useful.\n But now it is gone.\n  - - - - - - - - - - - -\n Yesterday it worked\n Today it is not working\n Windows is like that\n  - - - - - - - - - - - -\n Stay the patient course\n Of little worth is your ire\n The network is down\n  - - - - - - - - - - - -\n Three things are certain:\n Death, taxes, and lost data.\n Guess which has occurred.\n  - - - - - - - - - - - -\n You step in the stream,\n but the water has moved on.\n This page is not here.\n  - - - - - - - - - - - -\n Out of memory.\n We wish to hold the whole sky,\n But we never will.\n  - - - - - - - - - - - -\n Having been erased,\n The document you're seeking\n Must now be retyped.\n  - - - - - - - - - - - -\n Rather than a beep\n Or a rude error message,\n These words: \"File not found.\"\n  - - - - - - - - - - - -\n Serious error.\n All shortcuts have disappeared.\n Screen. Mind. Both are blank.\n  - - - - - - - - - - - -\n The Web site you seek\n cannot be located but\n endless more exist.\n  - - - - - - - - - - - -\n Chaos reigns within.\n Reflect, repent, and reboot.\n Order shall return.\n  - - - - - - - - - - - -\n ABORTED effort:\n Close all that you have.\n You ask way too much.\n  - - - - - - - - - - - -\n First snow, then silence.\n This thousand dollar screen dies\n so beautifully.\n  - - - - - - - - - - - -\n With searching comes loss\n and the presence of absence:\n \"My Novel\" not found.\n  - - - - - - - - - - - -\n The Tao that is seen\n Is not the true Tao, until\n You bring fresh toner.\n  - - - - - - - - - - - -\n Windows NT crashed.\n I am the Blue Screen of Death.\n No one hears your screams.\n  - - - - - - - - - - - -\n A crash reduces\n your expensive computer\n to a simple stone.\n  - - - - - - - - - - - -\n Error messages\n cannot completely convey.\n We now know shared loss.\n\n             -- Anonymous Author\n-->\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[09-week09.Rmd](09-week09.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"09-week09.Rmd\"), sep = \"\\n\")\n```"},{"path":"week10.html","id":"week10","chapter":"10 Week 10","heading":"10 Week 10","text":"week’s lesson cover additional R odds ends.","code":""},{"path":"week10.html","id":"r-markdown-to-microsoft-word","chapter":"10 Week 10","heading":"10.1 R Markdown to Microsoft Word","text":"Microsoft Word (“Word”), used widely document research. advanced word processing “track changes” capabilities, commonly used preparation manuscripts. Using R generate output Word often tedious process (e.g., create CSV files \\(\\rightarrow\\) paste contents \\(\\rightarrow\\) convert table; export R graphics png() ggsave() \\(\\rightarrow\\) insert file).RMarkdown can used generate Word documents. thought one-way operation. say, team works manuscript using Word, typical work flow lead author creates first draft. authors make changes document using tracked changes. manuscript circulates authors, lead author decides changes accept reject, resulting new version. process continues group authors agrees manuscript ready publication.Unfortunately backwards path take existing Word docx regenerate Rmd (e.g., colleagues made lot changes Word docx). Nevertheless using method save “busy work” time Word, well provide common stylistic template R outputs generating Word documents.export Word document, following work flow followed:Create bare-bones Rmd file contains elements want output, little actual content.Render Rmd file Word docx file.Open docx file Word make stylistic changes using Word styles (see workshop Microsoft Word Social Sciences)Use style-edited docx file template Rmd file.Write complete Rmd file content want placed Word docx file render. output docx file stylistic configuration template docx.detailed work flow:use Word output, first make minimal RMarkdown document Word output.Save Rmd file knit Word.output document elements Rmd file.important part Word document number styles. Make changes styles margins. become template output containing actual scientific content. add, remove, rename styles document! Save copy document stylistic changes.example, changes header styles:Presumably, styles output docx can modified:made changes, save file “template”:YAML header Rmd file scientific content, construction, specify path name template document.Rmd file rendered Word document, stylistic changes applied output. example, just changing head matter previous document re-rendering shows heading styles applied defined.Although overall functionality somewhat limited, Rmd code generates scientific content, want output Word document predefined formats, save busy work reformatting.","code":"output:\n  word_document:  \n    reference_docx: \"template.docx\""},{"path":"week10.html","id":"r-markdown-output","chapter":"10 Week 10","heading":"10.2 R Markdown output","text":"two different basic output formats available, document presentation. writing, list specific output types includes:beamer_presentationcontext_documentgithub_documenthtml_documentioslides_presentationlatex_documentmd_documentodt_documentpdf_documentpowerpoint_presentationrtf_documentslidy_presentationword_documentVarious packages can also specify output types, e.g., bookdown::html_document2 `tufte::tufte_html.","code":""},{"path":"week10.html","id":"r-markdown-rendering-to-specific-formats","chapter":"10 Week 10","heading":"10.2.1 R Markdown rendering to specific formats","text":"Rendering R Markdown files done R console using rmarkdown::render() function, e.g.,clicking Knit control RSTudio.YAML header specifies multiple output formats, first listed format used output options specified render() function call. example, header, default output format bookdown::html_document2The RStudio interface present listed choices Knit pick list GUI, desired output format can selected interactively:supported outputs can created, including listed YAML header specifying output format render() function, e.g. create Slidy presentation:render PDF file, use e.g.,Using code rather RStudio GUI allows flexible automation; R script runs render() function part multi-step workflow. example, continuous data collection process, work flow coded run cron generate new PDF (file type) file daily basis.","code":"rmarkdown::render(input = \"input_filename.Rmd\")---\ntitle: \"A Document\"\nauthor: \"Jane Doe\"\ndate: \"2021-01-23\"\noutput: \n    bookdown::html_document2: default\n    pdf_document: default\n    html_document: default\n    word_document: default\n---rmarkdown::render(input = \"input_filename.Rmd\", output_format = \"slidy_presentation\")rmarkdown::render(input = \"input_filename.Rmd\", output_format = \"pdf_document\")"},{"path":"week10.html","id":"testing-output_type","chapter":"10 Week 10","heading":"10.2.2 Testing output_type()","text":"different output formats support (support) different features, test can made output format determine code run, using is_html_output() is_latex_output(). R code within Rmd file can run run based tests. working example, download render file output_type_test. Using single source, output rendered HTML appears aswhereas PDF output rendered asThere appears similar test MS Word output, creating Word documents Rmd files, suggested create Rmd scratch intention creating Word output.","code":""},{"path":"week10.html","id":"advantages-and-disadvantages-of-pdf","chapter":"10 Week 10","heading":"10.3 Advantages and disadvantages of PDF","text":"Portable document format (PDF) number advantages:Document formatting maintained. Font face positioning elements consistent. formats shared (e.g., MS Word), formatting inconsistent.format widely used able created variety different proprietary open software applications.Files often parsimonious size. large images embedded, file sizes can grow, often options -sampling images smaller file size.Files can protected passwords.Files supported across operating systems (Windows, Mac, Linux, UNIX).Multiple different elements can included (text, images, tables).format stood test time, introduced 1993. standard opened 2008, allowing developers create PDF outputs. led PDF standard fixed-format documents.disadvantages:\n1. Direct editing PDF files straightforward (usually requires dedicated software), often results undesired layout changes. Therefore good format collaborative editing.\n1. Copy--paste PDF often results missing extra spaces strange characters.\n1. R functions produce HTML output used PDF outputs.","code":""},{"path":"week10.html","id":"bibliography-in-r-markdown","chapter":"10 Week 10","heading":"10.4 Bibliography in R Markdown","text":"pandoc engine performs document conversion can generate bibliographies. See Bibliographies Citations detailed information.exercise, using \\({B\\kern-0.1emi\\kern-0.017emb}\\kern-0.15em\\TeX\\) formatted references.YAML header needs formatted include bibliography file, either complete path name located directory Rmd file. Similarly, CSL (Citation Style Language) file specified. CSL files can obtained Zotero Style RepositoryThe YAML header include something form:citations made references, corresponding record automatically added end document.examples syntax APA-like AMA-like references bibliographies, see filesAPA: HTML; RmdAMA: HTML; RmdRendered 2022-03-04 00:46:4210-week10.Rmd","code":"---\ntitle: \"My glorious, shiny dissertation\"\noutput: \n    bookdown::html_document2\nbibliography: myreferences_20200121.bib\ncsl: biomed-central.csl\n---\ncat(readLines(con = \"10-week10.Rmd\"), sep = \"\\n\")Warning in readLines(con = \"10-week10.Rmd\"): incomplete final line found on '10-\nweek10.Rmd'# Week 10 {#week10}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(haven)\nlibrary(curl)\nlibrary(ggplot2)\n\n# URL home\nurlhome <- \"\"\n```\n\n<h2>Topic: Odds and ends<\/h2>\n\nThis week's lesson will cover some additional R odds and ends.\n\n## R Markdown to Microsoft Word\nMicrosoft Word (\"Word\"), is used widely to document research. Because of its advanced word processing and \"track changes\" capabilities, it is commonly used for preparation of manuscripts. Using R to generate output for Word is often a tedious process (e.g., create CSV files $\\rightarrow$ paste the contents $\\rightarrow$ convert to table; export R graphics with `png()` or `ggsave()` $\\rightarrow$ insert the file).  \n\nRMarkdown can be used to generate Word documents. This should be thought of as a one-way operation. That is to say, when a team works on a manuscript using Word, the typical work flow is that the lead author creates the first draft. Other authors make changes to the document using tracked changes. When the manuscript circulates over all authors, the lead author decides which changes to accept and which to reject, resulting in a new version. The process continues until the group of authors agrees that the manuscript is ready for publication.\n\nUnfortunately there is no backwards path to take an existing Word docx and regenerate an Rmd (e.g., after you and your colleagues made a lot of changes to the Word docx). Nevertheless using this method could save you some \"busy work\" time in Word, as well as to provide a common stylistic template for your R outputs if you will be generating Word documents.\n\nTo export to a Word document, the following work flow should be followed:\n\n1. Create a bare-bones Rmd file that contains all of the elements you want in your output, but little actual content.\n1. Render the Rmd file to a Word docx file.\n1. Open the docx file in Word and make any stylistic changes __using Word styles__ (see the workshop  [Microsoft Word for the Social Sciences](https://csde.washington.edu/workshop/microsoft-word-for-the-social-sciences/))\n1. Use the style-edited docx file as a template in the Rmd file.\n1. Write your complete Rmd file with the content you want to have placed in the Word docx file and then render. The output docx file will have the same stylistic configuration as the template docx.\n\nA more detailed work flow:\n\nTo use Word output, first make a minimal RMarkdown document with Word output. \n\n![](images/week03/20200419_233754-C__Users_phurvitz_nextcloud_uw_csde_courses_msword_soc_sci_-_RStudio.png) \n\nSave the Rmd file and knit to to Word.\n\n![](images/week03/20200419_233851-Window.png) \n\nThe output document will have the elements from the Rmd file.\n\n![](images/week03/20200419_234510-minimal.docx_[Read-Only]_[Compatibility_Mode]_-_Word.png) \n\nThe important part of this is that the Word document will have a number of styles. Make any changes to the styles or margins. This will become the template for the output containing the actual scientific content. ___Do not add, remove, or rename any styles in this document!___ Save a copy of the document with any stylistic changes. \n\nFor example, here are some changes to the header styles:\n\n![](images/week03/20200420_002233-Window.png) \n\nPresumably, all of the styles in the output docx can be modified:\n\n![](images/week03/20210121_020407-Window.png)\n\nAfter you have made any changes, save the file as a \"template\":\n\n![](images/week03/20200419_235426-Save_As.png)\n\nIn the YAML header of the Rmd file with your scientific content, this construction, in which you specify the path name to the template document.\n\n```\noutput:\n  word_document:  \n    reference_docx: \"template.docx\"\n```\n\nWhen the Rmd file is rendered to a Word document, the stylistic changes will be applied to the output. For example, just changing the head matter of the previous document and re-rendering shows that the heading styles were applied as defined.\n\n![](images/week03/20200420_002536-minimal.docx_[Read-Only]_[Compatibility_Mode]_-_Word.png)\n\nAlthough this overall functionality is somewhat limited, if you do have some Rmd code that generates some scientific content, and you want to output to a Word document with predefined formats, this will save you some busy work of reformatting.\n\n## R Markdown output \nThere are two different basic output formats available, document and presentation. As of this writing, the list of specific output types includes:\n\n* `beamer_presentation`\n* `context_document`\n* `github_document`\n* `html_document`\n* `ioslides_presentation`\n* `latex_document`\n* `md_document`\n* `odt_document`\n* `pdf_document`\n* `powerpoint_presentation`\n* `rtf_document`\n* `slidy_presentation`\n* `word_document`\n\nVarious packages can also specify their own output types, e.g., `bookdown::html_document2` or `tufte::tufte_html.\n\n### R Markdown rendering to specific formats\nRendering R Markdown files is done at the R console using the `rmarkdown::render()` function, e.g., \n\n```\nrmarkdown::render(input = \"input_filename.Rmd\")\n```\n\nor by clicking the `Knit` control in RSTudio.\n\nIf the YAML header specifies multiple output formats, the first listed format will be used for the output if  other options are not specified in the `render()` function call. For example, for this header, the default output format is `bookdown::html_document2`\n\n```\n---\ntitle: \"A Document\"\nauthor: \"Jane Doe\"\ndate: \"2021-01-23\"\noutput: \n    bookdown::html_document2: default\n    pdf_document: default\n    html_document: default\n    word_document: default\n---\n```\n\nThe RStudio interface will present the listed choices in the `Knit` pick list in the GUI, so the desired output format can be selected interactively:\n\n<img src=\"../images/week03/20210124_010442-C__Users_phurvitz_OneDrive_uw_courses_csde502_csde502_winter_2021_course - RStud.png\" class=\"border1\">\n\nOther supported outputs can be created, including those that are not listed in the YAML header by specifying the output format in the `render()` function, e.g. to create a [Slidy](https://www.w3.org/Talks/Tools/Slidy2/#(1)) presentation: \n\n```\nrmarkdown::render(input = \"input_filename.Rmd\", output_format = \"slidy_presentation\")\n```\n\nTo render a PDF file, use e.g., \n\n```\nrmarkdown::render(input = \"input_filename.Rmd\", output_format = \"pdf_document\")\n```\n\nUsing code rather than the RStudio GUI allows more flexible automation; you could have an R script that runs the `render()` function as part of a multi-step workflow. For example, if you had a continuous data collection process, the work flow could be coded and run with [cron](https://www.rdocumentation.org/packages/cronR) to generate a new PDF (or other file type) file on a daily basis.\n\n### Testing `output_type()`\nBecause different output formats support (or do not support) different features, a test can be made for the output format to determine which code to run, using `is_html_output()` and `is_latex_output()`. Any R code within the Rmd file can be run or not run based on these tests. For a working example, download and render the file [output_type_test](files/output_type_test.Rmd). Using a single source, the [output rendered as HTML](files/output_type_test.html) appears as\n\n![](images/week03/20210124_190945-R Markdown Output Type Test - Work - MicrosoftEdge.png)\n\nwhereas the [PDF output](files/output_type_test.pdf) is rendered as\n\n![](images/week03/20210124_191706-output_type_test.pdf - [R Markdown Output Type Test] - SumatraPDF.png)\n\nThere appears to be no similar test for MS Word output, so for creating Word documents from Rmd files, it is suggested to create the Rmd from scratch with the intention of creating only Word output.\n\n## Advantages and disadvantages of PDF\nPortable document format (PDF) has a number of advantages:\n\n1. Document formatting is maintained. Font face and positioning of elements is consistent. When some other formats are shared (e.g., MS Word), formatting is inconsistent. \n1. The format is widely used and able to be created from a variety of different proprietary and open software applications.\n1. Files are often parsimonious in size. When large images are embedded, the file sizes can grow, but there are often options for down-sampling images for smaller file size.\n1. Files can be protected with passwords.\n1. Files are supported across all operating systems (Windows, Mac, Linux, UNIX).\n1. Multiple different elements can be included (text, images, tables).\n1. The format has stood the test of time, having been introduced 1993. The standard was opened in 2008, allowing developers to create PDF outputs. This has led to PDF being the standard for fixed-format documents. \n\nThe disadvantages:\n1. Direct editing of PDF files is not straightforward (usually requires dedicated software), and often results in undesired layout changes. Therefore this is not a good format for collaborative editing.\n1. Copy-and-paste from PDF often results in missing or extra spaces or strange characters.\n1. R functions that produce HTML output cannot be used in PDF outputs.\n\n## Bibliography in R Markdown\nThe `pandoc` engine that performs document conversion can generate bibliographies. See [Bibliographies and Citations](https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html) for detailed information.\n\nFor this exercise, we will be using ${B\\kern-0.1emi\\kern-0.017emb}\\kern-0.15em\\TeX$ formatted references.\n\nThe YAML header needs to be formatted to include the bibliography file, which should either have a complete path name or be located in the same directory as the Rmd file. Similarly, any CSL (Citation Style Language) file should be specified. CSL files can be obtained from the [Zotero Style Repository\n](https://www.zotero.org/styles)\n\nThe YAML header would include something of the form:\n\n```\n---\ntitle: \"My glorious, shiny dissertation\"\noutput: \n    bookdown::html_document2\nbibliography: myreferences_20200121.bib\ncsl: biomed-central.csl\n---\n```\n\nWhen citations are made to references, the corresponding record will be automatically added to the end of the document.\n\nFor examples of syntax for both APA-like and AMA-like references and bibliographies, see the files \n\n* APA: [HTML](files/bibliography.html); [Rmd](files/bibliography.Rmd)\n* AMA: [HTML](files/bibliography_ama.html); [Rmd](files/bibliography_ama.Rmd)\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[10-week10.Rmd](10-week10.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"10-week10.Rmd\"), sep = \"\\n\")\n```"},{"path":"assignment_files.html","id":"assignment_files","chapter":"11 Assignment support files","heading":"11 Assignment support files","text":"","code":"\n# path to this file name\nif (!interactive()) {\n    fnamepath <- knitr::current_input(dir = TRUE)\n}"},{"path":"assignment_files.html","id":"r-markdown-template","chapter":"11 Assignment support files","heading":"11.1 R Markdown Template","text":"weekly lessons: template.Rmd.","code":""},{"path":"assignment_files.html","id":"assignment-1","chapter":"11 Assignment support files","heading":"11.2 Assignment 1","text":"file_naming.RmdRendered 2022-03-04 00:46:44","code":""},{"path":"assignment_files.html","id":"source-code-9","chapter":"11 Assignment support files","heading":"11.3 Source code","text":"File H:/csde502-winter-2022-main/11-assignment-files.Rmd.","code":""},{"path":"assignment_files.html","id":"source-code-for-this-document","chapter":"11 Assignment support files","heading":"11.3.1 Source code for this document","text":"","code":"\n# path to this file name\nif (!interactive()) {\n    fnamepath <- knitr::current_input(dir = TRUE)\n}\n\ncat(readLines(fnamepath), sep = '\\n')"},{"path":"assignment_files.html","id":"complete-rmd-code-9","chapter":"11 Assignment support files","heading":"11.3.2 Complete Rmd code","text":"","code":"\ncat(readLines(fnamepath), sep = '\\n')# Assignment support files {#assignment_files}\n\n```{r fileamepath}\n\n# path to this file name\nif (!interactive()) {\n    fnamepath <- knitr::current_input(dir = TRUE)\n}\n\n```\n\n## R Markdown Template\nFor weekly lessons: [template.Rmd](files/template.Rmd).\n\n## Assignment 1\n[file_naming.Rmd](files/file_naming.Rmd)\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n## Source code\nFile is at `r fnamepath`.\n\n### Source code for this document\n\n```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n### Complete Rmd code\n\n```{r comment=''}\ncat(readLines(fnamepath), sep = '\\n')\n```"}]

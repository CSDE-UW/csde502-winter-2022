[{"path":"index.html","id":"introduction-and-welcome","chapter":"Introduction and Welcome!","heading":"Introduction and Welcome!","text":"main course notes CSDE 502 Winter 2022. contain link lecture notes, code examples, exercises, assignments. review course notes lecture. Assignment answer keys provided Canvas site, accessible currently enrolled CSDE 502 students.","code":""},{"path":"index.html","id":"about-this-course","chapter":"Introduction and Welcome!","heading":"About this course","text":"Course listing syllabusLinks course listing page official course syllabus :Course description: CSDE 502 ProseminarEntry UW course catalog: Ctr Stdies Demography EcologyThe course syllabus available PDF: files/csde502_syllabus_2022.pdf DOCX: files/csde502_syllabus_2022.docxThis required course students wishing obtain [Demographic Methods Graduate Certificate CSDE] (https://csde.washington.edu/training/demographic-certificate/). However, open interested students.Scope: course meant fill perceived curriculum gap methods courses emphasize study design statistics courses teach statistical analysis. focuses applied methods data preparation introduce following topics: data management documentation, data cleaning variable creation, summarizing variables, working demographic data, reproducibility. short, course teaches introductory “data wrangling” focused primarily demographic analysis applications.CSDE 502 tightly paired SOC/CSSS/CSDE 533 (Research Methods Demography) (“CSDE 533”). Expect see cross-references notes notes CSDE 533 vice versa. Techniques introduced course applied CSDE 533. analytic topics introduced CSDE 533 covered depth, explanation data processing notes.Objectives: Upon completion, familiar range data processing approaches quantitative demographic analysis. skills support understanding use concepts tools demography introduced CSDE 533.Instructor: Phil Hurvitz, phurvitz@uw.edu\nOffice hours: appointment; see calendar suggest times meet.","code":""},{"path":"index.html","id":"course-logistics","chapter":"Introduction and Welcome!","heading":"Course logistics","text":"Class meetings happen initially Zoom. Zoom link course https://washington.zoom.us/j/97609440755. known whether -person class meetings held Winter 2022.Friday 10:30-12:20\nPlease come class promptly scheduled time. 10-minute break halfway class session.course Canvas site https://canvas.uw.edu/courses/1515226, used collection assignments distribution graded assignments. site may also used distribution data sets used course.","code":""},{"path":"index.html","id":"course-location","chapter":"Introduction and Welcome!","heading":"Course location","text":"Class meetings happen initially Zoom. Zoom link course https://washington.zoom.us/j/97609440755. known whether -person class meetings held Winter 2022.","code":""},{"path":"index.html","id":"course-days-and-times","chapter":"Introduction and Welcome!","heading":"Course days and times","text":"Friday 10:30-12:20\nPlease come class promptly scheduled time. 10-minute break halfway class session.","code":""},{"path":"index.html","id":"canvas-site","chapter":"Introduction and Welcome!","heading":"Canvas site","text":"course Canvas site https://canvas.uw.edu/courses/1515226, used collection assignments distribution graded assignments. site may also used distribution data sets used course.","code":""},{"path":"index.html","id":"class-format","chapter":"Introduction and Welcome!","heading":"Class format","text":"Default class-time agenda:Address outstanding issues previous sessions assignments (~10 minutes)brief lecture introduce topics day (~5 minutes)hands-instructional session (~75 minutes)Overview/clarification assignment (~10 minutes)","code":""},{"path":"index.html","id":"computing","chapter":"Introduction and Welcome!","heading":"Computing","text":"assignments R. Use Internet-connected computer provisioned latest versions R,1 RStudio Desktop, latest versions number R packages.computing course optimally done CSDE Terminal Servers (TS). students already TS access (e.g., CSDE trainees) able use existing TS1, TS2, TS3 accounts, encouraged use TS4 course using environment. recent student CSDE computing accounts general UW student population use TS4 (csde-ts4.csde.washington.edu).students computers capable running R handling relatively large data sets. However, using common computing environment help us avoid problems associated running code different machines different operating systems, processors, RAM, graphics cards, R versions, etc. aid troubleshooting problems arise. may use computer lessons, limited time available problems arise due computer’s unique environment addressed quickly.order get access CSDE Terminal Servers, see CSDE Computing Accounts. students UW pay Student Technology Fee legible obtain CSDE computing accounts.information CSDE Terminal Servers, see Choosing Terminal Server. instructions connecting Terminal Server, see Computing tutorials.order make remote connections TS4, need remote desktop protocol (RDP) client. Windows built-“Remote Desktop” application. available Macs Apple Store. Windows users may also want use mRemoteNG, find bit full-featured built-Windows application. example, mRemoteNG can window size, whereas Windows RDP application fixed size must specified time connection. Linux users can use Remmina.addition RDP client, order access CSDE’s computing resources -campus locations, necessary install enable Husky OnNet, UW virtual private network (VPN) client. Instructions available Download use Husky OnNetComputing resource linksCSDE Computing ResourcesRStudio Education Beginners course","code":""},{"path":"index.html","id":"assignments-and-grading","chapter":"Introduction and Welcome!","heading":"Assignments and grading","text":"week assignment made available 12:00 day class meetings. assignments designed allow students practice skills introduced class sessions. Assignments due 09:00 Friday week following assignment distributed; answer keys posted time. answer keys posted due date/time, late work reviewed without prior arrangement instructor. Assignments submitted using Canvas site; send assignments instructor via e-mail.Assignments reviewed thoroughly returned relevant mark-, corrections, suggestions, etc. returned via course Canvas site.course graded credit/credit. Students complete much assignments can within reasonable amount time. general, courses require two hours homework every hour class, expect spend least 4 hours assignments outside class time.","code":""},{"path":"index.html","id":"course-policies","chapter":"Introduction and Welcome!","heading":"Course policies","text":"Student conduct: “Students University Washington expected maintain certain standard conduct responsible members community. Student Conduct Code defines prohibited conduct describes University holds students accountable pursue academic goals.” Prohibited academic conduct includes cheating, falsification, plagiarism. Evidence academic misconduct referred relevant UW conduct office.encouraged work assignments students, work turn must best effort.UW Libraries Plagiarism Awareness guideA link guide :UW Libraries Plagiarism Awareness guideAccommodation: experience class important . already established accommodations Disability Resources Students (DRS), please communicate approved accommodations earliest convenience can discuss needs course. website DRS provides resources students faculty making accommodations.Washington state law requires UW develop policy accommodation student absences significant hardship due reasons faith conscience, organized religious activities. UW’s policy, including information request accommodation, available Religious Accommodations Policy. Accommodations must requested within first two weeks course using Religious Accommodations Request form.Accommodation resource linksDisability Resources StudentsReligious Accommodations PolicyReligious Accommodations Request formDiversity inclusion: “University Washington, diversity integral excellence. value honor diverse experiences perspectives, strive create welcoming respectful learning environments, promote access, opportunity justice .”SafeCampus: Preventing violence shared responsibility everyone UW plays part. experience harassment studies, please report SafeCampus website (anonymous reports possible). SafeCampus provides information counseling safety resources, University policies, violence reporting requirements help us maintain safe personal, work learning environment.SafeCampus websiteA link SafeCampus program :SafeCampus website","code":""},{"path":"index.html","id":"course-calendar","chapter":"Introduction and Welcome!","heading":"Course calendar","text":"Week 1TopicsCourse introductionGetting started CSDE terminal server 4Introduction R/RStudio/RMarkdownR data typesR data structuresR pipes (magrittr. tidyverse, native pipes)Data manipulation tidyverseEmployee turnover data\nBabushkin data\nKaggle documentation Babuskin data\nBen’s attrition rate code\nBabushkin dataKaggle documentation Babuskin dataBen’s attrition rate codeWeek 2TopicsRmarkdown\nCode blocks R Markdown\nGraphs R Markdown\nTables R Markdown\nEquations R Markdown\nHTML output R Markdown\nCode blocks R MarkdownGraphs R MarkdownTables R MarkdownEquations R MarkdownHTML output R MarkdownKeyring: securely store secretsData:\nHuman Mortality Database\nHuman Fertility Database\nHuman Mortality DatabaseHuman Fertility DatabaseWeek 3Topics:tidycensus: Load US Census Boundary Attribute Data ‘tidyverse’ ‘sf’-Ready Data Framesidbr: R Interface US Census Bureau International Data Base APIsf: Simple Features R: Simple Features (GIS) Rleaflet: Create Interactive Web Maps JavaScript ‘Leaflet’ Librarymapview: Interactive Viewing Spatial Data RdemogR: Analysis Age-Structured Demographic Modelsdemography: Forecasting Mortality, Fertility, Migration Population Data; R intro demography package)Pretty printouts life tables flextable DTData:\nAccessing Human Mortality Database life tables using HMDHFDplus\nAccessing Human Mortality Database life tables using HMDHFDplusWeek 4Topics:R environmentsR functionsSampling RRevisiting Ben’s code reading HMD HFD dataWeek 5Topics:Git: file versioning code repositoryWeek 6Topics:Reading labelled dataMetadata data setsCcmpp: Cohort Component Method Population ProjectionData:\nAdd Health public-use data\nAdd Health public-use dataWeek 7Topics:Creating value labelsTabulation (summarizing data)Week 8Topics:Scale scoring variablesReordering variable valuesWeek 9Topics:Miscellaneous data processingWeek 10Topics:Miscellaneous data processing, continued","code":""},{"path":"index.html","id":"about-this-web-site","chapter":"Introduction and Welcome!","heading":"About this web site","text":"web site built R using Rmarkdown bookdown bs4_book template, uses Bootstrap framework. One unfortunate side effects format captions placed table figure!pages book section bottom including link source file printed source code page.Rendered: 2022-01-08 17:59:26Source code: index.Rmd","code":"--- \ntitle: \"UW CSDE 502 A Course Notes\"\nauthor: \"Phil Hurvitz\"\ndate: '`r format(Sys.time(), \"%Y-%m-%d %H:%M\")`'\nsite: bookdown::bookdown_site\ndescription: \"These are the course notes for Proseminar Winter 2022 (CSDE 502 A) at the University of Washington.\"\n\nbibliography: [book.bib, packages.bib]\nbiblio-style: apalike\ncsl: chicago-fullnote-bibliography.csl\nsuppress-bibliography: true\n---\n\n```{r setup, warning=FALSE, message=FALSE, echo=FALSE}\nlibrary(dplyr)\nlibrary(emo)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(scales)\nlibrary(tibble)\n\nknitr::opts_chunk$set(echo = FALSE)\n\nyear <- Sys.Date() %>% format(\"%Y\")\nsyllabus <- paste0(\"files/csde502_syllabus_\", year, \".pdf\")\nsyllabusdocx <- paste0(\"files/csde502_syllabus_\", year, \".docx\")\n```\n\n\n# Introduction and Welcome! {.unnumbered}\n\nThis is the main course notes for CSDE 502 for Winter 2022. It will contain or link to all lecture notes, code examples, exercises, and assignments. We will review these course notes during lecture. Assignment answer keys will be provided on the Canvas site, accessible only to currently enrolled CSDE 502 students.\n\n:::{.rmdcaution}\n<center>\n**CAUTION**\nMaterial on these pages will be in major flux until the second week of the quarter!\n<\/center>\n:::\n\n## About this course {.unnumbered}\n\n:::{.rmdnote}\n**Course listing and syllabus**\n\nLinks to the course listing page and official course syllabus are below:\n\n* Course description: [CSDE 502 Proseminar](https://csde.washington.edu/training/demographic-certificate/courses/csde-502/a)\n* Entry in the UW course catalog: [Ctr for Stdies in Demography and Ecology](https://www.washington.edu/students/crscat/csde.html)\n* The course syllabus is available as a PDF: [`r syllabus`](`r syllabus`) or DOCX: [`r syllabusdocx`](`r syllabusdocx`)\n:::\n\nThis is a required course for students wishing to obtain a [Demographic Methods Graduate Certificate from CSDE] (https://csde.washington.edu/training/demographic-certificate/). However, it is open to all interested students.\n\n**Scope:** This course is meant to fill a perceived curriculum gap between methods courses that emphasize study design and statistics courses that teach statistical analysis. It focuses on applied methods for data preparation and will introduce the following topics: data management and documentation, data cleaning and variable creation, summarizing variables, working with demographic data, and reproducibility. In short, this course teaches introductory â€œdata wranglingâ€ focused primarily on demographic analysis applications. \n\n\nCSDE 502 is tightly paired with [SOC/CSSS/CSDE 533 A (Research Methods in Demography)](https://hanowell.github.io/uwsoc533a/index.html) (\"CSDE 533\"). Expect to see cross-references in these notes to the notes for CSDE 533 and vice versa. Techniques introduced in this course will be applied in CSDE 533. Some analytic topics introduced in CSDE 533 will be covered in more depth, with explanation of the data and processing in these notes.\n\n**Objectives:** Upon completion, you will be familiar with a range of data processing approaches for quantitative demographic analysis. These skills will support your understanding and use of concepts and tools of demography introduced in CSDE 533.\n\n**Instructor:** [Phil Hurvitz](gis.washington.edu/phurvitz), phurvitz@uw.edu<br>\nOffice hours: by appointment; see [my calendar](http://staff.washington.edu/phurvitz/calendar) and suggest times to meet.\n\n\n## Course logistics {.unnumbered}\n\n:::{.rmdnote}\n### Course location {.unnumbered}\n\nClass meetings will happen initially over Zoom. The Zoom link for this course is [https://washington.zoom.us/j/97609440755](https://washington.zoom.us/j/976094407559). It is not known whether in-person class meetings will be held during Winter 2022.\n\n### Course days and times {.unnumbered}\nFriday 10:30-12:20<br>\nPlease come to class promptly at the scheduled time. There will be a 10-minute break about halfway through each class session.\n\n### Canvas site {.unnumbered}\n\nThe course has a Canvas site [https://canvas.uw.edu/courses/1515226](https://canvas.uw.edu/courses/1515226), which will be used for collection of assignments and distribution of graded assignments. The site may also be used for distribution of data sets used in the course.\n:::\n\n### Class format {.unnumbered}\n\nDefault class-time agenda:\n\n1. Address outstanding issues from previous sessions or assignments (~10 minutes)\n1. A brief lecture to introduce the topics of the day (~5 minutes)\n1. A hands-on instructional session (~75 minutes)\n1. Overview/clarification of assignment (~10 minutes)\n\n## Computing {.unnumbered}\nWe will do our assignments in R. Use an Internet-connected computer provisioned with the latest versions of [R](https://www.r-project.org/) [-@R-base], [RStudio Desktop](https://www.rstudio.com/products/rstudio/), and the latest versions of a number of R packages.\n\nAll computing for this course should optimally be done on CSDE Terminal Servers (TS). Those students that already have TS access (e.g., CSDE trainees) should be able to use their existing TS1, TS2, or TS3 accounts, but are encouraged to use TS4 for this course so that we will all be using the same environment. More recent student CSDE computing accounts for the general UW student population will use TS4 (csde-ts4.csde.washington.edu).\n\nMost students have computers capable of running R and handling relatively large data sets. However, using a common computing environment will help us avoid some of the problems associated with running the same code on different machines that have different operating systems, processors, RAM, graphics cards, R versions, etc. This will aid in troubleshooting any problems that arise. You may use your own computer during lessons, but only limited time will be available if problems arise due to your computer's unique environment that cannot be addressed quickly.\n\nIn order to get access to the CSDE Terminal Servers, see [CSDE Computing Accounts](https://csde.washington.edu/computing/accounts/). All students at UW who pay the [Student Technology Fee](https://uwstf.org/) are legible to obtain CSDE computing accounts.\n\nFor information about the CSDE Terminal Servers, see [Choosing a Terminal  Server](https://csde.washington.edu/computing/resources/#TerminalServerChoosing). For instructions on connecting to a Terminal Server, see [Computing tutorials](https://csde.washington.edu/computing/tutorials/).\n\nIn order to make remote connections to TS4, you will need a remote desktop protocol (RDP) client. Windows has a built-in \"Remote Desktop\" application. The same is available for Macs at the Apple Store. Windows users may also want to use [mRemoteNG](https://mremoteng.org/), which I find to be a bit more full-featured than the built-in Windows application. For example, mRemoteNG can have any window size, whereas the Windows RDP application has fixed size that must be specified at the time of connection. Linux users can use [Remmina](https://sourceforge.net/projects/remmina/).\n\nIn addition to the RDP client, in order to access any of CSDE's computing resources from off-campus locations, it is necessary to install and enable Husky OnNet, the UW virtual private network (VPN) client. Instructions are available at [Download and use Husky OnNet](https://itconnect.uw.edu/connect/uw-networks/about-husky-onnet/use-husky-onnet/)\n\n:::{.rmdnote}\n**Computing resource links**\n\n* [CSDE Computing Resources](https://csde.washington.edu/computing/resources/)\n* [RStudio Education Beginners course](https://education.rstudio.com/learn/beginner/)\n:::\n\n## Assignments and grading {.unnumbered}\nEach week there will be an assignment made available at 12:00 on the day of class meetings. The assignments are designed to allow students to practice the skills introduced in class sessions. Assignments are due at 09:00 AM on Friday of the week following when the assignment was distributed; answer keys will be posted at this time. Because the answer keys are posted at the due date/time, <u>late work will not be reviewed without prior arrangement with the instructor<\/u>. Assignments are to be submitted using the Canvas site; <u>do not send any assignments to the instructor via e-mail<\/u>.\n\nAssignments will be reviewed thoroughly and returned with relevant mark-up, corrections, suggestions, etc. and returned via the course Canvas site.\n\nThis course is graded credit/no credit. Students should complete as much of each of the assignments as they can within a reasonable amount of time.  In general, courses require two hours of homework for every hour of class, so you should expect to spend at least 4 hours on assignments outside of class time.\n\n## Course policies {.unnumbered}\n\n**Student conduct:** [\"Students at the University of Washington are expected to maintain a certain standard of conduct and be responsible members of the community. The Student Conduct Code defines prohibited conduct and describes how the University holds students accountable as they pursue their academic goals.\"](https://www.washington.edu/studentconduct/) Prohibited academic conduct includes cheating, falsification, and plagiarism. Evidence of academic misconduct will be referred to the relevant UW conduct office.\n\n_You are encouraged to work on assignments with other students_, but the work you turn in must be your own best effort.\n\n:::{.rmdnote}\n**UW Libraries Plagiarism Awareness guide**\n\nA link to the guide is below:\n\n* [UW Libraries Plagiarism Awareness guide](https://www.lib.washington.edu/teaching/plagiarism)\n:::\n\n**Accommodation:** Your experience in this class is important to me. If you have already established accommodations with Disability Resources for Students (DRS), please communicate your approved accommodations to me at your earliest convenience so we can discuss your needs in this course. The website for the DRS provides other resources for students and faculty for making accommodations.\n\nWashington state law requires that UW develop a policy for accommodation of student absences or significant hardship due to reasons of faith or conscience, or for organized religious activities. The UW's policy, including more information about how to request an accommodation, is available at Religious Accommodations Policy. Accommodations must be requested within the first two weeks of this course using the Religious Accommodations Request form.\n\n:::{.rmdnote}\n**Accommodation resource links**\n\n* [Disability Resources for Students](https://depts.washington.edu/uwdrs/)\n* [Religious Accommodations Policy](https://registrar.washington.edu/staffandfaculty/religious-accommodations-policy/)\n* [Religious Accommodations Request form](https://registrar.washington.edu/students/religious-accommodations-request/)\n:::\n\n**Diversity and inclusion:** [\"At the University of Washington, diversity is integral to excellence. We value and honor diverse experiences and perspectives, strive to create welcoming and respectful learning environments, and promote access, opportunity and justice for all.\"](https://www.washington.edu/diversity/)\n\n**SafeCampus:** Preventing violence is a shared responsibility in which everyone at the UW plays a part. If you experience harassment during your studies, please report it to the SafeCampus website (anonymous reports are possible). SafeCampus provides information on counseling and safety resources, University policies, and violence reporting requirements help us maintain a safe personal, work and learning environment.\n\n:::{.rmdnote}\n**SafeCampus website**\n\nA link to the SafeCampus program is below:\n\n* [SafeCampus website](https://www.washington.edu/safecampus/)\n:::\n\n## Course calendar {.unnumbered}\n***Week 1***\n\n**Topics**\n\n* Course introduction\n* Getting started with CSDE terminal server 4\n* [Introduction to R/RStudio/RMarkdown](#intrormd)\n* R data types\n* R data structures\n* R pipes (`magrittr`. `tidyverse`, and native pipes)\n* Data manipulation in the `tidyverse`\n* Employee turnover data\n    * [Babushkin data](https://github.com/teuschb/hr_data/blob/master/datasets/turnover_babushkin.csv)\n    * [Kaggle documentation of Babuskin data](https://www.kaggle.com/davinwijaya/employee-turnover)\n    * [Ben's attrition rate code](https://github.com/hanowell/uwsoc533a/blob/main/gists/employee-turnover-gist.R)\n\n***Week 2***\n\n**Topics**\n\n* Rmarkdown\n    * Code blocks in R Markdown\n    * Graphs in R Markdown\n    * Tables in R Markdown\n    * Equations in R Markdown\n    * HTML output from R Markdown\n* [Keyring: securely store secrets](https://cran.r-project.org/web/packages/keyring/)\n* Data:\n    * [Human Mortality Database](https://www.mortality.org/)\n    * [Human Fertility Database](https://www.humanfertility.org/cgi-bin/main.php)\n\n***Week 3***\n\n**Topics**: \n\n* [`tidycensus`](https://walker-data.com/tidycensus/): Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready Data Frames\n* [`idbr`](https://cran.r-project.org/web/packages/idbr/index.html): R Interface to the US Census Bureau International Data Base API\n* [`sf: Simple Features for R`](https://cran.r-project.org/web/packages/sf/): Simple Features (GIS) for R\n* [`leaflet`](https://cran.r-project.org/web/packages/leaflet/): Create Interactive Web Maps with the JavaScript 'Leaflet' Library\n* [`mapview`](https://cran.r-project.org/web/packages/mapview/): Interactive Viewing of Spatial Data in R\n* [`demogR`](https://cran.r-project.org/web/packages/demogR/index.html): Analysis of Age-Structured Demographic Models\n* [`demography`](https://cran.r-project.org/web/packages/demography/): Forecasting Mortality, Fertility, Migration and Population Data; [An R intro to the demography package](https://rpubs.com/Timexpo/487053))\n* Pretty printouts of life tables with `flextable` and `DT`\n* Data:\n    * Accessing Human Mortality Database life tables using [HMDHFDplus](https://cran.r-project.org/web/packages/HMDHFDplus/index.html)\n\n***Week 4***\n\n**Topics**: \n\n* R environments\n* R functions\n* Sampling in R\n* Revisiting [Ben's code for reading HMD and HFD data](https://github.com/hanowell/uwsoc533a/blob/main/gists/HMDHFDplus-gist.R)\n\n***Week 5***\n\n**Topics**: \n\n* Git: file versioning and code repository\n\n***Week 6***\n\n**Topics**: \n\n* Reading labelled data\n* Metadata on data sets\n* Ccmpp: Cohort Component Method of Population Projection\n* Data: \n    * Add Health public-use data\n\n***Week 7***\n\n**Topics**: \n\n* Creating value labels\n* Tabulation (summarizing data)\n\n***Week 8***\n\n**Topics**: \n\n* Scale scoring variables\n* Reordering variable values\n\n***Week 9***\n\n**Topics**: \n\n* Miscellaneous data processing\n\n***Week 10***\n\n**Topics**: \n\n* Miscellaneous data processing, continued\n\n\n## About this web site {.unnumbered}\nThis web site was built in R using Rmarkdown and [bookdown](https://cran.r-project.org/web/packages/bookdown/) with the [bs4_book](https://pkgs.rstudio.com/bookdown/reference/bs4_book.html) template, which uses the [Bootstrap](https://getbootstrap.com/) framework. One of the unfortunate side effects of this format is that all captions are placed _below_ the table or figure! \n\n<h4>Source code for this document<\/h4>\nEach of the pages in this book will have a section at the bottom including a link to the source file and the printed source code for the page.\n\nRendered: `r Sys.time()`\n\nSource code: [index.Rmd](index.Rmd)\n\n```{r sourcecode_intro, comment='', echo=FALSE}\ncat(readLines(\"index.Rmd\"), sep = \"\\n\")\n```"},{"path":"week1.html","id":"week1","chapter":"1 Week 1","heading":"1 Week 1","text":"Getting started terminal server 4Introduction R/RStudio/R MarkdownR data typesR data structuresFile systemsData manipulation tidyverseData sets:\nEmployee turnover data\nEmployee turnover dataToday’s lessons cover getting started computing CSDE, quickly introduce R, RStudio, R Markdown.assumed students course basic working knowledge using R, including create variables assignment operator (“<-”), run simple functions(e.g., mean(dat$age)). Often courses include using R statistical analysis, following foundations explained fully. section intended comprehensive treatment R data types structures, provide background students either relatively new using R systematic introduction.main topic today tidyverse, refers related set R packages data management, analysis, display. See Hadley Wickham’s tidy tools manifesto logic behind suite tools. brief description specific R packages, see Tidyverse packages. intended complete introduction tidyverse, provide sufficient background data handling support technical aspects rest course CSDE 533.","code":""},{"path":"week1.html","id":"gettingstarted","chapter":"1 Week 1","heading":"1.1 Getting started on Terminal Server 4","text":"First, campus, make sure Husky OnNet VPN application running connected UW network. see f5 icon task area:Connect TS4: csde-ts4.csde.washington.eduIf using Windows Remote Desktop Protocol (RDP) connection, connection parameters look like :using mRemoteNG, connection parameters match :connected see number icons desktop application shortcuts Start area.Open Windows Explorer (running RDP full screen mode able use key combination Win-E).anything, let’s change annoying default settings Windows Explorer. Tap File > Options. View tab, make sure Always show menus checked Hide extensions known file types unchecked. latter setting important want see complete file name files times.Click Apply Folders settings become default. Click Yes next dialog.Now let’s make folder files course.Navigate PC:see H: drive. mapped drive links U Drive, place data course stored. store data C: drive! C: drive can wiped without prior notification.careful files U Drive! delete files, “undo” functionality. deleting files, get warning take seriously:Navigate H: create new folder named csde502_winter_2022. Note use lowercase letters underscores rather spaces. discussed section file systems later lesson.","code":""},{"path":"week1.html","id":"intrormd","chapter":"1 Week 1","heading":"1.2 Introduction to R Markdown in RStudio","text":"","code":""},{"path":"week1.html","id":"create-a-project","chapter":"1 Week 1","heading":"1.2.1 Create a project","text":"Now use RStudio create first R Markdown source file render HTML.Start RStudio either dbl-clicking desktop shortcut navigating alphabetical R section Start menu:brief aside: install R packages.get started, usually takes time install, open second RStudio session console, install tidyverse, packages CSDE 502 533, lesson, download file packages.R.Open file second RStudio session upper right source code pane, click Source > Source.Now continue lesson original RStudio session…..Create new project (File > New Project...).Since just created directory house project, select Existing Directory.Navigate directory select Open.Click Create Project.now blank project project file.","code":""},{"path":"week1.html","id":"create-an-r-markdown-file-from-built-in-rstudio-functionality","chapter":"1 Week 1","heading":"1.2.2 Create an R Markdown file from built-in RStudio functionality","text":"Let’s make R Markdown file (File > New File > R Markdown...).change metadata … just quick example.Click OK name file week_01.Rmd.","code":""},{"path":"week1.html","id":"render-the-rmd-file-as-html","chapter":"1 Week 1","heading":"1.2.2.1 Render the Rmd file as HTML","text":"console prompt, enter R Markdown::render(\"W tap TAB key. bring list files character “w” file name. Click week_01.Rmd.syntax means “run render() function R Markdown package file week_01.Rmd”moments, process complete message output created.HTML page open automatically, look week_01.html list files. Click select View Web Browser.now see bare-bones HTML file.Compare output file source code week_01.Rmd. Note section headers begin hash marks, R code indicated starting characters\n```{r}\nending characters\n```\nNext, explore enhancements basic R Markdown syntax.","code":""},{"path":"week1.html","id":"create-an-r-markdown-file-with-some-enhancements","chapter":"1 Week 1","heading":"1.2.3 Create an R Markdown file with some enhancements","text":"Download version week_01.Rmd overwrite version just created.RStudio prints message packages required installed, click Install.Change line 3 include name e-mail address shown.","code":""},{"path":"week1.html","id":"render-and-view-the-enhanced-output","chapter":"1 Week 1","heading":"1.2.3.1 Render and view the enhanced output","text":"Repeat rendering process (R Markdown::render(\"Week_01.Rmd\"))new HTML file number enhancements, including mailto: hyperlink name, table contents upper left, table easier read, Leaflet map, captions cross-references figures table, image derived PNG file referenced URL, code used generate various parts document produced R code, complete source code document. downloadable version rendered file: week_01.html.Including source code document especially useful readers documents lets see exactly . entire research chain can documented way, reading raw data, performing data cleaning analysis, generating results.","code":""},{"path":"week1.html","id":"rdatatypes","chapter":"1 Week 1","heading":"1.3 R data types","text":"six fundamental data types R:logicalnumericintegercomplexcharacterrawThe atomic object R exist one data types, described . atomic object data type can value, NA represents observation data (e.g., missing measurement), NULL isn’t really value , can still data type class.encounter data types, Date POSIXct working dates time stamps. data types extensions fundamental data types.determine data type object , use (obj), str(obj), class(obj).","code":"\nprint(is(\"a\"))## [1] \"character\"           \"vector\"              \"data.frameRowLabels\"\n## [4] \"SuperClassMethod\"\nprint(str(TRUE))##  logi TRUE\n## NULL\nprint(class(123.45))## [1] \"numeric\"\nprint(class(as.integer(1000)))## [1] \"integer\"\nn <- as.numeric(999999999999999999999)\n\nprint(class(n))## [1] \"numeric\""},{"path":"week1.html","id":"logical","chapter":"1 Week 1","heading":"1.3.1 Logical","text":"Use logical values characteristics either TRUE FALSE. Note logical elements can also NA value observation missing. following examples,Logical values often expressed binary format 0 = FALSE =TRUE`. R values interconvertible. software (e.g., Excel, MS Access) may convert logical values numbers expect.","code":"\n# evaluate as logical, test whether 1 is greater than two\na <- 1 > 2\n# create two numerical values, one being NA, representing ages\nage_john <- 39\nage_jane <- NA\n\n# logical NA from Jane's undefined age\n(jo <- age_john > 50)## [1] FALSE\n(ja <- age_jane > 50)## [1] NA\n(t <- as.logical(1))## [1] TRUE\n(f <- as.logical(0))## [1] FALSE"},{"path":"week1.html","id":"numeric","chapter":"1 Week 1","heading":"1.3.2 Numeric","text":"Numeric values numbers range 2e-308 2e+308, depending computer using. can see possible range entering .Machine R console. can also include decimals. information, see Double-precision floating-point format","code":""},{"path":"week1.html","id":"integer","chapter":"1 Week 1","heading":"1.3.3 Integer","text":"Integer values numerical, can take whole, rather fractional values, truncated range compared numeric. example, see , try create integer range. object created integer, range, value set NA.","code":"\ni <- as.integer(999999999999999999999)## Warning: NAs introduced by coercion to integer range\nprint(class(i))## [1] \"integer\""},{"path":"week1.html","id":"complex","chapter":"1 Week 1","heading":"1.3.4 Complex","text":"complex type used mathematics unlikely use applied social science research unless get heavy statistics. See Complex number full treatment.","code":""},{"path":"week1.html","id":"character","chapter":"1 Week 1","heading":"1.3.5 Character","text":"Character data include full set keys keyboard print character, typically [-Z], [-z], [0-9], punctuation, etc. full set ASCII characters supported, e.g. accent aigu Café:Also numbers can function characters. careful converting numerical character versions. example, see ZIP codes:","code":"\nprint(class(\"Café\"))## [1] \"character\"\n# this is a character\nmy_zip <- \"98115\"\n\n# it is not numeric.\nmy_zip + 2## Error in my_zip + 2: non-numeric argument to binary operator\n# we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values\nas.numeric(my_zip) + 2## [1] 98117\n# Boston has ZIP codes starting with zeros\nboston_zip <- \"02134\"\nas.numeric(boston_zip)## [1] 2134"},{"path":"week1.html","id":"raw","chapter":"1 Week 1","heading":"1.3.6 Raw","text":"Raw values used store raw bytes hexadecimal format. unlikely use applied social science research. example, hexadecimal value character z 7a:","code":"\nprint(charToRaw(\"z\"))## [1] 7a\nclass(charToRaw(\"z\"))## [1] \"raw\""},{"path":"week1.html","id":"rdatastructures","chapter":"1 Week 1","heading":"1.4 R data structures","text":"5 basic data structures R, shown graphic:vectormatrixarraylistdata frameIn addition, factor data type important","code":""},{"path":"week1.html","id":"vector","chapter":"1 Week 1","heading":"1.4.1 Vector","text":"vector ordered set elements one elements data type created using c() constructor function. example, single value vector:try creating vector mixed data types, may get unexpected results; mixing character elements type elements result character representations, e.g.,Results depend data type mixing, example logical values can expressed numerically, TRUE FALSE values converted 1 0, respectively.character added, elements converted characters.Order important, .e.,1, 2, 3 1, 3, 2R maintain order elements vectors unless process initiated changes order elements:can get information vectors, length data type:Elements vectors specified index number (1 .. n):","code":"\n# create a vector of length 1\na <- 1\nis(a)## [1] \"numeric\" \"vector\"\nc(1, \"a\", TRUE, charToRaw(\"z\"))## [1] \"1\"    \"a\"    \"TRUE\" \"7a\"\n(c(1:3, TRUE, FALSE))## [1] 1 2 3 1 0\nc(1:3, TRUE, FALSE, \"awesome!\")## [1] \"1\"        \"2\"        \"3\"        \"TRUE\"     \"FALSE\"    \"awesome!\"\n# a vector \n(v <- c(1, 3, 2))## [1] 1 3 2\n(sort(v))## [1] 1 2 3\n# create a random normal \nset.seed(5)\nnormvec1000 <- rnorm(n = 1000)\n\nlength(normvec1000)## [1] 1000\nclass(normvec1000)## [1] \"numeric\"\nclass(normvec1000 > 1)## [1] \"logical\"\nv <- seq(from = 0, to = 10, by = 2)\nv[4]## [1] 6"},{"path":"week1.html","id":"matrix","chapter":"1 Week 1","heading":"1.4.2 Matrix","text":"matrix like vector, contain one data type, two-dimensional, rows columns. simple example:try force vector matrix whose row \\(\\times\\) col length match length vector, elements recycled, may want. least R give warning.","code":"\n# make a vector 1 to 100\n(v <- 1:100)##   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n##  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n##  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n##  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n##  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n##  [91]  91  92  93  94  95  96  97  98  99 100\n# load to a matrix\n(m1 <- matrix(v, ncol = 10, byrow = TRUE))##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n##  [1,]    1    2    3    4    5    6    7    8    9    10\n##  [2,]   11   12   13   14   15   16   17   18   19    20\n##  [3,]   21   22   23   24   25   26   27   28   29    30\n##  [4,]   31   32   33   34   35   36   37   38   39    40\n##  [5,]   41   42   43   44   45   46   47   48   49    50\n##  [6,]   51   52   53   54   55   56   57   58   59    60\n##  [7,]   61   62   63   64   65   66   67   68   69    70\n##  [8,]   71   72   73   74   75   76   77   78   79    80\n##  [9,]   81   82   83   84   85   86   87   88   89    90\n## [10,]   91   92   93   94   95   96   97   98   99   100\n# different r, c ordering\n(m2 <- matrix(v, ncol = 10, byrow = FALSE))##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n##  [1,]    1   11   21   31   41   51   61   71   81    91\n##  [2,]    2   12   22   32   42   52   62   72   82    92\n##  [3,]    3   13   23   33   43   53   63   73   83    93\n##  [4,]    4   14   24   34   44   54   64   74   84    94\n##  [5,]    5   15   25   35   45   55   65   75   85    95\n##  [6,]    6   16   26   36   46   56   66   76   86    96\n##  [7,]    7   17   27   37   47   57   67   77   87    97\n##  [8,]    8   18   28   38   48   58   68   78   88    98\n##  [9,]    9   19   29   39   49   59   69   79   89    99\n## [10,]   10   20   30   40   50   60   70   80   90   100\n(m3 <- matrix(letters, ncol = 10, nrow = 10))## Warning in matrix(letters, ncol = 10, nrow = 10): data length [26] is not a sub-\n## multiple or multiple of the number of rows [10]##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n##  [1,] \"a\"  \"k\"  \"u\"  \"e\"  \"o\"  \"y\"  \"i\"  \"s\"  \"c\"  \"m\"  \n##  [2,] \"b\"  \"l\"  \"v\"  \"f\"  \"p\"  \"z\"  \"j\"  \"t\"  \"d\"  \"n\"  \n##  [3,] \"c\"  \"m\"  \"w\"  \"g\"  \"q\"  \"a\"  \"k\"  \"u\"  \"e\"  \"o\"  \n##  [4,] \"d\"  \"n\"  \"x\"  \"h\"  \"r\"  \"b\"  \"l\"  \"v\"  \"f\"  \"p\"  \n##  [5,] \"e\"  \"o\"  \"y\"  \"i\"  \"s\"  \"c\"  \"m\"  \"w\"  \"g\"  \"q\"  \n##  [6,] \"f\"  \"p\"  \"z\"  \"j\"  \"t\"  \"d\"  \"n\"  \"x\"  \"h\"  \"r\"  \n##  [7,] \"g\"  \"q\"  \"a\"  \"k\"  \"u\"  \"e\"  \"o\"  \"y\"  \"i\"  \"s\"  \n##  [8,] \"h\"  \"r\"  \"b\"  \"l\"  \"v\"  \"f\"  \"p\"  \"z\"  \"j\"  \"t\"  \n##  [9,] \"i\"  \"s\"  \"c\"  \"m\"  \"w\"  \"g\"  \"q\"  \"a\"  \"k\"  \"u\"  \n## [10,] \"j\"  \"t\"  \"d\"  \"n\"  \"x\"  \"h\"  \"r\"  \"b\"  \"l\"  \"v\""},{"path":"week1.html","id":"array","chapter":"1 Week 1","heading":"1.4.3 Array","text":"array similar matrix, can one dimension. can useful analyzing time series data multidimensional data. using array data course, simple example creating viewing contents array:","code":"\n# a vector 1 to 27\nv <- 1:27\n\n# create an array, 3 x 3 x 3\n(a <- array(v, dim = c(3, 3, 3)))## , , 1\n## \n##      [,1] [,2] [,3]\n## [1,]    1    4    7\n## [2,]    2    5    8\n## [3,]    3    6    9\n## \n## , , 2\n## \n##      [,1] [,2] [,3]\n## [1,]   10   13   16\n## [2,]   11   14   17\n## [3,]   12   15   18\n## \n## , , 3\n## \n##      [,1] [,2] [,3]\n## [1,]   19   22   25\n## [2,]   20   23   26\n## [3,]   21   24   27\n# array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3:\n(a[1,2,3])## [1] 22"},{"path":"week1.html","id":"list","chapter":"1 Week 1","heading":"1.4.4 List","text":"R lists ordered collections objects need data type. objects can single-value vectors, multiple-value vectors, matrices, data frames, lists, etc. , lists flexible data type. can little much structure want, can become difficult manage analyze.example list comprised single value vectors different data type. Compare attempt make vector comprised elements different data type:Let’s modify list bit:top-level indexing list denoted using two sets square brackets. example, first element list can accessed l[[1]]. example, mean element 2 obtained mean(l[[2]]): 10.5.perform operations elements list, use lapply():","code":"\n(l <- list(\"a\", 1, TRUE))## [[1]]\n## [1] \"a\"\n## \n## [[2]]\n## [1] 1\n## \n## [[3]]\n## [1] TRUE\n(l <- list(\"a\", \n           1:20, \n           as.logical(c(0,1,1,0))))## [[1]]\n## [1] \"a\"\n## \n## [[2]]\n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n## \n## [[3]]\n## [1] FALSE  TRUE  TRUE FALSE\n# show the data types\n(lapply(X = l, FUN = class))## [[1]]\n## [1] \"character\"\n## \n## [[2]]\n## [1] \"integer\"\n## \n## [[3]]\n## [1] \"logical\"\n# mean, maybe?\n(lapply(X = l, FUN = function(x) {mean(x)}))## Warning in mean.default(x): argument is not numeric or logical: returning NA## [[1]]\n## [1] NA\n## \n## [[2]]\n## [1] 10.5\n## \n## [[3]]\n## [1] 0.5"},{"path":"week1.html","id":"factor","chapter":"1 Week 1","heading":"1.4.5 Factor","text":"Factors similar vectors, one-dimensional ordered sets. However, factors also use informational labels. example, may variable household income text value:“<$10,000”“$10,000-$549,999”“$50,000-$99,999”“$100,000-$200,000”“>$200,000”vector:characters, sort proper numeric order:treated factor, levels can set proper ordering:factor, data can also used statistical models magnitude variable also correctly ordered.","code":"\n(income <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\"))## [1] \"<$10,000\"          \"$10,000-$49,999\"   \"$50,000-$99,999\"  \n## [4] \"$100,000-$200,000\" \">$200,000\"\nsort(income)## [1] \"$10,000-$49,999\"   \"$100,000-$200,000\" \"$50,000-$99,999\"  \n## [4] \"<$10,000\"          \">$200,000\"\n# create a factor from income and set the levels\n(income_factor <- factor(x = income, levels = income))## [1] <$10,000          $10,000-$49,999   $50,000-$99,999   $100,000-$200,000\n## [5] >$200,000        \n## 5 Levels: <$10,000 $10,000-$49,999 $50,000-$99,999 ... >$200,000\n# sort again\n(sort(income_factor))## [1] <$10,000          $10,000-$49,999   $50,000-$99,999   $100,000-$200,000\n## [5] >$200,000        \n## 5 Levels: <$10,000 $10,000-$49,999 $50,000-$99,999 ... >$200,000"},{"path":"week1.html","id":"data-frame","chapter":"1 Week 1","heading":"1.4.6 Data frame","text":"vectors, data frames probably used data type R. can think data frames matrices allow columns different data type. example, might data set represents subject IDs characters, sex gender text, height, weight, age numerical values, income factor, smoking status logical. matrix requires one data type, possible store matrix. example:","code":"\n# income levels \ninc <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\")\n\nBMI <-  data.frame(\n   sid = c(\"A1001\", \"A1002\", \"B1001\"),\n   gender = c(\"Male\", \"Male\",\"Female\"), \n   height_cm = c(152, 171.5, 165), \n   weight_kg = c(81, 93, 78),\n   age_y = c(42, 38, 26),\n   income = factor(c(\"$50,000-$99,999\", \"$100,000-$200,000\", \"<$10,000\"), levels = inc)\n)\nprint(BMI)##     sid gender height_cm weight_kg age_y            income\n## 1 A1001   Male     152.0        81    42   $50,000-$99,999\n## 2 A1002   Male     171.5        93    38 $100,000-$200,000\n## 3 B1001 Female     165.0        78    26          <$10,000"},{"path":"week1.html","id":"filesystems","chapter":"1 Week 1","heading":"1.5 File systems","text":"Although full treatment effective uses file systems beyond scope course, basic rules worth covering:Never use spaces folder file names.\nNinety-nine 44/100ths percent time, modern software problems handling file names spaces. 0.56% time software chokes, may wonder processes failing. directly file names spaces, can least rule !Never use spaces folder file names.\nNinety-nine 44/100ths percent time, modern software problems handling file names spaces. 0.56% time software chokes, may wonder processes failing. directly file names spaces, can least rule !Use lowercase letters directory file names.\nolden days (MS-DOS), case sensitivity file names. UNIX always used case sensitive file names. \nMyGloriousPhDDissertation.tex mygloriousphddissertation.tex actually different files. Macs, based UNIX kernel, also employ case sensitivity file names. Windows? . Consider following: foo.txt FOO.txt directory.\n\nWindows doesn’t care, ? Save keyboarding time confusion using lowercase characters file names.Use lowercase letters directory file names.\nolden days (MS-DOS), case sensitivity file names. UNIX always used case sensitive file names. \nMyGloriousPhDDissertation.tex mygloriousphddissertation.tex actually different files. Macs, based UNIX kernel, also employ case sensitivity file names. Windows? . Consider following: foo.txt FOO.txt directory.\nWindows doesn’t care, ? Save keyboarding time confusion using lowercase characters file names.Include dates file names.\nexpect multiple files sequential versions file progress, alternative using content management system git, particularly binary files Word documents SAS data files, multiple versions files including date part file name. expect multiple versions date, include lowercase alphabetical character; improbable 26 versions fine single calendar date. paranoid, use suffix number 0000, 0002 .. 9999. ten thousand versions file given date, probably something right.\nNow convinced including dates file names good idea, please use format yyyy-mm-dd yyyymmdd. , file names sort temporal order.Include dates file names.\nexpect multiple files sequential versions file progress, alternative using content management system git, particularly binary files Word documents SAS data files, multiple versions files including date part file name. expect multiple versions date, include lowercase alphabetical character; improbable 26 versions fine single calendar date. paranoid, use suffix number 0000, 0002 .. 9999. ten thousand versions file given date, probably something right.\nNow convinced including dates file names good idea, please use format yyyy-mm-dd yyyymmdd. , file names sort temporal order.Make use directories!\nAlthough folder containing 100,000 files can handled programatically (file naming conventions used), possible human visually scan 100,000 file names. lot files project, consider creating directories, e.g.,\n- raw_data\n- processed_data\n- analysis_results\n- scripts\n- manuscriptMake use directories!\nAlthough folder containing 100,000 files can handled programatically (file naming conventions used), possible human visually scan 100,000 file names. lot files project, consider creating directories, e.g.,\n- raw_data\n- processed_data\n- analysis_results\n- scripts\n- manuscriptAgonize file names.\nOptimally look file names, able know something content file. spend lot time analysis creating output. Spending extra minute thinking good file names time well spent.Agonize file names.\nOptimally look file names, able know something content file. spend lot time analysis creating output. Spending extra minute thinking good file names time well spent.","code":""},{"path":"week1.html","id":"tidyverse","chapter":"1 Week 1","heading":"1.6 Data manipulation in the tidyverse","text":"One R packages use frequently tidyverse, collection several packages, specific domain:ggplot2 (graphics)dplyr (data manipulation)tidyr (reformatting data efficient processing)readr (reading rectangular R x C data)purrr (functional programming, e.g., replace () loops)tibble (enhanced data frames)stringr (string, .e., text manipulation)forcats (handling factor, .e., categorical variables)touch course, full review treatment tidyverse.section introduce main workhorse functions tidy data handling.Installing tidyverse straightforward may take time download install packages. done yet, useFor today’s lesson using one Add Health public use data sets, AHwave1_v1.dta.data set includes variable labels, make handling data easier. print column names labels. Wrapping DT::data_table presents nice interface showing variables time allows sorting searching.","code":"install.packages(\"tidyverse\")\n# load pacman if necessary\npackage.check <- lapply(\"pacman\", FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n        install.packages(x, dependencies = TRUE)\n        library(x, character.only = TRUE)\n    }\n})\n\n# load readstata13 if necessary\npacman::p_load(readstata13)\n\n# read the dta file\ndat <- readstata13::read.dta13(file.path(myurl, \"data/AHwave1_v1.dta\"))\nx <- data.frame(colname = names(dat), label = attributes(dat)$var.labels)\nDT::datatable(data = x, caption = \"Column names and labels in AHwave1_v1.dta.\")"},{"path":"week1.html","id":"magrittr","chapter":"1 Week 1","heading":"1.6.1 magrittr","text":"R package magrittr allows use “pipes.” UNIX, pipes used take output one program feed input another program. example, UNIX command cat prints contents text file. print contents file 00README.txt:cat 00README.txtbut large files, entire contents scroll fast read. Using “pipe,” denoted vertical bar character | allowed using command print one screen time tapping Enter key screen full text:cat 00README.txt | moreAs shown two screen captures:two main pipe operators use magrittr %>% ‘%<>%.’%>% pipe operator, functions UNIX pipe, , take something left hand side operator feed right hand side.%<>% assignment pipe operator, takes something left hand side operator, feeds right hand side, replaces object left-hand side.simple example pipe, list first 6 lines data frame base R, use head(), e.g.,using tidy version :R base version, first read head, know printing first 6 elements something, don’t know “something” . read ahead know reading first 6 records iris. tidy version, start knowing something data set, know printing first 6 records.base R functions, process evaluated inside . example, get mean sepal length setosa species iris, :inside , read making subset iris Species = “setosa,” selecting column “Sepal.Length,” taking mean. However, requires reading inside . large set nested functions, y <- f(g(h(((x))))), require first creating innermost function (()) working outward.tidy approach like y <- x %>% () %>% h() %>% g() %>% f()first function applied data setxisi()`. Revisiting mean sepal length setosa irises, example, tidy approach :, read left right, translates “using iris data frame, make subset records species setosa, summarize records get mean value sepal length.” tidy version intended easier write, read, understand. command uses filter() function, described .","code":"\nhead(iris)##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\niris %>% head()##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\nmean(iris[iris$Species == 'setosa', \"Sepal.Length\"])## [1] 5.006\niris %>% filter(Species == 'setosa') %>% summarise(mean(Sepal.Length))##   mean(Sepal.Length)\n## 1              5.006"},{"path":"week1.html","id":"data-subsetting-dplyr","chapter":"1 Week 1","heading":"1.6.2 Data subsetting (dplyr)","text":"dplyr tidyverse R package used frequently data manipulation. Selection records (.e., subsetting) done using logical tests determine selected set. First look logical tests cover subsetting rows columns data frames.","code":""},{"path":"week1.html","id":"logical-tests","chapter":"1 Week 1","heading":"1.6.2.0.1 Logical tests","text":"elements meet logical test, end selected set. data frame records values variables meet logical criteria, records selected.logical tests shown .","code":""},{},{},{},{},{"path":"week1.html","id":"subset-rows-filter","chapter":"1 Week 1","heading":"1.6.2.1 Subset rows (filter())","text":"filter() function creates subset records based logical test. Logical tests can combined “” statements using & operator “” statements using | operator. perform filters subset data.June\n1995\nFemale\nOctober\n1977\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nFemale\nNovember\n1976\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nOctober\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nMale\nJanuary\n1977\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nFemale\nJune\n1976\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nDecember\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nMale\nOctober\n1983\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nMarch\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nSeptember\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nAugust\n1995\nMale\nJune\n1981\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nSeptember\n1995\nMale\nSeptember\n1980\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nMale\nJanuary\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJune\n1995\nMale\nApril\n1980\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nMale\nSeptember\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nFemale\nOctober\n1982\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nFemale\nOctober\n1982\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nJuly\n1995\nFemale\nApril\n1979\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nMay\n1995\nMale\nSeptember\n1982\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nAugust\n1995\nMale\nOctober\n1976\nYes\nMarked\nmarked\nJuly\n1995\nFemale\nAugust\n1976\n\nLegitimate skip (Hispanic)\nLegitimate skip (Hispanic)\nRecords one month:Records one month females:Records one month females day month 15th, probably include males:Although examples silly trivial, show filter() used create selected set data","code":"\n# first 20 records, fist 10 columns\ndat_sub <- dat[1:20, 1:10]\nkable(dat_sub, format = \"html\") %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n# from May\n(dat_sub %>% filter(imonth == \"(5) May\"))##        aid  imonth iday     iyear    bio_sex        h1gi1m    h1gi1y  h1gi4\n## 1 57101310 (5) May    5 (95) 1995 (2) Female (11) November (76) 1976 (0) No\n## 2 57104676 (5) May   31 (95) 1995   (1) Male  (10) October (83) 1983 (0) No\n## 3 57113943 (5) May   20 (95) 1995   (1) Male   (1) January (79) 1979 (0) No\n## 4 57117997 (5) May   20 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n## 5 57118381 (5) May    6 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n## 6 57120005 (5) May   25 (95) 1995   (1) Male (9) September (82) 1982 (0) No\n##                               h1gi5a                             h1gi5b\n## 1 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 4 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 5 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 6 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n(dat_sub %>% filter(imonth == \"(5) May\" & bio_sex == \"(2) Female\"))##        aid  imonth iday     iyear    bio_sex        h1gi1m    h1gi1y  h1gi4\n## 1 57101310 (5) May    5 (95) 1995 (2) Female (11) November (76) 1976 (0) No\n## 2 57117997 (5) May   20 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n## 3 57118381 (5) May    6 (95) 1995 (2) Female  (10) October (82) 1982 (0) No\n##                               h1gi5a                             h1gi5b\n## 1 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n(dat_sub %>% filter(imonth == \"(5) May\" & (bio_sex == \"(2) Female\") | iday < 15))##         aid        imonth iday     iyear    bio_sex        h1gi1m    h1gi1y\n## 1  57101310       (5) May    5 (95) 1995 (2) Female (11) November (76) 1976\n## 2  57103869      (7) July   14 (95) 1995   (1) Male   (1) January (77) 1977\n## 3  57104553      (7) July   14 (95) 1995 (2) Female      (6) June (76) 1976\n## 4  57104649      (6) June   12 (95) 1995   (1) Male (12) December (81) 1981\n## 5  57109625      (6) June    7 (95) 1995   (1) Male     (3) March (81) 1981\n## 6  57111071    (8) August    3 (95) 1995   (1) Male      (6) June (81) 1981\n## 7  57111786 (9) September    7 (95) 1995   (1) Male (9) September (80) 1980\n## 8  57117542      (7) July   11 (95) 1995   (1) Male (9) September (79) 1979\n## 9  57117997       (5) May   20 (95) 1995 (2) Female  (10) October (82) 1982\n## 10 57118381       (5) May    6 (95) 1995 (2) Female  (10) October (82) 1982\n##     h1gi4                             h1gi5a                             h1gi5b\n## 1  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 4  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 5  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 6  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 7  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 8  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 9  (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 10 (0) No (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)"},{"path":"week1.html","id":"subset-columns-select","chapter":"1 Week 1","heading":"1.6.2.2 Subset columns (select())","text":"subset columns can extracted data frames using select() function, simply using named list columns keep.select() can also used rename columns:column renaming can done rename(), maintains input data changes named columns:","code":"\n# select 3 columns\n(dat_sub_sel <- dat_sub %>%   \n    select(\"aid\", \"imonth\", \"iday\"))##         aid        imonth iday\n## 1  57100270      (6) June   23\n## 2  57101310       (5) May    5\n## 3  57103171      (6) June   27\n## 4  57103869      (7) July   14\n## 5  57104553      (7) July   14\n## 6  57104649      (6) June   12\n## 7  57104676       (5) May   31\n## 8  57109625      (6) June    7\n## 9  57110897      (6) June   27\n## 10 57111071    (8) August    3\n## 11 57111786 (9) September    7\n## 12 57113943       (5) May   20\n## 13 57116359      (6) June   24\n## 14 57117542      (7) July   11\n## 15 57117997       (5) May   20\n## 16 57118381       (5) May    6\n## 17 57118943      (7) July   19\n## 18 57120005       (5) May   25\n## 19 57120046    (8) August   20\n## 20 57120371      (7) July   20\n# select all but two named columns\n(dat_sub_sel <- dat_sub %>%   \n    select(-\"imonth\", -\"iday\"))##         aid     iyear    bio_sex        h1gi1m    h1gi1y   h1gi4\n## 1  57100270 (95) 1995 (2) Female  (10) October (77) 1977  (0) No\n## 2  57101310 (95) 1995 (2) Female (11) November (76) 1976  (0) No\n## 3  57103171 (95) 1995   (1) Male  (10) October (79) 1979  (0) No\n## 4  57103869 (95) 1995   (1) Male   (1) January (77) 1977  (0) No\n## 5  57104553 (95) 1995 (2) Female      (6) June (76) 1976  (0) No\n## 6  57104649 (95) 1995   (1) Male (12) December (81) 1981  (0) No\n## 7  57104676 (95) 1995   (1) Male  (10) October (83) 1983  (0) No\n## 8  57109625 (95) 1995   (1) Male     (3) March (81) 1981  (0) No\n## 9  57110897 (95) 1995   (1) Male (9) September (81) 1981  (0) No\n## 10 57111071 (95) 1995   (1) Male      (6) June (81) 1981  (0) No\n## 11 57111786 (95) 1995   (1) Male (9) September (80) 1980  (0) No\n## 12 57113943 (95) 1995   (1) Male   (1) January (79) 1979  (0) No\n## 13 57116359 (95) 1995   (1) Male     (4) April (80) 1980  (0) No\n## 14 57117542 (95) 1995   (1) Male (9) September (79) 1979  (0) No\n## 15 57117997 (95) 1995 (2) Female  (10) October (82) 1982  (0) No\n## 16 57118381 (95) 1995 (2) Female  (10) October (82) 1982  (0) No\n## 17 57118943 (95) 1995 (2) Female     (4) April (79) 1979  (0) No\n## 18 57120005 (95) 1995   (1) Male (9) September (82) 1982  (0) No\n## 19 57120046 (95) 1995   (1) Male  (10) October (76) 1976 (1) Yes\n## 20 57120371 (95) 1995 (2) Female    (8) August (76) 1976  (0) No\n##                                h1gi5a                             h1gi5b\n## 1  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 2  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 3  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 4  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 5  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 6  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 7  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 8  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 9  (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 10 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 11 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 12 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 13 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 14 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 15 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 16 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 17 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 18 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n## 19                         (1) Marked                     (0) Not marked\n## 20 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic)\n# select columns by position and whose name matches a pattern, in this case the regular expression \"^i\" meaning \"starts with lowercase i\"\n(dat_sub_sel <- dat_sub %>%   \n    select(1, matches(\"^i\")))##         aid        imonth iday     iyear\n## 1  57100270      (6) June   23 (95) 1995\n## 2  57101310       (5) May    5 (95) 1995\n## 3  57103171      (6) June   27 (95) 1995\n## 4  57103869      (7) July   14 (95) 1995\n## 5  57104553      (7) July   14 (95) 1995\n## 6  57104649      (6) June   12 (95) 1995\n## 7  57104676       (5) May   31 (95) 1995\n## 8  57109625      (6) June    7 (95) 1995\n## 9  57110897      (6) June   27 (95) 1995\n## 10 57111071    (8) August    3 (95) 1995\n## 11 57111786 (9) September    7 (95) 1995\n## 12 57113943       (5) May   20 (95) 1995\n## 13 57116359      (6) June   24 (95) 1995\n## 14 57117542      (7) July   11 (95) 1995\n## 15 57117997       (5) May   20 (95) 1995\n## 16 57118381       (5) May    6 (95) 1995\n## 17 57118943      (7) July   19 (95) 1995\n## 18 57120005       (5) May   25 (95) 1995\n## 19 57120046    (8) August   20 (95) 1995\n## 20 57120371      (7) July   20 (95) 1995\n#select one column, rename two columns\n(dat_sub_sel %>% \n   select(aid, Month = imonth, Day = iday))##         aid         Month Day\n## 1  57100270      (6) June  23\n## 2  57101310       (5) May   5\n## 3  57103171      (6) June  27\n## 4  57103869      (7) July  14\n## 5  57104553      (7) July  14\n## 6  57104649      (6) June  12\n## 7  57104676       (5) May  31\n## 8  57109625      (6) June   7\n## 9  57110897      (6) June  27\n## 10 57111071    (8) August   3\n## 11 57111786 (9) September   7\n## 12 57113943       (5) May  20\n## 13 57116359      (6) June  24\n## 14 57117542      (7) July  11\n## 15 57117997       (5) May  20\n## 16 57118381       (5) May   6\n## 17 57118943      (7) July  19\n## 18 57120005       (5) May  25\n## 19 57120046    (8) August  20\n## 20 57120371      (7) July  20\n(dat_sub_sel %>% \n   rename(Month = imonth, Day = iday))##         aid         Month Day     iyear\n## 1  57100270      (6) June  23 (95) 1995\n## 2  57101310       (5) May   5 (95) 1995\n## 3  57103171      (6) June  27 (95) 1995\n## 4  57103869      (7) July  14 (95) 1995\n## 5  57104553      (7) July  14 (95) 1995\n## 6  57104649      (6) June  12 (95) 1995\n## 7  57104676       (5) May  31 (95) 1995\n## 8  57109625      (6) June   7 (95) 1995\n## 9  57110897      (6) June  27 (95) 1995\n## 10 57111071    (8) August   3 (95) 1995\n## 11 57111786 (9) September   7 (95) 1995\n## 12 57113943       (5) May  20 (95) 1995\n## 13 57116359      (6) June  24 (95) 1995\n## 14 57117542      (7) July  11 (95) 1995\n## 15 57117997       (5) May  20 (95) 1995\n## 16 57118381       (5) May   6 (95) 1995\n## 17 57118943      (7) July  19 (95) 1995\n## 18 57120005       (5) May  25 (95) 1995\n## 19 57120046    (8) August  20 (95) 1995\n## 20 57120371      (7) July  20 (95) 1995"},{"path":"week1.html","id":"subset-rows-and-columns-filter-and-select","chapter":"1 Week 1","heading":"1.6.2.3 Subset rows and columns: filter() and select()","text":"can combine filter() select() pipe create new data frame subset rows columns:","code":"\n# records with day of month > 15 and the first 3 named columns\n(x <- dat_sub %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday)\n   )##         aid     imonth iday\n## 1  57100270   (6) June   23\n## 2  57103171   (6) June   27\n## 3  57104676    (5) May   31\n## 4  57110897   (6) June   27\n## 5  57113943    (5) May   20\n## 6  57116359   (6) June   24\n## 7  57117997    (5) May   20\n## 8  57118943   (7) July   19\n## 9  57120005    (5) May   25\n## 10 57120046 (8) August   20\n## 11 57120371   (7) July   20"},{"path":"week1.html","id":"create-or-calculate-columns-mutate","chapter":"1 Week 1","heading":"1.6.2.4 Create or calculate columns: mutate()","text":"mutate() create new named columns re-calculate existing columns. make column stratifies birth month, cut June.Although birth month column (h1gi1m) factor, unordered, need make ordered using factor label numeric comparison. Fortunately, factor labels handled correct order:Assign order, create new column, print nicely:June\nOctober\nJune\nOctober\nMay\nOctober\nJune\nSeptember\nMay\nJanuary\nJune\nApril\nMay\nOctober\nJuly\nApril\nMay\nSeptember\nAugust\nOctober\nJuly\nAugust\nMay\nOctober\nJuly\nFebruary\nJuly\nFebruary\nAugust\nOctober\nApril\nJuly\nJuly\nFebruary\nJuly\nApril\nMay\nMay\nJune\nOctober\nsilly example showing mutate() can change values existing columns:… careful!functions can used mutate include (means limited !)if_else(): create column assigning values based logical criteriacase_when(): similar if_else() multiple input valuesrecode(): change particular valuesWhen recoded birth month, output logical data type. wanted create \ncharacter factor, use if_else(). creating new data frame based several operations dat.June\nOctober\nJune\nOctober\nMay\nOctober\nJune\nSeptember\nMay\nJanuary\nJune\nApril\nMay\nOctober\nJuly\nApril\nMay\nSeptember\nAugust\nOctober\nJuly\nAugust\nMay\nOctober\nJuly\nFebruary\nJuly\nFebruary\nAugust\nOctober\nApril\nJuly\nJuly\nFebruary\nJuly\nApril\nMay\nMay\nJune\nOctober\none variables contains multiple values want create classes, use case_when(). verbose example stratifying months quarters. Also using magrittr assignment pipe update input based statement, .e., dat_1 change based commands use. careful using assignment pipe change data frame.case_when() recode order way command written, months quarters, necessary specify ends quarter. Also cases explicitly handled can addressed TRUE ~ ... argument; case, records birth months September get assigned quarter 4.June\nOctober\nJune\nOctober\nMay\nOctober\nJune\nSeptember\nMay\nJanuary\nJune\nApril\nMay\nOctober\nJuly\nApril\nMay\nSeptember\nAugust\nOctober\nJuly\nAugust\nMay\nOctober\nJuly\nFebruary\nJuly\nFebruary\nAugust\nOctober\nApril\nJuly\nJuly\nFebruary\nJuly\nApril\nMay\nMay\nJune\nOctober\nrecode() used change birth_year_half column:","code":"\n# is this ordered?\nis.ordered(dat$h1gi1m)## [1] FALSE\n# what are the levels?\n(levels(dat$h1gi1m))##  [1] \"(1) January\"   \"(2) February\"  \"(3) March\"     \"(4) April\"    \n##  [5] \"(5) May\"       \"(6) June\"      \"(7) July\"      \"(8) August\"   \n##  [9] \"(9) September\" \"(10) October\"  \"(11) November\" \"(12) December\"\n## [13] \"(96) Refused\"\n# make birth month ordered\ndat$h1gi1m <- factor(dat$h1gi1m, ordered = TRUE)\n\n# now is it ordered?\nis.ordered(dat$h1gi1m)## [1] TRUE\n# perform the mutate() using the string representation of the factor for comparison\ndat %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_1st_half = (birth_month < \"(7) July\")) %>% \n    head(20) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n(X <- dat_sub %>% \n     mutate(iday = -1000 + iday))##         aid        imonth iday     iyear    bio_sex        h1gi1m    h1gi1y\n## 1  57100270      (6) June -977 (95) 1995 (2) Female  (10) October (77) 1977\n## 2  57101310       (5) May -995 (95) 1995 (2) Female (11) November (76) 1976\n## 3  57103171      (6) June -973 (95) 1995   (1) Male  (10) October (79) 1979\n## 4  57103869      (7) July -986 (95) 1995   (1) Male   (1) January (77) 1977\n## 5  57104553      (7) July -986 (95) 1995 (2) Female      (6) June (76) 1976\n## 6  57104649      (6) June -988 (95) 1995   (1) Male (12) December (81) 1981\n## 7  57104676       (5) May -969 (95) 1995   (1) Male  (10) October (83) 1983\n## 8  57109625      (6) June -993 (95) 1995   (1) Male     (3) March (81) 1981\n## 9  57110897      (6) June -973 (95) 1995   (1) Male (9) September (81) 1981\n## 10 57111071    (8) August -997 (95) 1995   (1) Male      (6) June (81) 1981\n## 11 57111786 (9) September -993 (95) 1995   (1) Male (9) September (80) 1980\n## 12 57113943       (5) May -980 (95) 1995   (1) Male   (1) January (79) 1979\n## 13 57116359      (6) June -976 (95) 1995   (1) Male     (4) April (80) 1980\n## 14 57117542      (7) July -989 (95) 1995   (1) Male (9) September (79) 1979\n## 15 57117997       (5) May -980 (95) 1995 (2) Female  (10) October (82) 1982\n## 16 57118381       (5) May -994 (95) 1995 (2) Female  (10) October (82) 1982\n## 17 57118943      (7) July -981 (95) 1995 (2) Female     (4) April (79) 1979\n## 18 57120005       (5) May -975 (95) 1995   (1) Male (9) September (82) 1982\n## 19 57120046    (8) August -980 (95) 1995   (1) Male  (10) October (76) 1976\n## 20 57120371      (7) July -980 (95) 1995 (2) Female    (8) August (76) 1976\n##      h1gi4                             h1gi5a\n## 1   (0) No (7) Legitimate skip (not Hispanic)\n## 2   (0) No (7) Legitimate skip (not Hispanic)\n## 3   (0) No (7) Legitimate skip (not Hispanic)\n## 4   (0) No (7) Legitimate skip (not Hispanic)\n## 5   (0) No (7) Legitimate skip (not Hispanic)\n## 6   (0) No (7) Legitimate skip (not Hispanic)\n## 7   (0) No (7) Legitimate skip (not Hispanic)\n## 8   (0) No (7) Legitimate skip (not Hispanic)\n## 9   (0) No (7) Legitimate skip (not Hispanic)\n## 10  (0) No (7) Legitimate skip (not Hispanic)\n## 11  (0) No (7) Legitimate skip (not Hispanic)\n## 12  (0) No (7) Legitimate skip (not Hispanic)\n## 13  (0) No (7) Legitimate skip (not Hispanic)\n## 14  (0) No (7) Legitimate skip (not Hispanic)\n## 15  (0) No (7) Legitimate skip (not Hispanic)\n## 16  (0) No (7) Legitimate skip (not Hispanic)\n## 17  (0) No (7) Legitimate skip (not Hispanic)\n## 18  (0) No (7) Legitimate skip (not Hispanic)\n## 19 (1) Yes                         (1) Marked\n## 20  (0) No (7) Legitimate skip (not Hispanic)\n##                                h1gi5b\n## 1  (7) Legitimate skip (not Hispanic)\n## 2  (7) Legitimate skip (not Hispanic)\n## 3  (7) Legitimate skip (not Hispanic)\n## 4  (7) Legitimate skip (not Hispanic)\n## 5  (7) Legitimate skip (not Hispanic)\n## 6  (7) Legitimate skip (not Hispanic)\n## 7  (7) Legitimate skip (not Hispanic)\n## 8  (7) Legitimate skip (not Hispanic)\n## 9  (7) Legitimate skip (not Hispanic)\n## 10 (7) Legitimate skip (not Hispanic)\n## 11 (7) Legitimate skip (not Hispanic)\n## 12 (7) Legitimate skip (not Hispanic)\n## 13 (7) Legitimate skip (not Hispanic)\n## 14 (7) Legitimate skip (not Hispanic)\n## 15 (7) Legitimate skip (not Hispanic)\n## 16 (7) Legitimate skip (not Hispanic)\n## 17 (7) Legitimate skip (not Hispanic)\n## 18 (7) Legitimate skip (not Hispanic)\n## 19                     (0) Not marked\n## 20 (7) Legitimate skip (not Hispanic)\ndat_1 <- dat %>% \n    filter(iday > 15) %>%\n    head(20) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_year_half = ifelse(test = birth_month < \"(7) July\", yes = \"first\", no = \"last\"))\n\n# make that a factor\ndat_1$birth_year_half <- factor(dat_1$birth_year_half, levels = c(\"first\", \"last\"))\n    \n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\ndat_1 %<>% \n    mutate(quarter = case_when(\n        birth_month < \"(3) March\" ~ 1,\n        birth_month < \"(6) June\" ~ 2,\n        birth_month < \"(9) September\" ~ 3,\n        TRUE ~ 4))\n\n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n(dat_1 %<>% \n     mutate(birth_year_half_split = recode(birth_year_half,\n                   \"first\" = \"early\",\n                   \"last\" = \"late\")))##         aid     imonth iday   birth_month birth_year_half quarter\n## 1  57100270   (6) June   23  (10) October            last       4\n## 2  57103171   (6) June   27  (10) October            last       4\n## 3  57104676    (5) May   31  (10) October            last       4\n## 4  57110897   (6) June   27 (9) September            last       4\n## 5  57113943    (5) May   20   (1) January           first       1\n## 6  57116359   (6) June   24     (4) April           first       2\n## 7  57117997    (5) May   20  (10) October            last       4\n## 8  57118943   (7) July   19     (4) April           first       2\n## 9  57120005    (5) May   25 (9) September            last       4\n## 10 57120046 (8) August   20  (10) October            last       4\n## 11 57120371   (7) July   20    (8) August            last       3\n## 12 57121476    (5) May   20  (10) October            last       4\n## 13 57123494   (7) July   21  (2) February           first       1\n## 14 57129567   (7) July   26  (2) February           first       1\n## 15 57130633 (8) August   26  (10) October            last       4\n## 16 57131909  (4) April   27      (7) July            last       3\n## 17 57133772   (7) July   19  (2) February           first       1\n## 18 57134457   (7) July   18     (4) April           first       2\n## 19 57136630    (5) May   16       (5) May           first       2\n## 20 57139880   (6) June   19  (10) October            last       4\n##    birth_year_half_split\n## 1                   late\n## 2                   late\n## 3                   late\n## 4                   late\n## 5                  early\n## 6                  early\n## 7                   late\n## 8                  early\n## 9                   late\n## 10                  late\n## 11                  late\n## 12                  late\n## 13                 early\n## 14                 early\n## 15                  late\n## 16                  late\n## 17                 early\n## 18                 early\n## 19                 early\n## 20                  late"},{"path":"week1.html","id":"summarizingaggregating-data","chapter":"1 Week 1","heading":"1.6.2.5 Summarizing/aggregating data","text":"spend time later course data summaries, introduction dplyr worthwhile introducing stage. two main functions summarise() group_by().simple summary tabulate count respondents mean age. filter ! str_detect(h1gi1y, \"Refused\") drops records respondents refused give birth year.summarize age sex using group_by() function, also piping prop_table() get percentage:","code":"\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    summarise(n = n(),\n              mean_age = mean(yeari - yearb))##      n mean_age\n## 1 6501 16.03676\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    group_by(bio_sex) %>% \n    summarise(mean_age = mean(yeari - yearb),\n              sd_age = sd(yeari - yearb),\n              n = n(),\n              .groups = \"drop_last\") %>% \n    mutate(pct = prop.table(n) * 100)## # A tibble: 2 x 5\n##   bio_sex    mean_age sd_age     n   pct\n##   <fct>         <dbl>  <dbl> <int> <dbl>\n## 1 (1) Male       16.1   1.77  3147  48.4\n## 2 (2) Female     16.0   1.77  3354  51.6"},{"path":"week1.html","id":"purrr-efficient-iterating-over-elements-in-vectors-and-lists","chapter":"1 Week 1","heading":"1.6.2.6 purrr: efficient iterating over elements in vectors and lists","text":"attention paid purrr lesson functions.workhorse function purrr map(), applies function list atomic vector.brief example uses vector c(9, 16, 25) map() function used get square root element. output listOther resources purrr: Learn purrr, purrr tutorial","code":"\n# apply the sqrt() function to each element of a vector of integers\nmap(c(9, 16, 25), sqrt)## [[1]]\n## [1] 3\n## \n## [[2]]\n## [1] 4\n## \n## [[3]]\n## [1] 5"},{"path":"week1.html","id":"datasets001","chapter":"1 Week 1","heading":"1.7 Data sets","text":"","code":""},{"path":"week1.html","id":"edward-babushkins-employee-turnover-data","chapter":"1 Week 1","heading":"1.7.1 Edward Babushkin’s Employee turnover data","text":"data used CSDE 533: Edward Babushkin’s employee turnover data, explained bit kaggle.com downloadable file.load data set URL:Just get bit tidyverse last minute, let’s get mean standard deviation job tenure gender 10-year age class:Rendered 2022-01-08 17:59:3301-week01.Rmd","code":"\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n# create 10-year age classes \netdata %<>% \n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling)) \n\n# summarize\netdata %>% \n    # group by gender and age class\n    group_by(gender, age_decade) %>% \n    # mean and sd\n    summarize(mean_tenure_months = mean(tenure) %>% round(1),\n              sd_tenure_months = sd(tenure) %>% round(1), \n              .groups = \"keep\") %>% \n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>% \n    # print it nicely\n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))# Week 1 {#week1}\n\n```{r, echo=FALSE, message=FALSE, error=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# this course's URL\nmyurl <- \"https://csde-uw.github.io/csde502-winter-2022\"\n```\n\n<h2>Topics:<\/h2>\n* [Getting started on terminal server 4](#gettingstarted)\n* [Introduction to R/RStudio/R Markdown](#intrormd)\n* [R data types](#rdatatypes)\n* [R data structures](#rdatastructures)\n* [File systems](#filesystems)\n* [Data manipulation in the `tidyverse`](#tidyverse)\n* [Data sets:](#datasets001)\n    * Employee turnover data\n    \n<hr>\nToday's lessons will cover getting started with computing at CSDE, and quickly introduce R, RStudio, and R Markdown.\n\nIt is assumed that students in this course have a basic working knowledge of using R, including how to create variables with the assignment operator (\"`<-`\"), and how to run simple functions(e.g., `mean(dat$age)`). Often in courses that include using R for statistical analysis, some of the following foundations are not explained fully. This section is not intended to be a comprehensive treatment of R data types and structures, but should provide some background for students who are either relatively new at using R or who have not had a systematic introduction.    \n\nThe other main topic for today is [`tidyverse`](https://www.tidyverse.org/), which refers to a related set of R packages for data management, analysis, and display. See Hadley Wickham's [tidy tools manifesto](https://tidyverse.tidyverse.org/articles/manifesto.html) for the logic behind the suite of tools. For a brief description of the specific R packages, see [Tidyverse packages](https://www.tidyverse.org/packages/). This is not intended to be a complete introduction to the `tidyverse`, but should provide sufficient background for data handling to support most of the technical aspects of the rest of the course and CSDE 533.\n\n## Getting started on Terminal Server 4 {#gettingstarted}\nFirst, if you are not on campus, make sure you have the Husky OnNet VPN application running and have connected to the UW network. You should see the f5 icon in your task area:\n\n![](images/week01/2021-01-07_21_40_25-.png)\n\nConnect to TS4: `csde-ts4.csde.washington.edu`\n\nIf you are using the Windows Remote Desktop Protocol (RDP) connection, your connection parameters should look like this:\n\n![](images/week01/2021-01-07_21_48_03-Remote Desktop Connection.png)\n\nIf you are using mRemoteNG, the connection parameters will match this:\n\n![](images/week01/2021-01-07_21_37_36-Window.png)\n\nOnce you are connected you should see a number of icons on the desktop and application shortcuts in the Start area.\n\n![](images/week01/2021-01-07_21_59_38-.png)\n\n![](images/week01/2021-01-07_22_00_14-Window.png)\n\nOpen a Windows Explorer (if you are running RDP in full screen mode you should be able to use the key combination Win-E).\n\nBefore doing anything, let's change some of the annoying default settings of the Windows Explorer. Tap `File > Options`. In the `View` tab, make sure that `Always show menus` is checked and `Hide extensions for known file types` is unchecked. The latter setting is very important because we want to see the complete file name for all files at all times.\n\n![](images/week01/2021-01-07_22_30_46-Folder_Options.png)\n\nClick `Apply to Folders` so that these settings become default. Click `Yes` to the next dialog.\n\n![](images/week01/2021-01-07_22_31_37-FolderViews.png)\n\nNow let's make a folder for the files in this course.\n\nNavigate to This PC:\n\n![](images/week01/2021-01-07_22_05_59-Window.png)\n\nYou should see the `H:` drive. This is is the mapped drive that links to your [U Drive](https://itconnect.uw.edu/wares/online-storage/u-drive-central-file-storage-for-users/), and is the place where all of the data for this course is to be stored. __Do not store any data on the `C:` drive!__ The `C:` drive can be wiped without any prior notification.\n\n__Be very careful with your files on the U Drive!__ If you delete files, there is no \"undo\" functionality. When you are deleting files, you will get a warning that you should take seriously:\n\n![](images/week01/2021-01-07_23_01_10-Delete_Folder.png)\n\nNavigate into `H:` and create a new folder named `csde502_winter_2022`. Note the use of lowercase letters and underscores rather than spaces. This will be discussed in the section on file systems later in this lesson.\n\n![](images/week01/2021-01-07_22_32_29-new_folder.png)\n\n## Introduction to R Markdown in RStudio {#intrormd}\n\n### Create a project\nNow we will use RStudio to create the first R Markdown source file and render it to HTML.\n\nStart RStudio by either dbl-clicking the desktop shortcut or navigating to the alphabetical R section of the Start menu:\n\n![](images/week01/2021-01-07_23_05_49-Window.png)\n\n:::{.rmdnote}\nA brief aside: install R packages.\n\nTo get started, because it usually takes some time to install, open a second RStudio session and at the console, to install `tidyverse`, the other packages for CSDE 502 and 533, and for this lesson, download the file [`packages.R`](tools/packages.R).\n\nOpen the file in your second RStudio session and in the upper right of the source code pane, click `Source > Source`.\n\n![](images/week01/2022-01-06 21_47_15-source.png)\n\nNow continue on with the lesson in your original RStudio session.....\n:::\n\nCreate a new project (`File > New Project...`).\n\n![](images/week01/2021-01-07_23_08_34-rstudiorappbroker.csde.washington.edu.png)\n\nSince we just created the directory to house the project, select `Existing Directory`.\n\n![](images/week01/2021-01-07_23_09_11-csde502_winter_2021_course-RStudiorappbroker.csde.washington.edu.png)\n\nNavigate to that directory and select `Open`.\n\n![](images/week01/2021-01-07_23_09_48-ChooseDirectoryrappbroker.csde.washington.edu.png)\n\nClick `Create Project`.\n\n![](images/week01/2021-01-07_23_10_02-csde502_winter_2021_course-RStudiorappbroker.csde.washington.edu.png)\n\nYou will now have a blank project with only the project file.\n\n![](images/week01/2021-01-07_23_11_16-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\n### Create an R Markdown file from built-in RStudio functionality\nLet's make an R Markdown file (`File > New File > R Markdown...`).\n\n![](images/week01/2021-01-07_23_12_31-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nDo not change any of the metadata ... this is just for a quick example.\n\n![](images/week01/2021-01-07_23_13_41-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nClick `OK` and then name the file `week_01.Rmd`.\n\n![](images/week01/2021-01-07_23_14_59-SaveFile-Untitled1rappbroker.csde.washington.edu.png)\n\n#### Render the Rmd file as HTML\n\nAt the console prompt, enter `R Markdown::render(\"W` and tap the `TAB` key. This should bring up a list of files that have the character \"w\" in the file name. Click `week_01.Rmd`.\n\nThe syntax here means \"run the `render()` function from the `R Markdown` package on the file `week_01.Rmd`\"\n\n![](images/week01/2021-01-07_23_15_32-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nAfter a few moments, the process should complete with a message that the output has been created.\n\n![](images/week01/2021-01-07_23_16_13-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nIf the HTML page does not open automatically, look for `week_01.html` in the list of files. Click it and select `View in Web Browser`.\n\n![](images/week01/2021-01-07_23_16_39-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nYou will now see the bare-bones HTML file.\n\n![](images/week01/2021-01-07_23_17_10-Untitled.png)\n\nCompare the output of this file with the source code in `week_01.Rmd`. Note there are section headers that begin with hash marks, and R code is indicated with the starting characters \n\n<code>\n\\`\\`\\`\\{r\\}\n<\/code>\n\nand the ending characters\n\n<code>\n\\`\\`\\`\n<\/code>\n\nNext, we will explore some enhancements to the basic R Markdown syntax.\n\n### Create an R Markdown file with some enhancements\n\nDownload this version of [`week_01.Rmd`](files/week_01.Rmd) and overwrite the version you just created.\n\nIf RStudio prints a message that some packages are required but are not installed, click `Install`.\n\n![](images/week01/2021-01-07_23_26_55-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png)\n\nChange line 3 to include your name and e-mail address as shown. \n\n![](images/week01/2021-01-08_00_35_18-Window.png)\n\n#### Render and view the enhanced output\nRepeat the rendering process (`R Markdown::render(\"Week_01.Rmd\")`) \n\nThe new HTML file has a number of enhancements, including a mailto: hyperlink for your name, a table of contents at the upper left, a table that is easier to read, a Leaflet map, captions and cross-references for the figures and table, an image derived from a PNG file referenced by a URL, the code used to generate various parts of the document that are produced by R code, and the complete source code for the document. A downloadable version of the rendered file: [week_01.html](files/week_01.html).\n\n![](images/week01/2021-01-08_00_19_27-Week01.png)\n\nIncluding the source code for the document is especially useful for readers of your documents because it lets them see exactly what you did. An entire research chain can be documented in this way, from reading in raw data, performing data cleaning and analysis, and generating results.\n\n## R data types {#rdatatypes}\nThere are six fundamental data types in R:\n\n1. logical\n1. numeric\n1. integer\n1. complex\n1. character\n1. raw\n\nThe most atomic object in R will exist having one of those data types, described below. An atomic object of the data type can have a value, `NA` which represents an observation with no data (e.g., a missing measurement), or `NULL` which isn't really a value at all, but can still have the data type class.\n\nYou will encounter other data types, such as `Date` or `POSIXct` if you are working with dates or time stamps. These other data types are extensions of the fundamental data types.\n\nTo determine what data type an object is, use `is(obj)`, `str(obj)`, or `class(obj)`. \n\n```{r}\nprint(is(\"a\"))\n\nprint(str(TRUE))\n\nprint(class(123.45))\n\nprint(class(as.integer(1000)))\n\nn <- as.numeric(999999999999999999999)\n\nprint(class(n))\n```\n\n### Logical\nUse `logical` values for characteristics that are either `TRUE` or `FALSE`. Note that if `logical` elements can also have an `NA` value if the observation is missing. In the following examples, \n\n```{r}\n# evaluate as logical, test whether 1 is greater than two\na <- 1 > 2\n```\n\n```{r}\n# create two numerical values, one being NA, representing ages\nage_john <- 39\nage_jane <- NA\n\n# logical NA from Jane's undefined age\n(jo <- age_john > 50)\n(ja <- age_jane > 50)\n```\n\nLogical values are often expressed in binary format as 0 = `FALSE` and ` = `TRUE`. in R these values are interconvertible. Other software (e.g., Excel, MS Access) may convert logical values to numbers that you do not expect.\n\n```{r}\n(t <- as.logical(1))\n(f <- as.logical(0))\n```\n\n### Numeric\n`Numeric` values are numbers with range about 2e-308 to 2e+308, depending on the computer you are using. You can see the possible range by entering `.Machine` at the R console. These can also include decimals. For more information, see [Double-precision floating-point format](https://en.wikipedia.org/wiki/Double-precision_floating-point_format)\n\n\n### Integer\n`Integer` values are numerical, but can only take on whole, rather than fractional values, and have a truncated range compared to `numeric`. For example, see below, if we try to create an integer that is out of range. The object we created is an integer, but because it is out of range, is value is set to `NA`.\n\n```{r}\ni <- as.integer(999999999999999999999)\n\nprint(class(i))\n```\n\n### Complex\nThe `complex` type is used in mathematics and you are unlikely to use it in applied social science research unless you get into some heavy statistics. See [Complex number](https://en.wikipedia.org/wiki/Complex_number) for a full treatment.\n\n### Character\n`Character` data include the full set of keys on your keyboard that print out a character, typically [A-Z], [a-z], [0-9], punctuation, etc. The full set of ASCII characters is supported, e.g. the `accent aigu` in CafÃ©:\n\n```{r}\nprint(class(\"CafÃ©\"))\n```\n\nAlso numbers can function as characters. Be careful in converting between numerical and character versions. For example, see these ZIP codes:\n\n```{r error=TRUE}\n# this is a character\nmy_zip <- \"98115\"\n\n# it is not numeric.\nmy_zip + 2\n```\n\n```{r}\n# we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values\nas.numeric(my_zip) + 2\n\n# Boston has ZIP codes starting with zeros\nboston_zip <- \"02134\"\nas.numeric(boston_zip)\n```\n\n### Raw\n`Raw` values are used to store raw bytes in hexadecimal format. You are unlikely to use it in applied social science research. For example, the hexadecimal value for the character `z` is `7a`:\n\n```{r}\nprint(charToRaw(\"z\"))\n\nclass(charToRaw(\"z\"))\n```\n\n\n## R data structures {#rdatastructures}\n\n![](images/week02/data_structures.png)\n\nThere are 5 basic data structures in R, as shown in the graphic: \n\n1. vector\n1. matrix\n1. array\n1. list\n1. data frame\n\nIn addition, the `factor` data type is very important\n\n### Vector\nA vector is an ordered set of elements of one or more elements of the same data type and are created using the `c()` constructor function. For example, a single value is a vector:\n\n```{r}\n# create a vector of length 1\na <- 1\nis(a)\n```\n\n\nIf you try creating a vector with mixed data types, you may get unexpected results; mixing character elements with other type elements will result in character representations, e.g., \n\n```{r}\nc(1, \"a\", TRUE, charToRaw(\"z\"))\n```\n\nResults will depend on the data type you are mixing, for example because logical values can be expressed numerically, the `TRUE` and `FALSE` values are converted to `1` and `0`, respectively.\n\n```{r}\n(c(1:3, TRUE, FALSE))\n```\n\nBut if a character is added, all elements are converted to characters.\n\n```{r}\nc(1:3, TRUE, FALSE, \"awesome!\")\n```\n\nOrder is important, i.e., \n\n`1, 2, 3` is not the same as `1, 3, 2`\n\nR will maintain the order of elements in vectors unless a process is initiated that changes the order of those elements:\n\n```{r}\n# a vector \n(v <- c(1, 3, 2))\n\n(sort(v))\n```\n\nYou can get some information about vectors, such as length and data type:\n\n```{r}\n# create a random normal \nset.seed(5)\nnormvec1000 <- rnorm(n = 1000)\n\nlength(normvec1000)\nclass(normvec1000)\nclass(normvec1000 > 1)\n```\n\nElements of vectors are specified with their index number (1 .. n):\n\n```{r}\nv <- seq(from = 0, to = 10, by = 2)\nv[4]\n```\n\n### Matrix\nA matrix is like a vector, in that it an contain only one data type, but it is two-dimensional, having rows and columns. A simple example:\n\n```{r}\n# make a vector 1 to 100\n(v <- 1:100)\n\n# load to a matrix\n(m1 <- matrix(v, ncol = 10, byrow = TRUE))\n\n# different r, c ordering\n(m2 <- matrix(v, ncol = 10, byrow = FALSE))\n```\n\nIf you try to force a vector into a matrix whose row $\\times$ col length does not match the length of the vector, the elements will be recycled, which may not be what you want. At least R will give you a warning.\n\n```{r}\n(m3 <- matrix(letters, ncol = 10, nrow = 10))\n```\n\n### Array\nAn array is similar to matrix, but it can have more than one dimension. These can be useful for analyzing time series data or other multidimensional data. We will not be using array data in this course, but a simple example of creating and viewing the contents of an array:\n\n```{r}\n# a vector 1 to 27\nv <- 1:27\n\n# create an array, 3 x 3 x 3\n(a <- array(v, dim = c(3, 3, 3)))\n\n# array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3:\n(a[1,2,3])\n```\n\n### List\nR lists are ordered collections of objects that do not need to be of the same data type. Those objects can be single-value vectors, multiple-value vectors, matrices, data frames, other lists, etc. Because of this, lists are a very flexible data type. But because they can have as little or as much structure as you want, can become difficult to manage and analyze.\n\nHere is an example of a list comprised of single value vectors of different data type. Compare this with the attempt to make a vector comprised of elements of different data type:\n\n```{r}\n(l <- list(\"a\", 1, TRUE))\n```\n\nLet's modify that list a bit:\n\n```{r}\n(l <- list(\"a\", \n           1:20, \n           as.logical(c(0,1,1,0))))\n```\n\nThe top-level indexing for a list is denoted using two sets of square brackets. For example, the first element of our list can be accessed by `l[[1]]`. For example, the mean of element 2 is obtained by `mean(l[[2]])`: ``r mean(l[[2]])``.\n\nTo perform operations on all elements of a list, use `lapply()`:\n\n```{r}\n# show the data types\n(lapply(X = l, FUN = class))\n\n# mean, maybe?\n(lapply(X = l, FUN = function(x) {mean(x)}))\n```\n### Factor\nFactors are similar to vectors, in that they are one-dimensional ordered sets. However, factors also use informational labels. For example, you may have a variable with household income as a text value:\n\n* \"<$10,000\"\n* \"$10,000-$549,999\"\n* \"$50,000-$99,999\"\n* \"$100,000-$200,000\"\n* \">$200,000\"\n\nAs a vector:\n\n```{r}\n(income <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\"))\n```\n\nBecause these are characters, they do not sort in proper numeric order:\n\n```{r}\nsort(income)\n```\n\nIf these are treated as a factor, the levels can be set for proper ordering:\n\n```{r}\n# create a factor from income and set the levels\n(income_factor <- factor(x = income, levels = income))\n\n# sort again\n(sort(income_factor))\n```\n\nAs a factor, the data can also be used in statistical models and the magnitude of the variable will also be correctly ordered.\n\n### Data frame\nOther than vectors, data frames are probably the most used data type in R. You can think of data frames as matrices that allow columns with different data type. For example, you might have a data set that represents subject IDs as characters, sex or gender as text, height, weight, and age as numerical values, income as a factor, and smoking status as logical. Because a matrix requires only one data type, it would not be possible to store all of these as a matrix. An example:\n\n```{r}\n# income levels \ninc <- c(\"<$10,000\"\n, \"$10,000-$49,999\"\n, \"$50,000-$99,999\"\n, \"$100,000-$200,000\"\n, \">$200,000\")\n\nBMI <-  data.frame(\n   sid = c(\"A1001\", \"A1002\", \"B1001\"),\n   gender = c(\"Male\", \"Male\",\"Female\"), \n   height_cm = c(152, 171.5, 165), \n   weight_kg = c(81, 93, 78),\n   age_y = c(42, 38, 26),\n   income = factor(c(\"$50,000-$99,999\", \"$100,000-$200,000\", \"<$10,000\"), levels = inc)\n)\nprint(BMI)\n```\n\n## File systems {#filesystems}\nAlthough a full treatment of effective uses of file systems is beyond the scope of this course, a few basic rules are worth covering:\n\n1. Never use spaces in folder or file names. \n    Ninety-nine and 44/100ths percent of the time, most modern software will have no problems handling file names with spaces. But that 0.56% of the time when software chokes, you may wonder why your processes are failing. If your directly and file names do not have spaces, then you can at least rule that out!\n1. Use lowercase letters in directory and file names.\n    In the olden days (MS-DOS), there was not case sensitivity in file names. UNIX has has always used case sensitive file names. So \n    `MyGloriousPhDDissertation.tex` and `mygloriousphddissertation.tex` could actually be different files. Macs, being based on a UNIX kernel, also employ case sensitivity in file names. But Windows? No. Consider the following: there cannot be both `foo.txt` and `FOO.txt` in the same directory. \n    ![](images/week01/2021-01-08_01_13_50-CommandPrompt.png)\n    \n    So if Windows doesn't care, why should we? Save yourself some keyboarding time and confusion by using only lowercase characters in your file names.\n1. Include dates in your file names.\n    If you expect to have multiple files that are sequential versions of a file in progress, an alternative to using a content management system such as [git](https://git-scm.com/), particularly for binary files such as Word documents or SAS data files, is to have multiple versions of the files but including the date as part of the file name. If you expect to have multiple versions on the same date, include a lowercase alphabetical character; it is improbable that you would have more than 26 versions of a fine on a single calendar date. If you are paranoid, use a suffix number `0000`, `0002` .. `9999`. If you have ten thousand versions of the same file on a given date, you are probably doing something that is not right.\n    Now that you are convinced that including dates in file names is a good idea, _please_ use the format `yyyy-mm-dd` or `yyyymmdd`. If you do so, your file names will sort in temporal order.\n1. Make use of directories! \n   Although a folder containing 100,000 files can be handled programatically (if file naming conventions are used), it is not possible for a human being to visually scan 100,000 file names. If you have a lot of files for your project, consider creating directories, e.g., \n       - raw_data\n       - processed_data\n       - analysis_results\n       - scripts\n       - manuscript\n1. Agonize over file names. \n    Optimally when you look at your file names, you will be able to know something about the content of the file. We spend a lot of time doing analysis and creating output. Spending an extra minute thinking about good file names is time well spent.\n\n\n## Data manipulation in the `tidyverse` {#tidyverse}\nOne of the R packages we will use frequently is [`tidyverse`](https://www.tidyverse.org/packages/), which is itself a collection of several other packages, each with a specific domain: \n\n* `ggplot2` (graphics)\n* `dplyr` (data manipulation)\n* `tidyr` (reformatting data for efficient processing)\n* `readr` (reading rectangular R x C data)\n* `purrr` (functional programming, e.g., to replace `for()` loops)\n* `tibble` (enhanced data frames)\n* `stringr` (string, i.e., text manipulation)\n* `forcats` (handling factor, i.e., categorical variables)\n\nWe will touch on some of these during this course, but there will not be a full review or treatment of the `tidyverse`.\n\nThis section will introduce some of the main workhorse functions in tidy data handling. \n\nInstalling tidyverse is straightforward but it may take some time to download and install all of the packages. If you have not done so yet, use\n\n```\ninstall.packages(\"tidyverse\")\n```\n\nFor today's lesson we will be using one of the Add Health public use data sets, [AHwave1_v1.dta](data/AHwave1_v1.dta). \n\n```{r warning=FALSE, message=FALSE}\n# load pacman if necessary\npackage.check <- lapply(\"pacman\", FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n        install.packages(x, dependencies = TRUE)\n        library(x, character.only = TRUE)\n    }\n})\n\n# load readstata13 if necessary\npacman::p_load(readstata13)\n\n# read the dta file\ndat <- readstata13::read.dta13(file.path(myurl, \"data/AHwave1_v1.dta\"))\n```\n\nThe data set includes variable labels, which make handling the data easier. Here we print the column names and their labels. Wrapping this in a `DT::data_table` presents a nice interface for showing only a few variables at a time and that allows sorting and searching.\n\n```{r}\nx <- data.frame(colname = names(dat), label = attributes(dat)$var.labels)\nDT::datatable(data = x, caption = \"Column names and labels in AHwave1_v1.dta.\")\n```\n\n\n### magrittr{#magrittr}\n![](images/week02/unepipe.jpeg)\n\nThe R package [`magrittr`](https://cran.r-project.org/web/packages/magrittr/index.html) allows the use of \"pipes\". In UNIX, pipes were used to take the output of one program and to feed as input to another program. For example, the UNIX command `cat` prints the contents of a text file. This would print the contents of the file `00README.txt`:\n\n```cat 00README.txt```\n\nbut with large files, the entire contents would scroll by too fast to read. Using a \"pipe\", denoted with the vertical bar character `|` allowed using the `more` command to print one screen at a time by tapping the `Enter` key for each screen full of text:\n\n```cat 00README.txt | more```\n\nAs shown in these two screen captures:\n\n![](images/week02/cat_more.png)\n\n![](images/week02/cat_more2.png)\n\nThe two main pipe operators we will use in `magrittr` are `%>%` and '%<>%'.\n\n`%>%` is the pipe operator, which functions as a UNIX pipe, that is, to take something on the left hand side of the operator and feed it to the right hand side. \n\n`%<>%` is the assignment pipe operator, which takes something on the left hand side of the operator, feeds it to the right hand side, and replaces the object on the left-hand side.\n\nFor a simple example of the pipe, to list only the first 6 lines of a data frame in base R, we use `head()`, e.g.,\n\n```{r}\nhead(iris)\n```\n\nusing a tidy version of this:\n\n```{r}\niris %>% head()\n```\n\nIn the R base version, we first read `head`, so we know we will be printing the first 6 elements of something, but we don't know what that \"something\" is. We have to read ahead to know we are reading the first 6 records of `iris`. In the tidy version, we start by knowing we are doing something to the data set, after which we know we are printing the first 6 records.\n\nIn base R functions, the process is evaluated from the inside out. For example, to get the mean sepal length of the _setosa_ species in iris, we would do this:\n\n```{r}\nmean(iris[iris$Species == 'setosa', \"Sepal.Length\"])\n```\n\nFrom the inside out, we read that we are making a subset of `iris` where Species = \"setosa\", we are selecting the column \"Sepal.Length\", and taking the mean. However, it requires reading from the inside out. For a large set of nested functions, we would have ` y <- f(g(h((i(x)))))`, which would require first creating the innermost function (`i()`) and then working outward.\n\nIn a tidy approach this would be more like y <- x %>% i() %>% h() %>% g() %>% f()` because the first function applied to the data set `x` is `i()`. Revisiting the mean sepal length of _setosa_ irises, example, under a tidy approach we would do this:\n\n```{r}\niris %>% filter(Species == 'setosa') %>% summarise(mean(Sepal.Length))\n```\n\nWhich, read from left to right, translates to \"using the iris data frame, make a subset of records where species is _setosa_, and summarize those records to get the mean value of sepal length.\" The tidy version is intended to be easier to write, read, and understand. The command uses the `filter()` function, which will be described below.\n\n### Data subsetting (dplyr)\n`dplyr` is the tidyverse R package used most frequently for data manipulation. Selection of records (i.e., subsetting) is done using logical tests to determine what is in the selected set. First we will look at logical tests and then we will cover subsetting rows and columns from data frames.\n\n##### Logical tests\nIf elements meet a logical test, they will end up in the selected set. If data frame records have values in variables that meet logical criteria, the records will be selected. \n\nSome logical tests are shown below.\n\n###### `==`: equals\n\n```{r}\n# numeric tests\n(1 == 2)\n```\n\n```{r}\n(1 == 3 - 2)\n```\n\n```{r}\n# character test (actually a factor)\n(dat$imonth %>% head() %>% str_c(collapse = \", \"))\n((dat$imonth == \"(6) June\") %>% head())\n```\n\n```{r}\n# character test for multiple patterns\n(dat$imonth %in% c(\"(6) June\", \"(7) July\") %>% head())\n```\n\n\n###### `>`, `>=`, `<`, `<=`: numeric comparisons\n\n```{r}\n1 < 2\n```\n\n```{r}\n1 > 2\n```\n\n```{r}\n1 <= -10:10\n```\n\n```{r}\n1 >= -10:10\n```\n\n###### `!=`: not equals\n\n```{r}\n1 != 2\n```\n\n```{r}\n# those of the first 6 days that are not 14\n(dat$iday %>% head())\n((dat$iday != 14) %>% head())\n```\n\n###### `!`: invert, or \"not\"\nSometimes it is more convenient to negate a single condition rather than enumerating all possible matching conditions.\n\n```{r}\ndat$imonth %>% head(20)\n((!dat$imonth %in% c(\"(6) June\", \"(7) July\")) %>% head(20))\n```\n\n#### Subset rows (`filter()`)\nThe `filter()` function creates a subset of records based on a logical test. Logical tests can be combined as \"and\" statements using the `&` operator and \"or\" statements using the `|` operator. Here we will perform a few filters on a subset of the data.\n\n```{r}\n# first 20 records, fist 10 columns\ndat_sub <- dat[1:20, 1:10]\nkable(dat_sub, format = \"html\") %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nRecords from one month:\n\n```{r}\n# from May\n(dat_sub %>% filter(imonth == \"(5) May\"))\n```\n\nRecords from one month from females:\n\n```{r}\n(dat_sub %>% filter(imonth == \"(5) May\" & bio_sex == \"(2) Female\"))\n```\n\nRecords from one month and from females or where the day of month was before the 15th, which will probably include some males:\n\n```{r}\n(dat_sub %>% filter(imonth == \"(5) May\" & (bio_sex == \"(2) Female\") | iday < 15))\n\n```\n\nAlthough these examples are silly and trivial, they show how `filter()` is used to create a selected set of data\n\n#### Subset columns (`select()`)\nA subset of columns can be extracted from data frames using the `select()` function, most simply using  named list of columns to keep.\n\n```{r}\n# select 3 columns\n(dat_sub_sel <- dat_sub %>%   \n    select(\"aid\", \"imonth\", \"iday\"))\n```\n\n```{r}\n# select all but two named columns\n(dat_sub_sel <- dat_sub %>%   \n    select(-\"imonth\", -\"iday\"))\n```\n\n```{r}\n# select columns by position and whose name matches a pattern, in this case the regular expression \"^i\" meaning \"starts with lowercase i\"\n(dat_sub_sel <- dat_sub %>%   \n    select(1, matches(\"^i\")))\n```\n\n`select()` can also be used to rename columns:\n\n```{r}\n#select one column, rename two columns\n(dat_sub_sel %>% \n   select(aid, Month = imonth, Day = iday))\n```\n\nOr column renaming can be done with `rename()`, which maintains all input data and only changes the named columns:\n\n```{r}\n(dat_sub_sel %>% \n   rename(Month = imonth, Day = iday))\n```\n\n#### Subset rows and columns: `filter()` and `select()`\nWe can combine `filter()` and `select()` with a pipe to create a new data frame with a subset of rows and columns:\n\n```{r}\n# records with day of month > 15 and the first 3 named columns\n(x <- dat_sub %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday)\n   )\n```\n\n#### Create or calculate columns: `mutate()`\n`mutate()` will create new named columns or re-calculate existing columns. Here we will make a column that stratifies birth month, with the cut at June. \n\nAlthough the birth month column (`h1gi1m`) is a factor, it is unordered, so we need to make it ordered before using the factor label in a numeric comparison. Fortunately, the factor labels were handled in correct order:\n\n```{r}\n# is this ordered?\nis.ordered(dat$h1gi1m)\n```\n\n```{r}\n# what are the levels?\n(levels(dat$h1gi1m))\n```\n\nAssign order, create a new column, and print nicely:\n\n```{r}\n# make birth month ordered\ndat$h1gi1m <- factor(dat$h1gi1m, ordered = TRUE)\n\n# now is it ordered?\nis.ordered(dat$h1gi1m)\n```\n\n```{r}\n# perform the mutate() using the string representation of the factor for comparison\ndat %>% \n    filter(iday > 15) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_1st_half = (birth_month < \"(7) July\")) %>% \n    head(20) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nA silly example but showing that `mutate()` can change values of existing columns:\n\n```{r}\n(X <- dat_sub %>% \n     mutate(iday = -1000 + iday))\n```\n\n... so do be careful!\n\nOther functions can be used with mutate include (but are by no means limited to!) \n\n* `if_else()`: create a column by assigning values based on logical criteria\n* `case_when()`: similar to `if_else()` but for multiple input values\n* `recode()`: change particular values\n\nWhen we recoded the birth month, the output was a `logical` data type. If we wanted to create a \n`character` or `factor`, we could use `if_else()`. Here we are creating a new data frame based on several operations on `dat`.\n\n```{r}\ndat_1 <- dat %>% \n    filter(iday > 15) %>%\n    head(20) %>%\n    select(aid, imonth, iday, birth_month = h1gi1m) %>% \n    mutate(birth_year_half = ifelse(test = birth_month < \"(7) July\", yes = \"first\", no = \"last\"))\n\n# make that a factor\ndat_1$birth_year_half <- factor(dat_1$birth_year_half, levels = c(\"first\", \"last\"))\n    \n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\nIf one of your variables contains multiple values and you want to create classes, use `case_when()`. Here is a verbose example stratifying months into quarters. Also we are using the `magrittr` assignment pipe to update the input based on the statement, i.e., `dat_1` will change based on the commands we use. __Be careful using the assignment pipe because it will change your data frame.__\n\n`case_when()` will recode in order or the way the command is written, so for months and quarters, it is not necessary to specify both ends of the quarter. Also any cases that are not explicitly handled can be addressed with the `TRUE ~ ...` argument; in this case, any records that had birth months that were not before September get assigned to quarter 4.\n\n```{r}\ndat_1 %<>% \n    mutate(quarter = case_when(\n        birth_month < \"(3) March\" ~ 1,\n        birth_month < \"(6) June\" ~ 2,\n        birth_month < \"(9) September\" ~ 3,\n        TRUE ~ 4))\n\n# print\nkable(dat_1) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\")\n```\n\n`recode()` is used to change the `birth_year_half` column:\n\n```{r}\n(dat_1 %<>% \n     mutate(birth_year_half_split = recode(birth_year_half,\n                   \"first\" = \"early\",\n                   \"last\" = \"late\")))\n```\n\n#### Summarizing/aggregating data\nWe will spend more time later in the course on data summaries, but an introduction with `dplyr` is worthwhile introducing at this stage. The two main functions are `summarise()` and `group_by()`.\n\nA simple summary will tabulate the count of respondents and the mean age. The filter `! str_detect(h1gi1y, \"Refused\")` drops records from respondents who refused to give their birth year.\n\n```{r}\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    summarise(n = n(),\n              mean_age = mean(yeari - yearb))\n```\n\nHere we will summarize age by sex using the `group_by()` function, and also piping to `prop_table()` to get the percentage:\n\n```{r}\ndat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    mutate(yeari = str_replace_all(iyear, \".* \", \"\") %>% as.integer(),\n           yearb = str_replace_all(h1gi1y, \".* \", \"\") %>% as.integer()) %>% \n    group_by(bio_sex) %>% \n    summarise(mean_age = mean(yeari - yearb),\n              sd_age = sd(yeari - yearb),\n              n = n(),\n              .groups = \"drop_last\") %>% \n    mutate(pct = prop.table(n) * 100)\n```\n\n#### purrr: efficient iterating over elements in vectors and lists\nMore attention will be paid to `purrr` in the lesson on [functions](#week2).\n\nThe workhorse function in `purrr` is `map()`, which applies a function over a list or atomic vector.\n\nA brief example uses a vector `c(9, 16, 25)` and the `map()` function is used to get the square root of each element. The output is a list\n\n```{r}\n# apply the sqrt() function to each element of a vector of integers\nmap(c(9, 16, 25), sqrt)\n```\n\nOther resources for `purrr`: [Learn to purrr](https://www.rebeccabarter.com/blog/2019-08-19_purrr/), [purrr tutorial](https://jennybc.github.io/purrr-tutorial/)\n\n## Data sets {#datasets001}\n\n### Edward Babushkin's Employee turnover data\nSome data that will be used in CSDE 533: Edward Babushkin's employee turnover data, explained a bit at [kaggle.com](https://www.kaggle.com/davinwijaya/employee-turnover) and as a [downloadable file](https://github.com/teuschb/hr_data/blob/master/datasets/turnover_babushkin.csv).\n\nHere we will load the data set from a URL:\n\n```{r}\netdata <- read.csv(\"https://raw.githubusercontent.com/teuschb/hr_data/master/datasets/turnover_babushkin.csv\")\n```\n\nJust to get a bit of `tidyverse` in at the last minute, let's get mean and standard deviation of job tenure by gender and 10-year age class:\n\n```{r}\n# create 10-year age classes \netdata %<>% \n    mutate(age_decade = plyr::round_any(age, 10, f = ceiling)) \n\n# summarize\netdata %>% \n    # group by gender and age class\n    group_by(gender, age_decade) %>% \n    # mean and sd\n    summarize(mean_tenure_months = mean(tenure) %>% round(1),\n              sd_tenure_months = sd(tenure) %>% round(1), \n              .groups = \"keep\") %>% \n    # order the output by age and gender\n    arrange(gender, mean_tenure_months) %>% \n    # print it nicely\n    kable() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[01-week01.Rmd](01-week01.Rmd)\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"01-week01.Rmd\"), sep = '\\n')\n```"},{"path":"week2.html","id":"week2","chapter":"2 Week 2","heading":"2 Week 2","text":"Code blocks RGraphs R MarkdownTables R MarkdowEquations R MarkdownCaptions cross-references R MarkdownData sets:\nData:\nHuman Mortality Database\nHuman Fertility Database\n\nData:\nHuman Mortality Database\nHuman Fertility Database\nHuman Mortality DatabaseHuman Fertility Database","code":""},{"path":"week2.html","id":"code-to-run-for-the-in-class-exercise","chapter":"2 Week 2","heading":"2.1 Code to run for the in-class exercise","text":"exercise class, download week02.R, use run code listed R Markdown result.","code":""},{"path":"week2.html","id":"r-markdown","chapter":"2 Week 2","heading":"2.2 R Markdown","text":"","code":""},{"path":"week2.html","id":"rmdcodeblocks","chapter":"2 Week 2","heading":"2.2.1 Code blocks","text":"","code":""},{"path":"week2.html","id":"rmdgraphics","chapter":"2 Week 2","heading":"2.2.2 Graphics in R Markdown","text":"Data-driven graphics Rmd files typically created base R graphics ggplot2 package. tutorial intended provide anywhere near comprehensive treatment creating graphics data, provide instruction options creating including data-driven graphics well inserting graphics image files.See Tips tricks working images figures R Markdown documents good explanation.","code":""},{"path":"week2.html","id":"base-r-graphics","chapter":"2 Week 2","heading":"2.2.2.1 Base R graphics","text":"include base R graphics, simply place code generate graphic R code block, e.g., using Add Health data last week (AHWave1_v1.dta):… render graph:","code":"```{r}\n# since loading the data takes awhile, only do this if necessary\nif(!exists(\"dat\")){\n    dat <- read.dta13(\"data/AHwave1_v1.dta\")\n}\n# birth year = h1gi1y\n# drop \"Refused\" birth year\n# for birth year and interview year, replace anything before white space, convert to numeric\n# subtract interview year - birth year\nages <- dat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    select(iyear, h1gi1y) %>% \n    mutate(yi = str_replace(iyear, \".*\\\\s\", \"\") %>% as.numeric(),\n           yb = str_replace(h1gi1y, \".*\\\\s\", \"\") %>% as.numeric(),\n           age = yi - yb)\n           \n# create a histogram using base graphics\nhist(ages$age, xlab = \"age (years)\", las = 1)\n```"},{"path":"week2.html","id":"ggplot2-graphics","chapter":"2 Week 2","heading":"2.2.2.2 ggplot2 graphics","text":"ggplot2 package creates compelling graphics use common syntax. main difference base R graphics ggplot2 graphics simply issuing plot() related command (e.g., hist(), barplot()) adds graphic output, whereas ggplot() necessary issue command prints graphic.Following previous example:","code":"\n# how many unique bins? \nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)"},{"path":"week2.html","id":"embedding-graphics-files","chapter":"2 Week 2","heading":"2.2.2.3 Embedding graphics files","text":"Journals frequently require graphics files submitted separately manuscript. case, graphic can created saved file inserted Rmd using code, also accessed stand-alone file. Let’s take previous example, add correlation coefficients embellishments, create graphics file add graphics Rmd.base graphics file created using pdf() function, although png() also works desired output format. PDF vector format, generally renders better different zoom levels.create PNG format file:ggplot2 graphics can saved using ggsave(), e.g., PDF PNG outputs. dpi argument important bitmap images.Graphics can added using several methods.","code":"\npdf(file = \"ah_age_hist.pdf\", width = 5, height = 5)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\npng(file = \"ah_age_hist.png\", width = 5, height = 5, units = \"in\", res = 300)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\nggsave(\n    filename = \"ah_age_hist_ggplot.pdf\",\n    plot = g, device = \"pdf\",\n    width = 5, height = 5\n)\nggsave(\n    filename = \"ah_age_hist_ggplot.png\",\n    plot = g, device = \"png\", \n    width = 5, height = 5, \n    units = \"in\", dpi = 300\n)"},{"path":"week2.html","id":"knitr","chapter":"2 Week 2","heading":"2.2.2.3.1 knitr","text":"knitr::include_graphics() function can used insert image files, caution inserted PDF files may produce unwanted results. syntax :code chunk can include .width, .height options.\n \ninsert PDF code chunk options, presents image scroll bar, rather full image:specify code chunk options .height = \"360px\", .width='360px', fig.align='left', … code chunk options .height = \"400px\", .width='100%', fig.align='left' seems embedding PDF files optimal.insert PNG: code chunk options:code chunk option .width = \"50%\"embedding bitmapped images appears work better embedding PDF files.","code":"```{r}\ninclude_graphics(\"graphics_filename\")\n```\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist.pdf\")\ninclude_graphics(\"ah_age_hist_ggplot.png\")\ninclude_graphics(\"ah_age_hist_ggplot.png\")"},{"path":"week2.html","id":"markdown-captionfilename","chapter":"2 Week 2","heading":"2.2.2.3.2 Markdown: ![caption](filename)","text":"native Markdown syntax:includes graphics file optional caption, e.g., , PDF caption,![](ah_age_hist.pdf) structure ![]() indicates inserted graphic; caption can specified including text within square brackets, e.g., displays caption inserted image (caption number!).![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)Add Health respondent age histogram… although seems inserting PDF odd things image scrolling, PNG inserts complete image without scroll bars.![Add Health respondent age histogram](ah_age_hist_ggplot.png):Add Health respondent age histogram","code":"![](filename)"},{"path":"week2.html","id":"html-img-tag","chapter":"2 Week 2","heading":"2.2.2.3.3 HTML <img> tag","text":"file rendered HTML, image bitmap, rather vector PDF graphics, <img> tag can used. Different utilities can used convert PDF bitmapped formats, e.g., ImageMagick GraphicsMagick.<img src=\"ah_age_hist_ggplot.png\">Including percentage page width:<img src=\"ah_age_hist_ggplot.png\" width=\"30%\">","code":""},{"path":"week2.html","id":"rmdtables","chapter":"2 Week 2","heading":"2.2.3 Tables in R Markdown","text":"look three methods including tables R Markdown documents, using packages knitr (kableExtra), pander, stargazer.example table, use frequency table health \\(\\times\\) White African American Assignment 2:","code":"\ndat <- readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\n\n# ordered factor; use fct_rev to establish the correct ordering where better health ranks higher\ndat %<>% \n    mutate(h1gh1 = fct_rev(as.ordered(h1gh1)))\n\n# stratify health; first we need to catch the \"don't know\" and \"refused\" as NAs\ndat %<>%  \n    mutate(health = \n    case_when(\n        h1gh1 <= \"(6) Refused\" ~ as.character(NA),\n        h1gh1 >  \"(3) Good\" ~ \"high\",\n        h1gh1 <= \"(3) Good\" ~ \"low\"\n    ))\n\n# tabulate by White\ntabhealth_white <- dat %>% \n    group_by(health, white = h1gi6a) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# tabulate by African American\ntabhealth_afram <- dat %>% \n    group_by(health, afram = h1gi6b) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# column-bind and remove the second \"health\" column\nsum_health_white_afram <- cbind(tabhealth_white, tabhealth_afram) %>% \n    select(-5)"},{"path":"week2.html","id":"kntir-kable-and-kableextra","chapter":"2 Week 2","heading":"2.2.3.1 kntir (kable()) and kableExtra","text":"simple table using kable() nice read.marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nadd kabelExtra options, :marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nHowever, column names duplicated, necessary add column grouping:marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nalso add row groupings:marked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\n","code":"\nkable(sum_health_white_afram)\nkable(sum_health_white_afram,\n      col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")) %>% \n        kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") \nkable(sum_health_white_afram,\n      col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>% \n    add_header_above(c(\" \" = 1, \"White\" = 3, \"African American\" = 3))\nsum_health_white_afram %>% \n    select(-1) %>% \n    kable(col.names = c(\"race\", \"n\", \"%\", \"race\", \"n\", \"%\"), align=c(rep('r',times=6))) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>% \n    add_header_above(c(\"White\" = 3, \"African American\" = 3)) %>% \n    pack_rows(\"health high\", 1, 4) %>% \n    pack_rows(\"health low\", 5, 8) %>% \n    pack_rows(\"health N/A\", 9, 12)"},{"path":"week2.html","id":"stargazer","chapter":"2 Week 2","heading":"2.2.3.2 stargazer","text":"stargazer package especially good PDF outputs, fairly limited HTML output.","code":"\nstargazer(sum_health_white_afram, \n          type = \"html\", \n          summary = FALSE,\n          rownames = FALSE)"},{"path":"week2.html","id":"pander","chapter":"2 Week 2","heading":"2.2.3.3 pander","text":"pander can used create output HTML tables well, although also fewer options knitr kableExtra.","code":"\npander(sum_health_white_afram)"},{"path":"week2.html","id":"rmdcaptions","chapter":"2 Week 2","heading":"2.2.4 Captions to support tables, figures, and equations","text":"several ways support captions R Markdown. two main requirements good captions: (1) automatic sequential numbering, (2) ability cross-reference.options adding captions:","code":""},{"path":"week2.html","id":"figures","chapter":"2 Week 2","heading":"2.2.4.1 Figures","text":"","code":""},{"path":"week2.html","id":"r-markdown-code-chunk-fig.cap","chapter":"2 Week 2","heading":"2.2.4.1.1 R Markdown code chunk fig.cap","text":"Code chunks can include fig_cap option, shown . However, standard Rmd \\(\\rightarrow\\) HTML appear method cross-referencing. code chunk look like\nFigure 2.1: Cars: speed distance\n","code":"```{r plotcars, fig.cap=\"Cars: speed and distance\"}\nplot(cars)\n```"},{"path":"week2.html","id":"bookdown-with-html_document2-output-type","chapter":"2 Week 2","heading":"2.2.4.1.2 bookdown with html_document2 output type","text":"Using bookdown package html_document2 output type, possible cross-reference using chunk name. example, download run code fig_cap_bookdown.RmdWhich renders file:seems difference HTML output usingversusso former suggested one way include captions support cross-referencing.","code":"output: \n    bookdown::html_document2:output: \n    html_document:"},{"path":"week2.html","id":"tables-kable-caption","chapter":"2 Week 2","heading":"2.2.4.2 Tables: kable() “caption”","text":"Tables created kable() can include caption option. example:\nTable 2.1: Self-reported health race\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nmarked\nmarked\nMarked\nMarked\nRefused\nRefused\nDon’t know\nDon’t know\nappears direct way cross-referencing within standard Rmd \\(\\rightarrow\\) HTML.","code":"\nkable(x = sum_health_white_afram, caption = \"Self-reported health by race\")"},{"path":"week2.html","id":"bookdown-with-html_document2-output-type-1","chapter":"2 Week 2","heading":"2.2.4.2.1 bookdown with html_document2 output type","text":"Similarly figures, bookdown package html_document2 output type, possible cross-reference using chunk name. example, download run code table_cap_bookdown.RmdWhich renders file:","code":""},{"path":"week2.html","id":"equations-rmdequations","chapter":"2 Week 2","heading":"2.2.4.3 Equations {# rmdequations}","text":"Equations numbered manuscripts. Using bookdown makes quite easy. equations require \\(\\LaTeX\\) syntax. numerous web sites examples tutorials creating mathematical expressions \\(\\LaTeX\\) example, include Einstein’s famous equation:sum squares:label equation set (\\#eq:emc) can referenced using \\@ref(eq:emc). Operationalized, see:Einstein’s equation, energy equals mass times square speed light shown (2.1).\\[\\begin{equation}\n  E=mc^2\n  \\tag{2.1}\n\\end{equation}\\]make sum squares n first integers, see (2.2).\\[\\begin{equation}\n  \\sum_{=1}^n ^2 = \\frac{n(n+1)(2n+1)}{6}\n  \\tag{2.2}\n\\end{equation}\\]","code":"\n\\begin{equation}\n  E=mc^2\n  (\\#eq:emc)\n\\end{equation}\n\n\\begin{equation}\n  \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\n  (\\#eq:sumn)\n\\end{equation}\n"},{"path":"week2.html","id":"captioner-for-any-captioning-and-cross-referencing-figures-and-tables","chapter":"2 Week 2","heading":"2.2.5 captioner for any captioning and cross-referencing figures and tables","text":"captioner package provides flexible, albeit cumbersome, framework captioning tables figures.R code :table_nums() figure_nums() functions used create captions cross-references, tied specific figure table, case kable table captions R code chunk fig.cap.caption created, e.g., figure:`r figure_nums(name = \"figname\", caption = \"Caption\")`referenced, e.g.,`r figure_nums(name = \"figname\", display = \"cite\")`matter whether reference precedes comes caption .Another benefit using captioner output can formatted using markdown syntax. example, format caption italics, use underscores:_`r figure_nums(name = \"figname\", caption = \"Caption\")`_Although method requires bit coding, allows great flexibility. complete example:shown figure 1, distribution age slight negative skew.figure 1: Add Health age histogramSimilarly, can present data frequency table, shown table 1.table 1: Add Health age frequency tableRendered 2022-01-08 17:59:39Source code: 02-week02.Rmd","code":"library(captioner)\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n# how many unique bins? \nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\nages %>% \n    group_by(age) %>% \n    summarise(n = n()) %>% \n    mutate(cumsum = cumsum(n),\n        \"%\" = round(n / sum(n) * 100, 1),\n        \"cum %\" = round(cumsum(n / sum(n) * 100), 1)) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = \n        c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n        full_width = F, \n        position = \"left\") # Week 2 {#week2}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\npacman::p_load(tidyverse, magrittr, knitr, kableExtra, readstata13, stargazer, pander, captioner)\n\n# captions\nfigure_nums <- captioner(prefix = \"figure\")\ntable_nums <- captioner(prefix = \"table\")\n```\n\n<h2>Topics:<\/h2>\n* [Code blocks in R](#rmdcodeblocks)\n* [Graphs in R Markdown](#rmdgraphicss)\n* [Tables in R Markdow](#rmdtables)\n* [Equations in R Markdown](#rmdequations)\n* [Captions and cross-references in R Markdown](#rmdcaptions)\n* [Data sets:](#datasets002)\n    * Data:\n        * [Human Mortality Database](https://www.mortality.org/)\n        * [Human Fertility Database](https://www.humanfertility.org/cgi-bin/main.php)\n\n\n## Code to run for the in-class exercise\n\n```{r, echo=FALSE}\n# generate the R code to run in class\n# O <- knitr::purl(input = \"02-week02.Rmd\", output = \"r_code/week02.R\", quiet = TRUE, documentation = 1)\n```\n\nFor the exercise in class, download [week02.R](r_code/week02.R), which we will use to run the code listed in this R Markdown result.\n\n## R Markdown \n\n### Code blocks {#rmdcodeblocks}\n\n### Graphics in R Markdown {#rmdgraphics}\nData-driven graphics in Rmd files are typically created as base R graphics or with the `ggplot2` package. This tutorial is not intended to provide anywhere near a comprehensive treatment of creating graphics from data, but will provide instruction on some options for creating and including data-driven graphics as well as inserting graphics from image files.\n\nSee [Tips and tricks for working with images and figures in R Markdown documents](http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/) for a good explanation.\n\n#### Base R graphics\nTo include base R graphics, simply place the code to generate the graphic in an R code block, e.g., using the Add Health data from last week ([AHWave1_v1.dta](data/AHWave1_v1.dta)):\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/rmd_insert_text_01.txt\"), sep = '\\n')\n```\n\n... which will render the graph:\n\n```{r, echo=FALSE, warning=FALSE}\n# since loading the data takes awhile, only do this if necessary\nif(!exists(\"dat\")){\n    dat <- read.dta13(\"data/AHwave1_v1.dta\")\n}\n# birth year = h1gi1y\n# drop \"Refused\" birth year\n# for birth year and interview year, replace anything before white space, convert to numeric\n# subtract interview year - birth year\nages <- dat %>% \n    filter(! str_detect(h1gi1y, \"Refused\")) %>% \n    select(iyear, h1gi1y) %>% \n    mutate(yi = str_replace(iyear, \".*\\\\s\", \"\") %>% as.numeric(),\n           yb = str_replace(h1gi1y, \".*\\\\s\", \"\") %>% as.numeric(),\n           age = yi - yb)\nhist(ages$age, xlab = \"age (years)\", las = 1)\n```\n\n#### `ggplot2` graphics\nThe `ggplot2` package creates compelling graphics that use a common syntax. The main difference between base R graphics and `ggplot2` graphics is that simply issuing the `plot()` or related command (e.g., `hist()`, `barplot()`) adds the graphic to the output, whereas with `ggplot()` it is necessary to issue a command that prints the graphic.\n\nFollowing the previous example:\n\n```{r}\n# how many unique bins? \nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\n```\n\n\n#### Embedding graphics files\nJournals frequently require graphics files to be submitted separately from the manuscript. In this case, the graphic can be created and saved as a file and then inserted in the Rmd using code, but also accessed as a a stand-alone file. Let's take the previous example, but add correlation coefficients and other embellishments, create a graphics file and add the graphics into the Rmd.\n\nThe base graphics file is created using the `pdf()` function, although `png()` also works if that is the desired output format. PDF is a vector format, so it generally renders better over different zoom levels.\n\n```{r, message=FALSE}\npdf(file = \"ah_age_hist.pdf\", width = 5, height = 5)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\n```\n\nHere we create a PNG format file:\n\n```{r, message=FALSE}\npng(file = \"ah_age_hist.png\", width = 5, height = 5, units = \"in\", res = 300)\nhist(ages$age, xlab = \"age (years)\", las = 1)\nx <- dev.off()\n```\n\n`ggplot2` graphics can be saved using `ggsave()`, e.g., for both PDF and PNG outputs. The `dpi` argument is important for bitmap images.\n\n```{r}\nggsave(\n    filename = \"ah_age_hist_ggplot.pdf\",\n    plot = g, device = \"pdf\",\n    width = 5, height = 5\n)\nggsave(\n    filename = \"ah_age_hist_ggplot.png\",\n    plot = g, device = \"png\", \n    width = 5, height = 5, \n    units = \"in\", dpi = 300\n)\n```\n\nGraphics can be added using several methods.\n\n##### `knitr`\nThe `knitr::include_graphics()` function can be used to insert image files, with the caution that inserted PDF files may produce unwanted results. The syntax is:\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/rmd_insert_text_02.txt\"), sep = '\\n')\n```\n\nand the code chunk can include `out.width`, `out.height` and other options.\n\\  \nHere we insert a PDF with no code chunk options, which presents the image with a scroll bar, rather than the full image:\n\n```{r}\ninclude_graphics(\"ah_age_hist.pdf\")\n```\n\nHere we specify in the code chunk options `out.height = \"360px\", out.width='360px', fig.align='left'`, \n\n```{r, out.height = \"360px\", out.width='360px', fig.align='left'}\ninclude_graphics(\"ah_age_hist.pdf\")\n\n```\n\n\\  \n\n... and with code chunk options `out.height = \"400px\", out.width='100%', fig.align='left'`\n\n```{r, out.height = \"400px\", out.width='100%', fig.align='left'}\ninclude_graphics(\"ah_age_hist.pdf\")\n```\n\n\\  \n\nIt seems that embedding PDF files is not optimal.\n\nHere we insert a PNG: with no code chunk options:\n\n```{r}\ninclude_graphics(\"ah_age_hist_ggplot.png\")\n```\n\nand with code chunk option `out.width = \"50%\"`\n\n```{r, out.width = \"50%\"}\ninclude_graphics(\"ah_age_hist_ggplot.png\")\n```\n\nSo embedding bitmapped images appears to work better than embedding PDF files. \n\n##### Markdown: `![caption](filename)`\n\nThe native Markdown syntax:\n\n```\n![](filename)\n```\n\nincludes a graphics file with an optional caption, e.g., here, a PDF with no caption, \n\n`![](ah_age_hist.pdf)`\n\n![](ah_age_hist.pdf)\n\n\\  \n\nThe structure `![]()` indicates this is an inserted graphic; a caption can be specified by including text within the square brackets, e.g., displays the caption below the inserted image (but with no caption number!). \n\n```![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)```\n\n![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)\n\n... although it seems that inserting a PDF does odd things with image scrolling, while a PNG inserts the complete image without scroll bars.\n\n```![Add Health respondent age histogram](ah_age_hist_ggplot.png)```:\n\n![Add Health respondent age histogram](ah_age_hist_ggplot.png)\n\n##### HTML `<img>` tag\nIf the file is to be rendered as HTML, _and_ the image is a bitmap, rather than vector PDF graphics, the `<img>` tag can be used. Different utilities can be used to convert PDF to bitmapped formats, e.g., [ImageMagick](https://imagemagick.org/index.php) and [GraphicsMagick](http://www.graphicsmagick.org/).\n\n```<img src=\"ah_age_hist_ggplot.png\">```\n\n<img src=\"ah_age_hist_ggplot.png\">\n\nIncluding a percentage of page width:\n\n```<img src=\"ah_age_hist_ggplot.png\" width=\"30%\">```\n\n<img src=\"ah_age_hist_ggplot.png\" width=\"30%\">\n\n\n### Tables in R Markdown {#rmdtables}\n\nWe will look at three methods of including tables in R Markdown documents, using the packages `knitr` (with `kableExtra`), `pander`, and `stargazer`.\n\nFor the example table, we will use the frequency table of health $\\times$ White and African American from Assignment 2:\n\n```{r, warning=FALSE, message=FALSE, error=FALSE}\ndat <- readstata13::read.dta13(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\n\n# ordered factor; use fct_rev to establish the correct ordering where better health ranks higher\ndat %<>% \n    mutate(h1gh1 = fct_rev(as.ordered(h1gh1)))\n\n# stratify health; first we need to catch the \"don't know\" and \"refused\" as NAs\ndat %<>%  \n    mutate(health = \n    case_when(\n        h1gh1 <= \"(6) Refused\" ~ as.character(NA),\n        h1gh1 >  \"(3) Good\" ~ \"high\",\n        h1gh1 <= \"(3) Good\" ~ \"low\"\n    ))\n\n# tabulate by White\ntabhealth_white <- dat %>% \n    group_by(health, white = h1gi6a) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# tabulate by African American\ntabhealth_afram <- dat %>% \n    group_by(health, afram = h1gi6b) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(\"%\" = round(n / sum(n) * 100, 2))\n\n# column-bind and remove the second \"health\" column\nsum_health_white_afram <- cbind(tabhealth_white, tabhealth_afram) %>% \n    select(-5)\n```\n\n#### `kntir` (`kable()`) and `kableExtra`\nThe simple table using `kable()` is not too nice to read.\n\n```{r}\nkable(sum_health_white_afram)\n```\n\nSo we add some `kabelExtra` options, :\n\n```{r}\nkable(sum_health_white_afram,\n      col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")) %>% \n        kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") \n```\n\nHowever, because some column names are duplicated, it is necessary to add some column grouping:\n\n```{r}\nkable(sum_health_white_afram,\n      col.names = c(\"health\", \"race\", \"n\", \"%\", \"race\", \"n\", \"%\")) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>% \n    add_header_above(c(\" \" = 1, \"White\" = 3, \"African American\" = 3))\n```\n\nWe could also add some row groupings:\n\n```{r}\n\nsum_health_white_afram %>% \n    select(-1) %>% \n    kable(col.names = c(\"race\", \"n\", \"%\", \"race\", \"n\", \"%\"), align=c(rep('r',times=6))) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F, position = \"left\") %>% \n    add_header_above(c(\"White\" = 3, \"African American\" = 3)) %>% \n    pack_rows(\"health high\", 1, 4) %>% \n    pack_rows(\"health low\", 5, 8) %>% \n    pack_rows(\"health N/A\", 9, 12)\n```\n\n#### `stargazer`\nThe [`stargazer`](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf) package is especially good for PDF outputs, but is fairly limited for HTML output.\n\n```{r results='asis'}\nstargazer(sum_health_white_afram, \n          type = \"html\", \n          summary = FALSE,\n          rownames = FALSE)\n```\n\n#### `pander`\n`pander` can be used to create output HTML tables as well, although also with fewer options than `knitr` with `kableExtra`.\n\n```{r}\npander(sum_health_white_afram)\n```\n\n### Captions to support tables, figures, and equations {#rmdcaptions}\nThere are several ways to support captions in R Markdown. The two main requirements for good captions: (1) automatic sequential numbering, and (2) ability to cross-reference.\n\nHere are some options for adding captions:\n\n#### Figures\n\n##### R Markdown code chunk `fig.cap`\nCode chunks can include `fig_cap` as an option, as shown below. However, in standard Rmd $\\rightarrow$ HTML there does not appear to be a method for cross-referencing. The code chunk would look like\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"files/rmd_insert_text_03.txt\"), sep = '\\n')\n```\n\n```{r plotcars, fig.cap=\"Cars: speed and distance\", echo=FALSE}\nplot(cars)\n```\n\n##### `bookdown` with `html_document2` output type\n\nUsing the `bookdown` package with `html_document2` output type, it is possible to cross-reference using the chunk name. For example, download and run this code [fig_cap_bookdown.Rmd](files/fig_cap_bookdown.Rmd)\n\nWhich renders a file:\n\n![](images/week03/fig_ref.png)\n\nThere seems to be no difference in the HTML output using\n\n```\noutput: \n    bookdown::html_document2:\n```\n\nversus \n\n```\noutput: \n    html_document:\n````\n\nso the former is suggested as one way to include captions that support cross-referencing.\n\n#### Tables: `kable()` \"caption\"\nTables created with `kable()` can include the `caption` option. For example:\n\n```{r}\nkable(x = sum_health_white_afram, caption = \"Self-reported health by race\")\n```\n\nBut there appears to be no direct way of cross-referencing within standard Rmd $\\rightarrow$ HTML.\n\n##### `bookdown` with `html_document2` output type\n\nSimilarly for figures, the `bookdown` package with `html_document2` output type, it is possible to cross-reference using the chunk name. For example, download and run this code [table_cap_bookdown.Rmd](files/table_cap_bookdown.Rmd)\n\nWhich renders a file:\n\n![](images/week03/tab_ref.png)\n\n#### Equations {# rmdequations}\nEquations should be numbered in manuscripts. Using `bookdown` makes this quite easy. The equations themselves require $\\LaTeX$ syntax. There are numerous web sites with examples and tutorials for creating mathematical expressions with $\\LaTeX$ In this example, we include Einstein's famous equation:\n\n<pre>\n\\begin{equation}\n  E=mc^2\n  (\\#eq:emc)\n\\end{equation}\n<\/pre>\n\nand the sum of squares:\n\n<pre>\n\\begin{equation}\n  \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\n  (\\#eq:sumn)\n\\end{equation}\n<\/pre>\n\nThe label for the equation is set with `(\\#eq:emc)` and can be referenced using `\\@ref(eq:emc)`. Operationalized, we see:\n\nEinstein's equation, energy equals mass times the square of the speed of light is shown in \\@ref(eq:emc).\n\n\\begin{equation}\n  E=mc^2\n  (\\#eq:emc)\n\\end{equation}\n\nTo make a sum of squares of _n_ first integers, see \\@ref(eq:sumn).\n\n\\begin{equation}\n  \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\n  (\\#eq:sumn)\n\\end{equation}\n\n\n### `captioner` for any captioning and cross-referencing figures and tables\nThe `captioner` package provides a flexible, albeit cumbersome, framework for captioning both tables and figures. \n\nThe R code to do this:\n\n```\nlibrary(captioner)\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n```\n\nThe `table_nums()` and `figure_nums()` functions are used to create captions and cross-references, and are not tied to any specific figure or table, as is the case with `kable` table captions and R code chunk `fig.cap`.\n\nA caption is created, e.g., for a figure:\n\n`` `r\nfigure_nums(name = \"figname\", caption = \"My Caption\")` ``\n\nand referenced, e.g., \n\n`` `r\nfigure_nums(name = \"figname\", display = \"cite\")` ``\n\nIt does not matter whether the reference precedes or comes after the caption itself.\n\nAnother benefit to using `captioner` is that the output can be formatted using markdown syntax. For example, to format the caption in italics, use underscores:\n\n`` _`r\nfigure_nums(name = \"figname\", caption = \"My Caption\")`_ ``\n\nAlthough this method requires a bit more coding, it allows great flexibility. A complete example:\n\nAs shown in `r figure_nums(name = \"ageplot\", display = \"cite\")`, the distribution of age has a slight negative skew.\n\n```{r, fig.width=3, fig.height=3}\n# how many unique bins? \nbins <- length(unique(ages$age))\n\n# create the graphic\ng <- ggplot(data = ages, mapping = aes(x = age)) +\n    geom_histogram(bins = bins)\n\n# print the graphic\nprint(g)\n```\n\n_`r figure_nums(name = \"ageplot\", caption = \"Add Health age histogram\")`_\n\nSimilarly, we can present the same data as a frequency table, as shown in `r table_nums(name = \"agetab\", display = \"cite\")`.\n\n_`r table_nums(name = \"agetab\", caption = \"Add Health age frequency table\")`_\n\n```{r}\nages %>% \n    group_by(age) %>% \n    summarise(n = n()) %>% \n    mutate(cumsum = cumsum(n),\n        \"%\" = round(n / sum(n) * 100, 1),\n        \"cum %\" = round(cumsum(n / sum(n) * 100), 1)) %>% \n    kable() %>% \n    kable_styling(bootstrap_options = \n        c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n        full_width = F, \n        position = \"left\") \n```\n\n<h4>Source code for this document<\/h4>\nRendered at <tt>`r Sys.time()`<\/tt>\n\nSource code: [02-week02.Rmd](02-week02.Rmd)\n\n```{r sourcecode_week2, comment='', echo=FALSE}\ncat(readLines(\"02-week02.Rmd\"), sep = \"\\n\")\n```"},{"path":"week3.html","id":"week3","chapter":"3 Week 3","heading":"3 Week 3","text":"tidycensus: Load US Census Boundary Attribute Data ‘tidyverse’ ‘sf’-Ready Data Frames\nidbr: R Interface US Census Bureau International Data Base API\nsf: Simple Features R: Simple Features (GIS) R\nleaflet: Create Interactive Web Maps JavaScript ‘Leaflet’ Library\nmapview: Interactive Viewing Spatial Data R\ndemogR: Analysis Age-Structured Demographic Models\ndemography: Forecasting Mortality, Fertility, Migration Population Data; R intro demography package)\nflextable DT: Pretty printing tabular data\nData:\nAccessing Human Mortality Database life tables using HMDHFDplusBen’s code reading HMD HFD data","code":""},{"path":"week3.html","id":"keyring-securely-store-secrets","chapter":"3 Week 3","heading":"3.1 Keyring: securely store secrets","text":"Keyring","code":""},{"path":"week3.html","id":"hanowell_hmdhfd","chapter":"3 Week 3","heading":"3.2 Ben’s code for reading HMD and HFD data","text":"Ben’s code reading HMD HFD dataBecause extensibility, HTML can considered preferred output R Markdown. However, document formats often necessary, particularly term papers, theses/dissertations, manuscripts submission scholarly journals. week’s lesson, focus creation two output types, including adding bibliographies (also applies HTML output), basic ggplot graphics.PDF Word output, much structure Rmd files HTML output. major difference tables handled, explore detail. Static graphics handled similarly across output formats, HTML output can support dynamic graphics, Leaflet map saw first lesson, responsive graphics Shiny.","code":"* [`tidycensus`](https://walker-data.com/tidycensus/): download census data easily\n* [`idbr: R Interface to the US Census Bureau International Data Base API`](https://cran.r-project.org/web/packages/idbr/index.html)\n* [`sf: Simple Features for R`](https://cran.r-project.org/web/packages/sf/): GIS in R!\n* [`leaflet: Create Interactive Web Maps with the JavaScript 'Leaflet' Library`](https://cran.r-project.org/web/packages/leaflet/)\n* [`mapview: Interactive Viewing of Spatial Data in R`](https://cran.r-project.org/web/packages/mapview/)\n* Life Tables with [`demogR`](https://cran.r-project.org/web/packages/demogR/index.html), [`demography`](https://cran.r-project.org/web/packages/demography/) ([`demography`](https://rpubs.com/Timexpo/487053))\n* Data:\n    * Accessing Muman Mortality Database life tables using [HMDHFDplus](https://cran.r-project.org/web/packages/HMDHFDplus/index.html)\n    * Pretty printouts of life tables with `flextable` and `DT`"},{"path":"week3.html","id":"getting-us-census-data-with-tigris-tidycensus","chapter":"3 Week 3","heading":"3.3 Getting US Census data with tigris, tidycensus","text":"Dealing US Census data can overwhelming, particularly using raw text-based data. Census Bureau API allows streamlined downloads variables (data frames) geographies (simple format shapes). necessary get API key, available free. See tidycensus tidycensus basic usage.tidycensus uses tigris, downloads geographic data portion census files.simple example download variables representing count White, Black/African American, American Indian/Native American, Asian persons American Community Survey (ACS) data King County 2019. example run, need US Census API key installed, e.g.,\ntidycensus::census_api_key(“*****************,” install = TRUE)\nAPI key stored .Renviron can accessed Sys.getenv(“CENSUS_API_KEY”).\nuse now, restart R run readRenviron(\"~/.Renviron\")\n\nlabels census API :values shown Table 3.1, simple map shown 3.1, percent African American residents tract identifier.\nTable 3.1: Selected census tract variables 5-year ACS 2019 King County, WA\n\nFigure 3.1: Percent African American census tracts King County, 2019 ACS 5-year estimate\nRendered 2022-01-08 17:59:4403-week03.Rmd","code":"\"Estimate!!Total\"                                         \n\"Estimate!!Total!!White alone\"                            \n\"Estimate!!Total!!Black or African American alone\"        \n\"Estimate!!Total!!American Indian and Alaska Native alone\"\n\"Estimate!!Total!!Asian alone\" \nlibrary(tidycensus)\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)## Getting data from the 2015-2019 5-year ACS## Downloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.## \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |=====================                                                 |  29%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |======================================================================| 100%\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(sf)\n\n# define the CRS\nst_crs(ctdat) <- 4326\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\nbins <- 0:50\npal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\nbins2 <- seq(0, 50, by = 10)\npal2 <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins2\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ pal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    addLegend(\n        position = \"bottomright\", pal = pal2, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()# Week 3 {#week3}\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(kableExtra)\nlibrary(stargazer)\nlibrary(pander)\nlibrary(psych)\nlibrary(readstata13)\nlibrary(knitr)\nlibrary(pander)\nlibrary(stargazer)\nlibrary(animation)\nlibrary(captioner)\n\ntable_nums <- captioner(prefix = \"Table\")\nfigure_nums <- captioner(prefix = \"Figure\")\n```\n\n<style>\n.border1 {   \n    border-width: 1px;   \n    border-color: black;   \n    border-style: solid; } \n<\/style>\n\n<h2>Topics: Graphics and Tables in R; Captions and cross-references; Census data; Mapping; Human Mortality Database<\/h2>\n\n[`tidycensus`](#tidycensus): Load US Census Boundary and Attribute Data as â€˜tidyverseâ€™ and â€˜sfâ€™-Ready Data Frames\n[`idbr`](#irbr): R Interface to the US Census Bureau International Data Base API\n[`sf`](#sf): Simple Features for R: Simple Features (GIS) for R\n[`leaflet`](#leaflet): Create Interactive Web Maps with the JavaScript â€˜Leafletâ€™ Library\n[`mapview`](#mapview): Interactive Viewing of Spatial Data in R\n[`demogR`](#demogR): Analysis of Age-Structured Demographic Models\n[`demography`](#demography): Forecasting Mortality, Fertility, Migration and Population Data; An R intro to the demography package)\n[`flextable`](#flextable) and [`DT`](#DT): Pretty printing of tabular data\nData:\nAccessing Human Mortality Database life tables using HMDHFDplus\n\n* [Ben's code for reading HMD and HFD data](#hanowell_hmdhfd)\n\n## Keyring: securely store secrets\n\n[Keyring](https://cran.r-project.org/web/packages/keyring/)\n\n\n## Ben's code for reading HMD and HFD data {#hanowell_hmdhfd}\n[Ben's code for reading HMD and HFD data](https://github.com/hanowell/uwsoc533a/blob/main/gists/HMDHFDplus-gist.R)\n\n    * [`tidycensus`](https://walker-data.com/tidycensus/): download census data easily\n    * [`idbr: R Interface to the US Census Bureau International Data Base API`](https://cran.r-project.org/web/packages/idbr/index.html)\n    * [`sf: Simple Features for R`](https://cran.r-project.org/web/packages/sf/): GIS in R!\n    * [`leaflet: Create Interactive Web Maps with the JavaScript 'Leaflet' Library`](https://cran.r-project.org/web/packages/leaflet/)\n    * [`mapview: Interactive Viewing of Spatial Data in R`](https://cran.r-project.org/web/packages/mapview/)\n    * Life Tables with [`demogR`](https://cran.r-project.org/web/packages/demogR/index.html), [`demography`](https://cran.r-project.org/web/packages/demography/) ([`demography`](https://rpubs.com/Timexpo/487053))\n    * Data:\n        * Accessing Muman Mortality Database life tables using [HMDHFDplus](https://cran.r-project.org/web/packages/HMDHFDplus/index.html)\n        * Pretty printouts of life tables with `flextable` and `DT`\n\n\n\n\n\n\n\n\nBecause of its extensibility, HTML can be considered a preferred output from R Markdown. However, document formats are often necessary, particularly for term papers, theses/dissertations, and manuscripts for submission to scholarly journals. In this week's lesson, we will focus on the creation of these two output types, including adding bibliographies (which also applies to HTML output), and some basic `ggplot` graphics. \n\nFor both PDF and Word output, much of the structure of your Rmd files will be the same as for HTML output. The major difference is how tables are handled, which we will explore in some detail. Static graphics are handled similarly across all output formats, other than HTML output can support dynamic graphics, such as the Leaflet map we saw in the first lesson, and responsive graphics as in [Shiny](https://shiny.rstudio.com/).\n\n\n## Getting US Census data with `tigris`, `tidycensus`\nDealing with US Census data can be overwhelming, particularly if using the raw text-based data. The Census Bureau has an API that allows more streamlined downloads of variables (as data frames) and geographies (as simple format shapes). It is necessary to get an API key, available for free. See [tidycensus](https://walker-data.com/tidycensus/) and  [tidycensus basic usage](https://walker-data.com/tidycensus/articles/basic-usage.html).\n\n`tidycensus` uses [`tigris`](https://www.rdocumentation.org/packages/tigris/versions/1.0), which downloads the geographic data portion of the census files.\n\nA simple example will download the variables representing the count of White, Black/African American, American Indian/Native American, and Asian persons from the American Community Survey (ACS) data for King County in 2019. For this example to run, you need to have your US Census API key installed, e.g., \n\n<tt>\ntidycensus::census_api_key(\"*****************\", install = TRUE)<br>\n<font color=\"red\">\nYour API key has been stored in your .Renviron and can be accessed by Sys.getenv(\"CENSUS_API_KEY\").<br>\nTo use now, restart R or run `readRenviron(\"~/.Renviron\")`\n<\/font>\n<\/tt>\n\nThe labels from the census API are:\n\n```\n\"Estimate!!Total\"                                         \n\"Estimate!!Total!!White alone\"                            \n\"Estimate!!Total!!Black or African American alone\"        \n\"Estimate!!Total!!American Indian and Alaska Native alone\"\n\"Estimate!!Total!!Asian alone\" \n```\n\n```{r, warning=FALSE}\nlibrary(tidycensus)\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)\n```\n\nA few values are shown in Table \\@ref(tab:census), and a simple map is shown in \\@ref(fig:ct), with percent African American residents and tract identifier.\n\n```{r census}\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n```{r ct, fig.cap=\"Percent African American in census tracts in King County, 2019 ACS 5-year estimate\", warning=FALSE, message=FALSE}\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(sf)\n\n# define the CRS\nst_crs(ctdat) <- 4326\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\nbins <- 0:50\npal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\nbins2 <- seq(0, 50, by = 10)\npal2 <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins2\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ pal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    addLegend(\n        position = \"bottomright\", pal = pal2, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()\n```\n\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[03-week03.Rmd](03-week03.Rmd)\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"03-week03.Rmd\"), sep = '\\n')\n```"},{"path":"week4.html","id":"week4","chapter":"4 Week 4","heading":"4 Week 4","text":"week’s topics functions sampling, latter including cursory treatment loops bootstrapping.","code":""},{"path":"week4.html","id":"environments","chapter":"4 Week 4","heading":"4.1 Environments","text":"Functions exist environments, “frames” collections containing objects including variables, functions, etc.). global environment (.GlobalEnv) contains data, functions, current R session. objects can enumerated ls() function.reason environments mentioned time functions instantiate environments exist function running. bit….","code":""},{"path":"week4.html","id":"functions","chapter":"4 Week 4","heading":"4.2 Functions","text":"Functions sets statements R grouped together perform specific task set tasks. Functions either built , included packages, user-defined. Functions used mainly simplify running series individual commands functions, situations process need run multiple times different inputs, control structures needed (e.g., looping, logical branching).","code":""},{"path":"week4.html","id":"function-components","chapter":"4 Week 4","heading":"4.2.1 Function Components","text":"different parts function :(Usually) Name: actual name function. stored R environment object name.(Optional) Arguments: Arguments specify inputs options function. function invoked, pass value argument. Arguments optional; , function may contain arguments. Also arguments can default values.Body: function body contains collection statements defines function .Return value: return value function last expression function body evaluated.Another important concept functions environments.","code":""},{"path":"week4.html","id":"name","chapter":"4 Week 4","heading":"4.2.1.1 Name","text":"functions created code formFor example, square vector numerical values:function name f_square.functions named, referred “anonymous” functions. example, functions can used within apply family functions. oprationalized example.last line code chunk :body function x[1], .e., obtain first element vector. function named, hence “anonymous.”","code":"function_name <- function(argument(s)){\n    statement(s)\n}\nf_square <- function(x){\n    x^2\n}\n# create a list of three vectors of random numbers of different random lengths\n\n# set.seed() makes the random process reproducible.\nset.seed(10)\n# vector lengths\nv.len <- rnorm(n = 3, mean = 30, sd = 10) %>% round(0)\n\n# make the random vectors\nset.seed(5)\nv1 <- rnorm(n = v.len[1])\nset.seed(3)\nv2 <- rnorm(n = v.len[2])\nset.seed(6)\nv3 <- rnorm(n = v.len[3])\n\n# create the list\nL <- list(v1, v2, v3)\n\n# get the first value from each vector in the list\nlapply(X = L, FUN = function(x) {x[1]})## [[1]]\n## [1] -0.8408555\n## \n## [[2]]\n## [1] -0.9619334\n## \n## [[3]]\n## [1] 0.269606lapply(X = L, FUN = function(x) {x[1]})\n"},{"path":"week4.html","id":"arguments","chapter":"4 Week 4","heading":"4.2.1.2 Arguments","text":"functions require arguments. Arguments used instantiate variables within function’s environment can used later body function. argument named, name used within function local variable within function’s environment.Following example , f_square takes argument named “x” numeric vector., let’s modify function demonstrate within environment function, x variable:can try running function using different () arguments:, using vector single NA numeric… vector contains numeric NA:… null:… vector containing null:… argument :functions require arguments, e.g., get current date time:… try use argument get error:","code":"\nf_square_2 <- function(x){\n    message(\"input:\")\n    print(x)\n    message(\"output:\")\n    x^2\n}\n\nf_square_2(c(1,2,3))## input:## [1] 1 2 3## output:## [1] 1 4 9\nf_square(as.numeric(NA))## [1] NA\nf_square(c(1, 2, NA))## [1]  1  4 NA\nf_square(NULL)## numeric(0)\nf_square(c(1, 2, NULL))## [1] 1 4f_square()## Error in f_square() : argument \"x\" is missing, with no default\nSys.Date()## [1] \"2022-01-08\"\nSys.time()## [1] \"2022-01-08 17:59:47 PST\"Sys.Date(1)## Error in Sys.Date(1) : unused argument (1)"},{"path":"week4.html","id":"default-values-for-arguments","chapter":"4 Week 4","heading":"4.2.1.2.1 Default values for arguments","text":"want argument default value, specified listed arguments form argument = value. Following previous f_square_2() function, can modify print input based logical argument verbose:run default verbose option (FALSE):… verbose = TRUE:meaningful example demonstrates stratification counts intensity bins using accelerometry data. using accelerometry one day’s data one subject study.cut points accelerometry identified 0, 2690, 6167, 9642 counts per minute, Sasaki et al. (2011).__Sasaki JE, John D, Freedson PS. Validation comparison ActiGraph activity monitors. J Sci Med Sport. 2011;14(5):411-416. doi:10.1016/j.jsams.2011.04.003__The variable vm3 vector magnitude measured accelerometer minute. Data: accelerometry.csv.following function codes intensity aforementioned cut points default using default labels:… run defaults tabulate minutes spent different PA levelsBut run different thresholds levels, SPLA = “sedentary/low physical activity” MVPA = “moderate--vigorous physical activity):","code":"\nf_square_3 <- function(x, verbose = FALSE){\n    # only run the next lines if verbose is true\n    if(verbose){\n        message(\"input:\")\n        print(x)\n        message(\"output:\")\n    }\n    x^2\n}\nf_square_3(x = c(1, 2, 3))## [1] 1 4 9\nf_square_3(x = c(1, 2, 3), verbose = TRUE)## input:## [1] 1 2 3## output:## [1] 1 4 9\nacc <- read.csv(\"files/accelerometry.csv\")\n\nhead(acc)##                 time_acc vm3\n## 1 2018-09-13 02:59:00-07   0\n## 2 2018-09-13 02:58:00-07   0\n## 3 2018-09-13 02:57:00-07   0\n## 4 2018-09-13 02:56:00-07   0\n## 5 2018-09-13 02:55:00-07   0\n## 6 2018-09-13 02:54:00-07   0\nf_acc_intensity <- function(x, \n                            cuts = c(-Inf, 2690, 6167, 9642, Inf),\n                            labels = c(\"sedentary/low\", \"moderate\", \"vigorous\", \"very vigorous\")){\n    cut(x = acc$vm3, breaks = cuts, labels = labels)\n}\nacc$intens_default <- f_acc_intensity(acc$vm3)\ntable(acc$intens_default)## \n## sedentary/low      moderate      vigorous very vigorous \n##          1435             4             1             0\nacc$intens_2lev <- f_acc_intensity(x = acc$vm3,\n                                cuts = c(-Inf, 2690, Inf),\n                                labels = c(\"SLPA\", \"MVVPA\"))\ntable(acc$intens_2lev)## \n##  SLPA MVVPA \n##  1435     5"},{"path":"week4.html","id":"the-...-argument","chapter":"4 Week 4","heading":"4.2.1.2.2 The ... argument","text":"functions known priori number set arguments, large number arguments passed another function ... argument used. cover encouraged read : Use Dots Argument R; three-dots construct R.","code":""},{"path":"week4.html","id":"body","chapter":"4 Week 4","heading":"4.2.1.3 Body","text":"function’s body contains code perform purpose function. Following initial example, body function simplyThe body can simple complicated needs order achieve desired result.","code":"x^2"},{"path":"week4.html","id":"return-value","chapter":"4 Week 4","heading":"4.2.1.4 Return value","text":"return value either last evaluated expression function object specified using return() function.original f_square() function, return value x^2 since return() value specified, e.g., vector one element:vector multiple elements:simple example explicitly specifying return values shown numerical comparison function:want handle expected error, can print informative message use return(invisible()), returns nothing (whereas return() results NULL) e.g., without invisible():… invisible():","code":"\nf_square <- function(x){\n    x^2\n}\nf_square(3)## [1] 9\nf_square(c(1,2,3))## [1] 1 4 9\nf_compare <- function(x, y){\n    # either missing?\n    if(nargs() != 2)\n        return(\"invalid number of arguments\")\n    # numeric?\n    if(!is.numeric(x) | !is.numeric(y)){\n        return(sprintf(\"%s or %s is not numeric.\", x, y))\n    }\n    # comparisons follow\n    if(x > y){\n        return(sprintf(\"%s is greater than %s\", x, y))\n    } \n    if(x < y) {\n        return(sprintf(\"%s is less than %s\", x, y))\n    }\n    if(x == y){\n        return(sprintf(\"%s equals %s\", x, y))\n    }\n}\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return()\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")## Warning in f_readfile(\"foobar.txt\"): foobar.txt does not exist!## NULL\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return(invisible())\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")## Warning in f_readfile(\"foobar.txt\"): foobar.txt does not exist!"},{"path":"week4.html","id":"function-environments","chapter":"4 Week 4","heading":"4.2.1.5 Function environments","text":"mentioned , functions instantiate environments exist function evaluated. means functions can include named variables name variable different environment. example function lists objects local global environments:function completes, objects local environment purged. running complicated function creates intermediate values want examine troubleshooting, kind thing can done, assign variable specific value different environment created specifically examining intermediate products function:function runs, objects bar foobar placed foo environment. can examine :can view values:","code":"\n# declare a few variables\nx <- 1\ny <- \"hello\"\n\n# a simple function\nf <- function(x){\n    # create a local variable\n    y <- x + 2\n    # another function inside this function\n    g <- function(x){\n        x * 3\n    }\n    # what variables are in this environment?\n    print(\"----------\")\n    print(\"objects in this function's environment:\")\n    print(ls())\n    # what is in the global env?\n    print(\"----------\")\n    print(\"objects in the global environment:\")\n    print(ls(envir = .GlobalEnv))\n    # return the output of the function\n    print(\"----------\")\n    y\n}\n\nf(1)## [1] \"----------\"\n## [1] \"objects in this function's environment:\"\n## [1] \"g\" \"x\" \"y\"\n## [1] \"----------\"\n## [1] \"objects in the global environment:\"\n##  [1] \"acc\"             \"f\"               \"f_acc_intensity\" \"f_compare\"      \n##  [5] \"f_readfile\"      \"f_square\"        \"f_square_2\"      \"f_square_3\"     \n##  [9] \"L\"               \"v.len\"           \"v1\"              \"v2\"             \n## [13] \"v3\"              \"x\"               \"y\"              \n## [1] \"----------\"## [1] 3\n# create an environment for holding intermediate objects created in the function run\nfoo <- new.env()\ng <- function(x){\n    # code for a bunch of complicated operations\n    # ...\n    # generates an intermediate data frame named \"bar\"\n    bar <- head(iris)\n    # save to the other env\n    assign(x = \"bar\", value = bar, envir = foo)\n    # more code to do more complicated stuff\n    # ...\n    foobar <- head(cars)\n    # assign this too\n    assign(x = \"foobar\", value = foobar, envir = foo)\n    # yet more complicated stuff here\n    # ...\n}\n# run the function\ng()\n\n# what is in environment \"foo\"?\nls(envir = foo)## [1] \"bar\"    \"foobar\"\nprint(foo$bar)##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\nprint(foo$foobar)##   speed dist\n## 1     4    2\n## 2     4   10\n## 3     7    4\n## 4     7   22\n## 5     8   16\n## 6     9   10"},{"path":"week4.html","id":"sampling","chapter":"4 Week 4","heading":"4.3 Sampling","text":"general topic sampling far greater can cover course. However, examples may helpful students little experience sampling.main R function sampling sample(), draws random sample vector data frame. Options sample() include size sample, whether replace sampled individuals pool, probability weight length (number rows) population sample drawn.","code":""},{"path":"week4.html","id":"sampling-with-replacement","chapter":"4 Week 4","heading":"4.3.1 Sampling with replacement","text":"Sampling replacement similar rolling die. roll die 1/6 probability coming value. example:probability rolling two number row 1/6 \\(\\times\\) 1/6, \\(\\approx\\) 0.028","code":"\n# create a vector to represent the faces of a die\nd <- 1:6\n\n# now make a sample of 100,000 rolls of the die\ns <- sample(x = d, size = 100000, replace = TRUE)\n\n# tabulate the result\n(tbs <- table(s))## s\n##     1     2     3     4     5     6 \n## 16391 16931 16557 16728 16609 16784\n# proportions\n(prop.table(tbs))## s\n##       1       2       3       4       5       6 \n## 0.16391 0.16931 0.16557 0.16728 0.16609 0.16784"},{"path":"week4.html","id":"sampling-without-replacement","chapter":"4 Week 4","heading":"4.3.2 Sampling without replacement","text":"Sampling without replacement removes population individual sampled. example, probability selecting ace whole deck cards 4/52, \\(\\approx\\) 0.077. drew deck returned card back deck draw , samples independent. probability drawing two aces 4/52 \\(\\times\\) 4/52, \\(\\approx\\) 0.0059. example sampling replacement.Performing sample without replacement, .e., finding ace, removing , sampling probability drawing two aces 4/52 \\(\\times\\) 3/51, \\(\\approx\\) 0.0045.population sufficient size relative sample, sampling without replacement lead nearly identical results.Let’s use example population 50,000 persons, 30,000 female 20,000 male. sample two persons replacement, probability female 30000/50000 \\(\\times\\) 30000/50000, 0.36.sample without replacement, probability selecting female first sample one 30000/50000, second sample 1 probability selecting female 29999/49999, joint probability \\(\\approx\\) 0.359995.","code":""},{"path":"week4.html","id":"bootstrapping","chapter":"4 Week 4","heading":"4.3.3 Bootstrapping","text":"Bootstrapping used estimate characteristics population repeating large number random samples (replacement) calculating summary statistics set samples. reason replacement used sample represents “snapshot” population. number samples increases, summary continues approach true population characteristics.use simple example previously created hypothetical population. idea male/female split , generate large number small-samples take mean.use R loop. loop constructed using formA simple examples follow.Print letter first 5 letters alphabet. example, iterated element letter. built vector letters used:similar approach, using numerical index:bootstrap use 5,000 samples size 100 hypothetical population estimate proportion females.Using bootstrap results, can estimate 95% confidence interval around mean using Rmisc::CI() function, make density plot showing mean confidence interval.already enumeration population, method unnecessary. However, survey-derived data generated samples. sample representative underlying population, sample can considered acceptable proxy.Rendered 2022-01-08 17:59:4804-week04.Rmd","code":"for (element in set){\n    do something\n}\nfor (i in head(letters, 5)){\n    print(i)\n}## [1] \"a\"\n## [1] \"b\"\n## [1] \"c\"\n## [1] \"d\"\n## [1] \"e\"\nstates_5 <- head(state.name, 5)\nfor (i in 1:length(states_5)){\n    s <- states_5[i]\n    print(s)\n}## [1] \"Alabama\"\n## [1] \"Alaska\"\n## [1] \"Arizona\"\n## [1] \"Arkansas\"\n## [1] \"California\"\n# create the population\n# 1 indicates female and 0 indicates male\npop <- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5))\n\n# initialize a vector\nF <- NULL\n\n# run the bootstrap\nfor (i in seq(from = 1, to = 5000, by = 1)){\n    # sample once\n    s <- sample(x = pop, size = 100, replace = TRUE)\n    # calculate percent female\n    p <- sum(s) / length(s)\n    # concatenate the result with the running result\n    F <- c(F, p)\n}\n\n# mean and standard deviation of the bootstrap\nmean(F)## [1] 0.600582\nsd(F)## [1] 0.04883276\n# 95% CI\nci_95 <- Rmisc::CI(x = F, ci = 0.95)\n\n# plot with 95 % CI\nplot(density(F), main = \"density plot of bootstrap\")\nabline(v = ci_95, col=c(2,1,2))# Week 4 {#week4}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(readstata13)\n```\n\n<h2>Topics: Functions and sampling<\/h2>\nThis week's topics are functions and sampling, the latter including a cursory treatment of loops and bootstrapping.\n\n## Environments\nFunctions exist in `environments`, which are \"frames\" or collections containing objects including variables, functions, etc.). There is a global environment (`.GlobalEnv`) that contains all of the data, functions, in the current R session. Those objects can be enumerated with the `ls()` function. \n\nThe reason environments are mentioned at this time is because functions instantiate environments that exist while the function is running. More on this in a bit....\n\n## Functions\nFunctions are sets of statements in R that are grouped together to perform a specific task or set of tasks. Functions are either built in, included in packages, or user-defined. Functions are used mainly to simplify running a series of individual commands or functions, for situations where the same process will need to be run multiple times on different inputs, or when control structures are needed (e.g., looping, logical branching).\n\n### Function Components\nThe different parts of a function are:\n\n1. (Usually) Name: This is the actual name of the function. It is stored in an R environment as an object with this name.\n1. (Optional) Arguments: Arguments specify the inputs or options to the function. When a function is invoked, you pass a value to the argument. Arguments are optional; that is, a function may contain no arguments. Also arguments can have default values.\n1. Body: The function body contains a collection of statements that defines what the function does.\n1. Return value: The return value of a function is the last expression in the function body to be evaluated.\n\nAnother important concept for functions is environments.\n\n#### Name\nMost functions are created with code of the form\n\n```\nfunction_name <- function(argument(s)){\n    statement(s)\n}\n```\n\nFor example, to square a vector of numerical values:\n\n```{r}\nf_square <- function(x){\n    x^2\n}\n```\n\nthe function name is `f_square`.\n\nSome functions are not named, and are referred to as \"anonymous\" functions. For example, functions can be used within the `apply` family of functions. Here is an oprationalized example.\n\n```{r}\n# create a list of three vectors of random numbers of different random lengths\n\n# set.seed() makes the random process reproducible.\nset.seed(10)\n# vector lengths\nv.len <- rnorm(n = 3, mean = 30, sd = 10) %>% round(0)\n\n# make the random vectors\nset.seed(5)\nv1 <- rnorm(n = v.len[1])\nset.seed(3)\nv2 <- rnorm(n = v.len[2])\nset.seed(6)\nv3 <- rnorm(n = v.len[3])\n\n# create the list\nL <- list(v1, v2, v3)\n\n# get the first value from each vector in the list\nlapply(X = L, FUN = function(x) {x[1]})\n```\n\nThe last line of the code chunk is:\n\n```\nlapply(X = L, FUN = function(x) {x[1]})\n\n```\n\nin which the body of the function is `x[1]`, i.e., obtain the first element of a vector. But the function itself is not named, and hence \"anonymous.\"\n\n#### Arguments\nMost functions require arguments. Arguments are used to instantiate variables within the function's environment that can be used later in the body of the function. Each argument is named, and the name is used within the function as a local variable within the function's environment.\n\nFollowing our example from above, `f_square` takes an argument named \"x\" that is a numeric vector.\n\nHere, let's modify the function to demonstrate that within the environment of the function, `x` is a variable:\n\n```{r}\nf_square_2 <- function(x){\n    message(\"input:\")\n    print(x)\n    message(\"output:\")\n    x^2\n}\n\nf_square_2(c(1,2,3))\n```\n\nWe can try running the function using different (or no) arguments:\n\nHere, using a vector of a single NA numeric\n\n```{r}\nf_square(as.numeric(NA))\n```\n\n... or a vector that contains a numeric NA:\n\n```{r}\nf_square(c(1, 2, NA))\n```\n\n... or a null:\n\n```{r}\nf_square(NULL)\n```\n\n... or a vector containing a null:\n\n```{r}\nf_square(c(1, 2, NULL))\n```\n\n... or with no argument at all:\n\n```\nf_square()\n```\n\n<font color=\"red\">\n```\n## Error in f_square() : argument \"x\" is missing, with no default\n```\n<\/font>\n\nSome functions do not require arguments, e.g., to get the current date or time:\n\n```{r}\nSys.Date()\nSys.time()\n```\n\n... and if we try to use an argument we get an error:\n\n```\nSys.Date(1)\n```\n\n<font color=\"red\">\n```\n## Error in Sys.Date(1) : unused argument (1)\n```\n<\/font>\n\n##### Default values for arguments\nIf you want an argument to have a default value, it is specified in the listed arguments in the form `argument = value`. Following our previous `f_square_2()` function, we can modify to print the input based on the logical argument `verbose`:\n\n```{r, collapse=TRUE}\nf_square_3 <- function(x, verbose = FALSE){\n    # only run the next lines if verbose is true\n    if(verbose){\n        message(\"input:\")\n        print(x)\n        message(\"output:\")\n    }\n    x^2\n}\n```\n\nHere we run with the default `verbose` option (`FALSE`):\n\n```{r}\nf_square_3(x = c(1, 2, 3))\n```\n\n... and with `verbose = TRUE`:\n\n```{r}\nf_square_3(x = c(1, 2, 3), verbose = TRUE)\n```\n\nA more meaningful example demonstrates stratification of counts into intensity bins using accelerometry data. We will be using accelerometry from one day's data from one subject in a study.\n\nThe cut points for accelerometry were identified at 0, 2690, 6167, and 9642 counts per minute, from Sasaki et al. (2011).\n\n__Sasaki JE, John D, Freedson PS. Validation and comparison of ActiGraph activity monitors. J Sci Med Sport. 2011;14(5):411-416. doi:10.1016/j.jsams.2011.04.003__\n\nThe variable `vm3` is the vector magnitude measured with the accelerometer for each minute. Data: [accelerometry.csv](files/accelerometry.csv).\n\n```{r}\nacc <- read.csv(\"files/accelerometry.csv\")\n\nhead(acc)\n```\n\n\nThe following function codes intensity by the aforementioned cut points by default and using default labels:\n\n```{r}\nf_acc_intensity <- function(x, \n                            cuts = c(-Inf, 2690, 6167, 9642, Inf),\n                            labels = c(\"sedentary/low\", \"moderate\", \"vigorous\", \"very vigorous\")){\n    cut(x = acc$vm3, breaks = cuts, labels = labels)\n}\n```\n\n... and when run with the defaults to tabulate the minutes spent in different PA levels\n\n```{r}\nacc$intens_default <- f_acc_intensity(acc$vm3)\ntable(acc$intens_default)\n```\n\nBut we could run this with different thresholds and levels, where SPLA = \"sedentary/low physical activity\" and MVPA = \"moderate-to-very vigorous physical activity):\n\n```{r}\nacc$intens_2lev <- f_acc_intensity(x = acc$vm3,\n                                cuts = c(-Inf, 2690, Inf),\n                                labels = c(\"SLPA\", \"MVVPA\"))\ntable(acc$intens_2lev)\n```\n\n\n##### The `...` argument\nWhen functions do not have a known _a priori_ number or set of arguments, or when a large number of arguments is to be passed to another function the `...` argument is used. We will not cover this but you are encouraged to read more: [How to Use the Dots Argument in R](https://www.dummies.com/programming/r/how-to-use-the-dots-argument-in-r/); [The three-dots construct in R](https://www.r-bloggers.com/2013/01/the-three-dots-construct-in-r/).\n\n#### Body\nThe function's body contains all of the code to perform the purpose of the function. Following our initial example, the body of the function is simply \n\n```\nx^2\n```\n\nThe body can be as simple or complicated as it needs to be in order to achieve the desired result.\n\n#### Return value\nThe return value is either the last evaluated expression in the function or an object specified using the `return()` function. \n\nIn our original `f_square()` function, the return value is `x^2` since no other `return()` value was specified, e.g., for a vector of one element:\n\n```{r}\nf_square <- function(x){\n    x^2\n}\nf_square(3)\n```\n\nor a vector with multiple elements:\n\n```{r}\nf_square(c(1,2,3))\n```\n\nAn simple example of explicitly specifying return values is shown in this numerical comparison function:\n\n```{r}\nf_compare <- function(x, y){\n    # either missing?\n    if(nargs() != 2)\n        return(\"invalid number of arguments\")\n    # numeric?\n    if(!is.numeric(x) | !is.numeric(y)){\n        return(sprintf(\"%s or %s is not numeric.\", x, y))\n    }\n    # comparisons follow\n    if(x > y){\n        return(sprintf(\"%s is greater than %s\", x, y))\n    } \n    if(x < y) {\n        return(sprintf(\"%s is less than %s\", x, y))\n    }\n    if(x == y){\n        return(sprintf(\"%s equals %s\", x, y))\n    }\n}\n```\n\nIf you want to handle an expected error, you can print an informative message and use `return(invisible())`, which returns nothing at all (whereas `return()` results in a `NULL`) e.g., here without `invisible()`:\n\n```{r}\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return()\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")\n```\n\n... and with `invisible()`:\n\n```{r}\nf_readfile <- function(fname){\n    if(!file.exists(fname)){\n        warning(paste(fname, \"does not exist!\"))\n        return(invisible())\n    } else {\n        read.csv(fname)\n    }\n}\n\nf_readfile(\"foobar.txt\")\n```\n\n\n#### Function environments\nAs mentioned before, functions instantiate environments that exist only while the function is being evaluated. This means that functions can include named variables that have the same name as a variable in a different environment. For example here is a function that only lists what objects are in the local and global environments:\n\n```{r}\n# declare a few variables\nx <- 1\ny <- \"hello\"\n\n# a simple function\nf <- function(x){\n    # create a local variable\n    y <- x + 2\n    # another function inside this function\n    g <- function(x){\n        x * 3\n    }\n    # what variables are in this environment?\n    print(\"----------\")\n    print(\"objects in this function's environment:\")\n    print(ls())\n    # what is in the global env?\n    print(\"----------\")\n    print(\"objects in the global environment:\")\n    print(ls(envir = .GlobalEnv))\n    # return the output of the function\n    print(\"----------\")\n    y\n}\n\nf(1)\n```\n\nOnce the function completes, all objects in its local environment are purged. If you are running a complicated function that creates intermediate values that you want to examine for troubleshooting, this kind of thing can be done, to assign a variable with a specific value to a different environment created specifically for examining the intermediate products of the function:\n\n```{r}\n# create an environment for holding intermediate objects created in the function run\nfoo <- new.env()\ng <- function(x){\n    # code for a bunch of complicated operations\n    # ...\n    # generates an intermediate data frame named \"bar\"\n    bar <- head(iris)\n    # save to the other env\n    assign(x = \"bar\", value = bar, envir = foo)\n    # more code to do more complicated stuff\n    # ...\n    foobar <- head(cars)\n    # assign this too\n    assign(x = \"foobar\", value = foobar, envir = foo)\n    # yet more complicated stuff here\n    # ...\n}\n```\n\nWhen the function runs, the objects `bar` and `foobar` are placed in the `foo` environment. We can examine those:\n\n```{r}\n# run the function\ng()\n\n# what is in environment \"foo\"?\nls(envir = foo)\n```\n\nAnd we can view their values:\n\n```{r}\nprint(foo$bar)\n```\n\n```{r}\nprint(foo$foobar)\n```\n\n## Sampling\nThe general topic of sampling is far greater than what we can cover in this course. However, a few examples may be helpful for students who have little experience in sampling.\n\nThe main R function for sampling is `sample()`, which draws a random sample from a vector or data frame. Options for `sample()` include the size of the sample, whether or not to replace sampled individuals to the pool, and a probability weight of the same length (or number of rows) as the population from which the sample is drawn.\n\n### Sampling with replacement\nSampling with replacement is similar to rolling a die. Each roll of the die has a 1/6 probability of coming up with each value. For example:\n\n```{r}\n# create a vector to represent the faces of a die\nd <- 1:6\n\n# now make a sample of 100,000 rolls of the die\ns <- sample(x = d, size = 100000, replace = TRUE)\n\n# tabulate the result\n(tbs <- table(s))\n\n# proportions\n(prop.table(tbs))\n```\n\nThe probability of rolling two of the same number in a row is 1/6 $\\times$ 1/6, or $\\approx$ 0.028\n\n### Sampling without replacement\nSampling without replacement removes from the population the individual that was sampled. For example, the probability of selecting an ace from a whole deck of cards is 4/52, or $\\approx$ 0.077. If we drew once from the deck and returned the card back to the deck to draw again, both samples would be independent. The probability of drawing two aces would be 4/52 $\\times$ 4/52, or $\\approx$ 0.0059. _That_ is an example of sampling _with_ replacement.\n\nPerforming the same sample _without_ replacement, i.e., finding an ace, removing it, and then sampling again would have a probability of drawing two aces being 4/52 $\\times$ 3/51, or $\\approx$ 0.0045.\n\nFor a population of sufficient size relative to the sample, sampling with or without replacement will lead to nearly identical results.\n\nLet's use an example of a population of 50,000 persons, where 30,000 are female and 20,000 are male. If we were to sample two persons with replacement, the probability that they would both be female would be 30000/50000 $\\times$ 30000/50000, or 0.36.\n\nIf we sample without replacement, the probability of selecting a female in the first sample of one would be 30000/50000, and the second sample of 1 would have a probability of selecting a female 29999/49999, with a joint probability of $\\approx$ 0.359995.\n\n### Bootstrapping\nBootstrapping is used to estimate the characteristics of a population by repeating a large number of random samples (with replacement) and then calculating summary statistics on the set of samples. The reason replacement is used is that each sample represents a \"snapshot\" of the population. As the number of samples increases, the summary continues to approach the true population characteristics.\n\nWe will use a simple example from our previously created hypothetical population. If we had no idea what the male/female split was, we could generate a large number of small-is samples and the take the mean.\n\nHere we will use an R loop. A loop is constructed using the form\n\n```\nfor (element in set){\n    do something\n}\n```\n\nA few simple examples follow.\n\nPrint each letter in the first 5 letters of the alphabet. In this example, the iterated element is a letter. The built in vector `letters` is used:\n\n```{r}\nfor (i in head(letters, 5)){\n    print(i)\n}\n```\n\nA similar approach, but using a numerical index:\n\n```{r}\nstates_5 <- head(state.name, 5)\nfor (i in 1:length(states_5)){\n    s <- states_5[i]\n    print(s)\n}\n```\n\nThe bootstrap will use 5,000 samples of size 100 from our hypothetical population to estimate the proportion of females.\n\n```{r}\n# create the population\n# 1 indicates female and 0 indicates male\npop <- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5))\n\n# initialize a vector\nF <- NULL\n\n# run the bootstrap\nfor (i in seq(from = 1, to = 5000, by = 1)){\n    # sample once\n    s <- sample(x = pop, size = 100, replace = TRUE)\n    # calculate percent female\n    p <- sum(s) / length(s)\n    # concatenate the result with the running result\n    F <- c(F, p)\n}\n\n# mean and standard deviation of the bootstrap\nmean(F)\nsd(F)\n```\n\nUsing the bootstrap results, we can estimate the 95% confidence interval around the mean using the `Rmisc::CI()` function, and make a density plot showing the mean and the confidence interval.\n\n```{r}\n# 95% CI\nci_95 <- Rmisc::CI(x = F, ci = 0.95)\n\n# plot with 95 % CI\nplot(density(F), main = \"density plot of bootstrap\")\nabline(v = ci_95, col=c(2,1,2))\n```\n\nIf we already had an enumeration of the population, this method would be unnecessary. However, most survey-derived data are generated from samples. If the sample is representative of the underlying population,  the sample can be considered an acceptable proxy.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[04-week04.Rmd](04-week04.Rmd)\n\n```{r, comment='', echo=FALSE}\ncat(readLines(\"04-week04.Rmd\"), sep = '\\n')\n```"},{"path":"week5.html","id":"week5","chapter":"5 Week 5","heading":"5 Week 5","text":"week’s topic brief introduction Git, free open source version control system text-based files. Much material lesson derived Software Carpentry Git tutorial.","code":""},{"path":"week5.html","id":"why-use-version-control","chapter":"5 Week 5","heading":"5.1 Why use version control?","text":"Version control simply control various versions documents. context code-based research using text files .R, .Rmd, .tex, .sql, ., simplest level, version control means ability track changes files. advanced levels, able revert previous versions, collaborate others know , merge together edits made one personWe covered one form version control previous assignment section document File systems. version control system simply keeping copies existing files naming new files according temporal sequence, date suggested method nomenclature.keeping backup, dated copies files necessarily bad approach, suffers major limitations, including:relies saving different versions file, can lead proliferation filesit often easy know changes made version versionJorge Cham’s (Piled Higher Deeper) comic points happens typical graduate student’s “final” version:","code":""},{"path":"week5.html","id":"why-use-git","chapter":"5 Week 5","heading":"5.2 Why use Git?","text":"Version controls systems use since early 1980s. Commonly used applications RCS, CVS, SVN, Subversion. However, require centralized servers, limited capabilities, free.Git multiple advantages:freesupports complex work flows branching, merging, etc., allowing multiple collaborators work set files timedoes require centralized server (version control can managed completely within single computer)\npossible use online repositories, github.com\npossible use online repositories, github.comcan used within RStudiohas large community users (.e., free advice)","code":""},{"path":"week5.html","id":"limitations-of-version-control-systems","chapter":"5 Week 5","heading":"5.3 Limitations of version control systems","text":"Although version control systems quite useful, potential drawbacks.requires learning yet another somewhat-complicated systemrequires mindfulness\nrecorded changes best performed interactively\ncan “undo” changes committed\nrecorded changes best performed interactivelycan “undo” changes committeddesigned text files; deal binary files, e.g., Word formats","code":""},{"path":"week5.html","id":"a-brief-git-tutorial","chapter":"5 Week 5","heading":"5.4 A brief Git tutorial","text":"using basic functions Git building Rmd file.","code":""},{"path":"week5.html","id":"setting-up-git-in-rstudio","chapter":"5 Week 5","heading":"5.4.1 Setting up Git in RStudio","text":"working CSDE Terminal Server 4 (see Getting started Terminal Server 4).Start RStudio open web browser.","code":""},{"path":"week5.html","id":"creating-a-repository","chapter":"5 Week 5","heading":"5.4.2 Creating a repository","text":"Using web browser, go github.com create repository named git_r.Make repository public add README file.Switch back RStudio select File > New Project choice project types, select Version Control. streamline process linking RStudio project github.Choose Git type version control.Enter complete URL new Git repository. project directly name automatically set base name pf URL. , enter git_r.need define local file system project files stored, click Browse navigate H: drive (note UDrive).specified repository URL, project directory name, parent directory project directory, click Create Project.","code":""},{"path":"week5.html","id":"tracking-changes","chapter":"5 Week 5","heading":"5.4.3 Tracking changes","text":"One files change week_01.Rmd, download main folder project.first file make changes README.md.Add text explaining purpose repository serves.Save changes README.md file. see updates Git tab, click Refresh listing button. may need frequently file changes frequent. Note status files change files saved.see blue “M” next README.md file. Click check box Staged prepare commit changes file prepare push remote server.Click Commit new window open. deletions shown light red background. Additions shown light green background, text changed white background.Enter explanatory text Commit message panel. message help identify historical commits. explanatory text succinctly describe changes made.idea make commits time substantially changed code. wait long commits, number changes single commit may unmanageable. commits made frequently, number commits may become unmanageable. Think similarly often might make new version document.Next, perform initial pull/push. recommended multi-user environments perform pull online repository pushing. lets download local file system files updated others.Git tab, click Pull icon.Since changes made online files, see message “Already date.”Next, click Push icon upload changed files.point process establishing connection github, may get popups asking sign . happens, proceed authorization.authorization completed, push proceed. screen look different, last line text shows truncated version unique hash (identifier) push transaction. allow download previous versions file case made commits pushes caused unintended consequences.refresh page repository, see updates made README.md file. basic process updating files, committing changes, pushing github.Perform steps (click Staged Commit week_01.Rmd). new file github repository, committed, show green since text added.Repeat pull/push cycle refresh browser show file added online github repository.click file name see contents.Let’s make changes file. Back RStudio, add list packages load line 51.Change description line 122 readand change code chunk add two additional points text popups point markers. chunk contain following code:Save edits file tap “knit” button enter console prompt rmarkdown::render(\"week_01.Rmd\") generate HTML file. see now three point markers, hover markers see name popup.","code":"library(htmltools) # popup on Leaflet map... for a Leaflet map that has the Space Needle, Savery Hall, and the Woodland Park Zoo.# the Space Needle\nsnxy <- data.frame(name = \"Space Needle\", x = -122.3493, y = 47.6205)\nspace_needle <- st_as_sf(snxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# Savery Hall\nshxy <- data.frame(name = \"Savery Hall\", x = -122.3083, y = 47.6572)\nsavery_hall <- st_as_sf(shxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# the Woodland Park Zoo\nzooxy <- data.frame(name = \"Woodland Park Zoo\", x = -122.3543, y = 47.6685)\nwp_zoo <- st_as_sf(zooxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# rbind() to put two points in one data frame\npts <- rbind(space_needle, savery_hall, wp_zoo)\n\n# a leaflet\nm <- leaflet() %>% \n    addTiles() %>% \n    addCircleMarkers(data = pts, label = ~htmlEscape(name))\nm"},{"path":"week5.html","id":"git-bash-shell","chapter":"5 Week 5","heading":"5.4.4 Git bash shell","text":"Another interface can use Git bash shell. open shell, click Tools > Shell.GUI commands used RStudio available shell. fact, little functionality Git available within RStudio. take full advantage Git, necessary use shell. number excellent tutorials use shell. now introductory lesson, focus mainly RStudio interface,shell set project folder; can enter e.g., cd /H/git_r (note corresponds Windows folder H:\\git_r).prompt, enter git status. show status files, case showing week_01.Rmd modified, files tracked.","code":""},{"path":"week5.html","id":"ignoring-specific-files","chapter":"5 Week 5","heading":"5.4.5 Ignoring specific files","text":"Sometimes interested particular files committed pushed repository. version control, interested managing code used create outputs rather outputs , idea code, can recreate outputs.files can ignored, specified .gitignore file. Open file add line *.html. tells Git bother managing HTML files (assumption output rendering Rmd files).Save .gitignore file re-run git status shell (tapping arrow key keyboard tapping Enter). see HTML file show list changed untracked files.Add line *.Rproj .gitignore file–file necessary repository.Likewise, refresh Git tab RStudio, HTML file longer listed.perform tasks shell. Enter add .gitignore add week_01.Rmd. equivalent clicking Staged check boxRefreshing Git tab show two files staged.","code":""},{"path":"week5.html","id":"exploring-file-change-history","chapter":"5 Week 5","heading":"5.4.6 Exploring file change history","text":"Click Commit prepare commit changes (addition .gitignore changes week_01.Rmd).previously mentioned, deleted lines shown light red, added lines light green, unchanged lines highlighting. Click entry week_01.Rmd changes apparent. Line numbers far left original line numbers. next column right shows updated line numbers.allows compare currently saved version previous version file.Committing changes shell done enteringgit commit -m \"somecomment\"effect clicking Commit RStudio entering comment.Note made initial user configurations, Git print informative text identity. avoid tag future commits, use git config --global commands, e.g.,git config --global user.name \"Full Name\" git config --global user.email \"myemailaddress@mydomain\"commit performed, either RStudio GUI shell, can verify files listed possibly staged.Perform another pull/push cycle refresh web browser. Click commit comment.see changes two files last commit/push. .gitignore file lines green, indicating new respect repository. file week_01.Rmd shows changes github saw local view pushing commit server.","code":""},{"path":"week5.html","id":"restoring-a-previous-version","chapter":"5 Week 5","heading":"5.4.7 Restoring a previous version","text":"good tracked changes revert previous version file? make intentional bad edits file, commit push, retrieve previous version file. version can recovered. Note mean can recover edits file. means can recover changed commits. example, made commit/push noon, made lot changes saved file multiple times 5 PM made commit/push, two versions file available. reason worth making commit/push cycles every time thing might want revert previous version.intentional bad change week_01.Rmd complete removal code produces Leaflet map. See following image.Perform standard cycle: stage, commit (comment), pull, push.see large swath deleted linesBack github, find click file name.file contents show recent saved version (missing Leaflet map lines). Click History link, show commits.Click commit followed questionable advice adviser.missing lines evident. like go back version large deletion lines.Identify previous commit click clipboard icon left first characters commit hash. copy hash, necessary restoring version.Back shell, enterwhere ***** hash.see text present commit, includes deleted Leaflet map.restore previous version new file, enterThis prints contents previously committed file redirects output named file > sign.open file, see restored text.","code":"git show *****:week_01.Rmdgit show *****:week_01.Rmd > week_01_someadditionaldescription.Rmd"},{"path":"week5.html","id":"conclusion","chapter":"5 Week 5","heading":"5.5 Conclusion","text":"brief introduction main functionality Git RStudio github. expect perform even modest amount coding, benefit Git way keep track work, collaborate others, avoid programming disasters due inadvertent deletion overwriting files.Rendered 2022-01-08 17:59:5105-week05.Rmd","code":"\ncat(readLines(\"05-week05.Rmd\"), sep = '\\n')# Week 5 {#week5}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(readstata13)\n```\n\n<h2>Topic: Git<\/h2>\nThis week's topic is a brief introduction to [Git](https://git-scm.com/), the free and open source version control system for text-based files. Much of the material in this lesson is derived from the [Software Carpentry Git tutorial](https://swcarpentry.github.io/git-novice/).\n\n## Why use version control?\nVersion control is simply having control over various versions of your documents. In the context of code-based research using text files such as `.R`, `.Rmd`, `.tex`, `.sql`, `.do`, at the simplest level, version control means having the ability to track changes to your files. In more advanced levels, you should be able to revert to previous versions, collaborate with others and know who did what and when, or to merge together edits made by more than one person\n\nWe covered one form of version control in a previous assignment and in the section of this document on [File systems](#file-systems). The version control system was simply keeping copies of existing files and naming new files according to a temporal sequence, with date being the suggested method of nomenclature.\n\nWhile keeping backup, dated copies of files is not necessarily a bad approach, it suffers from a few major limitations, including:\n\n1. because it relies on saving different versions of a file, it can lead to a proliferation of files\n1. it is not often easy to know what changes were made from version to version\n\nJorge Cham's ([Piled Higher and Deeper](http://www.phdcomics.com)) comic points out what happens to a typical graduate student's \"final\" version:\n\n[![](images/week05/phd101212s.png)](http://www.phdcomics.com)\n\n## Why use Git?\nVersion controls systems have been in use since the early 1980s. Commonly used applications are RCS, CVS, SVN, and Subversion. However, some of these require centralized servers, are limited in their capabilities, and are not free.\n\nGit has multiple advantages:\n\n* free\n* supports complex work flows with branching, merging, etc., allowing multiple collaborators to work on the same set of files at the same time\n* does not require a centralized server (version control can be managed completely within a single computer)\n    * it is possible to use online repositories, such as github.com\n* can be used within RStudio\n* has a large community of users (i.e., free advice)\n\n## Limitations of version control systems\nAlthough version control systems are quite useful, there are some potential drawbacks.\n\n1. requires learning yet another somewhat-complicated system\n1. requires mindfulness\n    * recorded changes are best performed interactively\n    * can only \"undo\" changes that were committed\n1. designed for text files; cannot deal with binary files, e.g., Word or other formats\n\n## A brief Git tutorial\nHere we will be using the basic functions of Git while building up an Rmd file.\n\n### Setting up Git in RStudio\nWe will be working on CSDE Terminal Server 4 (see [Getting started on Terminal Server 4](#getting-started-on-terminal-server-4)). \n\nStart RStudio and open a web browser.\n\n### Creating a repository\nUsing the web browser, go to [github.com](http://github.com) and create a repository named `git_r`.\n\n![](images/week05/2021-02-04_21_21_47.png)\n\nMake the repository public and add a README file.\n\n![](images/week05/2021-02-04_21_37_13.png)\n\nSwitch back to RStudio and select `File > New Project` and in the choice of project types, select `Version Control`. This will streamline the process of linking the RStudio project with github.\n\n![](images/week05/2021-02-04_21_39_10.png)\n\nChoose `Git` as the type of version control.\n\n![](images/week05/2021-02-04_21_39_46.png)\n\nEnter the complete URL of your new Git repository. The project directly name should automatically be set as the base name pf the URL. If not, enter `git_r`.\n\n![](images/week05/2021-02-04_21_52_48.png)\n\nBecause we need to define where on the local file system the project files will be stored, click `Browse` and navigate to your `H:` drive (note that this is your UDrive).\n\n![](images/week05/2021-02-04_21_53_32.png)\n\nAfter you have specified the repository URL, project directory name, and parent directory of the project directory, click `Create Project`.\n\n![](images/week05/2021-02-04_21_54_04.png)\n\n### Tracking changes\nOne of the files we will change is [week_01.Rmd](files/week_01.Rmd), so download this to the main folder of your project.\n\nThe first file we will make changes to is `README.md`.\n\nAdd some text explaining what purpose the repository serves.\n\n![](images/week05/2021-02-04_22_09_11.png)\n\nSave the changes to the README.md file. If you do not see updates in the Git tab, click the `Refresh listing` button. You may need to do this frequently if your file changes are frequent. Note the status of files will only change when the files are saved.\n\n![](images/week05/2021-02-04_22_37_42.png)\n\nYou should see a blue \"M\" next to the README.md file. Click the check box for `Staged` to prepare to commit the changes to the file and prepare to push to the remote server.\n\n![](images/week05/2021-02-04_22_11_45.png)\n\nClick `Commit` and a new window will open. Any deletions are shown with a light red background. Additions are shown with a light green background, and text that has not changed will have a white background.\n\nEnter some explanatory text in the `Commit message` panel. This message will help identify historical commits. The explanatory text should succinctly describe any changes you have made.\n\nThe idea is to make commits each time you have substantially changed your code. If you wait too long between commits, the number of changes in a single commit may be unmanageable. But if commits are made too frequently, the number of commits may become unmanageable. Think of this similarly to how often you might make a new version of a document.\n\n![](images/week05/2021-02-04_22_15_28.png)\n\nNext, we will perform an initial pull/push. It is recommended in multi-user environments to perform a pull from the online repository before pushing. This lets you download to your local file system any files that have been updated by others.\n\nIn the Git tab, click the `Pull` icon.\n\n![](images/week05/2021-02-04_22_17_19.png)\n\n\nSince no changes have been made to the online files, we see the message \"Already up to date\".\n\n![](images/week05/2021-02-04_22_17_41.png)\n\nNext, click the `Push` icon to upload any changed files.\n\n![](images/week05/2021-02-04_22_17_58.png)\n\nAt some point in the process of establishing the connection to github, you may get some popups asking you to sign in. If this happens, proceed with the authorization.\n\n![](images/week05/2021-02-04_22_19_18.png)\n\n![](images/week05/2021-02-04_22_19_59.png)\n\n![](images/week05/2021-02-04_22_20_08.png)\n\nWhen the authorization is completed, the push will proceed. Your screen will look different, but the last line of text here shows a truncated version of the unique hash (identifier) of the push transaction. This has will allow you to download previous versions of the file in case you made commits and pushes that caused unintended consequences.\n\n![](images/week05/2021-02-04_22_20_32.png)\n\nIf you refresh the page for your repository, you should see the updates you made to the README.md file. This is the basic process for updating files, committing changes, and pushing to github.\n\n![](images/week05/2021-02-04_22_21_18.png)\n\n\nPerform the same steps (click `Staged` then `Commit` for week_01.Rmd). Because this is a new file that was not in the github repository, when it is committed, it will show in all green since all of the text has been added. \n\n![](images/week05/2021-02-04_22_46_24.png)\n\nRepeat the pull/push cycle and then refresh your browser to show that the file was added to the online github repository.\n\n![](images/week05/2021-02-04_22_48_45.png)\n\nIf you click the file name you will see the contents.\n\n![](images/week05/2021-02-04_22_49_07.png)\n\nLet's make some changes to this file. Back in RStudio, add to the list of packages to load at line 51.\n\n```\nlibrary(htmltools) # popup on Leaflet map\n```\n\nChange the description at line 122 to read \n\n```\n... for a Leaflet map that has the Space Needle, Savery Hall, and the Woodland Park Zoo.\n```\n\nand change the code chunk to add two additional points and text popups for the point markers. The chunk should contain the following code:\n\n```\n# the Space Needle\nsnxy <- data.frame(name = \"Space Needle\", x = -122.3493, y = 47.6205)\nspace_needle <- st_as_sf(snxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# Savery Hall\nshxy <- data.frame(name = \"Savery Hall\", x = -122.3083, y = 47.6572)\nsavery_hall <- st_as_sf(shxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# the Woodland Park Zoo\nzooxy <- data.frame(name = \"Woodland Park Zoo\", x = -122.3543, y = 47.6685)\nwp_zoo <- st_as_sf(zooxy, coords = c(\"x\", \"y\"), crs = 4326)\n\n# rbind() to put two points in one data frame\npts <- rbind(space_needle, savery_hall, wp_zoo)\n\n# a leaflet\nm <- leaflet() %>% \n    addTiles() %>% \n    addCircleMarkers(data = pts, label = ~htmlEscape(name))\nm\n```\n\nSave the edits to the file and then tap the \"knit\" button or enter at the console prompt `rmarkdown::render(\"week_01.Rmd\")` to generate the HTML file. You should see that now there are three point markers, and if you hover over any of the markers you will see the name popup.\n\n![](images/week05/2021-02-04_22_32_50.png)\n\n### Git bash shell\n\nAnother interface you can use is the Git bash shell. To open the shell, click `Tools > Shell`. \n\n![](images/week05/2021-02-04_22_01_34.png) \n\nAll of the GUI commands we have used in RStudio are available in the shell. In fact, very little of the functionality of Git is available within RStudio. To take full advantage of Git, it is necessary to use the shell. There are a number of excellent tutorials on the use of the shell. For now because this is an introductory lesson, we will focus mainly on the RStudio interface,\n\nThe shell should be set to the project folder; if not you can enter e.g., `cd /H/git_r` (note that this corresponds to the Windows folder `H:\\git_r`).\n\nAt the prompt, enter `git status`. This will show the status of all files, in this case showing that `week_01.Rmd` has been modified, and that there are some files that are not being tracked.\n\n![](images/week05/2021-02-04_23_36_02.png)\n\n### Ignoring specific files\nSometimes we are not interested in particular files being committed or pushed to the repository. For version control, we are interested in managing the code that is used to create outputs rather than the outputs themselves, with the idea being that if you have the code, you can recreate any outputs.\n\nSo there are files that can be ignored, which are specified in the `.gitignore` file. Open the file and add the line `*.html`. This tells Git not to bother managing HTML files (under the assumption that these are the output of rendering Rmd files).\n\n![](images/week05/2021-02-04_23_40_15.png)\n\nSave the `.gitignore` file and re-run `git status` at the shell (by tapping the up arrow key on your keyboard and tapping Enter). You should see that the HTML file does not show up in the list of changed or untracked files.\n\n![](images/week05/2021-02-04_23_42_51.png)\n\nAdd the line `*.Rproj` to the `.gitignore` file--this file should not be necessary in the repository.\n\nLikewise, if you refresh the Git tab in RStudio, the HTML file is no longer listed.\n\n![](images/week05/2021-02-04_23_43_13.png)\n\nWe will perform a few more tasks with the shell. Enter `add .gitignore` and `add week_01.Rmd`. This is the equivalent of clicking the `Staged` check box \n\n![](images/week05/2021-02-04_23_45_14.png)\n\nRefreshing the Git tab will show that these two files are staged.\n\n![](images/week05/2021-02-04_23_45_37.png)\n\n\n### Exploring file change history\nClick `Commit` to prepare to commit the changes (addition of `.gitignore` and the changes to `week_01.Rmd`).\n\nAs previously mentioned, deleted lines are shown in light red, added lines in light green, and unchanged lines with no highlighting. Click the entry for `week_01.Rmd` and the changes are apparent. Line numbers on the far left are the original line numbers. The next column to the right shows updated line numbers.\n\nThis allows you to compare the currently saved version against the previous version of the file.\n\n![](images/week05/2021-02-04_23_48_02.png)\n\nCommitting changes with the shell is done by entering \n\n`\ngit commit -m \"somecomment\"\n`\n\nThis has the same effect as clicking `Commit` in RStudio and entering the comment.\n\nNote that if we have not made some initial user configurations, Git will print some informative text about your identity. To avoid this and to tag future commits, use the `git config --global` commands, e.g., \n\n`\ngit config --global user.name \"My Full Name\"\ngit config --global user.email \"myemailaddress@mydomain\"\n`\n\n![](images/week05/2021-02-04_23_51_55.png)\n\nOnce the commit is performed, either with the RStudio GUI or with the shell, you can verify that no files are listed to be possibly staged.\n\n![](images/week05/2021-02-04_23_53_10.png)\n\nPerform another pull/push cycle and then refresh your web browser. Click on the commit comment.\n\n![](images/week05/2021-02-05_00_10_46.png)\n\nYou will see the changes to the two files in the last commit/push. The `.gitignore` file has all of its lines in green, indicating they are all new with respect to the repository. The file `week_01.Rmd` shows the same changes on github as we saw in the local view before pushing the commit to the server.\n\n\n![](images/week05/2021-02-05_00_12_20.png)\n\n### Restoring a previous version\nWhat good are all of these tracked changes if we cannot revert to a previous version of a file? Here we will make some intentional bad edits to a file, commit and push, but then retrieve a previous version of the file. Any version can be recovered. Note that this does not mean you can recover any and all edits to a file. It only means you can recover what changed between commits. For example, if I made a commit/push at noon, then made a lot of changes and saved the file multiple times before 5 PM and then made a commit/push, there would only be two versions of the file available. For this reason it is worth making commit/push cycles every time you thing you might want to revert to a previous version.\n\nThe intentional bad change to `week_01.Rmd` is the complete removal of the code that produces the Leaflet map. See the following image.\n\n![](images/week05/2021-02-05_00_13_13.png)\n\nPerform the standard cycle: stage, commit (with comment), pull, push.\n\n![](images/week05/2021-02-05_00_14_07.png)\n\n![](images/week05/2021-02-05_00_14_24.png)\n\n![](images/week05/2021-02-05_00_16_23.png)\n\n![](images/week05/2021-02-05_00_17_10.png)\n\nYou should see the large swath of deleted lines\n\n![](images/week05/2021-02-05_00_21_01.png)\n\n\n![](images/week05/2021-02-05_00_22_10.png)\n\nBack in the github, find and click the file name.\n\n![](images/week05/2021-02-05_00_24_21.png)\n\nThe file contents will show the most recent saved version (missing the Leaflet map lines). Click on the `History` link, which will show all of the commits.\n\n![](images/week05/2021-02-05_00_25_05.png)\n\nClick the commit where you followed the questionable advice from your adviser.\n\n![](images/week05/2021-02-05_00_25_23.png)\n\nThe missing lines are evident. What we would like to do is to go back to the version before the large deletion of lines.\n\n![](images/week05/2021-02-05_00_25_40.png)\n\nIdentify the previous commit and click the clipboard icon to the left of the first characters of the commit hash. This will copy the hash, which is necessary for restoring that version.\n\n![](images/week05/2021-02-05_00_39_46.png)\n\nBack in the shell, enter\n\n```\ngit show *****:week_01.Rmd\n```\n\nwhere `*****` is the hash.\n\n![](images/week05/2021-02-05_00_40_36.png)\n\nYou will see the text that was present at that commit, which includes the deleted Leaflet map.\n\n![](images/week05/2021-02-05_00_40_59.png)\n\nTo restore this previous version to a new file, enter\n\n```\ngit show *****:week_01.Rmd > week_01_someadditionaldescription.Rmd\n```\n\nThis prints the contents of the previously committed file and redirects the output to the named file after the `>` sign.\n\n![](images/week05/2021-02-05_00_45_16.png)\n\nIf you open that file, you will see the restored text.\n\n![](images/week05/2021-02-05_00_46_04.png)\n\n## Conclusion\nThis was a brief introduction to the main functionality of Git with RStudio and github. If you expect to perform even a modest amount of coding, you could benefit from Git as a way to keep track of your work, collaborate with others, and avoid programming disasters due to inadvertent deletion of overwriting of files.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[05-week05.Rmd](05-week05.Rmd)\n\n```{r comment=''}\ncat(readLines(\"05-week05.Rmd\"), sep = '\\n')\n```"},{"path":"week6.html","id":"week6","chapter":"6 Week 6","heading":"6 Week 6","text":"","code":""},{"path":"week6.html","id":"the-add-health-study-data","chapter":"6 Week 6","heading":"6.1 The Add Health study data","text":"Add Health web site describes study:Initiated 1994 supported five program project grants Eunice Kennedy Shriver National Institute Child Health Human Development (NICHD) co-funding 23 federal agencies foundations, Add Health largest, comprehensive, nationally-representative longitudinal survey adolescents ever undertaken. Beginning -school questionnaire administered nationally representative sample students grades 7-12, study followed series -home interviews conducted 1995, 1996, 2001-02, 2008, 2016-18. Add Health participants now full-fledged adults, aged 33-44, soon moving midlife. years, Add Health added substantial amount additional data users, including contextual data communities states participants reside, genomic data range biological health markers participants, parental survey data.public-use data contain subset records variables restricted-use full data set. full data set requires lengthy application process meeting specific security standards. CSDE copy tables restricted-use data set UW Data Collaborative.using Wave 1 public-use Add Health data remainder term. week briefly delve documentation see data set use supported documentation.","code":""},{"path":"week6.html","id":"documentation","chapter":"6 Week 6","heading":"6.2 Documentation","text":"Add Health data well documented. PDFs contain verbatim text survey questions, range encoded answers, count tabulations responses.See full set metadata PDFs: Wave1_InHome_Codebooks, comprehensive codebook.revisit documentation later lesson.","code":""},{"path":"week6.html","id":"data-sets","chapter":"6 Week 6","heading":"6.3 Data sets","text":"two data sets using AHwave1_v1.dta.zip 21600-0001-Data.dta.zip. Download file unzip , result AHwave1_v1.dta, encountered , 21600-0001-Data.dta.Stata files. Stata files version 12 can read foreign::read.dta(), version 13 require haven::read_dta() readstata13::read.dta13().One benefits Stata file formats, compared e.g., CSV Excel, Stata files can contain metadata variables. imported data frames may cryptic variable names, extensive labels. R import process can expose labels, making data easy interpret","code":""},{"path":"week6.html","id":"ahwave1_v1.dta","chapter":"6 Week 6","heading":"6.3.1 AHwave1_v1.dta","text":"AHwave1_v1.dta Stata version 13 file. look two import options.","code":""},{"path":"week6.html","id":"havenread_dta","chapter":"6 Week 6","heading":"6.3.1.1 haven::read_dta()","text":"haven::read_dta() read data data frame. Note code examples run without modification, assumption data downloaded unzipped sub-folder named data within current working directory. can find current working directory entering getwd() R prompt.labeled variable attributes can perused listing structure:first values (head()):listing attributes variable , provides verbose listing variable label, data format, class, value labels:order access metadata single object, one can use lapply() function, data frame can also treated list. , variable name, label, data format, values extracted single data frame presented DT::datatable. provides metadata format probably easier use PDF documentation.","code":"\n# read the data\nif(!file.exists(\"data/AHwave1_v1.dta\")){\n    unzip(zipfile = \"data/AHwave1_v1.dta.zip\", exdir = \"data\")\n}\nAHwave1_v1_haven <- haven::read_dta(file = \"data/AHwave1_v1.dta\")\nstr(AHwave1_v1_haven$imonth)##  dbl+lbl [1:6504] 6, 5, 6, 7, 7, 6, 5, 6, 6, 8, 9, 5, 6, 7, 5, 5, 7, 5, 8, ...\n##  @ label       : chr \"MONTH OF INTERVIEW-W1\"\n##  @ format.stata: chr \"%13.0f\"\n##  @ labels      : Named num [1:10] 1 4 5 6 7 8 9 10 11 12\n##   ..- attr(*, \"names\")= chr [1:10] \"(1) January\" \"(4) April\" \"(5) May\" \"(6) June\" ...\nhead(AHwave1_v1_haven$bio_sex)## <labelled<double>[6]>: BIOLOGICAL SEX-W1\n## [1] 2 2 1 1 2 1\n## \n## Labels:\n##  value       label\n##      1    (1) Male\n##      2  (2) Female\n##      6 (6) Refused\nattributes(AHwave1_v1_haven$h1gi1m)## $label\n## [1] \"S1Q1 BIRTH MONTH-W1\"\n## \n## $format.stata\n## [1] \"%13.0f\"\n## \n## $class\n## [1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n## \n## $labels\n##   (1) January  (2) February     (3) March     (4) April       (5) May \n##             1             2             3             4             5 \n##      (6) June      (7) July    (8) August (9) September  (10) October \n##             6             7             8             9            10 \n## (11) November (12) December  (96) Refused \n##            11            12            96\nAHwave1_v1_haven_metadata <- bind_cols(\n    # variable name\n    varname = colnames(AHwave1_v1_haven),\n    # label\n    varlabel = lapply(AHwave1_v1_haven, function(x) attributes(x)$label) %>% \n        unlist(),\n    # format\n    varformat = lapply(AHwave1_v1_haven, function(x) attributes(x)$format.stata) %>%\n        unlist(),\n    # values\n    varvalues = lapply(AHwave1_v1_haven, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(AHwave1_v1_haven_metadata)"},{"path":"week6.html","id":"readstata13read.dta13","chapter":"6 Week 6","heading":"6.3.1.2 readstata13::read.dta13()","text":"readstata13::read.dta13() similarly read data data frame. number different options converting factors, dealing lot Stata files may want become familiar options.example, using default options kicks warnings double precision coding missing factor labels. [Note: hide warnings, better worse (.e., might want hide ), use code chunk option warning=FALSE].Metadata can generated similarly:default conversion creates factors, tables may easy read/interpret …… programming require work factors either need explicitly named, e.g.,factors really just labelled numbers, one use numeric values, care needs taken:months represented data, numerical value month may expect. example, 4th month factor level “(6) June” rather “(4) April.”Compare results haven::read_dta(). values factors, labelled double-precision numbers:perform similar filter() & select() operation haven version:approach prefer?","code":"\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\")## Warning in readstata13::read.dta13(file = \"data/AHwave1_v1.dta\"): \n##    Factor codes of type double or float detected in variables\n## \n##    h1hr7a, h1hr7b\n## \n##    No labels have been assigned.\n##    Set option 'nonint.factors = TRUE' to assign labels anyway.## Warning in readstata13::read.dta13(file = \"data/AHwave1_v1.dta\"): \n##    Missing factor labels for variables\n## \n##    h1hr8e\n## \n##    No labels have beend assigned.\n##    Set option 'generate.factors=TRUE' to generate labels.\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\", generate.factors = TRUE, nonint.factors = TRUE)\nAHwave1_v1_rs13_metadata <- bind_cols(\n    varname = colnames(AHwave1_v1_rs13),\n    varlabel = attributes(AHwave1_v1_rs13)$var.labels,\n    varformat = attributes(AHwave1_v1_rs13)$formats\n)\n\n# value ranges; need to do this separately because those variables with no value labels were not accounted for\nvarvalues <- bind_cols(\n    varname = names(attributes(AHwave1_v1_rs13)$label.table) %>% tolower,\n    vals = attributes(AHwave1_v1_rs13)$label.table %>% \n    lapply(., function(x) names(x)) %>% \n    as.character() %>% \n    str_remove_all(\"^c\\\\(|\\\\)$\"))\n\n# join\nAHwave1_v1_rs13_metadata %<>% \n    left_join(varvalues, by = \"varname\")\n\nDT::datatable(AHwave1_v1_rs13_metadata)\nhead(x = AHwave1_v1_rs13$imonth, n = 6)## [1] (6) June (5) May  (6) June (7) July (7) July (6) June\n## 10 Levels: (1) January (4) April (5) May (6) June (7) July ... (12) December\nAHwave1_v1_rs13 %>% \n    head(10) %>% \n    filter(imonth == \"(6) June\") %>% \n    select(aid, imonth, iday)##        aid   imonth iday\n## 1 57100270 (6) June   23\n## 2 57103171 (6) June   27\n## 3 57104649 (6) June   12\n## 4 57109625 (6) June    7\n## 5 57110897 (6) June   27\nlevels(AHwave1_v1_rs13$imonth) %>% t() %>% t()##       [,1]           \n##  [1,] \"(1) January\"  \n##  [2,] \"(4) April\"    \n##  [3,] \"(5) May\"      \n##  [4,] \"(6) June\"     \n##  [5,] \"(7) July\"     \n##  [6,] \"(8) August\"   \n##  [7,] \"(9) September\"\n##  [8,] \"(10) October\" \n##  [9,] \"(11) November\"\n## [10,] \"(12) December\"\nhead(AHwave1_v1_haven$imonth)## <labelled<double>[6]>: MONTH OF INTERVIEW-W1\n## [1] 6 5 6 7 7 6\n## \n## Labels:\n##  value         label\n##      1   (1) January\n##      4     (4) April\n##      5       (5) May\n##      6      (6) June\n##      7      (7) July\n##      8    (8) August\n##      9 (9) September\n##     10  (10) October\n##     11 (11) November\n##     12 (12) December\nAHwave1_v1_haven %>% \n    head(10) %>% \n    filter(imonth == 6) %>% \n    select(aid, imonth, iday)## # A tibble: 5 x 3\n##   aid            imonth  iday\n##   <chr>       <dbl+lbl> <dbl>\n## 1 57100270 6 [(6) June]    23\n## 2 57103171 6 [(6) June]    27\n## 3 57104649 6 [(6) June]    12\n## 4 57109625 6 [(6) June]     7\n## 5 57110897 6 [(6) June]    27"},{"path":"week6.html","id":"data.dta","chapter":"6 Week 6","heading":"6.3.2 21600-0001-Data.dta","text":"21600-0001-Data.dta much larger data set. count records, columns AHwave1_v1.dta.fact, AHwave1_v1.dta seems subset 21600-0001-Data.dta. can show lower-casing column names using select() named columnsWe can build similar table metadata, time function:","code":"\n# read in the larger data set\nif(!file.exists(\"data/21600-0001-Data.dta\")){\n    unzip(zipfile = \"data/21600-0001-Data.dta.zip\", exdir = \"data\")\n}\ndata_21600_0001 <- haven::read_dta(file = \"data/21600-0001-Data.dta\")\n# if(file.exists(\"data/21600-0001-Data.dta\")){\n#     file.remove(file = \"data/21600-0001-Data.dta\")\n# }\n\n# dimensions of the two\ndim(AHwave1_v1_haven)## [1] 6504  103\ndim(data_21600_0001)## [1] 6504 2794\n# lowercase the column names\ncolnames(data_21600_0001) %<>% str_to_lower()\n\n# select() some columns of the same name\ndat <- data_21600_0001 %>% \n    select(colnames(AHwave1_v1_haven))\n\n# identical?\nidentical(dat, AHwave1_v1_haven)## [1] TRUE\n# if(file.exists(\"data/AHwave1_v1.dta\")){\n#     file.remove(\"data/AHwave1_v1.dta\")\n# }\n# a generic(?) function to generate metadata for a Stata file read by haven::read_dta()\n# x is a haven data frame\nf_haven_stata_metadata <- function(x){\n    # variable names\n    varname <- colnames(x)\n    # labels\n    varlabel <- x %>% \n        lapply(., function(x) attributes(x)$label) %>% \n        unlist()\n    # format\n    varformat <- x %>% \n        lapply(., function(x) attributes(x)$format.stata) %>%\n        unlist()\n    # values\n    varvalues <- x %>% \n        lapply(., function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")  \n    \n    bind_cols(varname = varname, \n              varlabel = varlabel, \n              varformat = varformat,\n              varvalues = varvalues)\n}\n\n# generate the metadata\ndata_21600_0001_metadata <- f_haven_stata_metadata(data_21600_0001)\n\n# print the metadata table as a DT::datatable\nDT::datatable(data_21600_0001_metadata)"},{"path":"week6.html","id":"searching-through-documentation","chapter":"6 Week 6","heading":"6.4 Searching through documentation","text":"Good data sets good documentation. Sometimes documentation voluminous, case Add Health data. voluminous metadata, good approaches finding interested without opening PDF file, reading table contents, searching string matches, etc.?section cover two tools make searching PDF files less onerous efficient. two utilities pdfgrep pdftools::pdf_text()","code":""},{"path":"week6.html","id":"pdfgrep","chapter":"6 Week 6","heading":"6.4.1 pdfgrep","text":"grep string-matching utility developed mainly UNIX, now available common operating systems. also implemented base R function grep(). name comes ed command g/re/p (\\(\\underline{g}\\)lobally search \\(\\underline{r}\\)egular \\(\\underline{e}\\)xpression \\(\\underline{p}\\)rint matching lines), typically used print line number text file containing search pattern.familiar regular expressions plan computational social sciences, sooner learn, better. See R help topic base::regex().won’t covering grep general , introduce regular expression logic pdfgrep.Start installing version pdfgrep. three implementations, one Mac two Windows. demo today use Cygwin version. native Windows version powerful/customizable Cygwin version also likely comparable Mac version. Note: pdfgrep work PDF files contain text. PDFs composed solely scanned images contain text therefore searchable using regular expressions.pdfgrep native Windowspdfgrep Cygwin Windowspdfgrep MacA zipped file containing metadata files Home Questionnaire available Wave1_InHome_Codebooks.pdf.zip. Download file unzip appropriate location.","code":""},{"path":"week6.html","id":"a-few-use-examples","chapter":"6 Week 6","heading":"6.4.1.1 A few use examples","text":"[Note: images may hard read; clicking open full-size; click middle mouse button open new tab.]search entire set PDF files regular expression black. First, let’s list PDF files usingls *.pdfThe syntax search ispdfgrep black *.pdfThis prints file name matching text PDF containing regular expression black. Suppose wanted search black Black BLACK? Use flag -short case \\(\\underline{}\\)nsensitive.pdfgrep -black *.pdfThis shows files contain black case combination.might want know look (.e., page number) file. Using -n flag prints page \\(\\underline{n}\\)umber.Seeing several matches inh25pub.pdf, first match page 13, let’s view :Let’s look another pattern, word recreation:pdfgrep -n -recreation *.pdfSeeing matches, might want narrow search include “social recreation”al activity. , regular expression social.*recreation, .* regexp translates “number characters.”perform one pattern match. Suppose interested tired stressed. regexp pattern \"pat1|pat2\" (note quotes vertical bar). quotes indicate shell pipe, part regexp.full expression show metadata files match either patterns.pdfgrep -\"tired|stress\" *.pdfWhy, may ask, created fancy metadata tables data, want search specific strings PDF documentation? full documentation likely provide complete explanations, whereas metadata created data labels brief description.","code":""},{"path":"week6.html","id":"pdftoolspdf_text","chapter":"6 Week 6","heading":"6.4.2 pdftools::pdf_text()","text":"Staying completely within R, can perform similar searches PDF files. start pdftools::pdf_text(), converts PDFs text vectors, page converted one vector element. can piped text-matching functions, base::grep() stringr::str_match() (stringr loaded tidyverse).Unlike pdfgrep, can serially search set files directory, pdf_text() requires additional work. example mimics searching case-insensitive regular expression black set PDFs.create function searches single PDF loop function set PDFs specified folder, returning file name list, pattern searched , page number match, whether search case sensitive .","code":"\n# a function to get matching strings in a PDF, ignore case\nf_pdf_str_match <- function(x, pat, ignore.case = TRUE){\n    # convert the PDF to text\n    mytext <- pdf_text(x)\n    # pattern\n    if(ignore.case){\n        mypat <- regex(pat, ignore_case = TRUE)\n    } else {\n        mypat <- pat\n    }\n    # match strings = pages\n    pages <- str_which(string = mytext, pattern = mypat)\n    if(length(pages) == 0){\n        return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case))\n    }\n    # create a data frame\n    data.frame(fname = x, pat, page_num = pages, ignore.case)\n}\n\n# a list of my PDFs\nmypdfs <- list.files(path = \"data/metadata/Wave1_InHome_Codebooks\", pattern = \"*.pdf$\", full.names = TRUE)\n\n# an empty data frame\nx <- NULL\n\n# run each one\nfor(i in mypdfs){\n    x <- rbind(x, f_pdf_str_match(i, \"black\", ignore.case = TRUE))\n}\n\n# ignore NAs\nx %>% filter(!is.na(page_num))##                                               fname   pat page_num ignore.case\n## 1 data/metadata/Wave1_InHome_Codebooks/inh01pub.pdf black        7        TRUE\n## 2 data/metadata/Wave1_InHome_Codebooks/inh01pub.pdf black        9        TRUE"},{"path":"week6.html","id":"conclusion-1","chapter":"6 Week 6","heading":"6.5 Conclusion","text":"use data sets metadata next several lessons. methods presented today’s lesson increase efficiency reduce busy-work.Rendered 2022-01-08 17:59:5906-week06.Rmd","code":"\ncat(readLines(con = \"06-week06.Rmd\"), sep = '\\n')# Week 6 {#week6}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(readstata13)\nlibrary(haven)\nlibrary(pdftools)\n```\n\n<h2>Topic: Add Health data: exploring variables and data documentation<\/h2>\n\n## The Add Health study data\nThe Add Health [web site](https://data.cpc.unc.edu/projects/2/view) describes the study:\n\n> Initiated in 1994 and supported by five program project grants from the Eunice Kennedy Shriver National Institute of Child Health and Human Development (NICHD) with co-funding from 23 other federal agencies and foundations, Add Health is the largest, most comprehensive, nationally-representative longitudinal survey of adolescents ever undertaken. Beginning with an in-school questionnaire administered to a nationally representative sample of students in grades 7-12, the study followed up with a series of in-home interviews conducted in 1995, 1996, 2001-02, 2008, and 2016-18. Add Health participants are now full-fledged adults, aged 33-44, and will soon be moving into midlife. Over the years, Add Health has added a substantial amount of additional data for users, including contextual data on the communities and states in which participants reside, genomic data and a range of biological health markers of participants, and parental survey data.\n\nThe public-use data contain a subset of records and variables from the restricted-use full data set. The full data set requires a lengthy application process and meeting specific security standards. [CSDE](https://csde.washington.edu/) has a copy of most of the tables in the restricted-use data set on the [UW Data Collaborative](https://dcollab.uw.edu/data/add-health/).\n\nWe will be using the Wave 1 public-use Add Health data for most of the remainder of the term. This week we will briefly delve into the documentation and see how the data set use is supported by the documentation.\n\n## Documentation\nThe Add Health data are very well documented. The PDFs contain the verbatim text of the survey questions, the range of encoded answers, and count tabulations of responses.\n\nSee the full set of metadata PDFs: [Wave1_InHome_Codebooks](data/metadata/Wave1_InHome_Codebooks/), and the [comprehensive codebook](data/metadata/Wave1_Comprehensive_Codebook/).\n\nWe will revisit the documentation later in this lesson.\n\n## Data sets\nThe two data sets we will be using are [AHwave1_v1.dta.zip](data/AHwave1_v1.dta.zip) and [21600-0001-Data.dta.zip](data/21600-0001-Data.dta.zip). Download each file and unzip them, which will result in `AHwave1_v1.dta`, which we have encountered before, and `21600-0001-Data.dta`.\n\nBoth of these are Stata files. Stata files version 12 and below can be read with `foreign::read.dta()`, but version 13 and up require `haven::read_dta()` or `readstata13::read.dta13()`.\n\nOne of the benefits of the Stata file formats, as compared to e.g., CSV or Excel, is that the Stata files can contain metadata about the variables. The imported data frames themselves may have cryptic variable names, but more extensive _labels_. The R import process can expose those labels, making the data more easy to interpret\n\n### `AHwave1_v1.dta`\n`AHwave1_v1.dta` is a Stata version 13 file. Here we will look at the two import options.\n\n#### `haven::read_dta()`\n`haven::read_dta()` will read the data in as a data frame. Note for the code examples to run without modification, the assumption is that the data have been downloaded and unzipped in a sub-folder named `data` within the current working directory. You can find out what the current working directory is by entering `getwd()` at the R prompt.\n\n```{r}\n# read the data\nif(!file.exists(\"data/AHwave1_v1.dta\")){\n    unzip(zipfile = \"data/AHwave1_v1.dta.zip\", exdir = \"data\")\n}\nAHwave1_v1_haven <- haven::read_dta(file = \"data/AHwave1_v1.dta\")\n```\n\nEach labeled variable has attributes can be perused by listing structure:\n\n```{r}\nstr(AHwave1_v1_haven$imonth)\n```\n\nor the first few values (`head()`):\n\n```{r}\nhead(AHwave1_v1_haven$bio_sex)\n```\n\nor listing the attributes of the variable itself, which provides a more verbose listing of the variable label, data format, class, and value labels:\n\n```{r}\nattributes(AHwave1_v1_haven$h1gi1m)\n```\n\n\nIn order to access the metadata as a single object, one can use the `lapply()` function, because the data frame can also be treated as a list. Here, each variable has its name, label, data format, and values extracted to a single data frame and presented as a `DT::datatable`. This provides the metadata in a format that is probably easier to use than the PDF documentation.\n\n```{r}\nAHwave1_v1_haven_metadata <- bind_cols(\n    # variable name\n    varname = colnames(AHwave1_v1_haven),\n    # label\n    varlabel = lapply(AHwave1_v1_haven, function(x) attributes(x)$label) %>% \n        unlist(),\n    # format\n    varformat = lapply(AHwave1_v1_haven, function(x) attributes(x)$format.stata) %>%\n        unlist(),\n    # values\n    varvalues = lapply(AHwave1_v1_haven, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(AHwave1_v1_haven_metadata)\n\n```\n\n#### `readstata13::read.dta13()`\n`readstata13::read.dta13()` will similarly read the data as a data frame. There are a number of different options for converting factors, so if you are dealing with a lot of Stata files you may want to become familiar with some of these options.\n\nFor example, using all default options kicks out some warnings about double precision coding and missing factor labels. _[Note: to hide these warnings, for better or worse (i.e., you might not want to hide them), use the code chunk option `warning=FALSE`]._\n\n```{r}\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\")\n```\n\n```{r}\n# read the data\nAHwave1_v1_rs13 <- readstata13::read.dta13(file = \"data/AHwave1_v1.dta\", generate.factors = TRUE, nonint.factors = TRUE)\n```\n\nMetadata can be generated similarly:\n\n```{r}\nAHwave1_v1_rs13_metadata <- bind_cols(\n    varname = colnames(AHwave1_v1_rs13),\n    varlabel = attributes(AHwave1_v1_rs13)$var.labels,\n    varformat = attributes(AHwave1_v1_rs13)$formats\n)\n\n# value ranges; need to do this separately because those variables with no value labels were not accounted for\nvarvalues <- bind_cols(\n    varname = names(attributes(AHwave1_v1_rs13)$label.table) %>% tolower,\n    vals = attributes(AHwave1_v1_rs13)$label.table %>% \n    lapply(., function(x) names(x)) %>% \n    as.character() %>% \n    str_remove_all(\"^c\\\\(|\\\\)$\"))\n\n# join\nAHwave1_v1_rs13_metadata %<>% \n    left_join(varvalues, by = \"varname\")\n\nDT::datatable(AHwave1_v1_rs13_metadata)\n```\n\nThe default conversion creates factors, so the tables _may_ be easy to read/interpret ...\n\n```{r}\nhead(x = AHwave1_v1_rs13$imonth, n = 6)\n```\n\n... but programming will require more work because the factors would either need to be explicitly named, e.g.,\n\n```{r}\nAHwave1_v1_rs13 %>% \n    head(10) %>% \n    filter(imonth == \"(6) June\") %>% \n    select(aid, imonth, iday)\n```\n\nBecause the factors are really just labelled numbers, one could use the numeric values, but care needs to be taken:\n\n```{r}\nlevels(AHwave1_v1_rs13$imonth) %>% t() %>% t()\n```\n\nBecause not all months are represented in the data, the numerical value of the month may not be what you expect. For example, the 4th month factor level is \"(6) June\" rather than \"(4) April\".\n\nCompare this with the results from `haven::read_dta()`. The values are not factors, but labelled double-precision numbers:\n\n```{r}\nhead(AHwave1_v1_haven$imonth)\n```\n\nTo perform a similar `filter()` & `select()` operation with the haven version:\n\n```{r}\nAHwave1_v1_haven %>% \n    head(10) %>% \n    filter(imonth == 6) %>% \n    select(aid, imonth, iday)\n```\n\n___Which approach do you prefer?___\n\n### `21600-0001-Data.dta`\n`21600-0001-Data.dta` is a much larger data set. It has the same count of records, but more columns than `AHwave1_v1.dta`.\n\n```{r}\n# read in the larger data set\nif(!file.exists(\"data/21600-0001-Data.dta\")){\n    unzip(zipfile = \"data/21600-0001-Data.dta.zip\", exdir = \"data\")\n}\ndata_21600_0001 <- haven::read_dta(file = \"data/21600-0001-Data.dta\")\n# if(file.exists(\"data/21600-0001-Data.dta\")){\n#     file.remove(file = \"data/21600-0001-Data.dta\")\n# }\n\n# dimensions of the two\ndim(AHwave1_v1_haven)\ndim(data_21600_0001)\n```\n\nIn fact, `AHwave1_v1.dta` seems to be a subset of `21600-0001-Data.dta`. We can show this by lower-casing the column names and then using a `select()` for the same named columns\n\n```{r}\n# lowercase the column names\ncolnames(data_21600_0001) %<>% str_to_lower()\n\n# select() some columns of the same name\ndat <- data_21600_0001 %>% \n    select(colnames(AHwave1_v1_haven))\n\n# identical?\nidentical(dat, AHwave1_v1_haven)\n# if(file.exists(\"data/AHwave1_v1.dta\")){\n#     file.remove(\"data/AHwave1_v1.dta\")\n# }\n```\n\nWe can build a similar table of metadata, but this time as a function:\n\n```{r}\n# a generic(?) function to generate metadata for a Stata file read by haven::read_dta()\n# x is a haven data frame\nf_haven_stata_metadata <- function(x){\n    # variable names\n    varname <- colnames(x)\n    # labels\n    varlabel <- x %>% \n        lapply(., function(x) attributes(x)$label) %>% \n        unlist()\n    # format\n    varformat <- x %>% \n        lapply(., function(x) attributes(x)$format.stata) %>%\n        unlist()\n    # values\n    varvalues <- x %>% \n        lapply(., function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")  \n    \n    bind_cols(varname = varname, \n              varlabel = varlabel, \n              varformat = varformat,\n              varvalues = varvalues)\n}\n\n# generate the metadata\ndata_21600_0001_metadata <- f_haven_stata_metadata(data_21600_0001)\n\n# print the metadata table as a DT::datatable\nDT::datatable(data_21600_0001_metadata)\n\n```\n\n## Searching through documentation\nGood data sets have good documentation. Sometimes the documentation is voluminous, as is the case for the Add Health data. With voluminous metadata, are there good approaches to finding what you are interested in without opening each PDF file, reading the table of contents, searching for string matches, etc.?\n\nThis section will cover two tools to make searching through PDF files less onerous and more efficient. The two utilities are `pdfgrep` and `pdftools::pdf_text()`\n\n### `pdfgrep`\n`grep` is a string-matching utility developed mainly for UNIX, now available for all common operating systems. It is also implemented in base R with the function `grep()`. The name comes from the ed command g/re/p ($\\underline{g}$lobally search for a $\\underline{r}$egular $\\underline{e}$xpression and $\\underline{p}$rint matching lines), typically used to print the line number of a text file containing the search pattern. \n\nIf you are not familiar with regular expressions and you plan on doing computational social sciences, the sooner you learn, the better. See the R help topic for `base::regex()`.\n\nWe won't be covering `grep` in general here, but will introduce some of the regular expression logic in `pdfgrep`. \n\nStart by installing a version of `pdfgrep`. These are three implementations, one for Mac and two for Windows. The demo today will use the Cygwin version. The native Windows version is not as powerful/customizable as the Cygwin version and will also likely be more comparable with the Mac version. ___Note:___ `pdfgrep` will only work on PDF files that contain text. PDFs that are composed solely from scanned images contain no text and are therefore not searchable using regular expressions.\n\n[pdfgrep for native Windows](https://soft.rubypdf.com/software/pdfgrep-windows-version)\n\n[pdfgrep for Cygwin under Windows](https://cygwin.com/cgi-bin2/package-cat.cgi?file=x86%2Fpdfgrep%2Fpdfgrep-1.4.1-1&grep=pdfgrep)\n\n[pdfgrep for Mac](http://macappstore.org/pdfgrep/)\n\nA zipped file containing all of the metadata files for the In Home Questionnaire is available as [Wave1_InHome_Codebooks.pdf.zip](data/metadata/Wave1_InHome_Codebooks/Wave1_InHome_Codebooks.pdf.zip). Download the file and unzip it in an appropriate location.\n\n#### A few use examples\n_[Note: the images below may be hard to read; clicking them will open them in full-size; click with the middle mouse button to open in a new tab.]_\n\nHere we will search through the entire set of PDF files for the regular expression `black`. First, let's list the PDF files using\n\n`\nls *.pdf\n`\n\n[![](images/week06/2021-02-11_21_31_11-_cygdrive_L.png)](images/week06/2021-02-11_21_31_11-_cygdrive_L.png)\n\n\nThe syntax for the search is \n\n`\npdfgrep black *.pdf\n`\n\n[![](images/week06/2021-02-11_21_45_41-_cygdrive_L.png)](images/week06/2021-02-11_21_45_41-_cygdrive_L.png)\n\nThis prints the file name and the matching text of each PDF containing the regular expression `black`. Suppose we wanted to search for `black` or `Black` or `BLACK`? Use the flag `-i` which is short for case $\\underline{i}$nsensitive.\n\n`\npdfgrep -i black *.pdf\n`\n\n[![](images/week06/2021-02-11_21_47_06-_cygdrive_L.png)](images/week06/2021-02-11_21_47_06-_cygdrive_L.png)\n\nThis shows all files that contain `black` in any case combination. \n\nWe might want to know where to look (i.e., page number) in the file. Using the `-n` flag prints the page $\\underline{n}$umber.\n\n[![](images/week06/2021-02-11_21_47_38-_cygdrive_L.png)](images/week06/2021-02-11_21_47_38-_cygdrive_L.png)\n\nSeeing that there are several matches in `inh25pub.pdf`, the first match on page 13, let's view that:\n\n[![](images/week06/2021-02-11_22_16_08-inh25pub.pdf.png)](images/week06/2021-02-11_22_16_08-inh25pub.pdf.png)\n\nLet's look for another pattern, the word `recreation`:\n\n`\npdfgrep -n -i recreation *.pdf\n`\n\n[![](images/week06/2021-02-11_21_48_14-_cygdrive_L.png)](images/week06/2021-02-11_21_48_14-_cygdrive_L.png)\n\nSeeing the matches, we might want to narrow the search to include only \"social or recreation\"al activity. Here, the regular expression is `social.*recreation`, where the `.*` regexp translates to \"any number of any characters.\"\n\n\n[![](images/week06/2021-02-11_21_48_34-_cygdrive_L.png)](images/week06/2021-02-11_21_48_34-_cygdrive_L.png)\n\n\nWe will perform one more pattern match. Suppose we were interested in being tired or stressed. The regexp pattern `\"pat1|pat2\"` (note the quotes and the vertical bar). The quotes indicate to the shell that [this is not a pipe](#magrittr), but part of the regexp.\n\nHere the full expression to show those metadata files that match either of these patterns.\n\n`\npdfgrep -i \"tired|stress\" *.pdf\n`\n\n[![](images/week06/2021-02-11_21_54_04-_cygdrive_L.png)](images/week06/2021-02-11_21_54_04-_cygdrive_L.png)\n\n___Why___, you may ask, if we created those fancy metadata tables from the data, would we want to search for specific strings in the PDF documentation? Because the full documentation is likely to provide more complete explanations, whereas the metadata created from the data labels is only a brief description.\n\n### `pdftools::pdf_text()`\nStaying completely within R, we can perform similar searches through PDF files. We start with `pdftools::pdf_text()`, which converts PDFs to text vectors, where each page is converted to one vector element. This can be piped through text-matching functions, such as `base::grep()` or `stringr::str_match()` (`stringr` is loaded by `tidyverse`).\n\nUnlike `pdfgrep`, which can serially search through a set of files in a directory, `pdf_text()` requires additional work. Here is an example that mimics searching for the case-insensitive regular expression `black` in the set of PDFs.\n\nWe create a function that searches through a single PDF and then loop the function over the set of PDFs in a specified folder, returning the file name list, the pattern we searched on, the page number with the match, and whether the search was case sensitive or not.\n\n```{r}\n# a function to get matching strings in a PDF, ignore case\nf_pdf_str_match <- function(x, pat, ignore.case = TRUE){\n    # convert the PDF to text\n    mytext <- pdf_text(x)\n    # pattern\n    if(ignore.case){\n        mypat <- regex(pat, ignore_case = TRUE)\n    } else {\n        mypat <- pat\n    }\n    # match strings = pages\n    pages <- str_which(string = mytext, pattern = mypat)\n    if(length(pages) == 0){\n        return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case))\n    }\n    # create a data frame\n    data.frame(fname = x, pat, page_num = pages, ignore.case)\n}\n\n# a list of my PDFs\nmypdfs <- list.files(path = \"data/metadata/Wave1_InHome_Codebooks\", pattern = \"*.pdf$\", full.names = TRUE)\n\n# an empty data frame\nx <- NULL\n\n# run each one\nfor(i in mypdfs){\n    x <- rbind(x, f_pdf_str_match(i, \"black\", ignore.case = TRUE))\n}\n\n# ignore NAs\nx %>% filter(!is.na(page_num))\n\n```\n\n## Conclusion\nWe will use these data sets and metadata for the next several lessons. The methods presented in today's lesson should increase efficiency and reduce busy-work.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[06-week06.Rmd](06-week06.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"06-week06.Rmd\"), sep = '\\n')\n```"},{"path":"week7.html","id":"week7","chapter":"7 Week 7","heading":"7 Week 7","text":"week’s lesson provide background variable creation tabulation variables.","code":""},{"path":"week7.html","id":"creating-value-labels","chapter":"7 Week 7","heading":"7.1 Creating value labels","text":"“Labeled” data important documentation data sets. labels can apply different objects, e.g., columns (saw column labels used “decode” data set AHwave1_v1.dta, Section 1.6), individual values variables, e.g., attribute labels variable h1gi1m:Consider difference different file formats. save data set, CSV file RDS file:read back investigate structure. using temporary folder, specified using tmpdir() function. time R session started, unique temporary folder used. session temporary dir C:\\7. First, read CSV format:kind object ?simple data frame. attributes data set ? list attributes enumerate first 6 elements attributeThere three attributes, names, individual column names; class, indicating data frame, row.names, case serial number 1 .. n.columns attributes?, columns attributes.Now read RDS file:kind object ?data frame–example tidyr subclass tibble; see documentationWhat attributes data set ?overall attributes similar basic data frame, overall data set label, National Longitudinal Study Adolescent Adult Health (Add Health), 1994-200 (sic).can also look attributes specific columns:see original column attributes preserved data set saved RDS format.Importantly, saving data set CSV format loses built-metadata, whereas saving RDS format maintains built-metadata. plain text formats, metadata maintained; formats, worth determining whether metadata maintained. metadata maintained file structure data set, important maintain metadata external format (e.g., text, PDF).","code":"\nAHwave1_v1_haven <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\nattributes(AHwave1_v1_haven$h1gi1m)$labels##   (1) January  (2) February     (3) March     (4) April       (5) May \n##             1             2             3             4             5 \n##      (6) June      (7) July    (8) August (9) September  (10) October \n##             6             7             8             9            10 \n## (11) November (12) December  (96) Refused \n##            11            12            96\n# temp dir\nmytempdir <- tempdir()\n\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"), row.names = FALSE)\nsaveRDS(object = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\nAHwave1_v1_haven_csv <- read.csv(file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"))\nis(AHwave1_v1_haven_csv)## [1] \"data.frame\" \"list\"       \"oldClass\"   \"vector\"\nAHwave1_v1_haven_csv %>% \n    attributes() %>% \n    map(~ head(.))## $names\n## [1] \"aid\"     \"imonth\"  \"iday\"    \"iyear\"   \"bio_sex\" \"h1gi1m\" \n## \n## $class\n## [1] \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\nAHwave1_v1_haven_csv$h1gi1m %>% \n    attributes() ## NULL\nAHwave1_v1_haven_rds <- readRDS(file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\nis(AHwave1_v1_haven_rds)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\" \"list\"       \"oldClass\"  \n## [6] \"vector\"\nAHwave1_v1_haven_rds %>% \n    attributes() %>% \n    map(~ head(.))## $class\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\n## \n## $label\n## [1] \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-200\"\n## \n## $names\n## [1] \"aid\"     \"imonth\"  \"iday\"    \"iyear\"   \"bio_sex\" \"h1gi1m\"\nAHwave1_v1_haven_rds$h1gi1m %>% \n    attributes()## $label\n## [1] \"S1Q1 BIRTH MONTH-W1\"\n## \n## $format.stata\n## [1] \"%13.0f\"\n## \n## $class\n## [1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n## \n## $labels\n##   (1) January  (2) February     (3) March     (4) April       (5) May \n##             1             2             3             4             5 \n##      (6) June      (7) July    (8) August (9) September  (10) October \n##             6             7             8             9            10 \n## (11) November (12) December  (96) Refused \n##            11            12            96"},{"path":"week7.html","id":"creating-factor-variables","chapter":"7 Week 7","heading":"7.1.1 Creating factor variables","text":"Factor variables used R store categorical variables. categorical variables can nominal, value distinct ordered, race, classified asWhiteBlack/African AmericanAmerican IndianAsian/Pacific IslanderotherFactor variables can ordered, difference amount intensity, self-reported health status:ExcellentVery goodGoodFairPoorOrdinal variables may may equal intervals; example, “distance” excellent good health may represent “distance” difference good fair health.Structurally, factor variables stored integers can linked text labels. Operationally, use factor variables important statistical modeling, variables handled correctly categorical.Factor variables created using factor() as_factor() functions. convert self-reported general health variable (h1gh1) factor. First, let’s look variable:shows values 1 6 8, coding indicated labels attribute. Using head() also reveals structure variable, including label variable well coding variable values:convert variable factor:result? can see first values; head() presents values well levels.Although levels numerical order, meaningful labels. use labels = argument assign labels level. Simultaneously, factor ordered order alphanumeric ordering attributes, can set ordering based attributes. Finally, reverse order levels better health higher position order.[Note ordering alphanumeric, one enter list values ... labels = c(\"label1\", \"label2, ..., \"labeln\"), ordered = TRUE ... enforce correct ordering.]Let’s compare two variables simple tabulation. “raw” variable:“raw” variable shows labeled, double precision variable (<dbl+lbl>).Now factor variable:counts , factor variable, <ord> additionally indicates ordering health levels. Note order different (1) Excellent highest numerical value.Bar plots also show difference raw factor variables. bar plot raw variable.numerical values special meaning, bar plot uses default method displaying axes. bar plot created factor variable, shows informative labels correct position axes.One potential sides using factor variables using text values requires additional code. example, select (filter()) subset records, two methods. first method uses label. case factor ordered, possible use ordinal comparison.method use as_numeric() specify underlying numerical values. case, value 2 indicated good, can filter health %>% .numeric() <= 2.Using unordered factor variables shows coding involved specifying values filter() statements. example, let’s create factor variable interviewer’s observed single race variable:Suppose wanted make subset White Black records, syntax methods:, value explicitly named, using | “” operatorA different approach uses str_detect() regular expression match values obsrace contain strings white black upper/lower case combination.Finally, know numeric values representing factors, can use directly:first method verbose, requires code, probably easiest read. two methods may easier code (.e., fewer keystrokes), seem difficult interpret., care needs taken saving data set file. factor text labels, written output CSV file. read back , treated character values rather factors. example, health variable created ordered factor:cycled write/read CSV cycle, variable maintained factor.Additional work needed re-establish factor. Fortunately, alphanumeric sorting order character strings logical order; without numeric values, ordering need explicitly set. example, vector desired sorting order \"Excellent\", \"good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"know\" sorts know, Excellent, Fair, Good, Poor, Refused, good), proper sorting order.save data set RDS, factor structures maintained.","code":"\nAHwave1_v1_haven$h1gh1 %>% \n    attributes()## $label\n## [1] \"S3Q1 GENERAL HEALTH-W1\"\n## \n## $format.stata\n## [1] \"%14.0f\"\n## \n## $class\n## [1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n## \n## $labels\n##  (1) Excellent  (2) Very good       (3) Good       (4) Fair       (5) Poor \n##              1              2              3              4              5 \n##    (6) Refused (8) Don't know \n##              6              8\nhead(AHwave1_v1_haven$h1gh1)## <labelled<double>[6]>: S3Q1 GENERAL HEALTH-W1\n## [1] 3 4 4 4 3 3\n## \n## Labels:\n##  value          label\n##      1  (1) Excellent\n##      2  (2) Very good\n##      3       (3) Good\n##      4       (4) Fair\n##      5       (5) Poor\n##      6    (6) Refused\n##      8 (8) Don't know\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1)\n# look at the first few values of the factor variable\nhead(AHwave1_v1_haven$health)## [1] 3 4 4 4 3 3\n## Levels: 1 2 3 4 5 6 8\n# extract the labels from the column attribute\nhealth_levels <- AHwave1_v1_haven$h1gh1 %>% \n    attributes() %>% \n    extract2(\"labels\") %>% \n    names()\n\n# create the factor variable\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1, \n                                  labels = health_levels, \n                                  ordered = TRUE) %>% \n    fct_relevel(rev)\n# \"raw\" variable\n(tab_h1gh1 <- AHwave1_v1_haven %>% \n     group_by(h1gh1) %>% \n     summarise(n = n()))## # A tibble: 7 x 2\n##                h1gh1     n\n##            <dbl+lbl> <int>\n## 1 1 [(1) Excellent]   1847\n## 2 2 [(2) Very good]   2608\n## 3 3 [(3) Good]        1605\n## 4 4 [(4) Fair]         408\n## 5 5 [(5) Poor]          28\n## 6 6 [(6) Refused]        3\n## 7 8 [(8) Don't know]     5\n# factor variable\n(tab_health <- AHwave1_v1_haven %>% \n     group_by(health) %>% \n     summarise(n = n()))## # A tibble: 7 x 2\n##   health             n\n##   <ord>          <int>\n## 1 (8) Don't know     5\n## 2 (6) Refused        3\n## 3 (5) Poor          28\n## 4 (4) Fair         408\n## 5 (3) Good        1605\n## 6 (2) Very good   2608\n## 7 (1) Excellent   1847\nggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) +\n    geom_bar(stat = \"identity\") + \n    coord_flip()\nggplot(data = tab_health, mapping = aes(x = health, y = n)) +\n    geom_bar(stat = \"identity\") + \n    coord_flip()\n# filter for Excellent or Very good\ny <- AHwave1_v1_haven %>% \n    filter (health <= \"(2) Very good\")\n\n# tabulate\ntable(y$health)## \n## (8) Don't know    (6) Refused       (5) Poor       (4) Fair       (3) Good \n##              5              3             28            408           1605 \n##  (2) Very good  (1) Excellent \n##           2608              0\nx <- AHwave1_v1_haven %>% \n    filter(health %>% as.numeric() <= 2)\n# number of labels\nnlabs <- length(unique(AHwave1_v1_haven$h1gi9))\n# get the values, \"as.numeric()\"\nobsrace_values <- AHwave1_v1_haven$h1gi9 %>% \n    attributes() %>% \n    extract2(\"labels\") %>% \n    as.numeric()\n\n# get the labels, names()\nobsrace_labels <- AHwave1_v1_haven$h1gi9 %>% \n    attributes() %>% \n    extract2(\"labels\") %>% \n    names() \n\n# create the factor\nAHwave1_v1_haven$obsrace <- factor(AHwave1_v1_haven$h1gi9, \n                                   levels = obsrace_values, \n                                   labels = obsrace_labels)\ndat_wb1 <- AHwave1_v1_haven %>% \n    filter(obsrace == \"(1) White\" |\n           obsrace == \"(2) Black/African American\")\n\ntable(dat_wb1$obsrace)## \n##                           (1) White          (2) Black/African American \n##                                4291                                1601 \n## (3) American Indian/Native American          (4) Asian/Pacific Islander \n##                                   0                                   0 \n##                           (5) Other                         (6) Refused \n##                                   0                                   0 \n##                      (8) Don't know                  (9) Not applicable \n##                                   0                                   0\ndat_wb2 <- AHwave1_v1_haven %>% \n    filter(str_detect(obsrace, regex(\"white|black\", ignore_case = TRUE)))\n\ntable(dat_wb2$obsrace)## \n##                           (1) White          (2) Black/African American \n##                                4291                                1601 \n## (3) American Indian/Native American          (4) Asian/Pacific Islander \n##                                   0                                   0 \n##                           (5) Other                         (6) Refused \n##                                   0                                   0 \n##                      (8) Don't know                  (9) Not applicable \n##                                   0                                   0\ndat_wb3 <- AHwave1_v1_haven %>% \n    filter(obsrace %>% as.numeric() %in% c(1, 2))\n\ntable(dat_wb3$obsrace)## \n##                           (1) White          (2) Black/African American \n##                                4291                                1601 \n## (3) American Indian/Native American          (4) Asian/Pacific Islander \n##                                   0                                   0 \n##                           (5) Other                         (6) Refused \n##                                   0                                   0 \n##                      (8) Don't know                  (9) Not applicable \n##                                   0                                   0\nhead(AHwave1_v1_haven$health)## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good\n## 7 Levels: (8) Don't know < (6) Refused < (5) Poor < (4) Fair < ... < (1) Excellent\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.csv\"), row.names = FALSE)\n\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\nhead(y$health)## [1] \"(3) Good\" \"(4) Fair\" \"(4) Fair\" \"(4) Fair\" \"(3) Good\" \"(3) Good\"\ny$health <- factor(y$health,\n                   labels = y$health %>% unique() %>% sort(),\n                   ordered = TRUE)\nhead(y$health)## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good\n## 7 Levels: (1) Excellent < (2) Very good < (3) Good < (4) Fair < ... < (8) Don't know\nwrite_rds(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.Rds\"))\n\nz <- readRDS(file = file.path(mytempdir, \"foo.Rds\"))\n\nhead(z$health)## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good\n## 7 Levels: (8) Don't know < (6) Refused < (5) Poor < (4) Fair < ... < (1) Excellent"},{"path":"week7.html","id":"creating-attributes","chapter":"7 Week 7","heading":"7.1.2 Creating attributes","text":"addition creating factors, can serve capacity self-documenting (.e., value labels least somewhat self-explanatory), can create attributes seen Stata .dta files.Let’s start CSV file, know stripped descriptive attributes:First, attribute data frame :… can verify:Next, attributes health obsrace variables, documenting variables values:Verify created:caveats apply saving data frame files.","code":"\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\ny %>% attributes() %>% map(~ head(.))## $names\n## [1] \"aid\"     \"imonth\"  \"iday\"    \"iyear\"   \"bio_sex\" \"h1gi1m\" \n## \n## $class\n## [1] \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\nattributes(y)$label <- \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\ny %>% attributes() %>% extract(\"label\")## $label\n## [1] \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\n# label for health\nattributes(y$health)$label <- \"General health from public Add Health Wave 1 Section 3 question 1\"\n# values for health\nattributes(y$health)$levels <- c(\"(1) Excellent\", \"(2) Very good\", \"(3) Good\", \"(4) Fair\", \"(5) Poor\", \"(6) Refused\", \"(8) Don't know\")\n\n# label for obsrace\nattributes(y$obsrace)$label <- \"Interviewer observation of race from public Add Health Wave 1 Section 1 question 9\"\n# values  for obsrace\nattributes(y$obsrace)$levels <- c(\"(1) White\", \"(2) Black/African American\", \"(3) American Indian/Native American\", \"(4) Asian/Pacific Islander\", \"(5) Other\", \"(6) Refused\", \"(8) Don't know\", \"(9) Not applicable\")\ny$health %>% attributes()## $label\n## [1] \"General health from public Add Health Wave 1 Section 3 question 1\"\n## \n## $levels\n## [1] \"(1) Excellent\"  \"(2) Very good\"  \"(3) Good\"       \"(4) Fair\"      \n## [5] \"(5) Poor\"       \"(6) Refused\"    \"(8) Don't know\"\ny$obsrace %>% attributes()## $label\n## [1] \"Interviewer observation of race from public Add Health Wave 1 Section 1 question 9\"\n## \n## $levels\n## [1] \"(1) White\"                           \"(2) Black/African American\"         \n## [3] \"(3) American Indian/Native American\" \"(4) Asian/Pacific Islander\"         \n## [5] \"(5) Other\"                           \"(6) Refused\"                        \n## [7] \"(8) Don't know\"                      \"(9) Not applicable\""},{"path":"week7.html","id":"tabulation","chapter":"7 Week 7","heading":"7.2 Tabulation","text":"seen examples tabulation previous exercises (Sections 1.6.2.5, 2.2.3, 4.2.1.2.1). section give complete treatment using Add Health data example.","code":""},{"path":"week7.html","id":"raw-counts","chapter":"7 Week 7","heading":"7.2.1 Raw counts","text":"basic tabulations simply give count observations different strata. strata can based numeric ratio interval data, using functions cut() BAMMtools::getJenksBreaks(), nominal data (Add Health interviewer’s observation respondents’ single race), ordinal data (self-reported health status). use examples type data.First, code load full Add Health data set, includes additional variables present data set used previously.Present metadata (variable names labels): \nLet’s look body mass index (BMI) data, uses weight height values. find variables representing weight height metadata . need determine invalid values:First, need select variables representing feet inches, filter invalid heights (> 90) weights (> 900) identified , finally calculate height m, weight kg, BMI (\\(\\frac{weight\\_{kg}}{{height\\_m}^2}\\)). future use also select self-reported health interviewer observed race factors.histogram shows distribution BMI respondents vertical lines 5th 85th percentile. range generally considered “normal” “healthy” according CDC, although sample varying age, sex, height, weight ranges, difficult interpret. Nevertheless cut points can serve purpose demonstration.assign BMI class using cut points, cut() breaks minimum, 5%, 85%, maximum BMI, also assign labels set ordering:tabulation count respondents weight class can generated base R function table() dplyr functions group_by() summarise().variables already nominal ordinal factors, tabulations can made directly. converted factors, correct labels show, rather simple numeric values.Excellent\ngood\nGood\nFair\nPoor\nDon’t know\nWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nRefused\nDon’t know\n","code":"\n# download and unzip the larger data set\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n# zip file in $temp\nzipfile <- file.path(mytempdir, basename(myUrl))\n# dta file in $temp\ndtafile <- tools::file_path_sans_ext(zipfile)\n# check if the dta file exists\nif(!file.exists(dtafile)){\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if(!file.exists(zipfile)){\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    unzip(zipfile = zipfile, exdir = mytempdir)\n}\n\n# if the data set has not been read, read it in \nif(!exists(\"ahcomplete\")){\n    ahcomplete <- haven::read_dta(dtafile)\n}\n# lowercase column names\ncolnames(ahcomplete) %<>% str_to_lower()\nahcomplete_metadata <- bind_cols(\n    varname = colnames(ahcomplete),\n    varlabel = ahcomplete %>% map(~ attributes(.)$label) %>% unlist()\n)\n\nDT::datatable(ahcomplete_metadata)\nattributes(ahcomplete$h1gh59a)$labels##      (4) 4 feet      (5) 5 feet      (6) 6 feet    (96) Refused (98) Don't know \n##               4               5               6              96              98\nattributes(ahcomplete$h1gh59b)$labels##        (0) 0 inches          (1) 1 inch        (2) 2 inches        (3) 3 inches \n##                   0                   1                   2                   3 \n##        (4) 4 inches        (5) 5 inches        (6) 6 inches        (7) 7 inches \n##                   4                   5                   6                   7 \n##        (8) 8 inches        (9) 9 inches      (10) 10 inches      (11) 11 inches \n##                   8                   9                  10                  11 \n##        (96) Refused     (98) Don't know (99) Not applicable \n##                  96                  98                  99\nattributes(ahcomplete$h1gh60)$labels##        (996) Refused     (998) Don't know (999) Not applicable \n##                  996                  998                  999\n# make the data frame\nhtwt <- ahcomplete %>% \n    # select columns\n    select(feet = h1gh59a,\n           inches = h1gh59b,\n           weight_lb = h1gh60,\n           health = h1gh1,\n           obsrace = h1gi9) %>% \n    # filter for valid values\n    filter(feet < 90 & inches < 90 & weight_lb < 900) %>% \n    # calculate \n    mutate(height_m = (feet * 12 + inches) / 39.37008,\n           weight_kg = weight_lb / 2.205,\n           BMI = weight_kg / height_m^2)\n\n# factor: get values and labels\nhealthvals <- htwt$health %>% attributes() %>% extract2(\"labels\") %>% as.numeric()\nhealthlabs <- htwt$health %>% attributes() %>% extract2(\"labels\") %>% names()\n\nracevals <- htwt$obsrace %>% attributes() %>% extract2(\"labels\") %>% as.numeric()\nracelabs <- htwt$obsrace %>% attributes() %>% extract2(\"labels\") %>% names()\n\nhtwt %<>% \n    mutate(health = factor(health,\n                           levels = healthvals,\n                           labels = healthlabs),\n           obsrace = factor(obsrace,\n                           levels = racevals,\n                           labels = racelabs))\n# get the 5th & 85th percentile\nbmibreaks <- quantile(x = htwt$BMI, probs = c(0.05, 0.85))\nggplot(htwt, aes(x = BMI)) +\n    geom_histogram(bins = 30) +\n    geom_vline(xintercept = bmibreaks)\nhtwt %<>% \n    mutate(bmiclass = cut(x = BMI, \n                          breaks = c(min(BMI), bmibreaks, max(BMI)), \n                          labels = c(\"underweight\", \"normal\", \"overweight\"),\n                          include.lowest = TRUE) %>% \n               factor(ordered = TRUE))\n# base R\ntable(htwt$bmiclass, useNA = \"ifany\")## \n## underweight      normal  overweight \n##         324        5023         944\n# tidyR\nhtwt %>% \n    group_by(bmiclass) %>% \n    summarise(n = n()) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\nhtwt %>% \n    group_by(health) %>% \n    summarise(n = n()) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\nhtwt %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")"},{"path":"week7.html","id":"proportionspercentages","chapter":"7 Week 7","heading":"7.2.2 Proportions/percentages","text":"Proportions percentages can added tabulations greater interpretability. Using base R, prop_table() function can used wrapper around table() generate proportions, optionally multiplying 100 generate percentage. Remember round needed. example:surprisingly, BMI classes show 5% underweight 15% overweight, stratification defined.tidyR version requires bit coding provides readable output. percent sign special character, enclose back ticks, %. generate tabulation observed race.White\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nRefused\nDon’t know\n","code":"\nround(prop.table(table(htwt$bmiclass)), 2)## \n## underweight      normal  overweight \n##        0.05        0.80        0.15\nround(prop.table(table(htwt$bmiclass)) * 100, 0)## \n## underweight      normal  overweight \n##           5          80          15\nhtwt %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    mutate(`%` = `%` %>% round(1)) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")"},{"path":"week7.html","id":"stratified-tabulation","chapter":"7 Week 7","heading":"7.2.3 Stratified tabulation","text":"Tabulations can generated using multiple variables. examine BMI race well BMI health. percentages sum 100 based order grouping., see relative percent underweight, normal, overweight within race class:White\nWhite\nWhite\nBlack/African American\nBlack/African American\nBlack/African American\nAmerican Indian/Native American\nAmerican Indian/Native American\nAmerican Indian/Native American\nAsian/Pacific Islander\nAsian/Pacific Islander\nAsian/Pacific Islander\n\n\n\nRefused\nDon’t know\nsee relative percent different race groups within BMI class.White\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nRefused\nDon’t know\nWhite\nBlack/African American\nAmerican Indian/Native American\nAsian/Pacific Islander\n\nEven though n values two tables (e.g., underweight White n = 234), percentages different due grouping. , percent underweight persons among White race stratum different percent White persons within underweight stratum. Proper grouping critical answer specific questions data.Another way understand data, preferred , make graph. example, BMI race:Rendered 2022-01-08 18:00:1207-week07.Rmd","code":"\nhtwt %>% \n    group_by(obsrace,\n             bmiclass) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    mutate(`%` = `%` %>% round(1)) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\nhtwt %>% \n    group_by(bmiclass,\n             obsrace) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    mutate(`%` = `%` %>% round(1)) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\nbmi_race <- htwt %>% \n    group_by(obsrace,\n             bmiclass) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    filter(!str_detect(obsrace, regex(\"refused|know\", ignore_case = TRUE)))\n\nggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n    facet_grid(~obsrace)\nggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\ncat(readLines(con = \"07-week07.Rmd\"), sep = '\\n')# Week 7 {#week7}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(readstata13)\nlibrary(haven)\nlibrary(pdftools)\nlibrary(curl)\nlibrary(ggplot2)\n```\n\n<h2>Topic: Add Health data: variable creation and tabulation<\/h2>\nThis week's lesson will provide more background on variable creation and tabulation of variables.\n\n## Creating value labels\n\"Labeled\" data are important for documentation of data sets. The labels can apply to different objects, e.g., columns (as we saw in the column labels used to \"decode\" the data set in `AHwave1_v1.dta`, Section \\@ref(tidyverse)), or to individual values of variables, e.g., the attribute `labels` of the variable `h1gi1m`:\n\n```{r}\nAHwave1_v1_haven <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\nattributes(AHwave1_v1_haven$h1gi1m)$labels\n```\n\nConsider the difference between different file formats. Here we will save the data set, once as a CSV file and once an RDS file:\n\n```{r}\n# temp dir\nmytempdir <- tempdir()\n\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"), row.names = FALSE)\nsaveRDS(object = AHwave1_v1_haven, file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\n```\n\nThen we will read them back in and investigate their structure. Here we are using a temporary folder, specified using the `tmpdir()` function. Each time an R session is started, a unique temporary folder is used. For this session the temporary dir is `r mytempdir`. First, read the CSV format:\n\n```{r}\nAHwave1_v1_haven_csv <- read.csv(file = file.path(mytempdir, \"AHwave1_v1_haven.csv\"))\n```\n\nWhat kind of object is this?\n\n```{r}\nis(AHwave1_v1_haven_csv)\n```\n\nIt is a simple data frame. What attributes does this data set have? Here we list the attributes and enumerate the first 6 elements of each attribute\n\n```{r}\nAHwave1_v1_haven_csv %>% \n    attributes() %>% \n    map(~ head(.))\n```\n\nThere are three attributes, `names`, which are the individual column names; `class`, indicating this is a data frame, and `row.names`, in this case a serial number 1 .. n.\n\nDo the columns have any attributes?\n\n```{r}\nAHwave1_v1_haven_csv$h1gi1m %>% \n    attributes() \n```\n\nNo, the columns have no attributes.\n\nNow we will read in the RDS file:\n\n```{r}\nAHwave1_v1_haven_rds <- readRDS(file = file.path(mytempdir, \"AHwave1_v1_haven.RDS\"))\n```\n\nWhat kind of object is this?\n\n```{r}\nis(AHwave1_v1_haven_rds)\n```\n\nIt is a data frame--but an example of the `tidyr` subclass `tibble`; see the [documentation](https://www.rdocumentation.org/packages/tibble) \n\nWhat attributes does this data set have?\n\n```{r}\nAHwave1_v1_haven_rds %>% \n    attributes() %>% \n    map(~ head(.))\n```\n\nThe overall attributes are similar to the basic data frame, but there is an overall data set label, ``r AHwave1_v1_haven_rds %>% attributes() %>% extract(\"label\")`` (_sic_).\n\nWe can also look at the attributes of specific columns:\n\n```{r}\nAHwave1_v1_haven_rds$h1gi1m %>% \n    attributes()\n```\n\nHere we see that all of the original column attributes were preserved when the data set was saved in RDS format.\n\n__Importantly__, saving a data set in CSV format loses any built-in metadata, whereas saving in RDS format maintains the built-in metadata. For other plain text formats, metadata will not be maintained; for other formats, it is worth determining whether such metadata are maintained. If metadata are not maintained in the file structure of the data set, it will be important to maintain the metadata in an external format (e.g., text, PDF).\n\n### Creating factor variables\nFactor variables are used in R to store categorical variables. These categorical variables can be nominal, in which each value is distinct and not ordered, such as race, classified as \n\n* White\n* Black/African American\n* American Indian\n* Asian/Pacific Islander\n* other\n\nFactor variables can be ordered, where there is a difference in amount or intensity, such as self-reported health status:\n\n1. Excellent\n1. Very good\n1. Good\n1. Fair\n1. Poor\n\nOrdinal variables may or may not have equal intervals; for example, the \"distance\" between excellent and good health may not represent the same \"distance\" as the difference between good and fair health.\n\nStructurally, factor variables are stored as integers that can be linked to text labels. Operationally, __the use of factor variables is important in statistical modeling, so that the variables are handled correctly as being categorical__.\n\nFactor variables are created using the `factor()` or `as_factor()` functions. Here we will convert the self-reported general health variable (`h1gh1`) to a factor. First, let's look at the variable:\n\n```{r}\nAHwave1_v1_haven$h1gh1 %>% \n    attributes()\n```\n\nThis shows that there are values 1 through 6 and 8, with coding indicated in the `labels` attribute. Using `head()` also reveals the structure of the variable, including the label for the variable itself as well as the coding of the variable values:\n\n```{r}\nhead(AHwave1_v1_haven$h1gh1)\n```\n\n\nHere we convert the variable to a factor:\n\n```{r}\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1)\n```\n\nWhat is the result? We can see from the first few values; `head()` presents the values as well as the levels.\n\n```{r}\n# look at the first few values of the factor variable\nhead(AHwave1_v1_haven$health)\n```\n\nAlthough the levels are in numerical order, there are no meaningful labels. We use the `labels = ` argument to assign labels to each level. Simultaneously, because the factor is ordered in the same order as the alphanumeric ordering of the attributes, we can set the ordering based on those attributes. Finally, we reverse the order of the levels so that better health has a higher position in the order.\n\n```{r}\n# extract the labels from the column attribute\nhealth_levels <- AHwave1_v1_haven$h1gh1 %>% \n    attributes() %>% \n    extract2(\"labels\") %>% \n    names()\n\n# create the factor variable\nAHwave1_v1_haven$health <- factor(AHwave1_v1_haven$h1gh1, \n                                  labels = health_levels, \n                                  ordered = TRUE) %>% \n    fct_relevel(rev)\n```\n\n_[Note that if the ordering is not alphanumeric, one should enter the list of values as `... labels = c(\"label1\", \"label2, ..., \"labeln\"), ordered = TRUE ...` to enforce correct ordering.]_\n\nLet's compare the two variables through simple tabulation. Here is the \"raw\" variable:\n\n```{r}\n# \"raw\" variable\n(tab_h1gh1 <- AHwave1_v1_haven %>% \n     group_by(h1gh1) %>% \n     summarise(n = n()))\n```\n\nThe \"raw\" variable shows that it is a labeled, double precision variable (`<dbl+lbl>`). \n\nNow the factor variable:\n\n```{r}\n# factor variable\n(tab_health <- AHwave1_v1_haven %>% \n     group_by(health) %>% \n     summarise(n = n()))\n```\n\nThe counts are the same, but for the factor variable, the `<ord>` additionally indicates the ordering of health levels. Note that the order is different because `(1) Excellent` should have the highest numerical value.\n\nBar plots also show the difference between the raw and factor variables. Here is a bar plot from the raw variable. \n\n```{r, warning=FALSE, message=FALSE}\nggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) +\n    geom_bar(stat = \"identity\") + \n    coord_flip()\n```\n\nBecause the numerical values have no special meaning, the bar plot uses its default method of displaying the axes. Here is the bar plot created with the factor variable, which shows informative labels at the correct position on the axes.\n\n```{r}\nggplot(data = tab_health, mapping = aes(x = health, y = n)) +\n    geom_bar(stat = \"identity\") + \n    coord_flip()\n```\n\nOne of the potential down sides to using factor variables is that using the text values requires additional code. For example, to select (`filter()`) a subset of records, there are two methods. The first method uses the label. In this case because the factor is ordered, it is possible to use an ordinal comparison.\n\n```{r}\n# filter for Excellent or Very good\ny <- AHwave1_v1_haven %>% \n    filter (health <= \"(2) Very good\")\n\n# tabulate\ntable(y$health)\n```\n\nThe other method is to use `as_numeric()` to specify the underlying numerical values. In this case, because the value of 2 indicated `Very good`, we can filter for `health %>% as.numeric() <= 2`.  \n\n```{r}\nx <- AHwave1_v1_haven %>% \n    filter(health %>% as.numeric() <= 2)\n```\n\nUsing unordered factor variables shows that more coding is involved in specifying values in `filter()` statements. For example, let's create a factor variable for the interviewer's observed single race variable:\n\n```{r}\n# number of labels\nnlabs <- length(unique(AHwave1_v1_haven$h1gi9))\n# get the values, \"as.numeric()\"\nobsrace_values <- AHwave1_v1_haven$h1gi9 %>% \n    attributes() %>% \n    extract2(\"labels\") %>% \n    as.numeric()\n\n# get the labels, names()\nobsrace_labels <- AHwave1_v1_haven$h1gi9 %>% \n    attributes() %>% \n    extract2(\"labels\") %>% \n    names() \n\n# create the factor\nAHwave1_v1_haven$obsrace <- factor(AHwave1_v1_haven$h1gi9, \n                                   levels = obsrace_values, \n                                   labels = obsrace_labels)\n```\n\nSuppose we wanted to make a subset of only White and Black records, there are a few syntax methods:\n\nHere, each value is explicitly named, using the `|` \"or\" operator \n\n```{r}\ndat_wb1 <- AHwave1_v1_haven %>% \n    filter(obsrace == \"(1) White\" |\n           obsrace == \"(2) Black/African American\")\n\ntable(dat_wb1$obsrace)\n```\n\nA different approach uses `str_detect()` with a regular expression to match any values of `obsrace` that contain the strings `white` or `black` in any upper/lower case combination.\n\n```{r}\ndat_wb2 <- AHwave1_v1_haven %>% \n    filter(str_detect(obsrace, regex(\"white|black\", ignore_case = TRUE)))\n\ntable(dat_wb2$obsrace)\n```\n\nFinally, if we know the numeric values representing the factors, we can use those directly:\n\n```{r}\ndat_wb3 <- AHwave1_v1_haven %>% \n    filter(obsrace %>% as.numeric() %in% c(1, 2))\n\ntable(dat_wb3$obsrace)\n```\n\nThe first method is the most verbose, requires the most code, and is probably the easiest to read. The other two methods may be easier to code (i.e., fewer keystrokes), but seem to be more difficult to interpret.\n\nAs above, care needs to be taken in saving the data set to a file. If the factor has text labels, those will be written to an output CSV file. When they are read back in, they will be treated as character values rather than factors. For example, the `health` variable we created is an ordered factor:\n\n```{r}\nhead(AHwave1_v1_haven$health)\n```\n\nBut when cycled through a write/read CSV cycle, the variable is not maintained as a factor.\n\n```{r}\nwrite.csv(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.csv\"), row.names = FALSE)\n\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\nhead(y$health)\n```\n\nAdditional work would be needed to re-establish it as a factor. Fortunately, the alphanumeric sorting order of the character strings is the logical order; without the numeric values, the ordering would need to be explicitly set. For example, the vector in desired sorting order `\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\"` sorts as ``r c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\", \"Refused\", \"Don't know\") %>% sort()``), which is not the proper sorting order.\n\n```{r}\ny$health <- factor(y$health,\n                   labels = y$health %>% unique() %>% sort(),\n                   ordered = TRUE)\nhead(y$health)\n```\n\nIf you save the data set as RDS, the factor and other structures are maintained.\n\n```{r}\nwrite_rds(x = AHwave1_v1_haven, file = file.path(mytempdir, \"foo.Rds\"))\n\nz <- readRDS(file = file.path(mytempdir, \"foo.Rds\"))\n\nhead(z$health)\n```\n\n### Creating attributes\nIn addition to creating factors, which can serve in some capacity as self-documenting (i.e., the value labels should be at least somewhat self-explanatory), we can create attributes as we have seen with the Stata `.dta` files.\n\nLet's start with the CSV file, which we know was stripped of its descriptive attributes:\n\n```{r}\ny <- read.csv(file.path(mytempdir, \"foo.csv\"))\n\ny %>% attributes() %>% map(~ head(.))\n```\n\nFirst, an attribute of the data frame itself:\n\n```{r}\nattributes(y)$label <- \"National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions\"\n```\n\n... which we can verify:\n\n```{r}\ny %>% attributes() %>% extract(\"label\")\n```\n\nNext, attributes for the `health` and `obsrace` variables, documenting the variables and values:\n\n```{r}\n# label for health\nattributes(y$health)$label <- \"General health from public Add Health Wave 1 Section 3 question 1\"\n# values for health\nattributes(y$health)$levels <- c(\"(1) Excellent\", \"(2) Very good\", \"(3) Good\", \"(4) Fair\", \"(5) Poor\", \"(6) Refused\", \"(8) Don't know\")\n\n# label for obsrace\nattributes(y$obsrace)$label <- \"Interviewer observation of race from public Add Health Wave 1 Section 1 question 9\"\n# values  for obsrace\nattributes(y$obsrace)$levels <- c(\"(1) White\", \"(2) Black/African American\", \"(3) American Indian/Native American\", \"(4) Asian/Pacific Islander\", \"(5) Other\", \"(6) Refused\", \"(8) Don't know\", \"(9) Not applicable\")\n```\n\nVerify these were created:\n\n```{r}\ny$health %>% attributes()\ny$obsrace %>% attributes()\n```\n\nThe same caveats apply to saving the data frame to files.\n\n## Tabulation\nWe have seen a few examples of tabulation in previous exercises (Sections \\@ref(summarizingaggregating-data), \\@ref(rmdtables), \\@ref(default-values-for-arguments)). This section will give a more complete treatment using the Add Health data as an example.\n\n### Raw counts\nThe most basic tabulations simply give the count of observations in different strata. Those strata can be based on numeric ratio or interval data, using functions such as `cut()` or `BAMMtools::getJenksBreaks()`, nominal data (such as the Add Health interviewer's observation of respondents' single race), or ordinal data (such as the self-reported health status). We will use examples of each type of data.\n\nFirst, this code will load the full Add Health data set, which includes additional variables not present in the data set we have used previously.\n\n```{r}\n# download and unzip the larger data set\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n# zip file in $temp\nzipfile <- file.path(mytempdir, basename(myUrl))\n# dta file in $temp\ndtafile <- tools::file_path_sans_ext(zipfile)\n# check if the dta file exists\nif(!file.exists(dtafile)){\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if(!file.exists(zipfile)){\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    unzip(zipfile = zipfile, exdir = mytempdir)\n}\n\n# if the data set has not been read, read it in \nif(!exists(\"ahcomplete\")){\n    ahcomplete <- haven::read_dta(dtafile)\n}\n# lowercase column names\ncolnames(ahcomplete) %<>% str_to_lower()\n```\n\nPresent the metadata (variable names and labels):\n\n```{r}\nahcomplete_metadata <- bind_cols(\n    varname = colnames(ahcomplete),\n    varlabel = ahcomplete %>% map(~ attributes(.)$label) %>% unlist()\n)\n\nDT::datatable(ahcomplete_metadata)\n```\n\n\\  \nLet's look at body mass index (BMI) data, which uses weight and height values. We find the variables representing weight and height from the metadata above. We need to determine if there are any invalid values:\n\n```{r}\nattributes(ahcomplete$h1gh59a)$labels\nattributes(ahcomplete$h1gh59b)$labels\nattributes(ahcomplete$h1gh60)$labels\n```\n\nFirst, we need to select the variables representing feet and inches, then filter out invalid heights (> 90) and weights (> 900) identified above, and finally calculate height in m, weight in kg, and BMI ($\\frac{weight\\_{kg}}{{height\\_m}^2}$). For future use we will also select self-reported health and interviewer observed race as factors.\n\n```{r}\n# make the data frame\nhtwt <- ahcomplete %>% \n    # select columns\n    select(feet = h1gh59a,\n           inches = h1gh59b,\n           weight_lb = h1gh60,\n           health = h1gh1,\n           obsrace = h1gi9) %>% \n    # filter for valid values\n    filter(feet < 90 & inches < 90 & weight_lb < 900) %>% \n    # calculate \n    mutate(height_m = (feet * 12 + inches) / 39.37008,\n           weight_kg = weight_lb / 2.205,\n           BMI = weight_kg / height_m^2)\n\n# factor: get values and labels\nhealthvals <- htwt$health %>% attributes() %>% extract2(\"labels\") %>% as.numeric()\nhealthlabs <- htwt$health %>% attributes() %>% extract2(\"labels\") %>% names()\n\nracevals <- htwt$obsrace %>% attributes() %>% extract2(\"labels\") %>% as.numeric()\nracelabs <- htwt$obsrace %>% attributes() %>% extract2(\"labels\") %>% names()\n\nhtwt %<>% \n    mutate(health = factor(health,\n                           levels = healthvals,\n                           labels = healthlabs),\n           obsrace = factor(obsrace,\n                           levels = racevals,\n                           labels = racelabs))\n```\n\nA histogram shows the distribution of BMI for the respondents with vertical lines at the 5th and 85th percentile. This range is generally considered \"normal\" or \"healthy\" according to the CDC, although for a sample with varying age, sex, height, and weight ranges, it is difficult to interpret. Nevertheless the cut points can serve the purpose of demonstration.\n\n```{r}\n# get the 5th & 85th percentile\nbmibreaks <- quantile(x = htwt$BMI, probs = c(0.05, 0.85))\nggplot(htwt, aes(x = BMI)) +\n    geom_histogram(bins = 30) +\n    geom_vline(xintercept = bmibreaks)\n```\n\nWe assign the BMI class using these cut points, with `cut()` breaks at the minimum, 5%, 85%, and maximum BMI, and also assign labels and set ordering:\n\n```{r}\nhtwt %<>% \n    mutate(bmiclass = cut(x = BMI, \n                          breaks = c(min(BMI), bmibreaks, max(BMI)), \n                          labels = c(\"underweight\", \"normal\", \"overweight\"),\n                          include.lowest = TRUE) %>% \n               factor(ordered = TRUE))\n```\n\nThe tabulation of count of respondents by weight class can be generated with the base R function `table()` or `dplyr` functions `group_by()` and `summarise()`.\n\n```{r}\n# base R\ntable(htwt$bmiclass, useNA = \"ifany\")\n```\n\n```{r}\n# tidyR\nhtwt %>% \n    group_by(bmiclass) %>% \n    summarise(n = n()) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nFor variables that are already nominal or ordinal factors, tabulations can be made directly. Because these were converted to factors, the correct labels will show, rather than simple numeric values.\n\n```{r}\nhtwt %>% \n    group_by(health) %>% \n    summarise(n = n()) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n```{r}\nhtwt %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n### Proportions/percentages\nProportions and percentages can be added to tabulations for greater interpretability. Using base R, the `prop_table()` function can be used as a wrapper around `table()` to generate proportions, optionally multiplying by 100 to generate a percentage. Remember to round as needed. For example:\n\n```{r}\nround(prop.table(table(htwt$bmiclass)), 2)\n\nround(prop.table(table(htwt$bmiclass)) * 100, 0)\n```\n\nNot surprisingly, the BMI classes show 5% underweight and 15% overweight, because that is how the stratification was defined.\n\nThe `tidyR` version requires a bit more coding but provides a more readable output. Because the percent sign is a special character, we enclose it in back ticks, ``%``. Here we generate a tabulation of observed race.\n\n```{r}\nhtwt %>% \n    group_by(obsrace) %>% \n    summarise(n = n()) %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    mutate(`%` = `%` %>% round(1)) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n### Stratified tabulation\nTabulations can be generated using multiple variables. Here we will examine BMI and race as well as BMI and health. The percentages sum to 100 based on the order of the grouping.\n\nHere, we see the relative percent of underweight, normal, and overweight within each race class:\n\n```{r}\nhtwt %>% \n    group_by(obsrace,\n             bmiclass) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    mutate(`%` = `%` %>% round(1)) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nAnd here we see the relative percent of different race groups within each BMI class. \n\n```{r}\nhtwt %>% \n    group_by(bmiclass,\n             obsrace) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    mutate(`%` = `%` %>% round(1)) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nEven though the `n` values are the same in the two tables (e.g., underweight White n = `r htwt %>% filter(str_detect(obsrace, \"White\") & str_detect(bmiclass, \"under\")) %>% nrow()`), the percentages are different due to grouping. That is, the percent of underweight persons among the White race stratum is different from the percent of White persons within the underweight stratum. Proper grouping is critical to answer specific questions about the data.\n\nAnother way to understand the data, preferred by some, would be to make a graph. For example, BMI by race:\n\n```{r}\nbmi_race <- htwt %>% \n    group_by(obsrace,\n             bmiclass) %>% \n    summarise(n = n(), .groups = \"drop_last\") %>% \n    mutate(`%` = n / sum(n) * 100) %>% \n    filter(!str_detect(obsrace, regex(\"refused|know\", ignore_case = TRUE)))\n\nggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n    facet_grid(~obsrace)\n\nggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[07-week07.Rmd](07-week07.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"07-week07.Rmd\"), sep = '\\n')\n```"},{"path":"week8.html","id":"week8","chapter":"8 Week 8","heading":"8 Week 8","text":"week’s lesson provide background variable creation scale scoring. scale scoring exercise used create single variable represents well respondents overall subset questions.","code":""},{"path":"week8.html","id":"scale-scoring","chapter":"8 Week 8","heading":"8.1 Scale scoring","text":"using data Knowledge Quiz. Download open 21600-0001-Codebook_Questionnaire.pdf new window tab go page 203, search string H1KQ1A.using file AHwave1_v1.dta, downloaded read following code chunk, along presentation column names, labels, values.Questions H1KQ1A, H1KQ2A, …, H1KQ10A factual questions contraception administered participants \\(\\ge\\) age 15. creating single score sums correct answers across questions participant \\(\\ge\\) age 15. set questions paired, question “” factual portion “b” level confidence, want questions column names ending “.”","code":"\ndat <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\nmetadata <- bind_cols(\n    # variable name\n    varname = colnames(dat),\n    # label\n    varlabel = lapply(dat, function(x) attributes(x)$label) %>% \n        unlist(),\n    # values\n    varvalues = lapply(dat, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(metadata)"},{"path":"week8.html","id":"selecting-specific-columns","chapter":"8 Week 8","heading":"8.1.1 Selecting specific columns","text":"several ways selecting desired columns new data frame. brute force approach:Although 10 columns name pattern, 30 50? want enter column name separately. tedious, always possibility making keyboarding mistake.Instead brute force approach, can use matches() function regular expression. regular expression ^h1kq.*$, translates “start string, match h1kq, number characters, followed end string.”check processes yielded result:","code":"\n# create a data frame of some columns and age >= 15\nmydat_bruteforce <- dat %>% \n    # drop those under 15 y\n    filter(h1kq1a != 7) %>% \n    # get answers\n    select(\n        aid, # subject ID\n        h1kq1a,\n        h1kq2a,\n        h1kq3a,\n        h1kq4a,\n        h1kq5a,\n        h1kq6a,\n        h1kq7a,\n        h1kq8a,\n        h1kq9a,\n        h1kq10a\n    )\nmydat <- dat %>% \n    filter(h1kq1a != 7) %>% \n    select(\n        aid,\n        matches(\"h1kq.*a\")\n    )\nidentical(mydat_bruteforce, mydat)## [1] TRUE"},{"path":"week8.html","id":"comparing-participant-answers-to-correct-answers","chapter":"8 Week 8","heading":"8.1.2 Comparing participant answers to correct answers","text":"Now data frame limited participants correct age range questions want, need set tests whether questions answered correctly . metadata can see questions, correct answer (1) true , correct answer (2) false.can scan questions metadata create vector correct answers:now need compare vector vector constructed answers mydat. approaches taken. brute force approach use loop iterate record answers, record iterate answer:took 20.1 s run. low performance algorithm visiting every cell comparing one--rotating value correct answer vector correct answers. object required handled separately RAM process continues.Another approach uses plyr::adply(), runs function set rows. plyr package contains set tools splitting data, applying functions, recombining.adply() version takes far less coding, still took 19.9 s run.Yet another different approach compares data frame participant answers vector correct answers. correct answers vector get recycled values processed. problem method comparison runs columns rather across rows.demonstrates problem. Table 8.1 shows pattern “correct” values, Table 8.2 shows table responses\nTable 8.1: pattern “correct” values\n\nTable 8.2: table responses\npattern matches first row data (Table 8.3)\nTable 8.3: Matches first row\npatterns match overall table might expected (8.4).\nTable 8.4: Unexpected pattern matches\norder match pattern row, transpose required. following code performs transpose, pattern match, re-transpose, results 8.5\nTable 8.5: Expected pattern matches\ntrick use transpose (t()) swap rows columns. unlist() enforce correct ordering. running comparison, data transposed recreate original structure.method took 0.01 s complete.Yet another method similarly uses double transpose method.method took 0 s complete.final direct method uses base::sweep(), can used compare vector rows columns data frame. order use function, data frame needs number rows (columns) comparison vector. additional rows columns need stripped. may additional columns (e.g., aid), must removed running sweep(), added back . Additionally, result sweep() matrix, needs converted data frame greater functionality.sweep() method took 0.01 s.check methods gave identical answers.","code":"\n# the correct answers\ncorrect <- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) \n# make a named vector of the answers using the selected column names\nnames(correct) <- str_subset(string = names(mydat),\n                             pattern = \"h1kq.*a\")\n# time this\nt0 <- Sys.time()\n\n# make an output\nans_loop <- NULL\n\n# iterate over rows\n#testing:\n#for(i in 1:3){ \nfor(i in 1:nrow(mydat)){\n    # init a vector\n    Q <- NULL\n    # iterate over columns, ignoring the first \"aid\" column\n    for(j in 2:ncol(mydat)){\n        # get the value of the answer\n        ans_subj <- mydat[i, j]\n        # get the correct answer\n        ans_actual <- correct[j - 1]\n        # compare\n        cmp <- ans_actual == ans_subj\n        # append\n        Q <- c(Q, cmp)\n    }\n    # append\n    ans_loop <- rbind(ans_loop, Q)\n}\n\n# package it up nicely\nans_loop %<>% data.frame()\ncolnames(ans_loop) <- names(correct)\nrow.names(ans_loop) <- NULL\n\n# timing\nt1 <- Sys.time()\nruntime_loop <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n# time this\nt0 <- Sys.time()\n\nans_adply <- mydat %>% \n    select(-1) %>% \n    plyr::adply(.margins = 1, \n                function(x) x == correct)\n\nt1 <- Sys.time()\nruntime_adply <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n# make a pattern to match against\npat1 <- c(1, 2, 3, 4)\nnames(pat1) <- paste(\"question\", 1:4, sep=\"_\")\n\npat1 %>% \n    t() %>% \n    data.frame() %>% \n    kable(caption = 'A pattern of \"correct\" values') %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n# make a data frame to process\nd1 <- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %>% \n    data.frame()\nnames(d1) <- names(pat1)\n\nd1 %>% \n    kable(caption = \"A table of responses\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n(pat1 == d1[1,]) %>% \n    kable(caption = \"Matches for the first row\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n(d1 == pat1) %>% \n    kable(caption = \"Unexpected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n# transpose, check for matching and transpose back\n(d1 %>% t() == pat1) %>% \n    t() %>% \n    kable(caption = \"Expected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n# time this\nt0 <- Sys.time()\n# transpose and compare\nans_unlist <- mydat %>%\n    select(-1) %>% \n    t(.) %>% \n    unlist(.) == correct\n\n# re-transpose and make a data frame\nans_unlist %<>% \n    t(.) %>% \n    data.frame()\n\n# column names\ncolnames(ans_unlist) <- names(correct)\n\nt1 <- Sys.time()\nruntime_unlist <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n# time this\nt0 <- Sys.time()\n# strip the ID column and transpose\nz <- mydat %>% \n    select(-1) %>% \n    t() \n\n# compare, transpose, and make a data frame\nans_tranpose <- (z == correct) %>% \n    t(.) %>% \n    data.frame()\n\nt1 <- Sys.time()\nruntime_transpose <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\nt0 <- Sys.time()\nans_sweep <- mydat %>%\n    # drop the aid column\n    select(-aid) %>% \n    # run the sweep\n    sweep(x = ., MARGIN = 2, STATS = correct, FUN = \"==\") %>% \n    # convert to data frame\n    data.frame()\nt1 <- Sys.time()\nruntime_sweep <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\nVectorize(identical, 'x')(list(ans_loop, ans_adply, ans_tranpose, ans_unlist), ans_loop)## [1] TRUE TRUE TRUE TRUE"},{"path":"week8.html","id":"scoring-across-columns","chapter":"8 Week 8","heading":"8.1.3 Scoring across columns","text":"Now data frame indicating participant whether answered question correctly, can total number correct answers participant. rowSums() function allows sums across rows. logical values automatically converted numerical values (TRUE = 1; FALSE = 0), sums provide total number correct answers per participant. Also data frame consists answers 1 .. 10, can use unqualified rowSums(), otherwise necessary specify columns included either position column name.also bring subject identifier (aid) back reorder columns select(). Note specified aid total h1kqNa_sum columns, can use everything() select remainder columns.show differences total score sex, can join main data back using aid identifier create simple graph. Figure 8.1 shows females males overall higher counts correct scores Knowledge Quiz.\nFigure 8.1: Histogram count correct answers Knowledge Quiz stratified sex respondent\n","code":"\nans_loop %<>%\n    # calculate the rowSums\n    mutate(h1kqNa_sum = rowSums(.)) %>% \n    # bring the ID back in\n    mutate(aid = mydat$aid) %>% \n    # reorder columns\n    select(aid, h1kqNa_sum, everything())\nans_loop %<>% \n    left_join(dat, by = \"aid\") %>% \n    mutate(\n        sex = case_when(\n            bio_sex == 1 ~ 'male',\n            bio_sex == 2 ~ 'female'\n        )\n    )\n\nggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+\n    geom_histogram(stat = \"count\") +\n    facet_grid(sex ~ .) + \n    xlab(\"correct answers on Knowledge Quiz\") +\n    scale_x_continuous(breaks=0:10)## Warning: Ignoring unknown parameters: binwidth, bins, pad"},{"path":"week8.html","id":"reordering-values","chapter":"8 Week 8","heading":"8.2 Reordering values","text":"Sometimes variables provided reverse order might want. example, answers pertaining confidence Knowledge Quiz specific order:come scale score , better valued 4 1 row-wise sums yield higher values confident many answers. One use existing values, interpretation overall confidence score might difficult, confidence lowest overall score.Changing values quite straightforward. case_when() function can used:bit awkward deal multiple columns. One might tempted use brute force method copy/paste/edit using mutate_at() function can help use regular expression pattern matching column names. function performed multiple columns. use similar regular expression find columns representing confidence answers Knowledge Quiz (h1kq.*b). use dot (.) shorthand “current object” case specified column.sake comparison show single bit code acted multiple columns:Now values reordered, can used multiple-column scale scoring demonstrated .Rendered 2022-01-08 18:00:5608-week08.Rmd","code":"\nattributes(dat$h1kq1b)$labels %>% t() %>% t() %>% data.frame()##                                    .\n## (1) Very                           1\n## (2) Moderately                     2\n## (3) Slightly                       3\n## (4) Not at all                     4\n## (6) Refused                        6\n## (7) Legitimate skip (less than 15) 7\n## (8) Don't know                     8\n## (9) Not applicable                 9\n# for comparison, make a backup data frame\ndatbak <- dat2 <- dat\n\n# reassign values\ndat %<>% \n    mutate(h1kq1b = \n               case_when(\n                   # main changes\n                   h1kq1b == 4 ~ 1,\n                   h1kq1b == 3 ~ 2,\n                   h1kq1b == 2 ~ 3,\n                   h1kq1b == 1 ~ 4,\n                   # anything that is not in the above list gets its original value\n                   TRUE ~ as.numeric(h1kq1b))\n               )\ndat2 %<>% \n    mutate_at(.vars = vars(matches(\"h1kq.*b\")),\n              funs(\n                  case_when(\n                      . == 4 ~ 1,\n                      . == 3 ~ 2,\n                      . == 2 ~ 3,\n                      . == 1 ~ 4,\n                      TRUE ~ as.numeric(.)\n                  )\n              )\n    )\norig1 <- table(datbak$h1kq1b) %>% data.frame()\n\nmod1 <- table(dat2$h1kq1b) %>% data.frame()\n\norig2 <- table(datbak$h1kq2b) %>% data.frame()\n\nmod2 <- table(dat2$h1kq2b) %>% data.frame()\n\ncbind(orig1, mod1, orig2, mod2) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") %>% \n    add_header_above(rep(c(\"original\" = 2, \"modified\" = 2), 2)) %>% \n    add_header_above(c(\"h1kq1b\" = 4, \"h1kq2b\" = 4))\n# too many unique combinations!\n# dat2 %>% \n#     group_by_at(vars(matches(\"h1kq.*b\"))) %>% \n#     dplyr::summarise(n = n())\ncat(readLines(con = \"08-week08.Rmd\"), sep = '\\n')# Week 8 {#week8}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(haven)\nlibrary(pdftools)\nlibrary(curl)\nlibrary(ggplot2)\n```\n\n<h2>Topic: Add Health data: variable creation and scale scoring<\/h2>\nThis week's lesson will provide more background on variable creation and scale scoring. The scale scoring exercise will be used to create a single variable that represents how well respondents did overall on a subset of questions.\n\n## Scale scoring\nWe will be using data from the Knowledge Quiz. Download or open [21600-0001-Codebook_Questionnaire.pdf](http://staff.washington.edu/phurvitz/csde502_winter_2021/data/metadata/Wave1_Comprehensive_Codebook/21600-0001-Codebook_Questionnaire.pdf) in a new window or tab and go to page 203, or search for the string `H1KQ1A`.\n\nWe will be using the file `AHwave1_v1.dta`, which is downloaded and read in the following code chunk, along with presentation of the column names, labels, and values.\n\n```{r}\ndat <- haven::read_dta(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta\")\n\nmetadata <- bind_cols(\n    # variable name\n    varname = colnames(dat),\n    # label\n    varlabel = lapply(dat, function(x) attributes(x)$label) %>% \n        unlist(),\n    # values\n    varvalues = lapply(dat, function(x) attributes(x)$labels) %>% \n        # names the variable label vector\n        lapply(., function(x) names(x)) %>% \n        # as character\n        as.character() %>% \n        # remove the c() construction\n        str_remove_all(\"^c\\\\(|\\\\)$\")\n)\n\nDT::datatable(metadata)\n```\n\nQuestions `H1KQ1A`, `H1KQ2A`, ..., `H1KQ10A` are factual questions about contraception that are administered to participants $\\ge$ age 15. We will be creating a single score that sums up all the correct answers across these questions for each participant $\\ge$ age 15. Because the set of questions is paired, with question \"a\" being the factual portion and \"b\" being the level of confidence, we want only those questions with column names ending with \"a\".\n\n### Selecting specific columns\nThere are several ways of selecting the desired columns into a new data frame. Here is brute force approach:\n\n```{r}\n# create a data frame of some columns and age >= 15\nmydat_bruteforce <- dat %>% \n    # drop those under 15 y\n    filter(h1kq1a != 7) %>% \n    # get answers\n    select(\n        aid, # subject ID\n        h1kq1a,\n        h1kq2a,\n        h1kq3a,\n        h1kq4a,\n        h1kq5a,\n        h1kq6a,\n        h1kq7a,\n        h1kq8a,\n        h1kq9a,\n        h1kq10a\n    )\n```\n\nAlthough there were only 10 columns with this name pattern, what if there had been 30 or 50? You would not want to have to enter each column name separately. Not only would this be tedious, there would always be the possibility of making a keyboarding mistake.\n\nInstead of the brute force approach, we can use the `matches()` function with a regular expression. The regular expression here is `^h1kq.*a$`, which translates to \"at the start of the string, match `h1kq`, then any number of any characters, then `a` followed by the end of the string\".\n\n```{r}\nmydat <- dat %>% \n    filter(h1kq1a != 7) %>% \n    select(\n        aid,\n        matches(\"h1kq.*a\")\n    )\n```\n\nWe check that both processes yielded the same result:\n\n```{r}\nidentical(mydat_bruteforce, mydat)\n```\n\n### Comparing participant answers to correct answers\n\nNow that we have a data frame limited to the participants in the correct age range and only the questions we want, we need to set up tests for whether the questions were answered correctly or not. From the metadata we can see that for some questions, the correct answer was `(1) true` and for some, the correct answer was `(2) false`.\n\nWe can scan through the questions in the metadata to create a vector of correct answers:\n\n```{r}\n# the correct answers\ncorrect <- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) \n# make a named vector of the answers using the selected column names\nnames(correct) <- str_subset(string = names(mydat),\n                             pattern = \"h1kq.*a\")\n```\n\nWhat we now need to do is compare this vector to a vector constructed of the answers in `mydat`. There are a few approaches that could be taken. A brute force approach could use a loop to iterate over each record in the answers, and for each record to iterate over each answer:\n\n```{r}\n# time this\nt0 <- Sys.time()\n\n# make an output\nans_loop <- NULL\n\n# iterate over rows\n#testing:\n#for(i in 1:3){ \nfor(i in 1:nrow(mydat)){\n    # init a vector\n    Q <- NULL\n    # iterate over columns, ignoring the first \"aid\" column\n    for(j in 2:ncol(mydat)){\n        # get the value of the answer\n        ans_subj <- mydat[i, j]\n        # get the correct answer\n        ans_actual <- correct[j - 1]\n        # compare\n        cmp <- ans_actual == ans_subj\n        # append\n        Q <- c(Q, cmp)\n    }\n    # append\n    ans_loop <- rbind(ans_loop, Q)\n}\n\n# package it up nicely\nans_loop %<>% data.frame()\ncolnames(ans_loop) <- names(correct)\nrow.names(ans_loop) <- NULL\n\n# timing\nt1 <- Sys.time()\nruntime_loop <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n```\n\nIt took `r runtime_loop` s to run. This low performance is because the algorithm is visiting every cell and comparing one-by-on with a rotating value for the correct answer from the vector of correct answers. Each object is required to be handled separately in RAM as the process continues.\n\nAnother approach uses `plyr::adply()`, which runs a function over a set of rows. The [`plyr`](https://www.rdocumentation.org/packages/plyr/) package contains a set of tools for splitting data, applying functions, and recombining.\n\n```{r}\n# time this\nt0 <- Sys.time()\n\nans_adply <- mydat %>% \n    select(-1) %>% \n    plyr::adply(.margins = 1, \n                function(x) x == correct)\n\nt1 <- Sys.time()\nruntime_adply <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(1)\n```\n\nThe `adply()` version takes far less coding, but still took `r runtime_adply` s to run.\n\nYet another different approach compares the data frame of participant answers to the vector of correct answers. The correct answers vector will get recycled until all values have been processed. The problem with this method is that the comparison runs down columns rather than across rows. \n\nThis demonstrates the problem. Table \\@ref(tab:pat1vector) shows a pattern of \"correct\" values, and Table \\@ref(tab:d1dataframe) shows a table of responses\n\n```{r pat1vector}\n# make a pattern to match against\npat1 <- c(1, 2, 3, 4)\nnames(pat1) <- paste(\"question\", 1:4, sep=\"_\")\n\npat1 %>% \n    t() %>% \n    data.frame() %>% \n    kable(caption = 'A pattern of \"correct\" values') %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n```{r d1dataframe}\n# make a data frame to process\nd1 <- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %>% \n    data.frame()\nnames(d1) <- names(pat1)\n\nd1 %>% \n    kable(caption = \"A table of responses\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nThe pattern matches the first row of data (Table \\@ref(tab:patmatchonerow))\n\n```{r patmatchonerow}\n(pat1 == d1[1,]) %>% \n    kable(caption = \"Matches for the first row\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n```\n\nThe patterns do not match the overall table as might be expected (\\@ref(tab:patmatchdfbad)). \n\n```{r patmatchdfbad}\n(d1 == pat1) %>% \n    kable(caption = \"Unexpected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\nIn order to match the pattern to each row, a transpose is required. The following code performs the transpose, pattern match, and re-transpose, with results in \\@ref(tab:patmatchdfgood)\n\n```{r patmatchdfgood}\n# transpose, check for matching and transpose back\n(d1 %>% t() == pat1) %>% \n    t() %>% \n    kable(caption = \"Expected pattern matches\") %>% \n    kable_styling(full_width = FALSE, position = \"left\")    \n```\n\nSo the trick is to use a transpose (`t()`) to swap rows and columns. Then `unlist()` will enforce the correct ordering. After running the comparison, the data are transposed again to recreate the original structure.\n\n```{r}\n# time this\nt0 <- Sys.time()\n# transpose and compare\nans_unlist <- mydat %>%\n    select(-1) %>% \n    t(.) %>% \n    unlist(.) == correct\n\n# re-transpose and make a data frame\nans_unlist %<>% \n    t(.) %>% \n    data.frame()\n\n# column names\ncolnames(ans_unlist) <- names(correct)\n\nt1 <- Sys.time()\nruntime_unlist <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n```\n\nThis method took `r runtime_unlist` s to complete.\n\nYet another method similarly uses the double transpose method.\n\n```{r}\n# time this\nt0 <- Sys.time()\n# strip the ID column and transpose\nz <- mydat %>% \n    select(-1) %>% \n    t() \n\n# compare, transpose, and make a data frame\nans_tranpose <- (z == correct) %>% \n    t(.) %>% \n    data.frame()\n\nt1 <- Sys.time()\nruntime_transpose <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(2)\n```\n\nThis method took `r runtime_transpose` s to complete.\n\nThe final and most direct method uses `base::sweep()`, which can be used to compare a vector against all rows or columns in a data frame. In order to use this function, the data frame needs to have the same number of rows (or columns) as the comparison vector. So any additional rows or columns need to be stripped. Because we may have additional columns (e.g., `aid`), those must be removed before running `sweep()`, then added back in again. Additionally, the result of `sweep()` is a matrix, so it needs to be converted to a data frame for greater functionality.\n\n```{r}\nt0 <- Sys.time()\nans_sweep <- mydat %>%\n    # drop the aid column\n    select(-aid) %>% \n    # run the sweep\n    sweep(x = ., MARGIN = 2, STATS = correct, FUN = \"==\") %>% \n    # convert to data frame\n    data.frame()\nt1 <- Sys.time()\nruntime_sweep <- difftime(t1, t0, units = \"secs\") %>% as.numeric() %>% round(3)\n```\n\nThe `sweep()` method took `r runtime_sweep` s.\n\nWe should check that the methods all gave identical answers.\n\n```{r}\nVectorize(identical, 'x')(list(ans_loop, ans_adply, ans_tranpose, ans_unlist), ans_loop)\n```\n\n### Scoring across columns{#scoring-across-columns}\nNow that we have a data frame indicating for each participant whether they answered each question correctly, we can total the number of correct answers for each participant. The `rowSums()` function allows sums across rows. Because the logical values are automatically converted to numerical values (TRUE = 1; FALSE = 0), the sums provide the total number of correct answers per participant. Also because the data frame only consists of answers 1 .. 10, we can use an unqualified `rowSums()`, otherwise it would be necessary to specify which columns would be included by either position or column name.\n\nWe also bring the subject identifier (`aid`) back in and reorder the columns with `select()`. Note that after the specified `aid` and total `h1kqNa_sum` columns, we can use `everything()` to select the remainder of the columns.\n\n```{r}\nans_loop %<>%\n    # calculate the rowSums\n    mutate(h1kqNa_sum = rowSums(.)) %>% \n    # bring the ID back in\n    mutate(aid = mydat$aid) %>% \n    # reorder columns\n    select(aid, h1kqNa_sum, everything())\n```\n\nTo show differences in total score by sex, we can join the main data back using the `aid` identifier and create a simple graph. Figure \\@ref(fig:hist) shows that more females than males had overall higher counts of correct scores on the Knowledge Quiz. \n\n```{r hist, fig.cap=\"Histogram of count of correct answers on Knowledge Quiz stratified by sex of respondent\"}\nans_loop %<>% \n    left_join(dat, by = \"aid\") %>% \n    mutate(\n        sex = case_when(\n            bio_sex == 1 ~ 'male',\n            bio_sex == 2 ~ 'female'\n        )\n    )\n\nggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+\n    geom_histogram(stat = \"count\") +\n    facet_grid(sex ~ .) + \n    xlab(\"correct answers on Knowledge Quiz\") +\n    scale_x_continuous(breaks=0:10)\n```\n\n\n## Reordering values\nSometimes variables are provided in the reverse order of what you might want. For example, the answers pertaining to confidence in the Knowledge Quiz are in this specific order:\n\n```{r}\nattributes(dat$h1kq1b)$labels %>% t() %>% t() %>% data.frame()\n```\n\nTo come up with a scale score for these, it would be better to have `Very` valued as a `4` and `Not at all` as a `1` so that row-wise sums would yield higher values for those who were more confident in many answers. One could use the existing values, but then the interpretation of an overall confidence score might be difficult, with the most confidence for the lowest overall score.\n\nChanging these values is quite straightforward. The `case_when()` function can be used:\n\n```{r}\n# for comparison, make a backup data frame\ndatbak <- dat2 <- dat\n\n# reassign values\ndat %<>% \n    mutate(h1kq1b = \n               case_when(\n                   # main changes\n                   h1kq1b == 4 ~ 1,\n                   h1kq1b == 3 ~ 2,\n                   h1kq1b == 2 ~ 3,\n                   h1kq1b == 1 ~ 4,\n                   # anything that is not in the above list gets its original value\n                   TRUE ~ as.numeric(h1kq1b))\n               )\n```\n\nIt is a bit more awkward to deal with multiple columns. One might be tempted to use a brute force method by copy/paste/edit but using the `mutate_at()` function can help through the use of regular expression pattern matching for column names. The same function will be performed on multiple columns. Here we use a similar regular expression to find the columns representing confidence in answers to the Knowledge Quiz (`h1kq.*b`). The use of the dot (`.`) is shorthand for \"the current object\" which in this case is the specified column.\n\n```{r, warning=FALSE}\ndat2 %<>% \n    mutate_at(.vars = vars(matches(\"h1kq.*b\")),\n              funs(\n                  case_when(\n                      . == 4 ~ 1,\n                      . == 3 ~ 2,\n                      . == 2 ~ 3,\n                      . == 1 ~ 4,\n                      TRUE ~ as.numeric(.)\n                  )\n              )\n    )\n```\n\nFor the sake of comparison to show that the single bit of code acted on multiple columns:\n\n```{r}\norig1 <- table(datbak$h1kq1b) %>% data.frame()\n\nmod1 <- table(dat2$h1kq1b) %>% data.frame()\n\norig2 <- table(datbak$h1kq2b) %>% data.frame()\n\nmod2 <- table(dat2$h1kq2b) %>% data.frame()\n\ncbind(orig1, mod1, orig2, mod2) %>% \n    kable() %>% \n    kable_styling(full_width = FALSE, position = \"left\") %>% \n    add_header_above(rep(c(\"original\" = 2, \"modified\" = 2), 2)) %>% \n    add_header_above(c(\"h1kq1b\" = 4, \"h1kq2b\" = 4))\n\n# too many unique combinations!\n# dat2 %>% \n#     group_by_at(vars(matches(\"h1kq.*b\"))) %>% \n#     dplyr::summarise(n = n())\n```\n\nNow that the values are reordered, they can be used in multiple-column scale scoring as demonstrated above.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[08-week08.Rmd](08-week08.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"08-week08.Rmd\"), sep = '\\n')\n```"},{"path":"week9.html","id":"week9","chapter":"9 Week 9","heading":"9 Week 9","text":"week’s lesson cover set miscellaneous data processing topics.Mostly set coded examples explanations","code":""},{"path":"week9.html","id":"substituting-text","chapter":"9 Week 9","heading":"9.1 Substituting text","text":"","code":""},{"path":"week9.html","id":"paste-paste0","chapter":"9 Week 9","heading":"9.1.1 paste(), paste0()","text":"Pasting text allows substitute variables within text string. example, running long loop series files want know file name loop iteration .function paste() combines set strings adds space strings, e.g., combining first values LETTERS letters built-vectors:whereas paste0 add spaces:code uses function tempdir() specify folder automatically generated per R session; rendering book, location C:\\73K almost certainly different session. code downloads unzips file quickfox tempdir() location. zip file contains separate file word phrase “quick brown fox jumps lazy dog.” code uses loop paste() show contents separate file along file name.","code":"\npaste(LETTERS[1], letters[1])## [1] \"A a\"\npaste0(LETTERS[1], letters[1])## [1] \"Aa\"\n# zip file\nzipfile <- file.path(tempdir(), \"quickfox.zip\")\n\n# download\ncurl_download(url = \"http://staff.washington.edu/phurvitz/csde502_winter_2021/files/quickfox.zip\", destfile = zipfile)\n\n# unzip\nunzip(zipfile = zipfile, overwrite = TRUE, exdir = tempdir())\n\n# files in the zip file\nfnames <- unzip(zipfile = file.path(tempdir(), \"quickfox.zip\"), list = TRUE) %>%\n    pull(Name) %>%\n    file.path(tempdir(), .)\n\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name with a forward slash\n    fname <- fnames[i] %>% normalizePath(winslash = \"/\")\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()`\n    mystr <- paste(mytext, \"    \", i, \"of\", length(fnames), fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    message(mystr)\n}## the      1 of 9 C:/Temp/7/RtmpQTLf3K/str_0017e602b137e88.txt## quick      2 of 9 C:/Temp/7/RtmpQTLf3K/str_0027e604fa83778.txt## brown      3 of 9 C:/Temp/7/RtmpQTLf3K/str_0037e60bc634af.txt## fox      4 of 9 C:/Temp/7/RtmpQTLf3K/str_0047e60195772f.txt## jumps      5 of 9 C:/Temp/7/RtmpQTLf3K/str_0057e60229c264.txt## over      6 of 9 C:/Temp/7/RtmpQTLf3K/str_0067e606cfd4207.txt## the      7 of 9 C:/Temp/7/RtmpQTLf3K/str_0077e601b5b742d.txt## lazy      8 of 9 C:/Temp/7/RtmpQTLf3K/str_0087e604c1a30c5.txt## dog      9 of 9 C:/Temp/7/RtmpQTLf3K/str_0097e6038323213.txt"},{"path":"week9.html","id":"sprintf","chapter":"9 Week 9","heading":"9.1.2 sprintf()","text":"sprintf() can used format text. just examples. result formatted text string.","code":""},{"path":"week9.html","id":"formatting-numerical-values","chapter":"9 Week 9","heading":"9.1.2.1 Formatting numerical values","text":"Leading zerosNumeric values can formatted specific number decimal places leading zeros. example, ZIP codes imported CSV files often converted integers. following code chunk converts numerical ZIP code-like values text values correct format.Bad ZIP codes:Good ZIP codes:Decimal placesNumerical values different numbers decimal places can rendered specific number decimal places.Note distinct round(), results numeric vector:","code":"\n# some numerical ZIP codes\n(zip_bad <- data.frame(id = 1:3, zipcode = c(90201, 02134, 00501)))##   id zipcode\n## 1  1   90201\n## 2  2    2134\n## 3  3     501\n# fix them up\n(zip_good <- zip_bad %>% mutate(\n    zipcode = sprintf(\"%05d\", zipcode)\n))##   id zipcode\n## 1  1   90201\n## 2  2   02134\n## 3  3   00501\n# numbers with a variety of decimal places\nv <- c(1.2, 2.345, 1e+5 + 00005)\n\n# four fixed decimal places\nv %>% sprintf(\"%0.4f\", .)## [1] \"1.2000\"      \"2.3450\"      \"100005.0000\"\n# round to 4 places\nv %>% round(., 4)## [1]      1.200      2.345 100005.000"},{"path":"week9.html","id":"string-substitutions","chapter":"9 Week 9","heading":"9.1.2.2 String substitutions","text":"sprintf() can also used achieve substitution file reading loop . %s substituted order position arguments following string. Also note \\t inserts TAB character.","code":"\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name\n    fname <- fnames[i]\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()`\n    mystr <- sprintf(\"%s\\t%s of %s:\\t%s\", mytext, i, length(fnames), fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    cat(mystr)\n}## the  1 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0017e602b137e88.txtquick   2 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0027e604fa83778.txtbrown   3 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0037e60bc634af.txtfox  4 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0047e60195772f.txtjumps    5 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0057e60229c264.txtover 6 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0067e606cfd4207.txtthe 7 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0077e601b5b742d.txtlazy    8 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0087e604c1a30c5.txtdog 9 of 9: C:\\Temp\\7\\RtmpQTLf3K/str_0097e6038323213.txt"},{"path":"week9.html","id":"str_replace-str_replace_all","chapter":"9 Week 9","heading":"9.1.3 str_replace(), str_replace_all()","text":"stringr functions str_replace() str_replace_all() can used substitute specific strings strings. example, might create generic function run set subject IDs generates file subject.","code":"\nsubjects <- c(\"a1\", \"b2\", \"c3\")\n\nf <- function(id) {\n    # create an output file name by substituting in the subject ID\n    outfname <- file.path(tempdir(), \"xIDx.csv\") %>% str_replace(pattern = \"xIDx\", id)\n    # ... do a bunch of stuff, for example\n    val <- rnorm(1)\n    # write the file\n    message(paste0(\"writing\"))\n    write.csv(x = val, file = outfname)\n}\n\nfor (i in subjects) {\n    f(i)\n}## writing\n## writing\n## writing"},{"path":"week9.html","id":"showing-progress","chapter":"9 Week 9","heading":"9.2 Showing progress","text":"text-based progress bar can shown using txtProgressBar(). run loop reading text files, rather printing loop iteration file names, show progress bar file contents. text printed console (unlike demonstrated cat()), progress bar print several lines.","code":"\nn_fnames <- length(fnames)\n# create progress bar\npb <- txtProgressBar(min = 0, max = n_fnames, style = 3)## \n  |                                                                            \n  |                                                                      |   0%\nfor (i in 1:n_fnames) {\n    # delay a bit\n    Sys.sleep(0.1)\n    # update progress bar\n    setTxtProgressBar(pb, i)\n    # read and print from the file\n    txt <- scan(fnames[i], what = \"character\", quiet = TRUE)\n    cat(\"\\n\", txt, \"\\n\")\n}## \n  |                                                                            \n  |========                                                              |  11%\n##  the \n## \n  |                                                                            \n  |================                                                      |  22%\n##  quick \n## \n  |                                                                            \n  |=======================                                               |  33%\n##  brown \n## \n  |                                                                            \n  |===============================                                       |  44%\n##  fox \n## \n  |                                                                            \n  |=======================================                               |  56%\n##  jumps \n## \n  |                                                                            \n  |===============================================                       |  67%\n##  over \n## \n  |                                                                            \n  |======================================================                |  78%\n##  the \n## \n  |                                                                            \n  |==============================================================        |  89%\n##  lazy \n## \n  |                                                                            \n  |======================================================================| 100%\n##  dog\nclose(pb)"},{"path":"week9.html","id":"turning-text-into-code-evalparsetext-some-string","chapter":"9 Week 9","heading":"9.3 Turning text into code: eval(parse(text = \"some string\"))","text":"Sometimes may variables whose values want use command function. example, suppose wanted write set files, one ZIP code data frame, file name including ZIP code. want use column name zipcode, want actual value.can generate command using kind text substitution sprintf()","code":"\nfor (i in zip_good %>% pull(zipcode)) {\n    # do some stuff\n    vals <- rnorm(n = 3)\n    y <- bind_cols(zipcode = i, v = vals)\n    # a writing command using sprintf() to substitute %s = ZIP code\n    cmd <- sprintf(\"write.csv(x = y, file = file.path(tempdir(), '%s.csv'), row.names = FALSE)\", i)\n\n    # this runs the command\n    eval(parse(text = cmd))\n}"},{"path":"week9.html","id":"sql-in-r-with-rsqlite-and-sqldf","chapter":"9 Week 9","heading":"9.4 SQL in R with RSQLite and sqldf","text":"Sometimes R’s syntax processing data can difficult confusing. programmers familiar structured query language (SQL), possible run SQL statements within R using supported database back end (default SQLite) sqldf() function.example, mean sepal length species built-iris data set can obtained, presented Table 9.1\nTable 9.1: Mean sepal length iris data set\n","code":"\nlibrary(sqldf)## Loading required package: gsubfn## Loading required package: proto## Loading required package: RSQLite\nsqlc <- 'select\n    \"Species\" as species\n    , avg(\"Sepal.Length\") as mean_sepal_length\nfrom iris\ngroup by \"Species\";\n'\n\niris_summary <- sqldf(x = sqlc)\n\niris_summary %>%\n    kable(caption = \"Mean sepal length from the iris data set\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")"},{"path":"week9.html","id":"downloading-files-from-password-protected-web-sites","chapter":"9 Week 9","heading":"9.5 Downloading files from password-protected web sites","text":"web sites protected simple username/password protection. example, try opening [http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected] (http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected). username/password pair csde/502, allow see contents web folder.try downloading file R, get error password supplied.However, username password can supplied part URL, . username password supplied, cached site duration R session.","code":"\ntry(\n    read.csv(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)## Warning in file(file, \"rt\"): cannot open URL 'http://staff.washington.edu/\n## phurvitz/csde502_winter_2021/password_protected/foo.csv': HTTP status was '401\n## Unauthorized'## Error in file(file, \"rt\") : cannot open the connection\ntry(\n    read.csv(\"http://csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)## Warning in file(file, \"rt\"): cannot open URL 'http://\n## csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/\n## foo.csv': HTTP status was '401 Unauthorized'## Error in file(file, \"rt\") : cannot open the connection"},{"path":"week9.html","id":"dates-and-time-stamps-posixct-and-lubridate","chapter":"9 Week 9","heading":"9.6 Dates and time stamps: POSIXct and lubridate","text":"R uses POSIX-style time stamps, stored internally number fractional seconds January 1, 1970. imperative control time stamps commensurate temporal accuracy precision data. example, measurement years residence, precision substantially important. measurement chemical reactions, fractional seconds may important. applications merging body-worn sensor data GPS units accelerometers estimating physical activity occurs, minutes error can result statistically significant mis-estimations.example, can see numeric value seconds options(digits = 22); Sys.time() %>% .numeric().time stamps text format, can converted POSIX time stamps, e.g., supposed time Neil Armstrong stepped moon:Formats can specified using specific codes, see strptime().lubridate package large number functions handling date time stamps. example, want convert time stamp current time zone different time zone, first get current timeAnd convert UTC:show different format:","code":"\noptions(digits = 22)\nSys.time() %>% as.numeric()## [1] 1641693661.3952329\n(eagle <- as.POSIXct(x = \"7/20/69 10:56 PM\", tz = \"CST6CDT\", format = \"%m/%d/%y %H:%M\"))## [1] \"1969-07-20 10:56:00 CDT\"\nlibrary(lubridate)## \n## Attaching package: 'lubridate'## The following objects are masked from 'package:base':\n## \n##     date, intersect, setdiff, union\n# set the option for fractional seconds\noptions(digits.secs = 3)\n(now <- Sys.time() %>% strptime(\"%Y-%m-%d %H:%M:%OS\"))## [1] \"2022-01-08 18:01:01.457 PST\"\n# show this at time zone UTC\n(with_tz(time = now, tzone = \"UTC\"))## [1] \"2022-01-09 02:01:01.457 UTC\"\n# in different format\nnow %>% format(\"%A, %B %d, %Y %l:%m %p %Z\")## [1] \"Saturday, January 08, 2022  6:01 PM PST\""},{"path":"week9.html","id":"timing-with-sys.time-and-difftime","chapter":"9 Week 9","heading":"9.7 Timing with Sys.time() and difftime()","text":"easy determine long process takes using sequential Sys.time() calls, one one process, getting difference difftime(). example,difftime() can also forced report time difference units choice:","code":"\n# mark time and run a process\nt0 <- Sys.time()\nSys.sleep(5)\nt1 <- Sys.time()\n\n# difftime() unqualified will make its best decision about what to print\n(difftime(time1 = t1, time2 = t0))## Time difference of 5.004136 secs\n# time between moon step and now-ish\n(difftime(time1 = t0, time2 = eagle))## Time difference of 19165.42 days\n(difftime(time1 = t1, time2 = t0, units = \"secs\") %>% as.numeric()) %>% round(0)## [1] 5\n(difftime(time1 = t1, time2 = t0, units = \"mins\") %>% as.numeric()) %>% round(2)## [1] 0.08\n(difftime(time1 = t1, time2 = t0, units = \"hours\") %>% as.numeric()) %>% round(4)## [1] 0.0014\n(difftime(time1 = t1, time2 = t0, units = \"days\") %>% as.numeric()) %>% round(6)## [1] 5.8e-05"},{"path":"week9.html","id":"faster-files-with-fst","chapter":"9 Week 9","heading":"9.8 Faster files with fst()","text":"fst package great rapid reading writing data frames. format can also result much smaller file sizes using compression. examine large Add Health file. First, download, unzip, read necessary:took 29.1 s write 41823590 bytes CSV, 0.3 s write 19064839 bytes FST file (default compression amount 50). Reading speeds comparable.noted file attributes saved FST format therefore used caution highly attributed data set (e.g., Stata DTA file extensive labeling). lose attributes! data sets simple structure, including factors, FST format good option.","code":"\nlibrary(fst)\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n# zip file in $temp\nzipfile <- file.path(tempdir(), basename(myUrl))\n# download\ncurl_download(url = myUrl, destfile = zipfile)\n# dta file in $temp\ndtafname <- tools::file_path_sans_ext(zipfile)\n# check if the dta file exists\nif (!file.exists(dtafname)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    unzip(zipfile = zipfile, exdir = tempdir())\n}\n\n# read the file\ndat <- read_dta(dtafname)\n\n# save as a CSV, along with timing\nt0 <- Sys.time()\ncsvfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"csv\")\nwrite.csv(x = dat, file = csvfname, row.names = FALSE)\nt1 <- Sys.time()\ncsvwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)\n\n# file size\ncsvsize <- file.info(csvfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\n\n# save as FST, along with timing\nt0 <- Sys.time()\nfstfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"fst\")\nwrite.fst(x = dat, path = fstfname)\nt1 <- Sys.time()\n\n# file size\nfstsize <- file.info(fstfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\nfstwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)"},{"path":"week9.html","id":"load-us-census-boundary-and-attribute-data-as-tidyverse-and-sf-ready-data-frames-tigris-tidycensus","chapter":"9 Week 9","heading":"9.9 Load US Census Boundary and Attribute Data as ‘tidyverse’ and ‘sf’-Ready Data Frames: tigris, tidycensus","text":"Dealing US Census data can overwhelming, particularly using raw text-based data. Census Bureau API allows streamlined downloads variables (data frames) geographies (simple format shapes). necessary get API key, available free. See tidycensus tidycensus basic usage.tidycensus uses tigris, downloads geographic data portion census files.","code":""},{"path":"week9.html","id":"download-data","chapter":"9 Week 9","heading":"9.9.1 Download data","text":"simple example download variables representing count White, Black/African American, American Indian/Native American, Asian persons American Community Survey (ACS) data King County 2019. example run, need US Census API key installed, e.g.,\ntidycensus::census_api_key(“*****************,” install = TRUE)\nAPI key stored .Renviron can accessed Sys.getenv(“CENSUS_API_KEY”).\nuse now, restart R run readRenviron(\"~/.Renviron\")\n\nlabels census API :values shown Table 3.1\nTable 3.1: Selected census tract variables 5-year ACS 2019 King County, WA\n","code":"\"Estimate!!Total\"                                         \n\"Estimate!!Total!!White alone\"                            \n\"Estimate!!Total!!Black or African American alone\"        \n\"Estimate!!Total!!American Indian and Alaska Native alone\"\n\"Estimate!!Total!!Asian alone\" \nlibrary(tidycensus)\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)## Getting data from the 2015-2019 5-year ACS## Downloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.## \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=========                                                             |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |==========================                                            |  36%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")"},{"path":"week9.html","id":"mapping-census-data","chapter":"9 Week 9","heading":"9.9.2 Mapping census data","text":"leaflet simple map shown 3.1, percent African American residents tract identifier.\nFigure 3.1: Percent African American census tracts King County, 2019 ACS 5-year estimate\n","code":"\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(sf)\n\n# define the CRS\nst_crs(ctdat) <- 4326\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\nbins <- 0:50\npal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\nbins2 <- seq(0, 50, by = 10)\npal2 <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins2\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ pal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # legend\n    addLegend(\n        position = \"bottomright\", pal = pal2, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()"},{"path":"week9.html","id":"creating-population-pyramids-from-census-data","chapter":"9 Week 9","heading":"9.9.3 Creating population pyramids from census data","text":"See Estimates population characteristicsRefer back 533 Week 2 age structure; Week 7 interpreting age structure","code":""},{"path":"week9.html","id":"easier-regular-expressions-with-rverbalexpressions","chapter":"9 Week 9","heading":"9.10 Easier regular expressions with RVerbalExpressions","text":"Regular expressions powerful take time trial--error master. RVerbalExpresions package can used easily generate regular expressions. See help rx() associated functions.examples show two constructions regular expressions matching two similar different URLs.","code":"\nlibrary(RVerbalExpressions)\n# a pattern\nx <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_maybe(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(x)## [1] \"^(http)(s)?(\\\\://)(www\\\\.)?([^ ]*)$\"\n# search for a pattern in some URLs\nurls <- c(\n    \"http://www.google.com\",\n    \"http://staff.washington.edu/phurvitz/csde502_winter_2021/\"\n)\ngrepl(pattern = x, x = urls)## [1] TRUE TRUE\n# a different pattern\ny <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_find(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(y)## [1] \"^(http)(s)?(\\\\://)(www\\\\.)([^ ]*)$\"\n# search for a pattern in the two URLs, matches one, does not match the other\ngrepl(pattern = y, x = urls)## [1]  TRUE FALSE"},{"path":"week9.html","id":"quick-copy-from-excel-windows-only","chapter":"9 Week 9","heading":"9.11 Quick copy from Excel (Windows only)","text":"Windows, possible copy selected cells Excel worksheet directly R. endorsement using Excel, cases Excel may able produce quick data don’t want develop ways.demonstration, can use analysis.xlsx. Download open file. shown selection cells copied.code shows data can copied.","code":"\nxlsclip <- read.table(file = \"clipboard\", sep = \"\\t\", header = TRUE)\n\nxlsclip %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\"\n    )"},{"path":"week9.html","id":"running-system-commands","chapter":"9 Week 9","heading":"9.12 Running system commands","text":"R can run arbitrary system commands normally run terminal command window. system() function used run commands, optionally results returned character vector. Mac Linux, usage quite straightforward, example, list files specific directory:Windows, takes bit extra code. requires prefix cmd /c system() call command . Also backslashes path names need specified double-backslashes R.running programs utilities executed terminal command window, can helpful.","code":"tempdirfiles <- system(\"ls C:\\Temp\\7\\RtmpQTLf3K\", intern = TRUE)\n# R prefers and automatically generates forward slashes\ntmpdir <- dirname(tempdir())\n\n# OS\nos <- .Platform$OS.type\n\n# construct a system command\n# under Windows\nif (os == \"windows\") {\n    # under Windows, path delimiters are backslashes so need to be rendered in R as double backslashes\n    tmpdir %<>% str_replace_all(\"/\", \"\\\\\\\\\")\n    cmd <- sprintf(\"cmd /c dir %s\", tmpdir)\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}\n\n# under *NIX\nif (os == \"unix\") {\n    cmd <- sprintf(\"ls %s\", tmpdir)\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}"},{"path":"week9.html","id":"code-styling","chapter":"9 Week 9","heading":"9.13 Code styling","text":"Good code meet least two functional requirements getting job done able able read. Code gets job done easy read cause problems later try figure something.styler package can help clean code conforms specific style tidyverse style guide. styler can integrated RStudio interactive use. can reformat selected code, entire file, entire project. example shown:lintr also useful identifying potential style errors.","code":""},{"path":"week9.html","id":"session-information","chapter":"9 Week 9","heading":"9.14 Session information","text":"may helpful troubleshooting complete documentation report complete session information. example, sometimes outdated versions packages may contain errors. session information printed sessionInfo().","code":"\nsessionInfo()## R version 4.1.2 (2021-11-01)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows Server x64 (build 17763)\n## \n## Matrix products: default\n## \n## locale:\n## [1] LC_COLLATE=English_United States.1252 \n## [2] LC_CTYPE=English_United States.1252   \n## [3] LC_MONETARY=English_United States.1252\n## [4] LC_NUMERIC=C                          \n## [5] LC_TIME=English_United States.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] RVerbalExpressions_0.1.0 sf_1.0-5                 htmltools_0.5.2         \n##  [4] leaflet_2.0.4.1          tidycensus_1.1           fst_0.9.4               \n##  [7] lubridate_1.8.0          sqldf_0.4-11             RSQLite_2.2.9           \n## [10] gsubfn_0.7               proto_1.0.0              curl_4.3.2              \n## [13] haven_2.4.3              kableExtra_1.3.4         knitr_1.37              \n## [16] magrittr_2.0.1           forcats_0.5.1            stringr_1.4.0           \n## [19] dplyr_1.0.7              purrr_0.3.4              readr_2.0.2             \n## [22] tidyr_1.1.4              tibble_3.1.6             ggplot2_3.3.5           \n## [25] tidyverse_1.3.1         \n## \n## loaded via a namespace (and not attached):\n##  [1] fs_1.5.0           bit64_4.0.5        RColorBrewer_1.1-2 webshot_0.5.2     \n##  [5] httr_1.4.2         tools_4.1.2        backports_1.3.0    bslib_0.3.1       \n##  [9] rgdal_1.5-27       utf8_1.2.2         R6_2.5.1           KernSmooth_2.23-20\n## [13] DBI_1.1.1          colorspace_2.0-2   sp_1.4-6           withr_2.4.3       \n## [17] tidyselect_1.1.1   downlit_0.4.0      bit_4.0.4          compiler_4.1.2    \n## [21] chron_2.3-56       cli_3.1.0          rvest_1.0.2        xml2_1.3.2        \n## [25] bookdown_0.24      sass_0.4.0         scales_1.1.1       classInt_0.4-3    \n## [29] proxy_0.4-26       rappdirs_0.3.3     systemfonts_1.0.3  digest_0.6.28     \n## [33] foreign_0.8-81     rmarkdown_2.11     svglite_2.0.0      pkgconfig_2.0.3   \n## [37] dbplyr_2.1.1       fastmap_1.1.0      highr_0.9          htmlwidgets_1.5.4 \n## [41] rlang_0.4.12       readxl_1.3.1       rstudioapi_0.13    farver_2.1.0      \n## [45] jquerylib_0.1.4    generics_0.1.1     jsonlite_1.7.2     crosstalk_1.2.0   \n## [49] Rcpp_1.0.7         munsell_0.5.0      fansi_0.5.0        lifecycle_1.0.1   \n## [53] stringi_1.7.5      yaml_2.2.1         maptools_1.1-2     grid_4.1.2        \n## [57] blob_1.2.2         parallel_4.1.2     crayon_1.4.2       lattice_0.20-45   \n## [61] hms_1.1.1          pillar_1.6.4       uuid_1.0-2         tcltk_4.1.2       \n## [65] reprex_2.0.1       glue_1.4.2         evaluate_0.14      data.table_1.14.2 \n## [69] modelr_0.1.8       vctrs_0.3.8        tzdb_0.2.0         cellranger_1.1.0  \n## [73] gtable_0.3.0       assertthat_0.2.1   cachem_1.0.6       xfun_0.27         \n## [77] broom_0.7.10       e1071_1.7-9        class_7.3-19       viridisLite_0.4.0 \n## [81] tigris_1.5         memoise_2.0.1      units_0.7-2        ellipsis_0.3.2"},{"path":"week9.html","id":"comment-out-rmdhtml-code","chapter":"9 Week 9","heading":"9.15 Comment out Rmd/HTML code","text":"comment entire parts Rmd appear rendered HTML, use HTML comments, specified delimiters <!-- -->.Rendered 2022-01-08 18:01:43.89709-week09.Rmd","code":"\ncat(readLines(con = \"09-week09.Rmd\"), sep = \"\\n\")# Week 9 {#week9}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(haven)\nlibrary(curl)\nlibrary(ggplot2)\n\n# URL home\nurlhome <- \"\"\n```\n\n<h2>Topic: Miscellaneous data processing <\/h2>\nThis week's lesson will cover a set of miscellaneous data processing topics.\n\nMostly this is a set of coded examples with explanations\n\n## Substituting text\n\n### `paste()`, `paste0()`\n\nPasting text allows you to substitute variables within a text string. For example, if you are running a long loop over a series of files and you want to know which file name and loop iteration you are on. \n\nThe function `paste()` combines a set of strings and adds a space between the strings, e.g., combining the first values from the `LETTERS` and the `letters` built-in vectors:\n\n```{r}\npaste(LETTERS[1], letters[1])\n```\n\nwhereas `paste0` does not add spaces:\n\n```{r}\npaste0(LETTERS[1], letters[1])\n```\n\nThe code below uses the function `tempdir()` to specify a folder that is automatically generated per R session; for this rendering of the book, the location was `r tempdir()` but will almost certainly be different for your session. The code downloads and unzips the file [quickfox](files/quickfox.zip) to the `tempdir()` location. The zip file contains a separate file for each word in the phrase \"the quick brown fox jumps over the lazy dog\". The code then uses a loop and `paste()` to show the contents of each separate file along with its file name.\n\n```{r}\n# zip file\nzipfile <- file.path(tempdir(), \"quickfox.zip\")\n\n# download\ncurl_download(url = \"http://staff.washington.edu/phurvitz/csde502_winter_2021/files/quickfox.zip\", destfile = zipfile)\n\n# unzip\nunzip(zipfile = zipfile, overwrite = TRUE, exdir = tempdir())\n\n# files in the zip file\nfnames <- unzip(zipfile = file.path(tempdir(), \"quickfox.zip\"), list = TRUE) %>%\n    pull(Name) %>%\n    file.path(tempdir(), .)\n\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name with a forward slash\n    fname <- fnames[i] %>% normalizePath(winslash = \"/\")\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()`\n    mystr <- paste(mytext, \"    \", i, \"of\", length(fnames), fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    message(mystr)\n}\n```\n\n\n### `sprintf()`\n`sprintf()` can be used to format text. Here are just a few examples. The result is a formatted text string.\n\n#### Formatting numerical values\n<u>Leading zeros<\/u>\n\nNumeric values can be formatted with a specific number of decimal places or leading zeros. For example, ZIP codes imported from CSV files often are converted to integers. The following code chunk converts some numerical ZIP code-like values to text values with the correct format.\n\nBad ZIP codes:\n```{r}\n# some numerical ZIP codes\n(zip_bad <- data.frame(id = 1:3, zipcode = c(90201, 02134, 00501)))\n```\n\nGood ZIP codes:\n```{r}\n# fix them up\n(zip_good <- zip_bad %>% mutate(\n    zipcode = sprintf(\"%05d\", zipcode)\n))\n```\n\n<u>Decimal places<\/u>\n\nNumerical values with different numbers of decimal places can be rendered with a specific number of decimal places. \n\n```{r}\n# numbers with a variety of decimal places\nv <- c(1.2, 2.345, 1e+5 + 00005)\n\n# four fixed decimal places\nv %>% sprintf(\"%0.4f\", .)\n```\n\nNote that this is distinct from `round()`, which results in a numeric vector:\n\n```{r}\n# round to 4 places\nv %>% round(., 4)\n```\n\n#### String substitutions\n`sprintf()` can also be used to achieve the same substitution in the file reading loop above. Each `%s` is substituted in order of the position of the arguments following the string. Also note that `\\t` inserts a `TAB` character.\n\n```{r}\n# read each file\nfor (i in seq_len(length(fnames))) {\n    # the file name\n    fname <- fnames[i]\n    # read the file\n    mytext <- scan(file = fname, what = \"character\", quiet = TRUE)\n\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # make a string using `paste()`\n    mystr <- sprintf(\"%s\\t%s of %s:\\t%s\", mytext, i, length(fnames), fname)\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # print the message\n    cat(mystr)\n}\n```\n\n### `str_replace()`, `str_replace_all()`\nThe `stringr` functions `str_replace()` and `str_replace_all()` can be used to substitute specific strings in other strings. For example, we might create a generic function to run over a set of subject IDs that generates a file for each subject.\n\n```{r}\nsubjects <- c(\"a1\", \"b2\", \"c3\")\n\nf <- function(id) {\n    # create an output file name by substituting in the subject ID\n    outfname <- file.path(tempdir(), \"xIDx.csv\") %>% str_replace(pattern = \"xIDx\", id)\n    # ... do a bunch of stuff, for example\n    val <- rnorm(1)\n    # write the file\n    message(paste0(\"writing\"))\n    write.csv(x = val, file = outfname)\n}\n\nfor (i in subjects) {\n    f(i)\n}\n```\n\n## Showing progress\nA text-based progress bar can be shown using `txtProgressBar()`. Here we run the same loop for reading the text files, but rather than printing the loop iteration and file names, we show the progress bar and the file contents. If no text is printed to the console (unlike what is demonstrated below with `cat()`), the progress bar will not print on several lines.\n\n```{r}\nn_fnames <- length(fnames)\n# create progress bar\npb <- txtProgressBar(min = 0, max = n_fnames, style = 3)\nfor (i in 1:n_fnames) {\n    # delay a bit\n    Sys.sleep(0.1)\n    # update progress bar\n    setTxtProgressBar(pb, i)\n    # read and print from the file\n    txt <- scan(fnames[i], what = \"character\", quiet = TRUE)\n    cat(\"\\n\", txt, \"\\n\")\n}\nclose(pb)\n```\n\n## Turning text into code: `eval(parse(text = \"some string\"))`\nSometimes you may have variables whose values that you want to use in a command or function. For example, suppose you wanted to write a set of files, one for each ZIP code in a data frame, with a file name including the ZIP code. We would not want to use the column name `zipcode`, but we want the actual value. \n\nWe can generate a command using some kind of text substitution as above with `sprintf()`\n\n```{r}\nfor (i in zip_good %>% pull(zipcode)) {\n    # do some stuff\n    vals <- rnorm(n = 3)\n    y <- bind_cols(zipcode = i, v = vals)\n    # a writing command using sprintf() to substitute %s = ZIP code\n    cmd <- sprintf(\"write.csv(x = y, file = file.path(tempdir(), '%s.csv'), row.names = FALSE)\", i)\n\n    # this runs the command\n    eval(parse(text = cmd))\n}\n```\n\n## SQL in R with `RSQLite` and `sqldf`\nSometimes R's syntax for processing data can be difficult and confusing. For programmers who are familiar with structured query language (SQL), it is possible to run SQL statements within R using a supported database back end (by default SQLite) and the `sqldf()` function.\n\nFor example, the mean sepal length by species from the built-in `iris` data set can be obtained, presented in Table \\@ref(tab:iris)\n\n```{r iris}\nlibrary(sqldf)\n\nsqlc <- 'select\n    \"Species\" as species\n    , avg(\"Sepal.Length\") as mean_sepal_length\nfrom iris\ngroup by \"Species\";\n'\n\niris_summary <- sqldf(x = sqlc)\n\niris_summary %>%\n    kable(caption = \"Mean sepal length from the iris data set\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n\n\n\n## Downloading files from password-protected web sites\nSome web sites are protected by simple username/password protection. For example, try opening [http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected] (http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected). The username/password pair is csde/502, which will allow you to see the contents of the web folder.\n\nIf you try downloading the file through R, you will get an error because no password is supplied.\n\n```{r}\ntry(\n    read.csv(\"http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)\n```\n\nHowever, the username and password can be supplied as part of the URL, as below. When the username and password are supplied, they will be cached for that site for the duration of the R session.\n\n```{r}\ntry(\n    read.csv(\"http://csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv\")\n)\n```\n\n\n## Dates and time stamps: `POSIXct` and `lubridate`\nR uses POSIX-style time stamps, which are stored internally as the number of fractional seconds from January 1, 1970. It is imperative that the control over time stamps is commensurate with the temporal accuracy and precision  your data. For example, in the measurement of years of residence, precision is not substantially important. For measurement of chemical reactions, fractional seconds may be very important. For applications such as merging body-worn sensor data from GPS units and accelerometers for estimating where and when physical activity occurs, minutes of error can result in statistically significant mis-estimations.\n\nFor example, you can see the numeric value of these seconds as `options(digits = 22); Sys.time() %>% as.numeric()`.\n\n```{r}\noptions(digits = 22)\nSys.time() %>% as.numeric()\n```\n\nIf you have time stamps in text format, they can be converted to POSIX time stamps, e.g., the supposed time Neil Armstrong stepped on the moon:\n\n```{r}\n(eagle <- as.POSIXct(x = \"7/20/69 10:56 PM\", tz = \"CST6CDT\", format = \"%m/%d/%y %H:%M\"))\n```\n\nFormats can be specified using specific codes, see `strptime()`.\n\nThe `lubridate` package has a large number of functions for handling date and time stamps. For example, if you want to convert a time stamp in the current time zone to a different time zone, first we get the current time\n\n```{r}\nlibrary(lubridate)\n# set the option for fractional seconds\noptions(digits.secs = 3)\n(now <- Sys.time() %>% strptime(\"%Y-%m-%d %H:%M:%OS\"))\n```\n\nAnd convert to UTC:\n\n```{r}\n# show this at time zone UTC\n(with_tz(time = now, tzone = \"UTC\"))\n```\n\nor show in a different format:\n\n```{r}\n# in different format\nnow %>% format(\"%A, %B %d, %Y %l:%m %p %Z\")\n```\n\n```{r, echo=FALSE}\n# reset the digits\noptions(digits = 7)\n```\n\n## Timing with `Sys.time()` and `difftime()`\nIt is easy to determine how long a process takes by using sequential `Sys.time()` calls, one before and one after the process, and getting the difference with `difftime()`. For example, \n\n```{r}\n# mark time and run a process\nt0 <- Sys.time()\nSys.sleep(5)\nt1 <- Sys.time()\n\n# difftime() unqualified will make its best decision about what to print\n(difftime(time1 = t1, time2 = t0))\n\n# time between moon step and now-ish\n(difftime(time1 = t0, time2 = eagle))\n```\n\n`difftime()` can also be forced to report the time difference in the units of choice:\n\n```{r}\n(difftime(time1 = t1, time2 = t0, units = \"secs\") %>% as.numeric()) %>% round(0)\n(difftime(time1 = t1, time2 = t0, units = \"mins\") %>% as.numeric()) %>% round(2)\n(difftime(time1 = t1, time2 = t0, units = \"hours\") %>% as.numeric()) %>% round(4)\n(difftime(time1 = t1, time2 = t0, units = \"days\") %>% as.numeric()) %>% round(6)\n```\n\n## Faster files with `fst()`\nThe `fst` package is great for rapid reading and writing of data frames. The format can also result in much smaller file sizes using compression. Here we will examine the large Add Health file. First, a download, unzip, and read as necessary:\n\n```{r}\nlibrary(fst)\nmyUrl <- \"http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip\"\n# zip file in $temp\nzipfile <- file.path(tempdir(), basename(myUrl))\n# download\ncurl_download(url = myUrl, destfile = zipfile)\n# dta file in $temp\ndtafname <- tools::file_path_sans_ext(zipfile)\n# check if the dta file exists\nif (!file.exists(dtafname)) {\n    # if the dta file doesn't exist, check for the zip file\n    # check if the zip file exists, download if necessary\n    if (!file.exists(zipfile)) {\n        curl::curl_download(url = myUrl, destfile = zipfile)\n    }\n    # unzip the downloaded zip file\n    unzip(zipfile = zipfile, exdir = tempdir())\n}\n\n# read the file\ndat <- read_dta(dtafname)\n\n# save as a CSV, along with timing\nt0 <- Sys.time()\ncsvfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"csv\")\nwrite.csv(x = dat, file = csvfname, row.names = FALSE)\nt1 <- Sys.time()\ncsvwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)\n\n# file size\ncsvsize <- file.info(csvfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\n\n# save as FST, along with timing\nt0 <- Sys.time()\nfstfname <- dtafname %>% str_replace(pattern = \"dta\", replacement = \"fst\")\nwrite.fst(x = dat, path = fstfname)\nt1 <- Sys.time()\n\n# file size\nfstsize <- file.info(fstfname) %>%\n    pull(size) %>%\n    sprintf(\"%0.f\", .)\nfstwrite_time <- difftime(time1 = t1, time2 = t0, units = \"secs\") %>%\n    as.numeric() %>%\n    round(1)\n```\n\nIt took `r csvwrite_time` s to write `r csvsize` bytes as CSV, and `r fstwrite_time` s to write `r fstsize` bytes as a FST file (with the default compression amount of 50). Reading speeds are comparable.\n\n___It should be noted___ that some file attributes will not be saved in FST format and therefore it should be used with caution if you have a highly attributed data set (e.g., a Stata DTA file with extensive labeling). You will lose those attributes! But for data sets with a simple structure, including factors, the FST format is a good option.\n\n## Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready Data Frames: `tigris`, `tidycensus`\nDealing with US Census data can be overwhelming, particularly if using the raw text-based data. The Census Bureau has an API that allows more streamlined downloads of variables (as data frames) and geographies (as simple format shapes). It is necessary to get an API key, available for free. See [tidycensus](https://walker-data.com/tidycensus/) and  [tidycensus basic usage](https://walker-data.com/tidycensus/articles/basic-usage.html).\n\n`tidycensus` uses [`tigris`](https://www.rdocumentation.org/packages/tigris/versions/1.0), which downloads the geographic data portion of the census files.\n\n### Download data\nA simple example will download the variables representing the count of White, Black/African American, American Indian/Native American, and Asian persons from the American Community Survey (ACS) data for King County in 2019. For this example to run, you need to have your US Census API key installed, e.g., \n\n<tt>\ntidycensus::census_api_key(\"*****************\", install = TRUE)<br>\n<font color=\"red\">\nYour API key has been stored in your .Renviron and can be accessed by Sys.getenv(\"CENSUS_API_KEY\").<br>\nTo use now, restart R or run `readRenviron(\"~/.Renviron\")`\n<\/font>\n<\/tt>\n\nThe labels from the census API are:\n\n```\n\"Estimate!!Total\"                                         \n\"Estimate!!Total!!White alone\"                            \n\"Estimate!!Total!!Black or African American alone\"        \n\"Estimate!!Total!!American Indian and Alaska Native alone\"\n\"Estimate!!Total!!Asian alone\" \n```\n\n```{r, warning=FALSE}\nlibrary(tidycensus)\n# the census variables\ncensus_vars <- c(\n    p_denom_race = \"B02001_001\",\n    p_n_white = \"B02001_002\",\n    p_n_afram = \"B02001_003\",\n    p_n_aian = \"B02001_004\",\n    p_n_asian = \"B02001_005\"\n)\n\n# get the data\nctdat <- get_acs(\n    geography = \"tract\",\n    variables = census_vars,\n    cache_table = TRUE,\n    year = 2019,\n    output = \"wide\",\n    state = \"WA\",\n    county = \"King\",\n    geometry = TRUE,\n    survey = \"acs5\"\n)\n```\n\nA few values are shown in Table \\@ref(tab:census)\n\n```{r census}\n# print a few records\nctdat %>%\n    head() %>%\n    kable(caption = \"Selected census tract variables from the 5-year ACS from 2019 for King County, WA\") %>%\n    kable_styling(full_width = FALSE, position = \"left\")\n```\n\n### Mapping census data \nA `leaflet` simple map is shown in \\@ref(fig:ct), with percent African American residents and tract identifier.\n\n```{r ct, fig.cap=\"Percent African American in census tracts in King County, 2019 ACS 5-year estimate\", warning=FALSE, message=FALSE}\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(sf)\n\n# define the CRS\nst_crs(ctdat) <- 4326\n\n# proportion Black\nctdat %<>%\n    mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %>% round(1))\n\n# a label\nlabels <- sprintf(\"%s<br/>%s%s\", ctdat$GEOID, ctdat$pct_black, \"%\") %>% lapply(htmltools::HTML)\n\nbins <- 0:50\npal <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins\n)\n\nbins2 <- seq(0, 50, by = 10)\npal2 <- colorBin(\n    palette = \"Reds\",\n    domain = ctdat$pct_black,\n    bins = bins2\n)\n\n# the leaflet map\nm <- leaflet(height = \"500px\") %>%\n    # add polygons from tracts\n    addPolygons(\n        data = ctdat,\n        weight = 1,\n        fillOpacity = 0.8,\n        # fill using the palette\n        fillColor = ~ pal(pct_black),\n        # highlighting\n        highlight = highlightOptions(\n            weight = 5,\n            color = \"#666\",\n            fillOpacity = 0.7,\n            bringToFront = TRUE\n        ),\n        # popup labels\n        label = labels,\n        labelOptions = labelOptions(\n            style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n            textsize = \"15px\",\n            direction = \"auto\"\n        )\n    ) %>%\n    # legend\n    addLegend(\n        position = \"bottomright\", pal = pal2, values = ctdat$pct_black,\n        title = \"% African American\",\n        opacity = 1\n    )\nm %>% addTiles()\n```\n\n### Creating population pyramids from census data\nSee [Estimates of population characteristics](https://walker-data.com/tidycensus/articles/other-datasets.html#estimates-of-population-characteristics-1)\n\nRefer back to 533 Week 2 age structure; Week 7 interpreting age structure\n\n\n\n\n## Easier regular expressions with `RVerbalExpressions`\nRegular expressions are powerful but take some time and trial-and-error to master. The `RVerbalExpresions` package can be used to more easily generate regular expressions. See the help for `rx()` and associated functions.\n\nThese examples show two constructions of regular expressions for matching two similar but different URLs.\n\n```{r}\nlibrary(RVerbalExpressions)\n# a pattern\nx <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_maybe(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(x)\n\n# search for a pattern in some URLs\nurls <- c(\n    \"http://www.google.com\",\n    \"http://staff.washington.edu/phurvitz/csde502_winter_2021/\"\n)\ngrepl(pattern = x, x = urls)\n\n\n# a different pattern\ny <- rx_start_of_line() %>%\n    rx_find(\"http\") %>%\n    rx_maybe(\"s\") %>%\n    rx_find(\"://\") %>%\n    rx_find(\"www.\") %>%\n    rx_anything_but(\" \") %>%\n    rx_end_of_line()\n\n# print the expression\n(y)\n\n# search for a pattern in the two URLs, matches one, does not match the other\ngrepl(pattern = y, x = urls)\n```\n\n## Quick copy from Excel (Windows only)\nUnder Windows, it is possible to copy selected cells from an Excel worksheet directly to R. This is not an endorsement for using Excel, but there are some cases in which Excel may be able to produce some quick data that you don't want to develop in other ways.\n\nAs a demonstration, you can use [analysis.xlsx](files/words_analysis.xlsx). Download and open the file. Here is shown a selection of cells that was copied. \n\n![](images/week09/excel.png)\n\nThe code below shows how the data can be copied.\n\n```{r, echo=FALSE}\nxlsclip <- fst::read.fst(\"files/xlsclip.fst\")\n```\n\n```{r, eval=FALSE}\nxlsclip <- read.table(file = \"clipboard\", sep = \"\\t\", header = TRUE)\n\nxlsclip %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\"\n    )\n```\n\n```{r, echo=FALSE}\nxlsclip %>%\n    kable() %>%\n    kable_styling(\n        full_width = FALSE,\n        position = \"left\"\n    )\n```\n\n## Running system commands\nR can run arbitrary system commands that you would normally run in a terminal or command window. The `system()` function is used to run commands, optionally with the results returned as a character vector. Under Mac and Linux, the usage is quite straightforward, for example, to list files in a specific directory:\n\n```\ntempdirfiles <- system(\"ls `r tempdir()`\", intern = TRUE)\n```\n\nUnder Windows, it takes a bit of extra code. To do the same requires the prefix `cmd /c` in the `system()` call before the command itself. Also any backslashes in path names need to be specified as double-backslashes for R.\n\n```{r}\n# R prefers and automatically generates forward slashes\ntmpdir <- dirname(tempdir())\n\n# OS\nos <- .Platform$OS.type\n\n# construct a system command\n# under Windows\nif (os == \"windows\") {\n    # under Windows, path delimiters are backslashes so need to be rendered in R as double backslashes\n    tmpdir %<>% str_replace_all(\"/\", \"\\\\\\\\\")\n    cmd <- sprintf(\"cmd /c dir %s\", tmpdir)\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}\n\n# under *NIX\nif (os == \"unix\") {\n    cmd <- sprintf(\"ls %s\", tmpdir)\n    tempdirfiles <- system(command = cmd, intern = TRUE)\n}\n```\n\nIf you are running other programs or utilities that are executed in a terminal or command window, this can be very helpful.\n\n## Code styling\nGood code should meet at least the two functional requirements of getting the job done and being able able to read. Code that gets the job done but that is not easy to read will cause problems later when you try to figure out how or why you did something.\n\nThe [`styler`](https://github.com/r-lib/styler) package can help clean up your code so that it conforms to a specific style such as that in the [tidyverse style guide](https://style.tidyverse.org/). `styler` can be integrated into RStudio for interactive use. It can reformat selected code, an entire file, or an entire project. An example is shown:\n\n![](images/week09/styler_0.1.gif)\n\n[`lintr`](https://github.com/jimhester/lintr) is also useful for identifying potential style errors.\n\n## Session information\nIt may be helpful in troubleshooting or complete documentation to report the complete session information. For example, sometimes outdated versions of packages may contain errors. The session information is printed with `sessionInfo()`.\n\n```{r}\nsessionInfo()\n```\n\n## Comment out Rmd/HTML code\nTo comment out entire parts of your Rmd so they do not appear in your rendered HTML, use HTML comments, which are specified with the delimiters `<!--` and `-->`.\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[09-week09.Rmd](09-week09.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"09-week09.Rmd\"), sep = \"\\n\")\n```"},{"path":"week10.html","id":"week10","chapter":"10 Week 10","heading":"10 Week 10","text":"week’s lesson cover additional R odds ends.","code":""},{"path":"week10.html","id":"r-markdown-to-microsoft-word","chapter":"10 Week 10","heading":"10.1 R Markdown to Microsoft Word","text":"Microsoft Word (“Word”), used widely document research. advanced word processing “track changes” capabilities, commonly used preparation manuscripts. Using R generate output Word often tedious process (e.g., create CSV files \\(\\rightarrow\\) paste contents \\(\\rightarrow\\) convert table; export R graphics png() ggsave() \\(\\rightarrow\\) insert file).RMarkdown can used generate Word documents. thought one-way operation. say, team works manuscript using Word, typical work flow lead author creates first draft. authors make changes document using tracked changes. manuscript circulates authors, lead author decides changes accept reject, resulting new version. process continues group authors agrees manuscript ready publication.Unfortunately backwards path take existing Word docx regenerate Rmd (e.g., colleagues made lot changes Word docx). Nevertheless using method save “busy work” time Word, well provide common stylistic template R outputs generating Word documents.export Word document, following work flow followed:Create bare-bones Rmd file contains elements want output, little actual content.Render Rmd file Word docx file.Open docx file Word make stylistic changes using Word styles (see workshop Microsoft Word Social Sciences)Use style-edited docx file template Rmd file.Write complete Rmd file content want placed Word docx file render. output docx file stylistic configuration template docx.detailed work flow:use Word output, first make minimal RMarkdown document Word output.Save Rmd file knit Word.output document elements Rmd file.important part Word document number styles. Make changes styles margins. become template output containing actual scientific content. add, remove, rename styles document! Save copy document stylistic changes.example, changes header styles:Presumably, styles output docx can modified:made changes, save file “template”:YAML header Rmd file scientific content, construction, specify path name template document.Rmd file rendered Word document, stylistic changes applied output. example, just changing head matter previous document re-rendering shows heading styles applied defined.Although overall functionality somewhat limited, Rmd code generates scientific content, want output Word document predefined formats, save busy work reformatting.","code":"output:\n  word_document:  \n    reference_docx: \"template.docx\""},{"path":"week10.html","id":"r-markdown-output","chapter":"10 Week 10","heading":"10.2 R Markdown output","text":"two different basic output formats available, document presentation. writing, list specific output types includes:beamer_presentationcontext_documentgithub_documenthtml_documentioslides_presentationlatex_documentmd_documentodt_documentpdf_documentpowerpoint_presentationrtf_documentslidy_presentationword_documentVarious packages can also specify output types, e.g., bookdown::html_document2 `tufte::tufte_html.","code":""},{"path":"week10.html","id":"r-markdown-rendering-to-specific-formats","chapter":"10 Week 10","heading":"10.2.1 R Markdown rendering to specific formats","text":"Rendering R Markdown files done R console using rmarkdown::render() function, e.g.,clicking Knit control RSTudio.YAML header specifies multiple output formats, first listed format used output options specified render() function call. example, header, default output format bookdown::html_document2The RStudio interface present listed choices Knit pick list GUI, desired output format can selected interactively:supported outputs can created, including listed YAML header specifying output format render() function, e.g. create Slidy presentation:render PDF file, use e.g.,Using code rather RStudio GUI allows flexible automation; R script runs render() function part multi-step workflow. example, continuous data collection process, work flow coded run cron generate new PDF (file type) file daily basis.","code":"rmarkdown::render(input = \"input_filename.Rmd\")---\ntitle: \"A Document\"\nauthor: \"Jane Doe\"\ndate: \"2021-01-23\"\noutput: \n    bookdown::html_document2: default\n    pdf_document: default\n    html_document: default\n    word_document: default\n---rmarkdown::render(input = \"input_filename.Rmd\", output_format = \"slidy_presentation\")rmarkdown::render(input = \"input_filename.Rmd\", output_format = \"pdf_document\")"},{"path":"week10.html","id":"testing-output_type","chapter":"10 Week 10","heading":"10.2.2 Testing output_type()","text":"different output formats support (support) different features, test can made output format determine code run, using is_html_output() is_latex_output(). R code within Rmd file can run run based tests. working example, download render file output_type_test. Using single source, output rendered HTML appears aswhereas PDF output rendered asThere appears similar test MS Word output, creating Word documents Rmd files, suggested create Rmd scratch intention creating Word output.","code":""},{"path":"week10.html","id":"advantages-and-disadvantages-of-pdf","chapter":"10 Week 10","heading":"10.3 Advantages and disadvantages of PDF","text":"Portable document format (PDF) number advantages:Document formatting maintained. Font face positioning elements consistent. formats shared (e.g., MS Word), formatting inconsistent.format widely used able created variety different proprietary open software applications.Files often parsimonious size. large images embedded, file sizes can grow, often options -sampling images smaller file size.Files can protected passwords.Files supported across operating systems (Windows, Mac, Linux, UNIX).Multiple different elements can included (text, images, tables).format stood test time, introduced 1993. standard opened 2008, allowing developers create PDF outputs. led PDF standard fixed-format documents.disadvantages:\n1. Direct editing PDF files straightforward (usually requires dedicated software), often results undesired layout changes. Therefore good format collaborative editing.\n1. Copy--paste PDF often results missing extra spaces strange characters.\n1. R functions produce HTML output used PDF outputs.","code":""},{"path":"week10.html","id":"bibliography-in-r-markdown","chapter":"10 Week 10","heading":"10.4 Bibliography in R Markdown","text":"pandoc engine performs document conversion can generate bibliographies. See Bibliographies Citations detailed information.exercise, using \\({B\\kern-0.1emi\\kern-0.017emb}\\kern-0.15em\\TeX\\) formatted references.YAML header needs formatted include bibliography file, either complete path name located directory Rmd file. Similarly, CSL (Citation Style Language) file specified. CSL files can obtained Zotero Style RepositoryThe YAML header include something form:citations made references, corresponding record automatically added end document.examples syntax APA-like AMA-like references bibliographies, see filesAPA: HTML; RmdAMA: HTML; RmdRendered 2022-01-08 18:01:4710-week10.Rmd","code":"---\ntitle: \"My glorious, shiny dissertation\"\noutput: \n    bookdown::html_document2\nbibliography: myreferences_20200121.bib\ncsl: biomed-central.csl\n---\ncat(readLines(con = \"10-week10.Rmd\"), sep = \"\\n\")Warning in readLines(con = \"10-week10.Rmd\"): incomplete final line found on '10-\nweek10.Rmd'# Week 10 {#week10}\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(haven)\nlibrary(curl)\nlibrary(ggplot2)\n\n# URL home\nurlhome <- \"\"\n```\n\n<h2>Topic:Odds and ends<\/h2>\nThis week's lesson will cover a additional R odds and ends.\n\n## R Markdown to Microsoft Word\nMicrosoft Word (\"Word\"), is used widely to document research. Because of its advanced word processing and \"track changes\" capabilities, it is commonly used for preparation of manuscripts. Using R to generate output for Word is often a tedious process (e.g., create CSV files $\\rightarrow$ paste the contents $\\rightarrow$ convert to table; export R graphics with `png()` or `ggsave()` $\\rightarrow$ insert the file).  \n\nRMarkdown can be used to generate Word documents. This should be thought of as a one-way operation. That is to say, when a team works on a manuscript using Word, the typical work flow is that the lead author creates the first draft. Other authors make changes to the document using tracked changes. When the manuscript circulates over all authors, the lead author decides which changes to accept and which to reject, resulting in a new version. The process continues until the group of authors agrees that the manuscript is ready for publication.\n\nUnfortunately there is no backwards path to take an existing Word docx and regenerate an Rmd (e.g., after you and your colleagues made a lot of changes to the Word docx). Nevertheless using this method could save you some \"busy work\" time in Word, as well as to provide a common stylistic template for your R outputs if you will be generating Word documents.\n\nTo export to a Word document, the following work flow should be followed:\n\n1. Create a bare-bones Rmd file that contains all of the elements you want in your output, but little actual content.\n1. Render the Rmd file to a Word docx file.\n1. Open the docx file in Word and make any stylistic changes __using Word styles__ (see the workshop  [Microsoft Word for the Social Sciences](https://csde.washington.edu/workshop/microsoft-word-for-the-social-sciences/))\n1. Use the style-edited docx file as a template in the Rmd file.\n1. Write your complete Rmd file with the content you want to have placed in the Word docx file and then render. The output docx file will have the same stylistic configuration as the template docx.\n\nA more detailed work flow:\n\nTo use Word output, first make a minimal RMarkdown document with Word output. \n\n![](images/week03/20200419_233754-C__Users_phurvitz_nextcloud_uw_csde_courses_msword_soc_sci_-_RStudio.png) \n\nSave the Rmd file and knit to to Word.\n\n![](images/week03/20200419_233851-Window.png) \n\nThe output document will have the elements from the Rmd file.\n\n![](images/week03/20200419_234510-minimal.docx_[Read-Only]_[Compatibility_Mode]_-_Word.png) \n\nThe important part of this is that the Word document will have a number of styles. Make any changes to the styles or margins. This will become the template for the output containing the actual scientific content. ___Do not add, remove, or rename any styles in this document!___ Save a copy of the document with any stylistic changes. \n\nFor example, here are some changes to the header styles:\n\n![](images/week03/20200420_002233-Window.png) \n\nPresumably, all of the styles in the output docx can be modified:\n\n![](images/week03/20210121_020407-Window.png)\n\nAfter you have made any changes, save the file as a \"template\":\n\n![](images/week03/20200419_235426-Save_As.png)\n\nIn the YAML header of the Rmd file with your scientific content, this construction, in which you specify the path name to the template document.\n\n```\noutput:\n  word_document:  \n    reference_docx: \"template.docx\"\n```\n\nWhen the Rmd file is rendered to a Word document, the stylistic changes will be applied to the output. For example, just changing the head matter of the previous document and re-rendering shows that the heading styles were applied as defined.\n\n![](images/week03/20200420_002536-minimal.docx_[Read-Only]_[Compatibility_Mode]_-_Word.png)\n\nAlthough this overall functionality is somewhat limited, if you do have some Rmd code that generates some scientific content, and you want to output to a Word document with predefined formats, this will save you some busy work of reformatting.\n\n## R Markdown output \nThere are two different basic output formats available, document and presentation. As of this writing, the list of specific output types includes:\n\n* `beamer_presentation`\n* `context_document`\n* `github_document`\n* `html_document`\n* `ioslides_presentation`\n* `latex_document`\n* `md_document`\n* `odt_document`\n* `pdf_document`\n* `powerpoint_presentation`\n* `rtf_document`\n* `slidy_presentation`\n* `word_document`\n\nVarious packages can also specify their own output types, e.g., `bookdown::html_document2` or `tufte::tufte_html.\n\n### R Markdown rendering to specific formats\nRendering R Markdown files is done at the R console using the `rmarkdown::render()` function, e.g., \n\n```\nrmarkdown::render(input = \"input_filename.Rmd\")\n```\n\nor by clicking the `Knit` control in RSTudio.\n\nIf the YAML header specifies multiple output formats, the first listed format will be used for the output if  other options are not specified in the `render()` function call. For example, for this header, the default output format is `bookdown::html_document2`\n\n```\n---\ntitle: \"A Document\"\nauthor: \"Jane Doe\"\ndate: \"2021-01-23\"\noutput: \n    bookdown::html_document2: default\n    pdf_document: default\n    html_document: default\n    word_document: default\n---\n```\n\nThe RStudio interface will present the listed choices in the `Knit` pick list in the GUI, so the desired output format can be selected interactively:\n\n<img src=\"../images/week03/20210124_010442-C__Users_phurvitz_OneDrive_uw_courses_csde502_csde502_winter_2021_course - RStud.png\" class=\"border1\">\n\nOther supported outputs can be created, including those that are not listed in the YAML header by specifying the output format in the `render()` function, e.g. to create a [Slidy](https://www.w3.org/Talks/Tools/Slidy2/#(1)) presentation: \n\n```\nrmarkdown::render(input = \"input_filename.Rmd\", output_format = \"slidy_presentation\")\n```\n\nTo render a PDF file, use e.g., \n\n```\nrmarkdown::render(input = \"input_filename.Rmd\", output_format = \"pdf_document\")\n```\n\nUsing code rather than the RStudio GUI allows more flexible automation; you could have an R script that runs the `render()` function as part of a multi-step workflow. For example, if you had a continuous data collection process, the work flow could be coded and run with [cron](https://www.rdocumentation.org/packages/cronR) to generate a new PDF (or other file type) file on a daily basis.\n\n### Testing `output_type()`\nBecause different output formats support (or do not support) different features, a test can be made for the output format to determine which code to run, using `is_html_output()` and `is_latex_output()`. Any R code within the Rmd file can be run or not run based on these tests. For a working example, download and render the file [output_type_test](files/output_type_test.Rmd). Using a single source, the [output rendered as HTML](files/output_type_test.html) appears as\n\n![](images/week03/20210124_190945-R Markdown Output Type Test - Work - MicrosoftEdge.png)\n\nwhereas the [PDF output](files/output_type_test.pdf) is rendered as\n\n![](images/week03/20210124_191706-output_type_test.pdf - [R Markdown Output Type Test] - SumatraPDF.png)\n\nThere appears to be no similar test for MS Word output, so for creating Word documents from Rmd files, it is suggested to create the Rmd from scratch with the intention of creating only Word output.\n\n## Advantages and disadvantages of PDF\nPortable document format (PDF) has a number of advantages:\n\n1. Document formatting is maintained. Font face and positioning of elements is consistent. When some other formats are shared (e.g., MS Word), formatting is inconsistent. \n1. The format is widely used and able to be created from a variety of different proprietary and open software applications.\n1. Files are often parsimonious in size. When large images are embedded, the file sizes can grow, but there are often options for down-sampling images for smaller file size.\n1. Files can be protected with passwords.\n1. Files are supported across all operating systems (Windows, Mac, Linux, UNIX).\n1. Multiple different elements can be included (text, images, tables).\n1. The format has stood the test of time, having been introduced 1993. The standard was opened in 2008, allowing developers to create PDF outputs. This has led to PDF being the standard for fixed-format documents. \n\nThe disadvantages:\n1. Direct editing of PDF files is not straightforward (usually requires dedicated software), and often results in undesired layout changes. Therefore this is not a good format for collaborative editing.\n1. Copy-and-paste from PDF often results in missing or extra spaces or strange characters.\n1. R functions that produce HTML output cannot be used in PDF outputs.\n\n## Bibliography in R Markdown\nThe `pandoc` engine that performs document conversion can generate bibliographies. See [Bibliographies and Citations](https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html) for detailed information.\n\nFor this exercise, we will be using ${B\\kern-0.1emi\\kern-0.017emb}\\kern-0.15em\\TeX$ formatted references.\n\nThe YAML header needs to be formatted to include the bibliography file, which should either have a complete path name or be located in the same directory as the Rmd file. Similarly, any CSL (Citation Style Language) file should be specified. CSL files can be obtained from the [Zotero Style Repository\n](https://www.zotero.org/styles)\n\nThe YAML header would include something of the form:\n\n```\n---\ntitle: \"My glorious, shiny dissertation\"\noutput: \n    bookdown::html_document2\nbibliography: myreferences_20200121.bib\ncsl: biomed-central.csl\n---\n```\n\nWhen citations are made to references, the corresponding record will be automatically added to the end of the document.\n\nFor examples of syntax for both APA-like and AMA-like references and bibliographies, see the files \n\n* APA: [HTML](files/bibliography.html); [Rmd](files/bibliography.Rmd)\n* AMA: [HTML](files/bibliography_ama.html); [Rmd](files/bibliography_ama.Rmd)\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[10-week10.Rmd](10-week10.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"10-week10.Rmd\"), sep = \"\\n\")\n```"},{"path":"assignment_files.html","id":"assignment_files","chapter":"11 Assignment support files","heading":"11 Assignment support files","text":"","code":""},{"path":"assignment_files.html","id":"assignment-1","chapter":"11 Assignment support files","heading":"11.1 Assignment 1","text":"file_naming.RmdRendered 2022-01-08 18:01:4811-assignment-files.Rmd-week10.Rmd","code":"\ncat(readLines(con = \"11-assignment-files.Rmd\"), sep = \"\\n\")Warning in readLines(con = \"11-assignment-files.Rmd\"): incomplete final line\nfound on '11-assignment-files.Rmd'# Assignment support files {#assignment_files}\n\n## Assignment 1\n[file_naming.Rmd](files/file_naming.Rmd)\n\n<hr>\nRendered at <tt>`r Sys.time()`<\/tt>\n\n<h4>Source code for this document<\/h4>\n[11-assignment-files.Rmd-week10.Rmd](11-assignment-files.Rmd)\n\n```{r comment=''}\ncat(readLines(con = \"11-assignment-files.Rmd\"), sep = \"\\n\")\n```"}]
